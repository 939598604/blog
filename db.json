{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/3-hexo/source/css/gitalk.css","path":"css/gitalk.css","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/mobile.styl","path":"css/mobile.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/style.styl","path":"css/style.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/img/alipay.jpg","path":"img/alipay.jpg","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/img/article-list-background.jpeg","path":"img/article-list-background.jpeg","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/img/avatar.jpg","path":"img/avatar.jpg","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/img/brown-papersq.png","path":"img/brown-papersq.png","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/img/school-book.png","path":"img/school-book.png","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/js/iconfont.js","path":"js/iconfont.js","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/js/jquery.autocomplete.min.js","path":"js/jquery.autocomplete.min.js","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/js/script.js","path":"js/script.js","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/js/search.js","path":"js/search.js","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/img/weixin.jpg","path":"img/weixin.jpg","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/fonts/icomoon.eot","path":"css/fonts/icomoon.eot","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/fonts/icomoon.svg","path":"css/fonts/icomoon.svg","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/fonts/icomoon.ttf","path":"css/fonts/icomoon.ttf","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/fonts/icomoon.woff","path":"css/fonts/icomoon.woff","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/fonts/iconfont.eot","path":"css/fonts/iconfont.eot","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/fonts/iconfont.ttf","path":"css/fonts/iconfont.ttf","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/fonts/iconfont.svg","path":"css/fonts/iconfont.svg","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/fonts/iconfont.woff","path":"css/fonts/iconfont.woff","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/fonts/selection.json","path":"css/fonts/selection.json","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/atom-dark.styl","path":"css/hl_theme/atom-dark.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/brown-paper.styl","path":"css/hl_theme/brown-paper.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/atom-light.styl","path":"css/hl_theme/atom-light.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/darcula.styl","path":"css/hl_theme/darcula.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/github-gist.styl","path":"css/hl_theme/github-gist.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/github.styl","path":"css/hl_theme/github.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/gruvbox-dark.styl","path":"css/hl_theme/gruvbox-dark.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/gruvbox-light.styl","path":"css/hl_theme/gruvbox-light.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/kimbie-dark.styl","path":"css/hl_theme/kimbie-dark.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/kimbie-light.styl","path":"css/hl_theme/kimbie-light.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/railscasts.styl","path":"css/hl_theme/railscasts.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/rainbow.styl","path":"css/hl_theme/rainbow.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/school-book.styl","path":"css/hl_theme/school-book.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/sublime.styl","path":"css/hl_theme/sublime.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/sunburst.styl","path":"css/hl_theme/sunburst.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/css/hl_theme/zenbum.styl","path":"css/hl_theme/zenbum.styl","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/js/gitment.js","path":"js/gitment.js","modified":0,"renderable":1},{"_id":"themes/3-hexo/source/js/gitalk.js","path":"js/gitalk.js","modified":0,"renderable":1}],"Cache":[{"_id":"themes/3-hexo/.DS_Store","hash":"0770f9d42bfdd8d420de48fed463015e001cf579","modified":1566309402000},{"_id":"themes/3-hexo/.gitignore","hash":"5e85fe97e87211619c1db29fd3f3b0dbf16be4a7","modified":1566309402000},{"_id":"themes/3-hexo/README.md","hash":"6b9e6fedc01b5524d5866a0fbc9991d0a8a0d5a8","modified":1566309402000},{"_id":"themes/3-hexo/_config.yml","hash":"abc60f06ef9b30779ad79c0b112d14fd0f7bb7b5","modified":1567589091897},{"_id":"source/_posts/hexo.md","hash":"829486bd815a61f291ee8c3ee256bbf8922bc96d","modified":1567588702727},{"_id":"source/_posts/hexo一键发布.md","hash":"7647ea34921ee4df46e5b1bcc40c2a92d2085c8d","modified":1567649185281},{"_id":"source/_posts/typora和picgo使用.md","hash":"f1b2dbca61700a80e20e30af3dbe689047c7bf9c","modified":1567581748999},{"_id":"source/_posts/内网穿透frp.md","hash":"a7ae180580669c12400cf87b8b889a5ba85b3659","modified":1567592410457},{"_id":"source/_posts/总-javaEE.md","hash":"eecb271b57609623ee2c8dfbd0f8628463e8ba6f","modified":1567648958038},{"_id":"source/about/index.md","hash":"0fbe748d28781d3411b2a04c80f64028ed8092d3","modified":1567571883031},{"_id":"source/guestbook/index.md","hash":"3e86b49b0469f07840296ffb18e771079e4b60a3","modified":1567578338684},{"_id":"source/guestbook/index2.md","hash":"3e86b49b0469f07840296ffb18e771079e4b60a3","modified":1567578338684},{"_id":"themes/3-hexo/layout/index.ejs","hash":"56fc95610a240e8bfe3d5b611896a819c1eb5dee","modified":1567580515563},{"_id":"themes/3-hexo/layout/indexs.md","hash":"22854d2e9801771ab61cf4adf0b295cb7dfed230","modified":1567578816107},{"_id":"themes/3-hexo/layout/post.ejs","hash":"810f046277fc49f523a72d1552eab1e39d3c299c","modified":1566309402000},{"_id":"themes/3-hexo/source/.DS_Store","hash":"fdcc907c46e093a14b153c5dc8c038461997ed3c","modified":1566309402000},{"_id":"source/_posts/我的activiti学习.md","hash":"f7017c76d13a1df1f843e7ae123b80a7ba0223f8","modified":1567593328111},{"_id":"themes/3-hexo/layout/_partial/article.ejs","hash":"5a81f9959cdf3bd44f5bef515ad284c69630b7c5","modified":1566309402000},{"_id":"themes/3-hexo/layout/_partial/article_copyright.ejs","hash":"1ecfeca2c4e11e424e92cbc1d22430a96bbdfab4","modified":1566309402000},{"_id":"themes/3-hexo/layout/_partial/comment.ejs","hash":"5507b4dfab2032345e012a0c5356f63b01395157","modified":1566309402000},{"_id":"themes/3-hexo/layout/_partial/copyright.ejs","hash":"d209ddcfd0149760a30837076be345a09e1797c5","modified":1566309402000},{"_id":"themes/3-hexo/layout/_partial/dashang.ejs","hash":"266e4b638b71892fdca1f5870e8f2e5d695e0958","modified":1566309402000},{"_id":"themes/3-hexo/layout/_partial/footer.ejs","hash":"919d07d8d06d4843566bca53d843398ee2fae013","modified":1566309402000},{"_id":"themes/3-hexo/layout/_partial/friends.ejs","hash":"7a31274da81c076021692ff7c80a1be3bbf6fa4c","modified":1566309402000},{"_id":"themes/3-hexo/layout/_partial/full-toc.ejs","hash":"7e6c50b6c24de864e0d6a106e6a8e423e312454a","modified":1566309402000},{"_id":"themes/3-hexo/layout/_partial/header.ejs","hash":"30c3ab5847a18db678ffbe3fc6309ec96cb010c0","modified":1566309402000},{"_id":"themes/3-hexo/layout/_partial/mathjax.ejs","hash":"c2e5cef2377884cd79e5f686fe4f74b082744306","modified":1566309402000},{"_id":"themes/3-hexo/layout/_partial/meta.ejs","hash":"4f7e00e37783208cb350842085f1987ee854452e","modified":1566309402000},{"_id":"themes/3-hexo/layout/_partial/nav-left.ejs","hash":"2d36b810293072ce9d7cea82c8a3a987e137b117","modified":1567586467052},{"_id":"themes/3-hexo/layout/_partial/nav-right.ejs","hash":"301837aa3787004f069206440be25db32e3fb087","modified":1566309402000},{"_id":"themes/3-hexo/layout/_partial/tag.ejs","hash":"da40cb48b6b1f24cbd7107f7c97b04f063e9c299","modified":1566309402000},{"_id":"themes/3-hexo/layout/_partial/toc-ref.ejs","hash":"6406251dabda66ef686d4c15edbc3061b6d828b8","modified":1566309402000},{"_id":"themes/3-hexo/source/css/gitalk.css","hash":"58177ce227c50ee359fbf99a4fdd26058887afc5","modified":1566309402000},{"_id":"themes/3-hexo/source/css/mobile.styl","hash":"3934bcba5095e7e6c6b3a801a6e4fa3a35096e10","modified":1566309402000},{"_id":"themes/3-hexo/source/css/style.styl","hash":"c7285882370f522c3bb17055cdf615cf92f48cd0","modified":1566309402000},{"_id":"themes/3-hexo/source/img/alipay.jpg","hash":"e457d1d3dfefbbd824d154cf756a2c6d10b812a2","modified":1566309402000},{"_id":"themes/3-hexo/source/img/article-list-background.jpeg","hash":"4fdf8b3e53dd02d6ee6360aebfadb0cba1fb5633","modified":1566309402000},{"_id":"themes/3-hexo/source/img/avatar.jpg","hash":"a42360089bfa892d803cf5747eab359d90f337f1","modified":1566309402000},{"_id":"themes/3-hexo/source/img/brown-papersq.png","hash":"3a1332ede3a75a3d24f60b6ed69035b72da5e182","modified":1566309402000},{"_id":"themes/3-hexo/source/img/school-book.png","hash":"711ec983c874e093bb89eb77afcbdf6741fa61ee","modified":1566309402000},{"_id":"themes/3-hexo/source/js/iconfont.js","hash":"3a0869ca1b09af07d82987e343a3bc4cb9558ecb","modified":1566309402000},{"_id":"themes/3-hexo/source/js/jquery.autocomplete.min.js","hash":"7b8ac4d06c9e763963832529f44a56ad42a81e5f","modified":1566309402000},{"_id":"themes/3-hexo/source/js/script.js","hash":"7502191e29366a11323dc72ae365b1aed254e6f2","modified":1566309402000},{"_id":"themes/3-hexo/source/js/search.js","hash":"c80c9a231ee040c7adc07a477793873fb85ce8bc","modified":1566309402000},{"_id":"source/_posts/总-大数据.md","hash":"e230da3e2915ba0f4ca8114c3bcb649daca48562","modified":1567648984644},{"_id":"themes/3-hexo/source/img/weixin.jpg","hash":"8dafb22561698d0758fba9ea2a45abf6ad3512a2","modified":1566309402000},{"_id":"themes/3-hexo/layout/_partial/comments/click2show.ejs","hash":"359f73329b9821f3ca3554d306a04d6766110a5a","modified":1566309402000},{"_id":"themes/3-hexo/layout/_partial/comments/disqus.ejs","hash":"cd0022ce7e6d6efb07a00e87477cdf791f7f6703","modified":1566309402000},{"_id":"themes/3-hexo/layout/_partial/comments/gentie.ejs","hash":"1d6eacdadeb247e3b349ca7168f797beae8ff4c5","modified":1566309402000},{"_id":"themes/3-hexo/layout/_partial/comments/gitalk.ejs","hash":"fbd3c7d72c8354d700918390c6cbfc0a11408277","modified":1566309402000},{"_id":"themes/3-hexo/layout/_partial/comments/gitment.ejs","hash":"f16442568b43d034faaa8e3507f5ae8da34c7b72","modified":1566309402000},{"_id":"themes/3-hexo/source/css/_partial/autocomplete.styl","hash":"f6847a2c6d35dbd6d06dc591bd34ed2019784048","modified":1566309402000},{"_id":"themes/3-hexo/source/css/_partial/comment.styl","hash":"cc0a862b31359a85d12579e49d2eca58d128275c","modified":1566309402000},{"_id":"themes/3-hexo/source/css/_partial/dashang.styl","hash":"f6447a2ac407228e1d53e3455db2919ac0e9f094","modified":1566309402000},{"_id":"themes/3-hexo/source/css/_partial/fade.styl","hash":"4f687cbc74caf8a0887f5e89250284a9bce8b5c1","modified":1566309402000},{"_id":"themes/3-hexo/source/css/_partial/font.styl","hash":"4d5ac149709447c5eee45f0e23dadeea94fd98ce","modified":1566309402000},{"_id":"themes/3-hexo/source/css/_partial/full-toc.styl","hash":"0ba318911afbbbffbd2473b472aedf2d3900e978","modified":1566309402000},{"_id":"themes/3-hexo/source/css/_partial/nav-left.styl","hash":"1bd865029ba8c11750fff83d87f69e5d7c137928","modified":1566309402000},{"_id":"themes/3-hexo/source/css/_partial/nav-right.styl","hash":"3da8fa04efccfd054a6a65f7153f197d4d68281d","modified":1566309402000},{"_id":"themes/3-hexo/source/css/_partial/nprogress.styl","hash":"65efbddd23a264e7d1e85f4073228526770e833c","modified":1566309402000},{"_id":"themes/3-hexo/source/css/_partial/num-load.styl","hash":"4b996440bba8ec755aa70bc6d074d7dbba55ec0c","modified":1566309402000},{"_id":"themes/3-hexo/source/css/_partial/post.styl","hash":"b89971bcab14b3273d98496ec8bf1067f5b0ab56","modified":1566309402000},{"_id":"themes/3-hexo/source/css/fonts/icomoon.eot","hash":"b6195bedc1cb2f9cfcb26cc27021f2e94be2ab0a","modified":1566309402000},{"_id":"themes/3-hexo/source/css/fonts/icomoon.svg","hash":"37ac1ef28b03f46bf3ad2606c86f0e1ec3e4405f","modified":1566309402000},{"_id":"themes/3-hexo/source/css/fonts/icomoon.ttf","hash":"eb976d8b8559fcddfc2658a03a4350cb566fc06b","modified":1566309402000},{"_id":"themes/3-hexo/source/css/fonts/icomoon.woff","hash":"3985d29416bb9b19f50a2f20f2bbbce47f10af8d","modified":1566309402000},{"_id":"themes/3-hexo/source/css/fonts/iconfont.eot","hash":"3dfe8e557d9dfaf39bca088a02b76deb82dbaa3d","modified":1566309402000},{"_id":"themes/3-hexo/source/css/fonts/iconfont.ttf","hash":"aa087561480fb9c2cfd541e33d1e99d5ac1a56bb","modified":1566309402000},{"_id":"themes/3-hexo/source/css/fonts/iconfont.svg","hash":"c61a31e5310430312677fffe4286097d29d10151","modified":1566309402000},{"_id":"themes/3-hexo/source/css/fonts/iconfont.woff","hash":"f8ed131ccf13f4bdd3ec11fc3e997339dd7b66ba","modified":1566309402000},{"_id":"themes/3-hexo/source/css/fonts/selection.json","hash":"57c7f100019d57b512aab509185cb0a6eb9aa4c8","modified":1566309402000},{"_id":"themes/3-hexo/source/css/hl_theme/atom-dark.styl","hash":"f3eb4e5feda9cbd6242ccf44ca064e2979b5d719","modified":1566309402000},{"_id":"themes/3-hexo/source/css/hl_theme/brown-paper.styl","hash":"03af387edcc1cf8c18d12e9c440fd51b6cf425b6","modified":1566309402000},{"_id":"themes/3-hexo/source/css/hl_theme/atom-light.styl","hash":"69d184a682bcaeba2b180b437dc4431bc3be38aa","modified":1566309402000},{"_id":"themes/3-hexo/source/css/hl_theme/darcula.styl","hash":"2bfc14f27ccca108b4b3755782de8366e8bd001e","modified":1566309402000},{"_id":"themes/3-hexo/source/css/hl_theme/github-gist.styl","hash":"5e05b19832c1099bd9d284bc3ed00dc8a3d7ee23","modified":1566309402000},{"_id":"themes/3-hexo/source/css/hl_theme/github.styl","hash":"53276ff1f224f691dfe811e82c0af7f4476abf5d","modified":1566309402000},{"_id":"themes/3-hexo/source/css/hl_theme/gruvbox-dark.styl","hash":"315ad610d303caba9eac80a7d51002193a15478a","modified":1566309402000},{"_id":"themes/3-hexo/source/css/hl_theme/gruvbox-light.styl","hash":"1bece084b1dbbbd4af064f05feffd8c332b96a48","modified":1566309402000},{"_id":"themes/3-hexo/source/css/hl_theme/kimbie-dark.styl","hash":"e9c190f9ffc37a13cac430512e4e0c760205be4a","modified":1566309402000},{"_id":"themes/3-hexo/source/css/hl_theme/kimbie-light.styl","hash":"0c3ccd0d64e7504c7061d246dc32737f502f64e4","modified":1566309402000},{"_id":"themes/3-hexo/source/css/hl_theme/railscasts.styl","hash":"a6e8cfd2202afd7893f5268f3437421e35066e7b","modified":1566309402000},{"_id":"themes/3-hexo/source/css/hl_theme/rainbow.styl","hash":"e5c37646a9d9c1094f9aab7a7c65a4b242e8db00","modified":1566309402000},{"_id":"themes/3-hexo/source/css/hl_theme/school-book.styl","hash":"51659351b391a2be5c68728bb51b7ad467c5e0db","modified":1566309402000},{"_id":"themes/3-hexo/source/css/hl_theme/sublime.styl","hash":"501d75ef0f4385bea24d9b9b4cc434ba68d4be27","modified":1566309402000},{"_id":"themes/3-hexo/source/css/hl_theme/sunburst.styl","hash":"2aa9817e68fb2ed216781ea04b733039ebe18214","modified":1566309402000},{"_id":"themes/3-hexo/source/css/hl_theme/zenbum.styl","hash":"933a3b196d01254dea5e6f48105ea15e210ae000","modified":1566309402000},{"_id":"themes/3-hexo/source/js/gitment.js","hash":"59a1e03f2b0ce61dd9bd405d3c52d3e07cc10dec","modified":1566309402000},{"_id":"themes/3-hexo/source/js/gitalk.js","hash":"d1eb82a3280981bd652d9a8e323060e4311c547b","modified":1566309402000},{"_id":"public/about/index.html","hash":"1efb3bc1cbfa8a393d1e53b63b31f48d35347baa","modified":1567649311123},{"_id":"public/guestbook/index.html","hash":"3ed3f245426ba2c19e915305a0c674cec22b8238","modified":1567649311123},{"_id":"public/guestbook/index2.html","hash":"3ed3f245426ba2c19e915305a0c674cec22b8238","modified":1567649311124},{"_id":"public/2019/08/09/typora和picgo使用/index.html","hash":"9da32cd3234cbb7019b1311df33876d16feb0188","modified":1567649311124},{"_id":"public/2019/08/09/内网穿透frp/index.html","hash":"9d5884550d0582a6b69b54faebe73b9e05072e3f","modified":1567649311124},{"_id":"public/2019/08/09/总-javaEE/index.html","hash":"d9b24f051386f53b10a65a9e20a025260a328307","modified":1567649311124},{"_id":"public/2019/08/09/我的activiti学习/index.html","hash":"4c303ad5123566c46ea3d9ca44d44878d3499ced","modified":1567649311124},{"_id":"public/2019/08/09/总-大数据/index.html","hash":"ff08fb9cdeaa08a8cabe5fe28d75c96096e15c6c","modified":1567649311124},{"_id":"public/2019/03/09/hexo/index.html","hash":"eac01ed83bc62aa3e3261d574100f52a4daae663","modified":1567649311125},{"_id":"public/2019/03/09/hexo一键发布/index.html","hash":"343564ea5efc5dd0080a4ed35cc9d2287d48e9ed","modified":1567649311125},{"_id":"public/archives/index.html","hash":"66926f92eb213cc8f5bcfa000fa18d3c5aa4b06f","modified":1567649311125},{"_id":"public/archives/2019/index.html","hash":"66926f92eb213cc8f5bcfa000fa18d3c5aa4b06f","modified":1567649311125},{"_id":"public/archives/2019/03/index.html","hash":"66926f92eb213cc8f5bcfa000fa18d3c5aa4b06f","modified":1567649311125},{"_id":"public/archives/2019/08/index.html","hash":"66926f92eb213cc8f5bcfa000fa18d3c5aa4b06f","modified":1567649311126},{"_id":"public/index.html","hash":"66926f92eb213cc8f5bcfa000fa18d3c5aa4b06f","modified":1567649311126},{"_id":"public/tags/hexo/index.html","hash":"66926f92eb213cc8f5bcfa000fa18d3c5aa4b06f","modified":1567649311126},{"_id":"public/tags/typora/index.html","hash":"66926f92eb213cc8f5bcfa000fa18d3c5aa4b06f","modified":1567649311126},{"_id":"public/tags/picgo/index.html","hash":"66926f92eb213cc8f5bcfa000fa18d3c5aa4b06f","modified":1567649311126},{"_id":"public/tags/工具/index.html","hash":"66926f92eb213cc8f5bcfa000fa18d3c5aa4b06f","modified":1567649311126},{"_id":"public/tags/汇总/index.html","hash":"66926f92eb213cc8f5bcfa000fa18d3c5aa4b06f","modified":1567649311126},{"_id":"public/tags/activiti/index.html","hash":"66926f92eb213cc8f5bcfa000fa18d3c5aa4b06f","modified":1567649311126},{"_id":"public/categories/hexo/index.html","hash":"66926f92eb213cc8f5bcfa000fa18d3c5aa4b06f","modified":1567649311126},{"_id":"public/categories/我的/index.html","hash":"66926f92eb213cc8f5bcfa000fa18d3c5aa4b06f","modified":1567649311127},{"_id":"public/categories/工具/index.html","hash":"66926f92eb213cc8f5bcfa000fa18d3c5aa4b06f","modified":1567649311127},{"_id":"public/categories/汇总/index.html","hash":"66926f92eb213cc8f5bcfa000fa18d3c5aa4b06f","modified":1567649311127},{"_id":"public/categories/javaEE/index.html","hash":"66926f92eb213cc8f5bcfa000fa18d3c5aa4b06f","modified":1567649311127},{"_id":"public/img/alipay.jpg","hash":"e457d1d3dfefbbd824d154cf756a2c6d10b812a2","modified":1567649311142},{"_id":"public/img/article-list-background.jpeg","hash":"4fdf8b3e53dd02d6ee6360aebfadb0cba1fb5633","modified":1567649311142},{"_id":"public/img/avatar.jpg","hash":"a42360089bfa892d803cf5747eab359d90f337f1","modified":1567649311142},{"_id":"public/img/brown-papersq.png","hash":"3a1332ede3a75a3d24f60b6ed69035b72da5e182","modified":1567649311142},{"_id":"public/img/school-book.png","hash":"711ec983c874e093bb89eb77afcbdf6741fa61ee","modified":1567649311143},{"_id":"public/css/fonts/icomoon.eot","hash":"b6195bedc1cb2f9cfcb26cc27021f2e94be2ab0a","modified":1567649311143},{"_id":"public/css/fonts/icomoon.svg","hash":"37ac1ef28b03f46bf3ad2606c86f0e1ec3e4405f","modified":1567649311143},{"_id":"public/css/fonts/icomoon.ttf","hash":"eb976d8b8559fcddfc2658a03a4350cb566fc06b","modified":1567649311144},{"_id":"public/css/fonts/icomoon.woff","hash":"3985d29416bb9b19f50a2f20f2bbbce47f10af8d","modified":1567649311144},{"_id":"public/css/fonts/iconfont.ttf","hash":"aa087561480fb9c2cfd541e33d1e99d5ac1a56bb","modified":1567649311144},{"_id":"public/css/fonts/iconfont.eot","hash":"3dfe8e557d9dfaf39bca088a02b76deb82dbaa3d","modified":1567649311144},{"_id":"public/css/fonts/iconfont.svg","hash":"c61a31e5310430312677fffe4286097d29d10151","modified":1567649311144},{"_id":"public/css/fonts/iconfont.woff","hash":"f8ed131ccf13f4bdd3ec11fc3e997339dd7b66ba","modified":1567649311144},{"_id":"public/img/weixin.jpg","hash":"8dafb22561698d0758fba9ea2a45abf6ad3512a2","modified":1567649312007},{"_id":"public/css/mobile.css","hash":"79ab291be160e0ca753512a96c5198f7477f13be","modified":1567649312031},{"_id":"public/js/jquery.autocomplete.min.js","hash":"7b8ac4d06c9e763963832529f44a56ad42a81e5f","modified":1567649312032},{"_id":"public/js/search.js","hash":"c80c9a231ee040c7adc07a477793873fb85ce8bc","modified":1567649312033},{"_id":"public/css/hl_theme/brown-paper.css","hash":"500c8e750373f6656ff49a7857c871ceedcf8777","modified":1567649312034},{"_id":"public/css/hl_theme/darcula.css","hash":"4341074bae4bc9f0b86e32b623e27babc0159b6e","modified":1567649312035},{"_id":"public/css/hl_theme/atom-light.css","hash":"a3c8f3ee9a655594eff7ac545cb2e6914c1abcc2","modified":1567649312035},{"_id":"public/css/hl_theme/github-gist.css","hash":"7a41c1c479d09df875f99f1f6d94aac42e9e2ad0","modified":1567649312035},{"_id":"public/css/hl_theme/github.css","hash":"e05a0806a508a26b9f3f3794b6b588ec6504ad3f","modified":1567649312035},{"_id":"public/css/hl_theme/gruvbox-dark.css","hash":"8c440d9b4ee19ac03eaee3c6af78ba52e5ba5535","modified":1567649312035},{"_id":"public/css/hl_theme/gruvbox-light.css","hash":"30514aaa242a34647aa666cfca4fc74c595ea8f2","modified":1567649312035},{"_id":"public/css/hl_theme/kimbie-dark.css","hash":"728527fcc308da454722c119b89e6da3025bd1e3","modified":1567649312035},{"_id":"public/css/hl_theme/kimbie-light.css","hash":"0c61926c989163faefb031d27bce3e287d6e10f2","modified":1567649312035},{"_id":"public/css/hl_theme/railscasts.css","hash":"511f2fd2a84d426e5da5cb17880cc08f73beb002","modified":1567649312035},{"_id":"public/css/hl_theme/rainbow.css","hash":"7ff4251938076ddb7e4e49413db82653e5b61321","modified":1567649312035},{"_id":"public/css/hl_theme/school-book.css","hash":"ffbbcd13a74ac2404262c50b7a43053dfd0096ff","modified":1567649312035},{"_id":"public/css/hl_theme/sublime.css","hash":"f65c5b116d9213afb9c324384a2f3bc86cb71121","modified":1567649312035},{"_id":"public/css/hl_theme/zenbum.css","hash":"0a78f74a93568e20b32ca7427c719e9bae9a0b55","modified":1567649312035},{"_id":"public/css/hl_theme/sunburst.css","hash":"8a135abac1512cf430d1d1ad2304b79afa1a4d6e","modified":1567649312036},{"_id":"public/css/hl_theme/atom-dark.css","hash":"88d11052a24e8100af6248eb4dbe1ce7b0e96408","modified":1567649312036},{"_id":"public/css/style.css","hash":"37e8c434cc17058a1a71a4e5bf0d655d519d6317","modified":1567649312036},{"_id":"public/css/gitalk.css","hash":"58177ce227c50ee359fbf99a4fdd26058887afc5","modified":1567649312036},{"_id":"public/js/iconfont.js","hash":"3a0869ca1b09af07d82987e343a3bc4cb9558ecb","modified":1567649312036},{"_id":"public/js/script.js","hash":"7502191e29366a11323dc72ae365b1aed254e6f2","modified":1567649312036},{"_id":"public/css/fonts/selection.json","hash":"047b615ea32dc48dae5b964061427d41feaaafdf","modified":1567649312036},{"_id":"public/js/gitment.js","hash":"59a1e03f2b0ce61dd9bd405d3c52d3e07cc10dec","modified":1567649312036},{"_id":"public/js/gitalk.js","hash":"d1eb82a3280981bd652d9a8e323060e4311c547b","modified":1567649312036}],"Category":[{"name":"hexo","_id":"ck061x9340004qguiqk4d6f1w"},{"name":"我的","_id":"ck061x93n000dqguiz62pfdwu"},{"name":"工具","_id":"ck061x93r000jqguis9a14jxg"},{"name":"汇总","_id":"ck061x93s000mqguiotd4p4yo"},{"name":"javaEE","_id":"ck061x94w000xqguimrm123rt"}],"Data":[],"Page":[{"title":"about","date":"2019-03-09T04:57:53.000Z","type":"about","layout":"about","_content":"","source":"about/index.md","raw":"---\ntitle: about\ndate: 2019-03-09 12:57:53\ntype: \"about\"\nlayout: \"about\"\n---\n","updated":"2019-09-04T04:38:03.031Z","path":"about/index.html","comments":1,"_id":"ck061x92u0001qguiiwr7040w","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"guestbook","date":"2019-09-04T06:25:12.000Z","_content":"\n# guestbook\n\n\n\nguestbookguestbook","source":"guestbook/index.md","raw":"---\ntitle: guestbook\ndate: 2019-09-04 14:25:12\n---\n\n# guestbook\n\n\n\nguestbookguestbook","updated":"2019-09-04T06:25:38.684Z","path":"guestbook/index.html","comments":1,"layout":"page","_id":"ck061x9330003qguiktftezym","content":"<h1 id=\"guestbook\"><a href=\"#guestbook\" class=\"headerlink\" title=\"guestbook\"></a>guestbook</h1><p>guestbookguestbook</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"guestbook\"><a href=\"#guestbook\" class=\"headerlink\" title=\"guestbook\"></a>guestbook</h1><p>guestbookguestbook</p>\n"},{"title":"guestbook","date":"2019-09-04T06:25:12.000Z","_content":"\n# guestbook\n\n\n\nguestbookguestbook","source":"guestbook/index2.md","raw":"---\ntitle: guestbook\ndate: 2019-09-04 14:25:12\n---\n\n# guestbook\n\n\n\nguestbookguestbook","updated":"2019-09-04T06:25:38.684Z","path":"guestbook/index2.html","comments":1,"layout":"page","_id":"ck061x93e0007qguif1gpngpr","content":"<h1 id=\"guestbook\"><a href=\"#guestbook\" class=\"headerlink\" title=\"guestbook\"></a>guestbook</h1><p>guestbookguestbook</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"guestbook\"><a href=\"#guestbook\" class=\"headerlink\" title=\"guestbook\"></a>guestbook</h1><p>guestbookguestbook</p>\n"}],"Post":[{"title":"hexo","date":"2019-03-09T03:29:24.000Z","author":"陈锦华","password":123,"toc":true,"_content":"\n## hexo\n\n### 一、 写博客\n\n1.定位到我们的项目的根目录，执行命令：\n\n```\nhexo new 'hexo'\n```\n\n2.hexo会帮我们在`_posts`下生成相关md文件  hexo.md\n\n```\ntitle: hello_hexo\ndate: 2019-03-09 11:29:24\ntags:\n```\n\n3.创建一个页面\n\n```bash\n$ hexo new \"My New Post\"\n```\n\n4.运行服务器\n\n```bash\n$ hexo server\n```\n\n5.生成文件\n\n```bash\n$ hexo generate\n```\n\n6.部署服务\n\n```bash\n$ hexo deploy\n```\n\n一般完整格式如下：\n\n```\ntitle: postName #文章页面上的显示名称，一般是中文\ndate: 2013-12-02 15:30:16 #文章生成时间，一般不改，当然也可以任意修改\ncategories: 默认分类 #分类\ntags: [tag1,tag2,tag3] #文章标签，可空，多标签请用格式，注意:后面有个空格\ndescription: 附加一段文章摘要，字数最好在140字以内，会出现在meta的description里面\n```\n\n那么`hexo new page 'hexo'`命令和`hexo new 'hexo'`有什么区别呢？ \n\n`hexo new page \"hexo\" ` 生成路径如下\n\n```\n项目\\source\\_posts\\hexo.md\n```\n\n最终部署时生成：`\\项目\\public\\hexo\\index.html`，但是它不会作为文章出现在博文目录。 \n\n3.如果文件夹下文章很多的时候，找起来就会很不方便。 \n\nHexo作者也给出来解决办法： \n\n在Hexo目录下的scripts目录中创建一个JavaScript脚本文件。如果没有这个scripts目录，则新建一个。 scripts目录新建的 js 脚本文件可以任意取名。 \n\n```\nvar spawn = require('child_process').exec;\n// Hexo 2.x 用户复制这段\n//hexo.on('new', function(path){\n//  spawn('start  \"Typora编辑器绝对路径.exe\" ' + path);\n//});\n//C:\\Program Files (x86)\\Typora\\Typora.exe 是MakdownPad编辑器在我本地的路径！\n// Hexo 3 用户复制这段\nhexo.on('new', function(data){\n  spawn('start  \"C:\\Program Files (x86)\\Typora\\Typora.exe\" ' + data.path);\n});\n```\n\n然后再创建文件输入命令之后就会自动打开Typora编辑器来编辑了 \n\n### 二、更换 Hexo 主题及样式\n\n1、默认主题\n我们通过 hexo init 初始化的网站，使用的是 hexo 默认的主题样式 lanscape，位于 xxx/themes/lanscape 目录，我们可以到官网的 主题市场  根据自己的喜好更换其它的主题。\n2、更换主题\n我目前使用的是 Next 主题，非常简约风。在此以 Next 主题为例，说明如何把 Hexo 的默认主题 lanscape 更换成 next 主题。\n3、下载新主题\n\n进入你本地创建的网站的 themes 目录中，在这里打开 Git Bash 命令行，使用 git clone 下载 next 主题：\n\n```\ngit clone https://github.com/iissnan/hexo-theme-next next\n```\n\n这是将 Next 主题下载到本地 themes 目录下的 next 文件夹中。\n\n4 、修改站点配置文件打开站点的配置文件 项目/_config.yml ，找到 theme 配置项，把值从 landscape 改为 next。\n\n```\ntheme: next\nscheme: Pisces\n```\n\n5 、修改 next 主题的样式next 主题提供了几个不同的样式可供选择。打开主题的配置文件 blog/themes/next/_config.yml ，找到 Schemes 模块，我用的是 5.1.4 版本的主题，包含有下面 4 种样式：\n\nMuse：这是默认的样式，是 NexT 最初的版本，黑白主调，大量留白；\nMist： Muse 的紧凑版本，整洁有序的单栏外观；\nPisces： 双栏 Scheme，小家碧玉似的清新；\nGemini： 左侧是网站信息及目录，块 + 片段结构布局；\n\n去掉 scheme 前面的注释符 # 即可启用该样式，你可以依次试用一下，选择某一个样式之后执行 hexo g 、hexo d 重新发布即可看到新样式了，我使用的是第三种 Pisces\n\n6、默认语言是英语。\n\n```\nlanguage: en\n# language: zh-Hans\n# language: zh-hk\n# language: zh-tw\n# language: ru\n# language: fr-FR\n# language: de\n# language: ja\n# language: id\n# language: pt\n# language: pt-BR\n# language: ko\n# language: it\n# language: nl-NL\n```\n\n7、在站点配置文件`_config.yml`中可以将语言切换成中文\n\n```\nlanguage: zh-Hans\n```\n\n\n\n\n\n\n\n","source":"_posts/hexo.md","raw":"---\ntitle: hexo\ndate: 2019-03-09 11:29:24\nauthor: 陈锦华\npassword: 123\ntoc: true\ncategories: hexo\ntags:\n  - hexo\n---\n\n## hexo\n\n### 一、 写博客\n\n1.定位到我们的项目的根目录，执行命令：\n\n```\nhexo new 'hexo'\n```\n\n2.hexo会帮我们在`_posts`下生成相关md文件  hexo.md\n\n```\ntitle: hello_hexo\ndate: 2019-03-09 11:29:24\ntags:\n```\n\n3.创建一个页面\n\n```bash\n$ hexo new \"My New Post\"\n```\n\n4.运行服务器\n\n```bash\n$ hexo server\n```\n\n5.生成文件\n\n```bash\n$ hexo generate\n```\n\n6.部署服务\n\n```bash\n$ hexo deploy\n```\n\n一般完整格式如下：\n\n```\ntitle: postName #文章页面上的显示名称，一般是中文\ndate: 2013-12-02 15:30:16 #文章生成时间，一般不改，当然也可以任意修改\ncategories: 默认分类 #分类\ntags: [tag1,tag2,tag3] #文章标签，可空，多标签请用格式，注意:后面有个空格\ndescription: 附加一段文章摘要，字数最好在140字以内，会出现在meta的description里面\n```\n\n那么`hexo new page 'hexo'`命令和`hexo new 'hexo'`有什么区别呢？ \n\n`hexo new page \"hexo\" ` 生成路径如下\n\n```\n项目\\source\\_posts\\hexo.md\n```\n\n最终部署时生成：`\\项目\\public\\hexo\\index.html`，但是它不会作为文章出现在博文目录。 \n\n3.如果文件夹下文章很多的时候，找起来就会很不方便。 \n\nHexo作者也给出来解决办法： \n\n在Hexo目录下的scripts目录中创建一个JavaScript脚本文件。如果没有这个scripts目录，则新建一个。 scripts目录新建的 js 脚本文件可以任意取名。 \n\n```\nvar spawn = require('child_process').exec;\n// Hexo 2.x 用户复制这段\n//hexo.on('new', function(path){\n//  spawn('start  \"Typora编辑器绝对路径.exe\" ' + path);\n//});\n//C:\\Program Files (x86)\\Typora\\Typora.exe 是MakdownPad编辑器在我本地的路径！\n// Hexo 3 用户复制这段\nhexo.on('new', function(data){\n  spawn('start  \"C:\\Program Files (x86)\\Typora\\Typora.exe\" ' + data.path);\n});\n```\n\n然后再创建文件输入命令之后就会自动打开Typora编辑器来编辑了 \n\n### 二、更换 Hexo 主题及样式\n\n1、默认主题\n我们通过 hexo init 初始化的网站，使用的是 hexo 默认的主题样式 lanscape，位于 xxx/themes/lanscape 目录，我们可以到官网的 主题市场  根据自己的喜好更换其它的主题。\n2、更换主题\n我目前使用的是 Next 主题，非常简约风。在此以 Next 主题为例，说明如何把 Hexo 的默认主题 lanscape 更换成 next 主题。\n3、下载新主题\n\n进入你本地创建的网站的 themes 目录中，在这里打开 Git Bash 命令行，使用 git clone 下载 next 主题：\n\n```\ngit clone https://github.com/iissnan/hexo-theme-next next\n```\n\n这是将 Next 主题下载到本地 themes 目录下的 next 文件夹中。\n\n4 、修改站点配置文件打开站点的配置文件 项目/_config.yml ，找到 theme 配置项，把值从 landscape 改为 next。\n\n```\ntheme: next\nscheme: Pisces\n```\n\n5 、修改 next 主题的样式next 主题提供了几个不同的样式可供选择。打开主题的配置文件 blog/themes/next/_config.yml ，找到 Schemes 模块，我用的是 5.1.4 版本的主题，包含有下面 4 种样式：\n\nMuse：这是默认的样式，是 NexT 最初的版本，黑白主调，大量留白；\nMist： Muse 的紧凑版本，整洁有序的单栏外观；\nPisces： 双栏 Scheme，小家碧玉似的清新；\nGemini： 左侧是网站信息及目录，块 + 片段结构布局；\n\n去掉 scheme 前面的注释符 # 即可启用该样式，你可以依次试用一下，选择某一个样式之后执行 hexo g 、hexo d 重新发布即可看到新样式了，我使用的是第三种 Pisces\n\n6、默认语言是英语。\n\n```\nlanguage: en\n# language: zh-Hans\n# language: zh-hk\n# language: zh-tw\n# language: ru\n# language: fr-FR\n# language: de\n# language: ja\n# language: id\n# language: pt\n# language: pt-BR\n# language: ko\n# language: it\n# language: nl-NL\n```\n\n7、在站点配置文件`_config.yml`中可以将语言切换成中文\n\n```\nlanguage: zh-Hans\n```\n\n\n\n\n\n\n\n","slug":"hexo","published":1,"updated":"2019-09-04T09:18:22.727Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck061x92o0000qgui7uvel78b","content":"<h2 id=\"hexo\"><a href=\"#hexo\" class=\"headerlink\" title=\"hexo\"></a>hexo</h2><h3 id=\"一、-写博客\"><a href=\"#一、-写博客\" class=\"headerlink\" title=\"一、 写博客\"></a>一、 写博客</h3><p>1.定位到我们的项目的根目录，执行命令：</p>\n<pre><code>hexo new &#39;hexo&#39;</code></pre><p>2.hexo会帮我们在<code>_posts</code>下生成相关md文件  hexo.md</p>\n<pre><code>title: hello_hexo\ndate: 2019-03-09 11:29:24\ntags:</code></pre><p>3.创建一个页面</p>\n<pre><code class=\"bash\">$ hexo new &quot;My New Post&quot;</code></pre>\n<p>4.运行服务器</p>\n<pre><code class=\"bash\">$ hexo server</code></pre>\n<p>5.生成文件</p>\n<pre><code class=\"bash\">$ hexo generate</code></pre>\n<p>6.部署服务</p>\n<pre><code class=\"bash\">$ hexo deploy</code></pre>\n<p>一般完整格式如下：</p>\n<pre><code>title: postName #文章页面上的显示名称，一般是中文\ndate: 2013-12-02 15:30:16 #文章生成时间，一般不改，当然也可以任意修改\ncategories: 默认分类 #分类\ntags: [tag1,tag2,tag3] #文章标签，可空，多标签请用格式，注意:后面有个空格\ndescription: 附加一段文章摘要，字数最好在140字以内，会出现在meta的description里面</code></pre><p>那么<code>hexo new page &#39;hexo&#39;</code>命令和<code>hexo new &#39;hexo&#39;</code>有什么区别呢？ </p>\n<p><code>hexo new page &quot;hexo&quot;</code> 生成路径如下</p>\n<pre><code>项目\\source\\_posts\\hexo.md</code></pre><p>最终部署时生成：<code>\\项目\\public\\hexo\\index.html</code>，但是它不会作为文章出现在博文目录。 </p>\n<p>3.如果文件夹下文章很多的时候，找起来就会很不方便。 </p>\n<p>Hexo作者也给出来解决办法： </p>\n<p>在Hexo目录下的scripts目录中创建一个JavaScript脚本文件。如果没有这个scripts目录，则新建一个。 scripts目录新建的 js 脚本文件可以任意取名。 </p>\n<pre><code>var spawn = require(&#39;child_process&#39;).exec;\n// Hexo 2.x 用户复制这段\n//hexo.on(&#39;new&#39;, function(path){\n//  spawn(&#39;start  &quot;Typora编辑器绝对路径.exe&quot; &#39; + path);\n//});\n//C:\\Program Files (x86)\\Typora\\Typora.exe 是MakdownPad编辑器在我本地的路径！\n// Hexo 3 用户复制这段\nhexo.on(&#39;new&#39;, function(data){\n  spawn(&#39;start  &quot;C:\\Program Files (x86)\\Typora\\Typora.exe&quot; &#39; + data.path);\n});</code></pre><p>然后再创建文件输入命令之后就会自动打开Typora编辑器来编辑了 </p>\n<h3 id=\"二、更换-Hexo-主题及样式\"><a href=\"#二、更换-Hexo-主题及样式\" class=\"headerlink\" title=\"二、更换 Hexo 主题及样式\"></a>二、更换 Hexo 主题及样式</h3><p>1、默认主题<br>我们通过 hexo init 初始化的网站，使用的是 hexo 默认的主题样式 lanscape，位于 xxx/themes/lanscape 目录，我们可以到官网的 主题市场  根据自己的喜好更换其它的主题。<br>2、更换主题<br>我目前使用的是 Next 主题，非常简约风。在此以 Next 主题为例，说明如何把 Hexo 的默认主题 lanscape 更换成 next 主题。<br>3、下载新主题</p>\n<p>进入你本地创建的网站的 themes 目录中，在这里打开 Git Bash 命令行，使用 git clone 下载 next 主题：</p>\n<pre><code>git clone https://github.com/iissnan/hexo-theme-next next</code></pre><p>这是将 Next 主题下载到本地 themes 目录下的 next 文件夹中。</p>\n<p>4 、修改站点配置文件打开站点的配置文件 项目/_config.yml ，找到 theme 配置项，把值从 landscape 改为 next。</p>\n<pre><code>theme: next\nscheme: Pisces</code></pre><p>5 、修改 next 主题的样式next 主题提供了几个不同的样式可供选择。打开主题的配置文件 blog/themes/next/_config.yml ，找到 Schemes 模块，我用的是 5.1.4 版本的主题，包含有下面 4 种样式：</p>\n<p>Muse：这是默认的样式，是 NexT 最初的版本，黑白主调，大量留白；<br>Mist： Muse 的紧凑版本，整洁有序的单栏外观；<br>Pisces： 双栏 Scheme，小家碧玉似的清新；<br>Gemini： 左侧是网站信息及目录，块 + 片段结构布局；</p>\n<p>去掉 scheme 前面的注释符 # 即可启用该样式，你可以依次试用一下，选择某一个样式之后执行 hexo g 、hexo d 重新发布即可看到新样式了，我使用的是第三种 Pisces</p>\n<p>6、默认语言是英语。</p>\n<pre><code>language: en\n# language: zh-Hans\n# language: zh-hk\n# language: zh-tw\n# language: ru\n# language: fr-FR\n# language: de\n# language: ja\n# language: id\n# language: pt\n# language: pt-BR\n# language: ko\n# language: it\n# language: nl-NL</code></pre><p>7、在站点配置文件<code>_config.yml</code>中可以将语言切换成中文</p>\n<pre><code>language: zh-Hans</code></pre>","site":{"data":{}},"excerpt":"","more":"<h2 id=\"hexo\"><a href=\"#hexo\" class=\"headerlink\" title=\"hexo\"></a>hexo</h2><h3 id=\"一、-写博客\"><a href=\"#一、-写博客\" class=\"headerlink\" title=\"一、 写博客\"></a>一、 写博客</h3><p>1.定位到我们的项目的根目录，执行命令：</p>\n<pre><code>hexo new &#39;hexo&#39;</code></pre><p>2.hexo会帮我们在<code>_posts</code>下生成相关md文件  hexo.md</p>\n<pre><code>title: hello_hexo\ndate: 2019-03-09 11:29:24\ntags:</code></pre><p>3.创建一个页面</p>\n<pre><code class=\"bash\">$ hexo new &quot;My New Post&quot;</code></pre>\n<p>4.运行服务器</p>\n<pre><code class=\"bash\">$ hexo server</code></pre>\n<p>5.生成文件</p>\n<pre><code class=\"bash\">$ hexo generate</code></pre>\n<p>6.部署服务</p>\n<pre><code class=\"bash\">$ hexo deploy</code></pre>\n<p>一般完整格式如下：</p>\n<pre><code>title: postName #文章页面上的显示名称，一般是中文\ndate: 2013-12-02 15:30:16 #文章生成时间，一般不改，当然也可以任意修改\ncategories: 默认分类 #分类\ntags: [tag1,tag2,tag3] #文章标签，可空，多标签请用格式，注意:后面有个空格\ndescription: 附加一段文章摘要，字数最好在140字以内，会出现在meta的description里面</code></pre><p>那么<code>hexo new page &#39;hexo&#39;</code>命令和<code>hexo new &#39;hexo&#39;</code>有什么区别呢？ </p>\n<p><code>hexo new page &quot;hexo&quot;</code> 生成路径如下</p>\n<pre><code>项目\\source\\_posts\\hexo.md</code></pre><p>最终部署时生成：<code>\\项目\\public\\hexo\\index.html</code>，但是它不会作为文章出现在博文目录。 </p>\n<p>3.如果文件夹下文章很多的时候，找起来就会很不方便。 </p>\n<p>Hexo作者也给出来解决办法： </p>\n<p>在Hexo目录下的scripts目录中创建一个JavaScript脚本文件。如果没有这个scripts目录，则新建一个。 scripts目录新建的 js 脚本文件可以任意取名。 </p>\n<pre><code>var spawn = require(&#39;child_process&#39;).exec;\n// Hexo 2.x 用户复制这段\n//hexo.on(&#39;new&#39;, function(path){\n//  spawn(&#39;start  &quot;Typora编辑器绝对路径.exe&quot; &#39; + path);\n//});\n//C:\\Program Files (x86)\\Typora\\Typora.exe 是MakdownPad编辑器在我本地的路径！\n// Hexo 3 用户复制这段\nhexo.on(&#39;new&#39;, function(data){\n  spawn(&#39;start  &quot;C:\\Program Files (x86)\\Typora\\Typora.exe&quot; &#39; + data.path);\n});</code></pre><p>然后再创建文件输入命令之后就会自动打开Typora编辑器来编辑了 </p>\n<h3 id=\"二、更换-Hexo-主题及样式\"><a href=\"#二、更换-Hexo-主题及样式\" class=\"headerlink\" title=\"二、更换 Hexo 主题及样式\"></a>二、更换 Hexo 主题及样式</h3><p>1、默认主题<br>我们通过 hexo init 初始化的网站，使用的是 hexo 默认的主题样式 lanscape，位于 xxx/themes/lanscape 目录，我们可以到官网的 主题市场  根据自己的喜好更换其它的主题。<br>2、更换主题<br>我目前使用的是 Next 主题，非常简约风。在此以 Next 主题为例，说明如何把 Hexo 的默认主题 lanscape 更换成 next 主题。<br>3、下载新主题</p>\n<p>进入你本地创建的网站的 themes 目录中，在这里打开 Git Bash 命令行，使用 git clone 下载 next 主题：</p>\n<pre><code>git clone https://github.com/iissnan/hexo-theme-next next</code></pre><p>这是将 Next 主题下载到本地 themes 目录下的 next 文件夹中。</p>\n<p>4 、修改站点配置文件打开站点的配置文件 项目/_config.yml ，找到 theme 配置项，把值从 landscape 改为 next。</p>\n<pre><code>theme: next\nscheme: Pisces</code></pre><p>5 、修改 next 主题的样式next 主题提供了几个不同的样式可供选择。打开主题的配置文件 blog/themes/next/_config.yml ，找到 Schemes 模块，我用的是 5.1.4 版本的主题，包含有下面 4 种样式：</p>\n<p>Muse：这是默认的样式，是 NexT 最初的版本，黑白主调，大量留白；<br>Mist： Muse 的紧凑版本，整洁有序的单栏外观；<br>Pisces： 双栏 Scheme，小家碧玉似的清新；<br>Gemini： 左侧是网站信息及目录，块 + 片段结构布局；</p>\n<p>去掉 scheme 前面的注释符 # 即可启用该样式，你可以依次试用一下，选择某一个样式之后执行 hexo g 、hexo d 重新发布即可看到新样式了，我使用的是第三种 Pisces</p>\n<p>6、默认语言是英语。</p>\n<pre><code>language: en\n# language: zh-Hans\n# language: zh-hk\n# language: zh-tw\n# language: ru\n# language: fr-FR\n# language: de\n# language: ja\n# language: id\n# language: pt\n# language: pt-BR\n# language: ko\n# language: it\n# language: nl-NL</code></pre><p>7、在站点配置文件<code>_config.yml</code>中可以将语言切换成中文</p>\n<pre><code>language: zh-Hans</code></pre>"},{"title":"hexo","date":"2019-03-09T03:29:24.000Z","author":"陈锦华","password":123,"toc":true,"_content":"\n## hexo发布\n\n### 一.配置git秘钥\n\n**1.在bash shell命令行执行**\n\n```\n$ ssh-keygen -t rsa -C \"939598604@qq.com\"\n```\n\n\n直接Enter就行。然后，会提示你输入密码，不需要输入密码：\nEnter passphrase (empty for no passphrase): [Type a passphrase] \n Enter same passphrase again: [Type passphrase again]\n完了之后，大概是这样。\nYour identification has been saved in /home/you/.ssh/id_rsa. \n Your public key has been saved in /home/you/.ssh/id_rsa.pub. \n The key fingerprint is:  01:0f:f4:3b:ca:85:d6:17:a1:7d:f0:68:9d:f0:a2:db your_email@youremail.com\n这样。你本地生成密钥对的工作就做好了。\n\n**2.添加公钥到你的github帐户**\n\n**(1)查看你生成的公钥：大概如下：**\n\n```\n$ cat ~/.ssh/id_rsa.pub  \n\nssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAklOUpkDHrfHY17SbrmTIpNLTGK9Tjom/BWDSU GPl+nafzlHDTYW7hdI4yZ5ew18JH4JW9jbhUFrviQzM7xlE\n\nLEVf4h9lFX5QVkbPppSwg0cda3 Pbv7kOdJ/MTyBlWXFCR+HAo3FXRitBqxiX1nKhXpHAZsMciLq8V6RjsNAQwdsdMFvSlVK/7XA t3FaoJoAsncM1Q9x5+3V\n\n0Ww68/eIFmb1zuUFljQJKprrX88XypNDvjYNby6vw/Pb0rwert/En mZ+AW4OZPnTPI89ZPmVMLuayrD2cE86Z/il8b+gw3r3+1nKatmIkjn2so1d01QraTlMqVSsbx NrRFi9wrf+M7Q== schacon@agadorlaptop.local\n```\n\n**(2)登陆你的github帐户。然后 Account Settings -> 左栏点击 SSH Keys -> 点击 Add SSH key**\n**(3)然后你复制上面的公钥内容，粘贴进“Key”文本域内,，点击 Add key**\n\n这样，就OK了。然后，验证下这个key是不是正常工作。\n\n```\n$ ssh -T git@github.com\n Attempts to ssh to github\n```\n\n如果，看到：\n`Hi username! You've successfully authenticated, but GitHub does not  provide shell access.`\n就表示你的设置已经成功了。\n\n###二. hexo配置\n\n1.安装发布插件\n\n```\nnpm install --save hexo-deployer-git\n```\n\n2.在_config.yml文件加入_\n\n```\ndeploy:\n  type: git\n  repository: git@github.com:939598604/939598604.github.io.git\n  branch: master\n```\n\n3.在bash shell执行命令\n\n```bash\n$ hexo d\n```\n\n报错信息\n\n```\nERROR Plugin load failed: hexo-deployer-git\nSyntaxError: Unexpected token ...\n```\n\n修改hexo-deployer-git版本为1.0.0\n\n```\n{\n  \"name\": \"hexo-site\",\n  \"version\": \"0.0.0\",\n  \"private\": true,\n  \"hexo\": {\n    \"version\": \"3.9.0\"\n  },\n  \"dependencies\": {\n    \"hexo\": \"^3.9.0\",\n\t\"hexo-deployer-git\": \"^1.0.0\",\n    \"hexo-generator-archive\": \"^0.1.5\",\n    \"hexo-generator-category\": \"^0.1.3\",\n    \"hexo-generator-index\": \"^0.2.1\",\n    \"hexo-generator-tag\": \"^0.2.0\",\n    \"hexo-renderer-ejs\": \"^0.3.1\",\n    \"hexo-renderer-marked\": \"^1.0.1\",\n    \"hexo-renderer-stylus\": \"^0.3.3\",\n    \"hexo-server\": \"^0.3.3\"\n  }\n}\n```\n\n4.再执行\n\n```\n$ hexo d\n```\n\n### 三.发布多余的md文件\n\n将其他md文件放到source/\\_posts文件目录下即可\n\n### 四.一键发布\n\n新建一个deploy.bat结尾的文档，在创建的.bat文档中输入以下内容 \n\n```\ncall  hexo clean\ncall  hexo g\ncall  hexo d\npause\n```\n\n\n\n\n\n\n\n","source":"_posts/hexo一键发布.md","raw":"---\ntitle: hexo\ndate: 2019-03-09 11:29:24\nauthor: 陈锦华\npassword: 123\ntoc: true\ncategories: hexo\ntags:\n  - hexo\n---\n\n## hexo发布\n\n### 一.配置git秘钥\n\n**1.在bash shell命令行执行**\n\n```\n$ ssh-keygen -t rsa -C \"939598604@qq.com\"\n```\n\n\n直接Enter就行。然后，会提示你输入密码，不需要输入密码：\nEnter passphrase (empty for no passphrase): [Type a passphrase] \n Enter same passphrase again: [Type passphrase again]\n完了之后，大概是这样。\nYour identification has been saved in /home/you/.ssh/id_rsa. \n Your public key has been saved in /home/you/.ssh/id_rsa.pub. \n The key fingerprint is:  01:0f:f4:3b:ca:85:d6:17:a1:7d:f0:68:9d:f0:a2:db your_email@youremail.com\n这样。你本地生成密钥对的工作就做好了。\n\n**2.添加公钥到你的github帐户**\n\n**(1)查看你生成的公钥：大概如下：**\n\n```\n$ cat ~/.ssh/id_rsa.pub  \n\nssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAklOUpkDHrfHY17SbrmTIpNLTGK9Tjom/BWDSU GPl+nafzlHDTYW7hdI4yZ5ew18JH4JW9jbhUFrviQzM7xlE\n\nLEVf4h9lFX5QVkbPppSwg0cda3 Pbv7kOdJ/MTyBlWXFCR+HAo3FXRitBqxiX1nKhXpHAZsMciLq8V6RjsNAQwdsdMFvSlVK/7XA t3FaoJoAsncM1Q9x5+3V\n\n0Ww68/eIFmb1zuUFljQJKprrX88XypNDvjYNby6vw/Pb0rwert/En mZ+AW4OZPnTPI89ZPmVMLuayrD2cE86Z/il8b+gw3r3+1nKatmIkjn2so1d01QraTlMqVSsbx NrRFi9wrf+M7Q== schacon@agadorlaptop.local\n```\n\n**(2)登陆你的github帐户。然后 Account Settings -> 左栏点击 SSH Keys -> 点击 Add SSH key**\n**(3)然后你复制上面的公钥内容，粘贴进“Key”文本域内,，点击 Add key**\n\n这样，就OK了。然后，验证下这个key是不是正常工作。\n\n```\n$ ssh -T git@github.com\n Attempts to ssh to github\n```\n\n如果，看到：\n`Hi username! You've successfully authenticated, but GitHub does not  provide shell access.`\n就表示你的设置已经成功了。\n\n###二. hexo配置\n\n1.安装发布插件\n\n```\nnpm install --save hexo-deployer-git\n```\n\n2.在_config.yml文件加入_\n\n```\ndeploy:\n  type: git\n  repository: git@github.com:939598604/939598604.github.io.git\n  branch: master\n```\n\n3.在bash shell执行命令\n\n```bash\n$ hexo d\n```\n\n报错信息\n\n```\nERROR Plugin load failed: hexo-deployer-git\nSyntaxError: Unexpected token ...\n```\n\n修改hexo-deployer-git版本为1.0.0\n\n```\n{\n  \"name\": \"hexo-site\",\n  \"version\": \"0.0.0\",\n  \"private\": true,\n  \"hexo\": {\n    \"version\": \"3.9.0\"\n  },\n  \"dependencies\": {\n    \"hexo\": \"^3.9.0\",\n\t\"hexo-deployer-git\": \"^1.0.0\",\n    \"hexo-generator-archive\": \"^0.1.5\",\n    \"hexo-generator-category\": \"^0.1.3\",\n    \"hexo-generator-index\": \"^0.2.1\",\n    \"hexo-generator-tag\": \"^0.2.0\",\n    \"hexo-renderer-ejs\": \"^0.3.1\",\n    \"hexo-renderer-marked\": \"^1.0.1\",\n    \"hexo-renderer-stylus\": \"^0.3.3\",\n    \"hexo-server\": \"^0.3.3\"\n  }\n}\n```\n\n4.再执行\n\n```\n$ hexo d\n```\n\n### 三.发布多余的md文件\n\n将其他md文件放到source/\\_posts文件目录下即可\n\n### 四.一键发布\n\n新建一个deploy.bat结尾的文档，在创建的.bat文档中输入以下内容 \n\n```\ncall  hexo clean\ncall  hexo g\ncall  hexo d\npause\n```\n\n\n\n\n\n\n\n","slug":"hexo一键发布","published":1,"updated":"2019-09-05T02:06:25.281Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck061x92y0002qgui87xymnjg","content":"<h2 id=\"hexo发布\"><a href=\"#hexo发布\" class=\"headerlink\" title=\"hexo发布\"></a>hexo发布</h2><h3 id=\"一-配置git秘钥\"><a href=\"#一-配置git秘钥\" class=\"headerlink\" title=\"一.配置git秘钥\"></a>一.配置git秘钥</h3><p><strong>1.在bash shell命令行执行</strong></p>\n<pre><code>$ ssh-keygen -t rsa -C &quot;939598604@qq.com&quot;</code></pre><p>直接Enter就行。然后，会提示你输入密码，不需要输入密码：<br>Enter passphrase (empty for no passphrase): [Type a passphrase]<br> Enter same passphrase again: [Type passphrase again]<br>完了之后，大概是这样。<br>Your identification has been saved in /home/you/.ssh/id_rsa.<br> Your public key has been saved in /home/you/.ssh/id_rsa.pub.<br> The key fingerprint is:  01:0f:f4:3b:ca:85:d6:17:a1:7d:f0:68:9d:f0:a2:db <a href=\"mailto:your_email@youremail.com\" target=\"_blank\" rel=\"noopener\">your_email@youremail.com</a><br>这样。你本地生成密钥对的工作就做好了。</p>\n<p><strong>2.添加公钥到你的github帐户</strong></p>\n<p><strong>(1)查看你生成的公钥：大概如下：</strong></p>\n<pre><code>$ cat ~/.ssh/id_rsa.pub  \n\nssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAklOUpkDHrfHY17SbrmTIpNLTGK9Tjom/BWDSU GPl+nafzlHDTYW7hdI4yZ5ew18JH4JW9jbhUFrviQzM7xlE\n\nLEVf4h9lFX5QVkbPppSwg0cda3 Pbv7kOdJ/MTyBlWXFCR+HAo3FXRitBqxiX1nKhXpHAZsMciLq8V6RjsNAQwdsdMFvSlVK/7XA t3FaoJoAsncM1Q9x5+3V\n\n0Ww68/eIFmb1zuUFljQJKprrX88XypNDvjYNby6vw/Pb0rwert/En mZ+AW4OZPnTPI89ZPmVMLuayrD2cE86Z/il8b+gw3r3+1nKatmIkjn2so1d01QraTlMqVSsbx NrRFi9wrf+M7Q== schacon@agadorlaptop.local</code></pre><p><strong>(2)登陆你的github帐户。然后 Account Settings -&gt; 左栏点击 SSH Keys -&gt; 点击 Add SSH key</strong><br><strong>(3)然后你复制上面的公钥内容，粘贴进“Key”文本域内,，点击 Add key</strong></p>\n<p>这样，就OK了。然后，验证下这个key是不是正常工作。</p>\n<pre><code>$ ssh -T git@github.com\n Attempts to ssh to github</code></pre><p>如果，看到：<br><code>Hi username! You&#39;ve successfully authenticated, but GitHub does not  provide shell access.</code><br>就表示你的设置已经成功了。</p>\n<p>###二. hexo配置</p>\n<p>1.安装发布插件</p>\n<pre><code>npm install --save hexo-deployer-git</code></pre><p>2.在<em>config.yml文件加入</em></p>\n<pre><code>deploy:\n  type: git\n  repository: git@github.com:939598604/939598604.github.io.git\n  branch: master</code></pre><p>3.在bash shell执行命令</p>\n<pre><code class=\"bash\">$ hexo d</code></pre>\n<p>报错信息</p>\n<pre><code>ERROR Plugin load failed: hexo-deployer-git\nSyntaxError: Unexpected token ...</code></pre><p>修改hexo-deployer-git版本为1.0.0</p>\n<pre><code>{\n  &quot;name&quot;: &quot;hexo-site&quot;,\n  &quot;version&quot;: &quot;0.0.0&quot;,\n  &quot;private&quot;: true,\n  &quot;hexo&quot;: {\n    &quot;version&quot;: &quot;3.9.0&quot;\n  },\n  &quot;dependencies&quot;: {\n    &quot;hexo&quot;: &quot;^3.9.0&quot;,\n    &quot;hexo-deployer-git&quot;: &quot;^1.0.0&quot;,\n    &quot;hexo-generator-archive&quot;: &quot;^0.1.5&quot;,\n    &quot;hexo-generator-category&quot;: &quot;^0.1.3&quot;,\n    &quot;hexo-generator-index&quot;: &quot;^0.2.1&quot;,\n    &quot;hexo-generator-tag&quot;: &quot;^0.2.0&quot;,\n    &quot;hexo-renderer-ejs&quot;: &quot;^0.3.1&quot;,\n    &quot;hexo-renderer-marked&quot;: &quot;^1.0.1&quot;,\n    &quot;hexo-renderer-stylus&quot;: &quot;^0.3.3&quot;,\n    &quot;hexo-server&quot;: &quot;^0.3.3&quot;\n  }\n}</code></pre><p>4.再执行</p>\n<pre><code>$ hexo d</code></pre><h3 id=\"三-发布多余的md文件\"><a href=\"#三-发布多余的md文件\" class=\"headerlink\" title=\"三.发布多余的md文件\"></a>三.发布多余的md文件</h3><p>将其他md文件放到source/_posts文件目录下即可</p>\n<h3 id=\"四-一键发布\"><a href=\"#四-一键发布\" class=\"headerlink\" title=\"四.一键发布\"></a>四.一键发布</h3><p>新建一个deploy.bat结尾的文档，在创建的.bat文档中输入以下内容 </p>\n<pre><code>call  hexo clean\ncall  hexo g\ncall  hexo d\npause</code></pre>","site":{"data":{}},"excerpt":"","more":"<h2 id=\"hexo发布\"><a href=\"#hexo发布\" class=\"headerlink\" title=\"hexo发布\"></a>hexo发布</h2><h3 id=\"一-配置git秘钥\"><a href=\"#一-配置git秘钥\" class=\"headerlink\" title=\"一.配置git秘钥\"></a>一.配置git秘钥</h3><p><strong>1.在bash shell命令行执行</strong></p>\n<pre><code>$ ssh-keygen -t rsa -C &quot;939598604@qq.com&quot;</code></pre><p>直接Enter就行。然后，会提示你输入密码，不需要输入密码：<br>Enter passphrase (empty for no passphrase): [Type a passphrase]<br> Enter same passphrase again: [Type passphrase again]<br>完了之后，大概是这样。<br>Your identification has been saved in /home/you/.ssh/id_rsa.<br> Your public key has been saved in /home/you/.ssh/id_rsa.pub.<br> The key fingerprint is:  01:0f:f4:3b:ca:85:d6:17:a1:7d:f0:68:9d:f0:a2:db <a href=\"mailto:your_email@youremail.com\" target=\"_blank\" rel=\"noopener\">your_email@youremail.com</a><br>这样。你本地生成密钥对的工作就做好了。</p>\n<p><strong>2.添加公钥到你的github帐户</strong></p>\n<p><strong>(1)查看你生成的公钥：大概如下：</strong></p>\n<pre><code>$ cat ~/.ssh/id_rsa.pub  \n\nssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAklOUpkDHrfHY17SbrmTIpNLTGK9Tjom/BWDSU GPl+nafzlHDTYW7hdI4yZ5ew18JH4JW9jbhUFrviQzM7xlE\n\nLEVf4h9lFX5QVkbPppSwg0cda3 Pbv7kOdJ/MTyBlWXFCR+HAo3FXRitBqxiX1nKhXpHAZsMciLq8V6RjsNAQwdsdMFvSlVK/7XA t3FaoJoAsncM1Q9x5+3V\n\n0Ww68/eIFmb1zuUFljQJKprrX88XypNDvjYNby6vw/Pb0rwert/En mZ+AW4OZPnTPI89ZPmVMLuayrD2cE86Z/il8b+gw3r3+1nKatmIkjn2so1d01QraTlMqVSsbx NrRFi9wrf+M7Q== schacon@agadorlaptop.local</code></pre><p><strong>(2)登陆你的github帐户。然后 Account Settings -&gt; 左栏点击 SSH Keys -&gt; 点击 Add SSH key</strong><br><strong>(3)然后你复制上面的公钥内容，粘贴进“Key”文本域内,，点击 Add key</strong></p>\n<p>这样，就OK了。然后，验证下这个key是不是正常工作。</p>\n<pre><code>$ ssh -T git@github.com\n Attempts to ssh to github</code></pre><p>如果，看到：<br><code>Hi username! You&#39;ve successfully authenticated, but GitHub does not  provide shell access.</code><br>就表示你的设置已经成功了。</p>\n<p>###二. hexo配置</p>\n<p>1.安装发布插件</p>\n<pre><code>npm install --save hexo-deployer-git</code></pre><p>2.在<em>config.yml文件加入</em></p>\n<pre><code>deploy:\n  type: git\n  repository: git@github.com:939598604/939598604.github.io.git\n  branch: master</code></pre><p>3.在bash shell执行命令</p>\n<pre><code class=\"bash\">$ hexo d</code></pre>\n<p>报错信息</p>\n<pre><code>ERROR Plugin load failed: hexo-deployer-git\nSyntaxError: Unexpected token ...</code></pre><p>修改hexo-deployer-git版本为1.0.0</p>\n<pre><code>{\n  &quot;name&quot;: &quot;hexo-site&quot;,\n  &quot;version&quot;: &quot;0.0.0&quot;,\n  &quot;private&quot;: true,\n  &quot;hexo&quot;: {\n    &quot;version&quot;: &quot;3.9.0&quot;\n  },\n  &quot;dependencies&quot;: {\n    &quot;hexo&quot;: &quot;^3.9.0&quot;,\n    &quot;hexo-deployer-git&quot;: &quot;^1.0.0&quot;,\n    &quot;hexo-generator-archive&quot;: &quot;^0.1.5&quot;,\n    &quot;hexo-generator-category&quot;: &quot;^0.1.3&quot;,\n    &quot;hexo-generator-index&quot;: &quot;^0.2.1&quot;,\n    &quot;hexo-generator-tag&quot;: &quot;^0.2.0&quot;,\n    &quot;hexo-renderer-ejs&quot;: &quot;^0.3.1&quot;,\n    &quot;hexo-renderer-marked&quot;: &quot;^1.0.1&quot;,\n    &quot;hexo-renderer-stylus&quot;: &quot;^0.3.3&quot;,\n    &quot;hexo-server&quot;: &quot;^0.3.3&quot;\n  }\n}</code></pre><p>4.再执行</p>\n<pre><code>$ hexo d</code></pre><h3 id=\"三-发布多余的md文件\"><a href=\"#三-发布多余的md文件\" class=\"headerlink\" title=\"三.发布多余的md文件\"></a>三.发布多余的md文件</h3><p>将其他md文件放到source/_posts文件目录下即可</p>\n<h3 id=\"四-一键发布\"><a href=\"#四-一键发布\" class=\"headerlink\" title=\"四.一键发布\"></a>四.一键发布</h3><p>新建一个deploy.bat结尾的文档，在创建的.bat文档中输入以下内容 </p>\n<pre><code>call  hexo clean\ncall  hexo g\ncall  hexo d\npause</code></pre>"},{"title":"typora和picgo使用","date":"2019-08-09T12:32:59.000Z","series":"hexo折腾","_content":"\n# typora和picgo使用\n\n## 1.picgo下载\n\nhttps://github.com/Molunerfinn/PicGo/releases/tag/v2.1.2\n\n## 2.picgo码云插件\n\n- 在picgo插件栏中搜索gitee-uploader插件\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904105711.png)\n\n## 3.设置gitee仓库\n\n- 在gitee新建一个公开的资源仓库\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904105937.png)\n\n- 设置个人token\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904110128.png)\n\n\n\n## 4.设置picgo的gitee配置参数\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904110538.png)\n\nrepo：仓库地址去掉码云域名  https://gitee.com/chenjinhua_939598604/resources    chenjinhua_939598604/resources  \n\nbranch：主干\n\ntoken：上面设置的个人token\n\npath：是仓库中新建static文件夹\n\n**点击设为默认图床，点击确定**\n\n## 5.在picgo上传区测试上传图片\n\n将本地文件拖拽到上传区，弹出返回的图片上传地址，测试上传成功\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904111322.png)\n\n## 6.设置picgo上传图片的快捷键\n\n点击picgo的设置栏，点击修改上传快捷键后面的设置按钮，然后输入组合键，确定\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904111017.png)\n\n## 7.打开Typora测试上传图片\n\n用QQ的ctrl+ALT+A快捷键对需要的区域截图，存储到剪贴板中，然后按下刚才在picgo设置好的上传快捷键ctrl+u组合键上传到gitee，会返回图片的上传地址到剪贴板中，最后在typora中ctrl+v粘贴。\n\n","source":"_posts/typora和picgo使用.md","raw":"---\ntitle: typora和picgo使用\ndate: 2019-08-09 20:32:59\ntags:  [hexo,typora,picgo] \nseries: hexo折腾\ncategory: 我的\n---\n\n# typora和picgo使用\n\n## 1.picgo下载\n\nhttps://github.com/Molunerfinn/PicGo/releases/tag/v2.1.2\n\n## 2.picgo码云插件\n\n- 在picgo插件栏中搜索gitee-uploader插件\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904105711.png)\n\n## 3.设置gitee仓库\n\n- 在gitee新建一个公开的资源仓库\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904105937.png)\n\n- 设置个人token\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904110128.png)\n\n\n\n## 4.设置picgo的gitee配置参数\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904110538.png)\n\nrepo：仓库地址去掉码云域名  https://gitee.com/chenjinhua_939598604/resources    chenjinhua_939598604/resources  \n\nbranch：主干\n\ntoken：上面设置的个人token\n\npath：是仓库中新建static文件夹\n\n**点击设为默认图床，点击确定**\n\n## 5.在picgo上传区测试上传图片\n\n将本地文件拖拽到上传区，弹出返回的图片上传地址，测试上传成功\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904111322.png)\n\n## 6.设置picgo上传图片的快捷键\n\n点击picgo的设置栏，点击修改上传快捷键后面的设置按钮，然后输入组合键，确定\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904111017.png)\n\n## 7.打开Typora测试上传图片\n\n用QQ的ctrl+ALT+A快捷键对需要的区域截图，存储到剪贴板中，然后按下刚才在picgo设置好的上传快捷键ctrl+u组合键上传到gitee，会返回图片的上传地址到剪贴板中，最后在typora中ctrl+v粘贴。\n\n","slug":"typora和picgo使用","published":1,"updated":"2019-09-04T07:22:28.999Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck061x93b0006qguitddj6tic","content":"<h1 id=\"typora和picgo使用\"><a href=\"#typora和picgo使用\" class=\"headerlink\" title=\"typora和picgo使用\"></a>typora和picgo使用</h1><h2 id=\"1-picgo下载\"><a href=\"#1-picgo下载\" class=\"headerlink\" title=\"1.picgo下载\"></a>1.picgo下载</h2><p><a href=\"https://github.com/Molunerfinn/PicGo/releases/tag/v2.1.2\" target=\"_blank\" rel=\"noopener\">https://github.com/Molunerfinn/PicGo/releases/tag/v2.1.2</a></p>\n<h2 id=\"2-picgo码云插件\"><a href=\"#2-picgo码云插件\" class=\"headerlink\" title=\"2.picgo码云插件\"></a>2.picgo码云插件</h2><ul>\n<li>在picgo插件栏中搜索gitee-uploader插件</li>\n</ul>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904105711.png\" alt></p>\n<h2 id=\"3-设置gitee仓库\"><a href=\"#3-设置gitee仓库\" class=\"headerlink\" title=\"3.设置gitee仓库\"></a>3.设置gitee仓库</h2><ul>\n<li>在gitee新建一个公开的资源仓库</li>\n</ul>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904105937.png\" alt></p>\n<ul>\n<li>设置个人token</li>\n</ul>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904110128.png\" alt></p>\n<h2 id=\"4-设置picgo的gitee配置参数\"><a href=\"#4-设置picgo的gitee配置参数\" class=\"headerlink\" title=\"4.设置picgo的gitee配置参数\"></a>4.设置picgo的gitee配置参数</h2><p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904110538.png\" alt></p>\n<p>repo：仓库地址去掉码云域名  <a href=\"https://gitee.com/chenjinhua_939598604/resources\" target=\"_blank\" rel=\"noopener\">https://gitee.com/chenjinhua_939598604/resources</a>    chenjinhua_939598604/resources  </p>\n<p>branch：主干</p>\n<p>token：上面设置的个人token</p>\n<p>path：是仓库中新建static文件夹</p>\n<p><strong>点击设为默认图床，点击确定</strong></p>\n<h2 id=\"5-在picgo上传区测试上传图片\"><a href=\"#5-在picgo上传区测试上传图片\" class=\"headerlink\" title=\"5.在picgo上传区测试上传图片\"></a>5.在picgo上传区测试上传图片</h2><p>将本地文件拖拽到上传区，弹出返回的图片上传地址，测试上传成功</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904111322.png\" alt></p>\n<h2 id=\"6-设置picgo上传图片的快捷键\"><a href=\"#6-设置picgo上传图片的快捷键\" class=\"headerlink\" title=\"6.设置picgo上传图片的快捷键\"></a>6.设置picgo上传图片的快捷键</h2><p>点击picgo的设置栏，点击修改上传快捷键后面的设置按钮，然后输入组合键，确定</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904111017.png\" alt></p>\n<h2 id=\"7-打开Typora测试上传图片\"><a href=\"#7-打开Typora测试上传图片\" class=\"headerlink\" title=\"7.打开Typora测试上传图片\"></a>7.打开Typora测试上传图片</h2><p>用QQ的ctrl+ALT+A快捷键对需要的区域截图，存储到剪贴板中，然后按下刚才在picgo设置好的上传快捷键ctrl+u组合键上传到gitee，会返回图片的上传地址到剪贴板中，最后在typora中ctrl+v粘贴。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"typora和picgo使用\"><a href=\"#typora和picgo使用\" class=\"headerlink\" title=\"typora和picgo使用\"></a>typora和picgo使用</h1><h2 id=\"1-picgo下载\"><a href=\"#1-picgo下载\" class=\"headerlink\" title=\"1.picgo下载\"></a>1.picgo下载</h2><p><a href=\"https://github.com/Molunerfinn/PicGo/releases/tag/v2.1.2\" target=\"_blank\" rel=\"noopener\">https://github.com/Molunerfinn/PicGo/releases/tag/v2.1.2</a></p>\n<h2 id=\"2-picgo码云插件\"><a href=\"#2-picgo码云插件\" class=\"headerlink\" title=\"2.picgo码云插件\"></a>2.picgo码云插件</h2><ul>\n<li>在picgo插件栏中搜索gitee-uploader插件</li>\n</ul>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904105711.png\" alt></p>\n<h2 id=\"3-设置gitee仓库\"><a href=\"#3-设置gitee仓库\" class=\"headerlink\" title=\"3.设置gitee仓库\"></a>3.设置gitee仓库</h2><ul>\n<li>在gitee新建一个公开的资源仓库</li>\n</ul>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904105937.png\" alt></p>\n<ul>\n<li>设置个人token</li>\n</ul>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904110128.png\" alt></p>\n<h2 id=\"4-设置picgo的gitee配置参数\"><a href=\"#4-设置picgo的gitee配置参数\" class=\"headerlink\" title=\"4.设置picgo的gitee配置参数\"></a>4.设置picgo的gitee配置参数</h2><p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904110538.png\" alt></p>\n<p>repo：仓库地址去掉码云域名  <a href=\"https://gitee.com/chenjinhua_939598604/resources\" target=\"_blank\" rel=\"noopener\">https://gitee.com/chenjinhua_939598604/resources</a>    chenjinhua_939598604/resources  </p>\n<p>branch：主干</p>\n<p>token：上面设置的个人token</p>\n<p>path：是仓库中新建static文件夹</p>\n<p><strong>点击设为默认图床，点击确定</strong></p>\n<h2 id=\"5-在picgo上传区测试上传图片\"><a href=\"#5-在picgo上传区测试上传图片\" class=\"headerlink\" title=\"5.在picgo上传区测试上传图片\"></a>5.在picgo上传区测试上传图片</h2><p>将本地文件拖拽到上传区，弹出返回的图片上传地址，测试上传成功</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904111322.png\" alt></p>\n<h2 id=\"6-设置picgo上传图片的快捷键\"><a href=\"#6-设置picgo上传图片的快捷键\" class=\"headerlink\" title=\"6.设置picgo上传图片的快捷键\"></a>6.设置picgo上传图片的快捷键</h2><p>点击picgo的设置栏，点击修改上传快捷键后面的设置按钮，然后输入组合键，确定</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904111017.png\" alt></p>\n<h2 id=\"7-打开Typora测试上传图片\"><a href=\"#7-打开Typora测试上传图片\" class=\"headerlink\" title=\"7.打开Typora测试上传图片\"></a>7.打开Typora测试上传图片</h2><p>用QQ的ctrl+ALT+A快捷键对需要的区域截图，存储到剪贴板中，然后按下刚才在picgo设置好的上传快捷键ctrl+u组合键上传到gitee，会返回图片的上传地址到剪贴板中，最后在typora中ctrl+v粘贴。</p>\n"},{"title":"frp服务端的安装","date":"2019-08-09T12:32:59.000Z","password":123,"abstract":"欢迎来到test, 请输入密码.","message":"欢迎来到test, 请输入密码.","toc":false,"mathjax":false,"_content":"\n#内网穿透frp\n\n##  一、frp服务端的安装\n\n###  1.内网穿透环境的准备\n\n- 必须准备一台公网的服务器\n\n- 公网服务器有域名指定\n- 同时配置在域名中添加一台A记录   * 指向该公网的服务器  原因是为了更好的匹配二级域名\n\n###  2.下载解压frp\n\n在地址：http://diannaobos.iok.la:81/frp/frp-v0.20.0/ 中找到`frp_0.20.0_linux_386.tar.gz `下载到服务器\n\n```shell\ntar -zxvf frp_0.20.0_linux_386.tar.gz\n```\n\n###  3.编辑frp的服务端配置文件\n\nvim frps.ini\n\n```shell\n[common]\nbind_port = 7001\nvhost_http_port = 80 \ndashboard_port = 7500\ndashboard_user = admin\ndashboard_pwd = admin\nsubdomains_host = gzstrong.cn\n```\n\n###  4.启动frp的服务端\n\n```shell\nnohup /soft/frp/frps -c /soft/frp/frps.ini>/dev/null 2>&1 &\n```\n\n\n\n##  二、frp客户端的安装\n\n###  1.客户内网穿透环境的准备\n\n只需在公司内网随便一台机器就可以\n\n###  2.下载解压frp\n\n在地址：http://diannaobos.iok.la:81/frp/frp-v0.20.0/ 中找到`frp_0.20.0_linux_386.tar.gz `下载到服务器\n\n```shell\ntar -zxvf frp_0.20.0_linux_386.tar.gz\n```\n\n###  3.编辑frp的服务端配置文件\n\nvim frpc.ini\n\n```shell\n[common]\nserver_addr = 47.106.228.4\nserver_port = 7001\n\n[ssh]\n#29的ssh端口映射\ntype = tcp\nlocal_ip = 192.168.197.29\nlocal_port = 22\nremote_port = 61000\n\n[www]\n#思创官网www.gzstrong.cn指向 www.gzstrong.com\ntype = http\nlocal_ip = 112.124.183.21\nlocal_port = 80\ncustom_domains = www.gzstrong.cn\n\n[myremote]\n#远程主机的端口映射\ntype = tcp\nlocal_ip = 192.168.197.223\nlocal_port = 3389\nremote_port = 61001\n\n[rep]\ntype = http\nlocal_ip = 192.168.197.67\nlocal_port = 9090\ncustom_domains = rep.gzstrong.cn\n\n[tomcat]\ntype = http\nlocal_ip = 192.168.197.29\nlocal_port = 8081 \ncustom_domains = tomcat.gzstrong.cn\n\n[mysql]\ntype = tcp\nlocal_ip = 192.168.197.205\nlocal_port = 3306\nremote_port = 61003\n```\n\n###  4.启动frp的客户端\n\n```shell\nnohup /soft/frp/frpc -c /soft/frp/frpc.ini>/dev/null 2>&1 &\n```\n\n\n\n##  三、访问frp\n\n- web端的服务\n\n  因frp服务端的配置文件frps.ini中配置了\n\n```\nvhost_http_port = 80 \n```\n\n所以客户端的配置\n\n```\n[rep]\ntype = http\nlocal_ip = 192.168.197.67\nlocal_port = 9090\ncustom_domains = rep.gzstrong.cn\n```\n\n这个配置中的192.168.197.67:9090可以映射成rep.gzstrong.cn\n\n即浏览器中直接输入http://rep.gzstrong.cn就可以访问到内网的机器192.168.197.67:9090\n\n- windows远程服务\n\n  ```\n  [myremote]\n  #远程主机的端口映射\n  type = tcp\n  local_ip = 192.168.197.223\n  local_port = 3389\n  remote_port = 61001\n  ```\n\n  打开windows的远程mstsc\n\n  输入`服务的ip地址:61001`即可访问到内网服务器的`192.168.197.223:3389`端口\n\n","source":"_posts/内网穿透frp.md","raw":"---\ntitle: frp服务端的安装\ndate: 2019-08-09 20:32:59\npassword: 123\nabstract: 欢迎来到test, 请输入密码.\nmessage: 欢迎来到test, 请输入密码.\ntoc: false\nmathjax: false\ntags:  [工具] \ncategory: 工具\n---\n\n#内网穿透frp\n\n##  一、frp服务端的安装\n\n###  1.内网穿透环境的准备\n\n- 必须准备一台公网的服务器\n\n- 公网服务器有域名指定\n- 同时配置在域名中添加一台A记录   * 指向该公网的服务器  原因是为了更好的匹配二级域名\n\n###  2.下载解压frp\n\n在地址：http://diannaobos.iok.la:81/frp/frp-v0.20.0/ 中找到`frp_0.20.0_linux_386.tar.gz `下载到服务器\n\n```shell\ntar -zxvf frp_0.20.0_linux_386.tar.gz\n```\n\n###  3.编辑frp的服务端配置文件\n\nvim frps.ini\n\n```shell\n[common]\nbind_port = 7001\nvhost_http_port = 80 \ndashboard_port = 7500\ndashboard_user = admin\ndashboard_pwd = admin\nsubdomains_host = gzstrong.cn\n```\n\n###  4.启动frp的服务端\n\n```shell\nnohup /soft/frp/frps -c /soft/frp/frps.ini>/dev/null 2>&1 &\n```\n\n\n\n##  二、frp客户端的安装\n\n###  1.客户内网穿透环境的准备\n\n只需在公司内网随便一台机器就可以\n\n###  2.下载解压frp\n\n在地址：http://diannaobos.iok.la:81/frp/frp-v0.20.0/ 中找到`frp_0.20.0_linux_386.tar.gz `下载到服务器\n\n```shell\ntar -zxvf frp_0.20.0_linux_386.tar.gz\n```\n\n###  3.编辑frp的服务端配置文件\n\nvim frpc.ini\n\n```shell\n[common]\nserver_addr = 47.106.228.4\nserver_port = 7001\n\n[ssh]\n#29的ssh端口映射\ntype = tcp\nlocal_ip = 192.168.197.29\nlocal_port = 22\nremote_port = 61000\n\n[www]\n#思创官网www.gzstrong.cn指向 www.gzstrong.com\ntype = http\nlocal_ip = 112.124.183.21\nlocal_port = 80\ncustom_domains = www.gzstrong.cn\n\n[myremote]\n#远程主机的端口映射\ntype = tcp\nlocal_ip = 192.168.197.223\nlocal_port = 3389\nremote_port = 61001\n\n[rep]\ntype = http\nlocal_ip = 192.168.197.67\nlocal_port = 9090\ncustom_domains = rep.gzstrong.cn\n\n[tomcat]\ntype = http\nlocal_ip = 192.168.197.29\nlocal_port = 8081 \ncustom_domains = tomcat.gzstrong.cn\n\n[mysql]\ntype = tcp\nlocal_ip = 192.168.197.205\nlocal_port = 3306\nremote_port = 61003\n```\n\n###  4.启动frp的客户端\n\n```shell\nnohup /soft/frp/frpc -c /soft/frp/frpc.ini>/dev/null 2>&1 &\n```\n\n\n\n##  三、访问frp\n\n- web端的服务\n\n  因frp服务端的配置文件frps.ini中配置了\n\n```\nvhost_http_port = 80 \n```\n\n所以客户端的配置\n\n```\n[rep]\ntype = http\nlocal_ip = 192.168.197.67\nlocal_port = 9090\ncustom_domains = rep.gzstrong.cn\n```\n\n这个配置中的192.168.197.67:9090可以映射成rep.gzstrong.cn\n\n即浏览器中直接输入http://rep.gzstrong.cn就可以访问到内网的机器192.168.197.67:9090\n\n- windows远程服务\n\n  ```\n  [myremote]\n  #远程主机的端口映射\n  type = tcp\n  local_ip = 192.168.197.223\n  local_port = 3389\n  remote_port = 61001\n  ```\n\n  打开windows的远程mstsc\n\n  输入`服务的ip地址:61001`即可访问到内网服务器的`192.168.197.223:3389`端口\n\n","slug":"内网穿透frp","published":1,"updated":"2019-09-04T10:20:10.457Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck061x93g0008qguilc7gicfc","content":"<p>#内网穿透frp</p>\n<h2 id=\"一、frp服务端的安装\"><a href=\"#一、frp服务端的安装\" class=\"headerlink\" title=\"一、frp服务端的安装\"></a>一、frp服务端的安装</h2><h3 id=\"1-内网穿透环境的准备\"><a href=\"#1-内网穿透环境的准备\" class=\"headerlink\" title=\"1.内网穿透环境的准备\"></a>1.内网穿透环境的准备</h3><ul>\n<li><p>必须准备一台公网的服务器</p>\n</li>\n<li><p>公网服务器有域名指定</p>\n</li>\n<li><p>同时配置在域名中添加一台A记录   * 指向该公网的服务器  原因是为了更好的匹配二级域名</p>\n</li>\n</ul>\n<h3 id=\"2-下载解压frp\"><a href=\"#2-下载解压frp\" class=\"headerlink\" title=\"2.下载解压frp\"></a>2.下载解压frp</h3><p>在地址：<a href=\"http://diannaobos.iok.la:81/frp/frp-v0.20.0/\" target=\"_blank\" rel=\"noopener\">http://diannaobos.iok.la:81/frp/frp-v0.20.0/</a> 中找到<code>frp_0.20.0_linux_386.tar.gz</code>下载到服务器</p>\n<pre><code class=\"shell\">tar -zxvf frp_0.20.0_linux_386.tar.gz</code></pre>\n<h3 id=\"3-编辑frp的服务端配置文件\"><a href=\"#3-编辑frp的服务端配置文件\" class=\"headerlink\" title=\"3.编辑frp的服务端配置文件\"></a>3.编辑frp的服务端配置文件</h3><p>vim frps.ini</p>\n<pre><code class=\"shell\">[common]\nbind_port = 7001\nvhost_http_port = 80 \ndashboard_port = 7500\ndashboard_user = admin\ndashboard_pwd = admin\nsubdomains_host = gzstrong.cn</code></pre>\n<h3 id=\"4-启动frp的服务端\"><a href=\"#4-启动frp的服务端\" class=\"headerlink\" title=\"4.启动frp的服务端\"></a>4.启动frp的服务端</h3><pre><code class=\"shell\">nohup /soft/frp/frps -c /soft/frp/frps.ini&gt;/dev/null 2&gt;&amp;1 &amp;</code></pre>\n<h2 id=\"二、frp客户端的安装\"><a href=\"#二、frp客户端的安装\" class=\"headerlink\" title=\"二、frp客户端的安装\"></a>二、frp客户端的安装</h2><h3 id=\"1-客户内网穿透环境的准备\"><a href=\"#1-客户内网穿透环境的准备\" class=\"headerlink\" title=\"1.客户内网穿透环境的准备\"></a>1.客户内网穿透环境的准备</h3><p>只需在公司内网随便一台机器就可以</p>\n<h3 id=\"2-下载解压frp-1\"><a href=\"#2-下载解压frp-1\" class=\"headerlink\" title=\"2.下载解压frp\"></a>2.下载解压frp</h3><p>在地址：<a href=\"http://diannaobos.iok.la:81/frp/frp-v0.20.0/\" target=\"_blank\" rel=\"noopener\">http://diannaobos.iok.la:81/frp/frp-v0.20.0/</a> 中找到<code>frp_0.20.0_linux_386.tar.gz</code>下载到服务器</p>\n<pre><code class=\"shell\">tar -zxvf frp_0.20.0_linux_386.tar.gz</code></pre>\n<h3 id=\"3-编辑frp的服务端配置文件-1\"><a href=\"#3-编辑frp的服务端配置文件-1\" class=\"headerlink\" title=\"3.编辑frp的服务端配置文件\"></a>3.编辑frp的服务端配置文件</h3><p>vim frpc.ini</p>\n<pre><code class=\"shell\">[common]\nserver_addr = 47.106.228.4\nserver_port = 7001\n\n[ssh]\n#29的ssh端口映射\ntype = tcp\nlocal_ip = 192.168.197.29\nlocal_port = 22\nremote_port = 61000\n\n[www]\n#思创官网www.gzstrong.cn指向 www.gzstrong.com\ntype = http\nlocal_ip = 112.124.183.21\nlocal_port = 80\ncustom_domains = www.gzstrong.cn\n\n[myremote]\n#远程主机的端口映射\ntype = tcp\nlocal_ip = 192.168.197.223\nlocal_port = 3389\nremote_port = 61001\n\n[rep]\ntype = http\nlocal_ip = 192.168.197.67\nlocal_port = 9090\ncustom_domains = rep.gzstrong.cn\n\n[tomcat]\ntype = http\nlocal_ip = 192.168.197.29\nlocal_port = 8081 \ncustom_domains = tomcat.gzstrong.cn\n\n[mysql]\ntype = tcp\nlocal_ip = 192.168.197.205\nlocal_port = 3306\nremote_port = 61003</code></pre>\n<h3 id=\"4-启动frp的客户端\"><a href=\"#4-启动frp的客户端\" class=\"headerlink\" title=\"4.启动frp的客户端\"></a>4.启动frp的客户端</h3><pre><code class=\"shell\">nohup /soft/frp/frpc -c /soft/frp/frpc.ini&gt;/dev/null 2&gt;&amp;1 &amp;</code></pre>\n<h2 id=\"三、访问frp\"><a href=\"#三、访问frp\" class=\"headerlink\" title=\"三、访问frp\"></a>三、访问frp</h2><ul>\n<li><p>web端的服务</p>\n<p>因frp服务端的配置文件frps.ini中配置了</p>\n</li>\n</ul>\n<pre><code>vhost_http_port = 80 </code></pre><p>所以客户端的配置</p>\n<pre><code>[rep]\ntype = http\nlocal_ip = 192.168.197.67\nlocal_port = 9090\ncustom_domains = rep.gzstrong.cn</code></pre><p>这个配置中的192.168.197.67:9090可以映射成rep.gzstrong.cn</p>\n<p>即浏览器中直接输入<a href=\"http://rep.gzstrong.cn就可以访问到内网的机器192.168.197.67:9090\" target=\"_blank\" rel=\"noopener\">http://rep.gzstrong.cn就可以访问到内网的机器192.168.197.67:9090</a></p>\n<ul>\n<li><p>windows远程服务</p>\n<pre><code>[myremote]\n#远程主机的端口映射\ntype = tcp\nlocal_ip = 192.168.197.223\nlocal_port = 3389\nremote_port = 61001</code></pre><p>打开windows的远程mstsc</p>\n<p>输入<code>服务的ip地址:61001</code>即可访问到内网服务器的<code>192.168.197.223:3389</code>端口</p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>#内网穿透frp</p>\n<h2 id=\"一、frp服务端的安装\"><a href=\"#一、frp服务端的安装\" class=\"headerlink\" title=\"一、frp服务端的安装\"></a>一、frp服务端的安装</h2><h3 id=\"1-内网穿透环境的准备\"><a href=\"#1-内网穿透环境的准备\" class=\"headerlink\" title=\"1.内网穿透环境的准备\"></a>1.内网穿透环境的准备</h3><ul>\n<li><p>必须准备一台公网的服务器</p>\n</li>\n<li><p>公网服务器有域名指定</p>\n</li>\n<li><p>同时配置在域名中添加一台A记录   * 指向该公网的服务器  原因是为了更好的匹配二级域名</p>\n</li>\n</ul>\n<h3 id=\"2-下载解压frp\"><a href=\"#2-下载解压frp\" class=\"headerlink\" title=\"2.下载解压frp\"></a>2.下载解压frp</h3><p>在地址：<a href=\"http://diannaobos.iok.la:81/frp/frp-v0.20.0/\" target=\"_blank\" rel=\"noopener\">http://diannaobos.iok.la:81/frp/frp-v0.20.0/</a> 中找到<code>frp_0.20.0_linux_386.tar.gz</code>下载到服务器</p>\n<pre><code class=\"shell\">tar -zxvf frp_0.20.0_linux_386.tar.gz</code></pre>\n<h3 id=\"3-编辑frp的服务端配置文件\"><a href=\"#3-编辑frp的服务端配置文件\" class=\"headerlink\" title=\"3.编辑frp的服务端配置文件\"></a>3.编辑frp的服务端配置文件</h3><p>vim frps.ini</p>\n<pre><code class=\"shell\">[common]\nbind_port = 7001\nvhost_http_port = 80 \ndashboard_port = 7500\ndashboard_user = admin\ndashboard_pwd = admin\nsubdomains_host = gzstrong.cn</code></pre>\n<h3 id=\"4-启动frp的服务端\"><a href=\"#4-启动frp的服务端\" class=\"headerlink\" title=\"4.启动frp的服务端\"></a>4.启动frp的服务端</h3><pre><code class=\"shell\">nohup /soft/frp/frps -c /soft/frp/frps.ini&gt;/dev/null 2&gt;&amp;1 &amp;</code></pre>\n<h2 id=\"二、frp客户端的安装\"><a href=\"#二、frp客户端的安装\" class=\"headerlink\" title=\"二、frp客户端的安装\"></a>二、frp客户端的安装</h2><h3 id=\"1-客户内网穿透环境的准备\"><a href=\"#1-客户内网穿透环境的准备\" class=\"headerlink\" title=\"1.客户内网穿透环境的准备\"></a>1.客户内网穿透环境的准备</h3><p>只需在公司内网随便一台机器就可以</p>\n<h3 id=\"2-下载解压frp-1\"><a href=\"#2-下载解压frp-1\" class=\"headerlink\" title=\"2.下载解压frp\"></a>2.下载解压frp</h3><p>在地址：<a href=\"http://diannaobos.iok.la:81/frp/frp-v0.20.0/\" target=\"_blank\" rel=\"noopener\">http://diannaobos.iok.la:81/frp/frp-v0.20.0/</a> 中找到<code>frp_0.20.0_linux_386.tar.gz</code>下载到服务器</p>\n<pre><code class=\"shell\">tar -zxvf frp_0.20.0_linux_386.tar.gz</code></pre>\n<h3 id=\"3-编辑frp的服务端配置文件-1\"><a href=\"#3-编辑frp的服务端配置文件-1\" class=\"headerlink\" title=\"3.编辑frp的服务端配置文件\"></a>3.编辑frp的服务端配置文件</h3><p>vim frpc.ini</p>\n<pre><code class=\"shell\">[common]\nserver_addr = 47.106.228.4\nserver_port = 7001\n\n[ssh]\n#29的ssh端口映射\ntype = tcp\nlocal_ip = 192.168.197.29\nlocal_port = 22\nremote_port = 61000\n\n[www]\n#思创官网www.gzstrong.cn指向 www.gzstrong.com\ntype = http\nlocal_ip = 112.124.183.21\nlocal_port = 80\ncustom_domains = www.gzstrong.cn\n\n[myremote]\n#远程主机的端口映射\ntype = tcp\nlocal_ip = 192.168.197.223\nlocal_port = 3389\nremote_port = 61001\n\n[rep]\ntype = http\nlocal_ip = 192.168.197.67\nlocal_port = 9090\ncustom_domains = rep.gzstrong.cn\n\n[tomcat]\ntype = http\nlocal_ip = 192.168.197.29\nlocal_port = 8081 \ncustom_domains = tomcat.gzstrong.cn\n\n[mysql]\ntype = tcp\nlocal_ip = 192.168.197.205\nlocal_port = 3306\nremote_port = 61003</code></pre>\n<h3 id=\"4-启动frp的客户端\"><a href=\"#4-启动frp的客户端\" class=\"headerlink\" title=\"4.启动frp的客户端\"></a>4.启动frp的客户端</h3><pre><code class=\"shell\">nohup /soft/frp/frpc -c /soft/frp/frpc.ini&gt;/dev/null 2&gt;&amp;1 &amp;</code></pre>\n<h2 id=\"三、访问frp\"><a href=\"#三、访问frp\" class=\"headerlink\" title=\"三、访问frp\"></a>三、访问frp</h2><ul>\n<li><p>web端的服务</p>\n<p>因frp服务端的配置文件frps.ini中配置了</p>\n</li>\n</ul>\n<pre><code>vhost_http_port = 80 </code></pre><p>所以客户端的配置</p>\n<pre><code>[rep]\ntype = http\nlocal_ip = 192.168.197.67\nlocal_port = 9090\ncustom_domains = rep.gzstrong.cn</code></pre><p>这个配置中的192.168.197.67:9090可以映射成rep.gzstrong.cn</p>\n<p>即浏览器中直接输入<a href=\"http://rep.gzstrong.cn就可以访问到内网的机器192.168.197.67:9090\" target=\"_blank\" rel=\"noopener\">http://rep.gzstrong.cn就可以访问到内网的机器192.168.197.67:9090</a></p>\n<ul>\n<li><p>windows远程服务</p>\n<pre><code>[myremote]\n#远程主机的端口映射\ntype = tcp\nlocal_ip = 192.168.197.223\nlocal_port = 3389\nremote_port = 61001</code></pre><p>打开windows的远程mstsc</p>\n<p>输入<code>服务的ip地址:61001</code>即可访问到内网服务器的<code>192.168.197.223:3389</code>端口</p>\n</li>\n</ul>\n"},{"title":"javaEE教程","date":"2019-08-09T12:32:59.000Z","password":123,"abstract":"欢迎来到test, 请输入密码.","message":"欢迎来到test, 请输入密码.","toc":false,"mathjax":false,"_content":"\n\n\n## 多线程\n\n### Synchronized\n\n#### Synchronized使用方式有几种\n\nSynchronized可以使用在三个地方：\n\n1. 非静态方法\n2. 静态方法\n3. 代码块\n\n首先我们先看一个普通的多线程方法\n\n```\npublic class Main6  {\n\n    public void method1() {\n        System.out.println(\"method1 start\");\n        try {\n            System.out.println(\"method1 exec\");\n            Thread.sleep(3000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        System.out.println(\"method1 completion\");\n    }\n\n    public void method2() {\n        System.out.println(\"method2 start\");\n        try {\n            System.out.println(\"method2 exec\");\n            Thread.sleep(1000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        System.out.println(\"method2 completion\");\n    }\n\n    public static void main(String[] args) {\n        Main6 m1 = new Main6();\n        Main6 m2 = new Main6();\n\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                m1.method1();\n            }\n        }).start();\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                m1.method2();\n            }\n        }).start();\n    }\n}\n```\n\n在这个方法执行的时候，method1()和method2()并行运行，但由于method2()的运行时间短，因此总是会先运行结束。 \n\n1.非静态方法 \n\n```\npublic class Main6  {\n\n    public synchronized void method1() {\n        System.out.println(\"method1 start\");\n        try {\n            System.out.println(\"method1 exec\");\n            Thread.sleep(3000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        System.out.println(\"method1 completion\");\n    }\n\n    public synchronized void method2() {\n        System.out.println(\"method2 start\");\n        try {\n            System.out.println(\"method2 exec\");\n            Thread.sleep(1000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        System.out.println(\"method2 completion\");\n    }\n\n    public static void main(String[] args) {\n        Main6 m1 = new Main6();\n        Main6 m2 = new Main6();\n\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                m1.method1();\n            }\n        }).start();\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                m1.method2();\n            }\n        }).start();\n    }\n}\n```\n\n在非静态方法上添加synchronized关键字，当我们使用同一个对象分别在不同线程中调用该方法时候，会出现如下顺序的结果：\n\nmethod1 start\nmethod1 exec\nmethod1 completion\nmethod2 start\nmethod2 exec\nmethod2 completion\n\n这是由于synchronized会获取当前调用对象的锁，当线程1在执行m1.method1();时候获取到了m1对象的锁，线程2企图执行m1.method2()方法时发现m1的锁已经被其他线程获取，因此会进入阻塞状态，直到线程1对method1()方法执行完。\n\n注意，由于调用线程1的start()方法并不是一定会立即开始执行线程1，它先会与main线程争夺cpu等资源，因此有可能method2先执行，method1进入阻塞，直到method2执行完成后才会开始执行。\n\n同时由于synchronized使用在非静态方法上获取的是当前对象的锁，因此假如线程1和2分别使用的是两个不同对象的mthod1方法和method2方法，则不会发生阻塞。\n\n2.静态方法\n\n```\npublic class Main6  {\n\n    public static synchronized void method1() {\n        System.out.println(\"method1 start\");\n        try {\n            System.out.println(\"method1 exec\");\n            Thread.sleep(3000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        System.out.println(\"method1 completion\");\n    }\n\n    public static synchronized void method2() {\n        System.out.println(\"method2 start\");\n        try {\n            System.out.println(\"method2 exec\");\n            Thread.sleep(1000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        System.out.println(\"method2 completion\");\n    }\n\n    public static void main(String[] args) {\n        Main6 m1 = new Main6();\n        Main6 m2 = new Main6();\n\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                m1.method1();\n            }\n        }).start();\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                m2.method2();\n            }\n        }).start();\n    }\n}\n```\n\n静态方法与非静态方法的不同处在于方法是属于类，而不是属于当前对象。\n\n这样即使我们调用的是不同对象的method1方法和method2方法，但是它们获取的锁是类对象的锁(Class对象的锁)，因此，不论使用的是哪个对象的method1和method2，均会发生线程阻塞的情况。只有当一个线程中的静态synchronized执行完成后才会执行另一个线程中的静态synchronized方法。\n\n3.代码块\n\n```\npublic class Main6  {\n\n    public void method1() {\n        System.out.println(\"method1 start\");\n        synchronized(this) {\n            try {\n                System.out.println(\"method1 exec\");\n                Thread.sleep(3000);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n        System.out.println(\"method1 completion\");\n    }\n\n    public void method2() {\n        System.out.println(\"method2 start\");\n        synchronized (this) {\n            try {\n                System.out.println(\"method2 exec\");\n                Thread.sleep(1000);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n        System.out.println(\"method2 completion\");\n    }\n\n    public static void main(String[] args) {\n        Main6 m1 = new Main6();new Thread(new Runnable() {\n            @Override\n            public void run() {\n                m1.method1();\n            }\n        }).start();\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                m1.method2();\n            }\n        }).start();\n    }\n}\n```\n\n输出的结果可能如下：\n\nmethod1 start\nmethod1 exec\nmethod2 start\nmethod1 completion\nmethod2 exec\nmethod2 completion\n\n当synchronized被使用在代码块上时，它所获取的锁是括号中接收的对象的锁(如样例代码中的this指代的是当前调用它的对象)，这样，假设method1方法正在执行，并且进入代码块休眠3秒，这时method2获取cpu，开始执行第一行代码打印\"method2 start\"，然后遇见代码块，尝试获取this对象的锁，却发现已经被method1获取(sleet不释放锁)，因此method2进入阻塞状态，直到method1执行完毕后释放锁，method2获取锁开始执行代码块。\n\n#### synchronized的案例分析\n\n**（1）标准访问，先打印短信还是邮件**\n\n```\npublic class Phone {\n    public synchronized void sendSMS(){\n            System.out.println(\"----sendSMS\");\n    }\n    public synchronized void sendEmail(){\n        System.out.println(\"----sendEmail\");\n    }\n    public static void main(String[] args) throws InterruptedException {\n        Phone phone = new Phone();\n        new Thread(()->{phone.sendSMS();},\"AA\").start();\n        Thread.sleep(1000); //让A先启动\n        new Thread(()->{phone.sendEmail();},\"BB\").start();\n    }\n}\n```\n\n----sendSMS\n----sendEmail\n\n由于方法上的锁是this，同样的phone对象，A先进入方法，获取到锁，B只能等待\n\n**（2）短信方法内停4秒，先打印短信还是邮件**\n\n```\npublic class Phone {\n    public synchronized void sendSMS(){\n        try {\n            Thread.sleep(4000);\n            System.out.println(\"----sendSMS\");\n        }catch (Exception e){}\n    }\n    public synchronized void sendEmail(){\n        System.out.println(\"----sendEmail\");\n    }\n    public static void main(String[] args) throws InterruptedException {\n        Phone phone = new Phone();\n        new Thread(()->{phone.sendSMS();},\"AA\").start();\n        Thread.sleep(1000); //让A先启动\n        new Thread(()->{phone.sendEmail();},\"BB\").start();\n    }\n}\n```\n\n----sendSMS\n----sendEmail\n\n由于方法上的锁是this，同样的phone对象，A先进入方法，获取到锁，且sleep方法是不释放锁的，B只能等待A先打印sendEmail\n\n**（3）新增的hello方法，先打印短信还是hello**\n\n```\npublic class Phone {\n    public synchronized void sendSMS(){\n        try {\n            Thread.sleep(4000);\n            System.out.println(\"----sendSMS\");\n        }catch (Exception e){ }\n    }\n    public void getHello(){\n        System.out.println(\"----getHello\");\n    }\n\n    public static void main(String[] args) throws InterruptedException {\n        Phone phone = new Phone();\n        new Thread(()->{phone.sendSMS();},\"AA\").start();\n        Thread.sleep(1000); //让A先启动\n        new Thread(()->{phone.getHello();},\"BB\").start();\n    }\n}\n```\n\n----getHello\n\n----sendSMS\n\n没有和锁有关系\n\n**（4）现有2部手机，先打印短信还是邮件**\n\n```\npublic class Phone {\n    public synchronized void sendSMS(){\n        try {\n            Thread.sleep(4000);\n            System.out.println(\"----sendSMS\");\n        }catch (Exception e){ }\n    }\n    public synchronized void sendEmail(){\n        System.out.println(\"----sendEmail\");\n    }\n    public static void main(String[] args) throws InterruptedException {\n        Phone phone1 = new Phone();\n        Phone phone2 = new Phone();\n        new Thread(()->{phone1.sendSMS();},\"AA\").start();\n        Thread.sleep(1000); //让A先启动\n        new Thread(()->{phone2.sendEmail();},\"BB\").start();\n    }\n}\n```\n\n----sendEmail\n----sendSMS\n\n2部手机，由于方法上的锁是this，不同的phone对象，各自维护，sendSMS睡眠了4秒，先打印sendEmail\n\n**（4）两个静态同步方法，1部手机，先打印短信还是邮件**\n\n```\npublic class Phone {\n    public static synchronized void sendSMS(){\n        try {\n            Thread.sleep(4000);\n            System.out.println(\"----sendSMS\");\n        }catch (Exception e){ }\n    }\n    public static synchronized void sendEmail(){\n        System.out.println(\"----sendEmail\");\n    }\n    public static void main(String[] args) throws InterruptedException {\n        Phone phone1 = new Phone();\n        new Thread(()->{phone1.sendSMS();},\"AA\").start();\n        Thread.sleep(1000); //让A先启动\n        new Thread(()->{phone1.sendEmail();},\"BB\").start();\n    }\n}\n```\n\n----sendSMS\n\n----sendEmail\n\n静态方法的锁是类的class字节码，只有一份，所以A先进入方法，获取到锁，B只能等待A\n\n**（4）两个静态同步方法，2部手机，先打印短信还是邮件**\n\n```\npublic class Phone {\n    public static synchronized void sendSMS(){\n        try {\n            Thread.sleep(4000);\n            System.out.println(\"----sendSMS\");\n        }catch (Exception e){ }\n    }\n    public static synchronized void sendEmail(){\n        System.out.println(\"----sendEmail\");\n    }\n    public void getHello(){\n        System.out.println(\"----getHello\");\n    }\n    public static void main(String[] args) throws InterruptedException {\n        Phone phone1 = new Phone();\n        Phone phone2 = new Phone();\n        new Thread(()->{phone1.sendSMS();},\"AA\").start();\n        Thread.sleep(1000); //让A先启动\n        new Thread(()->{phone2.sendEmail();},\"BB\").start();\n    }\n}\n```\n\n----sendSMS\n\n----sendEmail\n\n静态方法的锁是类的class字节码，虽然是不同的对象调用，但是字节码还是只有一份，所以A先进入方法，获取到锁，B只能等待A\n\n**（5）一个静态方法，一个普通方法，先打印短信还是邮件**\n\n```\npublic class Phone {\n    public static synchronized void sendSMS(){\n        try {\n            Thread.sleep(4000);\n            System.out.println(\"----sendSMS\");\n        }catch (Exception e){ }\n    }\n    public synchronized void sendEmail(){\n        System.out.println(\"----sendEmail\");\n    }\n    public static void main(String[] args) throws InterruptedException {\n        Phone phone = new Phone();\n        new Thread(()->{phone.sendSMS();},\"AA\").start();\n        Thread.sleep(1000); //让A先启动\n        new Thread(()->{phone.sendEmail();},\"BB\").start();\n    }\n}\n```\n\n\n\n\n\n\n\n#### [synchronized(this) 与synchronized(class) 之间的区别](https://www.cnblogs.com/huansky/p/8869888.html)\n\n###  ReentrantLock\n\n\n\n\n\n####  ReentrantReadWriteLock读写锁获取数据\n\n1个线程写数据，100个线程读取数据\n\n```\npublic class ReentrantReadWriteTest {\n    ReentrantReadWriteLock lock=new ReentrantReadWriteLock();\n    private Object obj;\n    public void write(Object obj){\n        lock.writeLock().lock();\n        this.obj=obj;\n        System.out.println(Thread.currentThread().getName()+\"set--\"+this.obj);\n        lock.writeLock().unlock();\n    }\n    public void get(){\n        lock.readLock().lock();\n        System.out.println(Thread.currentThread().getName()+\"--get---\"+this.obj);\n        lock.readLock().unlock();\n    }\n    public static void main(String[] args){\n        ReentrantReadWriteTest rw = new ReentrantReadWriteTest();\n        new Thread(()->{rw.write(\"测试\");},\"write\").start();\n        for (int i = 0; i < 100; i++) {\n            new Thread(()->{rw.get();},\"read--\"+i).start();\n        }\n    }\n}\n```\n\n\n\n###  CountDownLatch\n\n**CoundDownLatch**这个类能够**使一个线程等待其他线程完成各自的工作后再执行**。例如，应用程序的主线程希望在负责启动框架服务的线程已经启动所有的框架服务之后再执行。 \n\n编写20个同学离开教室之后，班长才锁门\n\n```\npublic class CountDownLatchTest {\n    public static void main(String[] args) {\n        CountDownLatch cd = new CountDownLatch(20);\n        for (int i = 0; i < 20; i++) {\n            new Thread(()->{\n                try {\n                    Thread.sleep(1000);\n                    System.out.println(Thread.currentThread().getName()+\"离开教室\");\n                    cd.countDown();\n                } catch (InterruptedException e) {}\n            },\"线程\"+i).start();\n        }\n        new Thread(()->{\n            try {\n                cd.await();\n            } catch (InterruptedException e) {}\n            System.out.println(\"班长锁门\");\n        },\"线程\").start();\n    }\n}\n```\n\n###   CyclicBarrier\n\n**CyclicBarrier**和**CountDownLatch**是非常类似的，**CyclicBarrier**核心的概念是在于设置一个等待线程的数量边界，到达了此边界之后进行执行。\n\n**CyclicBarrier**类是一个同步辅助类，它允许一组线程互相等待，直到到达某个公共屏障点（Common Barrier Point）。\n\n**CyclicBarrier**类是一种同步机制，它能够对处理一些算法的线程实现同。换句话讲，它就是一个所有线程必须等待的一个栅栏，直到所有线程都到达这里，然后所有线程才可以继续做其他事情。\n\n\n\n\n\n\n\n###   多线程代码编写\n\n####  （一）依次打印数字和字母\n\n * 12A34B56C78D910E1112F1314G1516H1718I1920J2122K2324L2526M2728N2930O3132P3334Q3536R3738S3940T4142U4344V4546W4748X4950Y5152Z\n\n   **（1）使用等待唤醒机制**\n\n```\npackage com.gzstrong.t;\npublic class NumChar {\n    private int n=1;\n    private int e=65;\n    private boolean flag=true;\n    public synchronized  void getNum(){\n        for (int i=n;i<53;i=i+2) {\n            try {\n                while (!flag){\n                    this.wait();\n                }\n                System.out.print(i+\"\"+(i+1));\n                flag=false;\n            } catch (InterruptedException e1) {\n                e1.printStackTrace();\n            }\n            this.notify();\n        }\n    }\n\n    public synchronized  void getChar() {\n        for (int i=e;i<91;i++) {\n            try {\n                while (flag){\n                    this.wait();\n                }\n                System.out.print((char)i);\n                flag=true;\n            } catch (InterruptedException e1) {\n                e1.printStackTrace();\n            }\n            this.notify();\n        }\n    }\n\n    public static void main(String[] args) {\n        NumChar numChar = new NumChar();\n        new Thread(()->{\n            numChar.getNum();\n        }).start();\n        new Thread(()->{\n            numChar.getChar();\n        }).start();\n    }\n}\n```\n\n**（2）使用ReentrantLock方式**\n\n```\npackage com.gzstrong.t;\n\nimport java.util.concurrent.locks.Condition;\nimport java.util.concurrent.locks.Lock;\nimport java.util.concurrent.locks.ReentrantLock;\n\npublic class NumCharLock {\n    private int n=1;\n    private int e=65;\n    private boolean flag=true;\n    Lock lock=new ReentrantLock();\n    Condition condition = lock.newCondition();\n    public void getNum(){\n        lock.lock();\n        for (int i=n;i<53;i=i+2) {\n            while (!flag){\n                try {\n                    condition.await();\n                } catch (InterruptedException e1) {\n                    e1.printStackTrace();\n                }\n            }\n            System.out.print(i+\"\"+(i+1));\n            flag=false;\n            condition.signal();\n        }\n        lock.unlock();\n    }\n\n    public  void getChar() {\n        lock.lock();\n        for (int i=e;i<91;i++) {\n            while (flag){\n                try {\n                    condition.await();\n                } catch (InterruptedException e1) {\n                    e1.printStackTrace();\n                }\n            }\n            System.out.print((char)i);\n            flag=true;\n            condition.signal();\n        }\n        lock.unlock();\n    }\n\n    public static void main(String[] args) {\n        NumCharLock numAA = new NumCharLock();\n        new Thread(()->{\n            numAA.getNum();\n        }).start();\n        new Thread(()->{\n            numAA.getChar();\n        }).start();\n    }\n}\n```\n\n\n\n##  Spring Cloud Alibaba学习\n\n###  一.Nacos\n\n#### 1.配置中心\n\nspringboot 启动报错\n\nthis is very likely to create a memory leak.\n\n\n\n### 二.Apollo\n\n####  (一)Apollo分布式配置中心部署\n\n**1.下载源码**\n\nhttps://github.com/ctripcorp/apollo\n\n比较重要的几个项目：\n\n- apollo-configservice：提供配置获取接口，提供配置更新推送接口，接口服务对象为Apollo客户端\n- apollo-adminservice：提供配置管理接口，提供配置修改、发布等接口，接口服务对象为Portal，以及Eureka\n\n- apollo-portal：提供Web界面供用户管理配置\n\n- apollo-client：Apollo提供的客户端程序，为应用提供配置获取、实时更新等功能\n\n**2.配置中心执行流程**\n\n- 用户在Portal操作配置发布\n- Portal调用Admin Service的接口操作发布\n- Admin Service发布配置后，发送ReleaseMessage给各个Config Service\n- Config Service收到ReleaseMessage后，通知对应的客户端\n\n**3.数据库初始化**\n下面的sql为大写格式，注意数据库的大小写敏感设置\n\n- ApolloPortalDB：执行apollo-master\\scripts\\db\\migration\\portaldb\\V1.0.0__initialization.sql\n- ApolloConfigDB：执行apollo-master\\scripts\\db\\migration\\configdb\\V1.0.0__initialization.sql\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904170710.png)\n\n**4.调整项目配置**\n\n\n\n### 三.Sentinel\n\n#### (一)Spring Cloud Alibaba整合Sentinel流控\n\n##### 1.部署Sentinel Dashboard\n\n- 下载地址：[sentinel-dashboard-1.6.0.jar](https://github.com/alibaba/Sentinel/releases/download/1.6.0/sentinel-dashboard-1.6.0.jar)\n- 其他版本：[Sentinel/releases](https://github.com/alibaba/Sentinel/releases)\n\n```shell\njava -jar sentinel-dashboard-1.6.0.jar  \n```\n\n要自定义端口号等内容的话，可以通过在启动命令中增加参数来调整，比如：`-Dserver.port=8888`\n\n默认情况下，sentinel-dashboard以8080端口启动，所以可以通过访问：`localhost:8080`来验证是否已经启动成功 \n\n> **注意**：只有1.6.0及以上版本，才有这个简单的登录页面。默认用户名和密码都是`sentinel`。对于用户登录的相关配置可以在启动命令中增加下面的参数来进行配置：\n\n- `-Dsentinel.dashboard.auth.username=sentinel`: 用于指定控制台的登录用户名为 sentinel；\n- `-Dsentinel.dashboard.auth.password=123456`: 用于指定控制台的登录密码为 123456；如果省略这两个参数，默认用户和密码均为 sentinel\n- `-Dserver.servlet.session.timeout=7200`: 用于指定 Spring Boot 服务端 session 的过期时间，如 7200 表示 7200 秒；60m 表示 60 分钟，默认为 30 分钟； \n\n#####  2.整合Sentinel\n\n（1）在gzstrong-system应用的`build.gradle`中引入Spring Cloud Alibaba的Sentinel模块： \n\n```java\n      compile(\"org.springframework.cloud:spring-cloud-starter-alibaba-sentinel:0.2.2.RELEASE\")\n```\n\n（2）在Spring Cloud应用中通过`spring.cloud.sentinel.transport.dashboard`参数配置sentinel dashboard的访问地址，比如： \n\n```java\nspring.cloud.sentinel.transport.dashboard=localhost:8080\n```\n\n（3）创建应用主类，并提供一个rest接口，比如： \n\n```java\npackage com.gzstrong;\n\nimport com.alibaba.csp.sentinel.annotation.SentinelResource;\nimport com.alibaba.csp.sentinel.annotation.aspectj.SentinelResourceAspect;\nimport com.alibaba.csp.sentinel.slots.block.BlockException;\nimport lombok.extern.slf4j.Slf4j;\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;\nimport org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration;\nimport org.springframework.cloud.client.discovery.EnableDiscoveryClient;\nimport org.springframework.cloud.openfeign.EnableFeignClients;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.RestController;\n\n@SpringBootApplication(exclude = DataSourceAutoConfiguration.class)\n@EnableDiscoveryClient\n@EnableFeignClients\npublic class SystemApp {\n    public static void main(String[] args) {\n        SpringApplication.run(SystemApp.class, args);\n    }\n\n    @Slf4j\n    @RestController\n    static class TestController {\n\n        @SentinelResource(value=\"hello-anon\",blockHandler=\"handleException\",blockHandlerClass=ExceptionUtil.class)\n        @GetMapping(\"/hello-anon\")\n        public String hello() {\n            return \"didispace.com\";\n        }\n\n    }\n\n    @Bean\n    @ConditionalOnMissingBean\n    public SentinelResourceAspect sentinelResourceAspect() {\n        return new SentinelResourceAspect();\n    }\n\n}\nclass ExceptionUtil {\n    public static String handleException(BlockException ex) {\n        return \"扛不住了啊....\";\n    }\n}\n```\n\n启动应用，然后通过postman或者curl访问几下`localhost:9097/hello-anon`接口 \n\n##  Git使用\n\n###  1.初始化仓库\n\n**查看状态**\n\ngit status  查看工作区代码相对于暂存区的差别\n\n###  2.移除版本控制\n\ngit rm -r --cached \".gradle/\"\n\n###  3.添加忽略文件规则\n\ntouch .gitignore\n\n忽略文件的规则\n\n```\n#               表示此为注释,将被Git忽略\n*.a             表示忽略所有 .a 结尾的文件\n!lib.a          表示但lib.a除外\n/TODO           表示仅仅忽略项目根目录下的 TODO 文件，不包括 subdir/TODO\nbuild/          表示忽略 build/目录下的所有文件，过滤整个build文件夹；\ndoc/*.txt       表示会忽略doc/notes.txt但不包括 doc/server/arch.txt\n \nbin/:           表示忽略当前路径下的bin文件夹，该文件夹下的所有内容都会被忽略，不忽略 bin 文件\n/bin:           表示忽略根目录下的bin文件\n/*.c:           表示忽略cat.c，不忽略 build/cat.c\ndebug/*.obj:    表示忽略debug/io.obj，不忽略 debug/common/io.obj和tools/debug/io.obj\n**/foo:         表示忽略/foo,a/foo,a/b/foo等\na/**/b:         表示忽略a/b, a/x/b,a/x/y/b等\n!/bin/run.sh    表示不忽略bin目录下的run.sh文件\n*.log:          表示忽略所有 .log 文件\nconfig.php:     表示忽略当前路径的 config.php 文件\n \n/mtk/           表示过滤整个文件夹\n*.zip           表示过滤所有.zip文件\n/mtk/do.c       表示过滤某个具体文件\n```\n\n###  4.添加到暂存区\n\ngit add .   不加参数默认为将修改操作的文件和未跟踪新添加的文件添加到git系统的暂存区，注意不包括删除\n\n###  5.提交到本地的版本库\n\ngit commit -m ‘message’  -m 参数表示注释\n\n###  6.将本地版本库的分支推送到远程服务器\n\n\n\n###  7.更新代码到本地仓库\n\ngit pull \n\n###  8.分支\n\ngit branch  查看分支\n\ngit chechout aaa 切换分支aaa   \n\ngit branck aaa 创建aaa分支\n\n## JMeter并发\n\n###  1 添加线程组\n\n右键点击“测试计划” -> “添加” -> “Threads(Users)” -> “线程组” \n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904170759.png)\n\n这里可以配置线程组名称，线程数，准备时长（Ramp-Up Period(in seconds)）循环次数，调度器等参数：\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904170826.png)\n\n线程组参数详解： \n\n1. 线程数：设置多少个线程数  \n2. Ramp-Up Period(in seconds)准备时长：线程数 需要多长时间全部启动。如果线程数为10，准备时长为2，那么需要2秒钟启动10个线程，也就是每秒钟启动5个线程。  一般为好理解设为1\n3. 循环次数：每个线程发送请求的次数。如果线程数为10，循环次数为100，那么每个线程发送100次请求。总请求数为10*100=1000 。如果勾选了“永远”，那么所有线程会一直发送请求，一到选择停止运行脚本。  \n4. Delay Thread creation until needed：直到需要时延迟线程的创建。  \n5. 调度器：设置线程组启动的开始时间和结束时间(配置调度器时，需要勾选循环次数为永远)  持续时间（秒）：测试持续时间，会覆盖结束时间  启动延迟（秒）：测试延迟启动时间，会覆盖启动时间  启动时间：测试启动时间，启动延迟会覆盖它。当启动时间已过，手动只需测试时当前时间也会覆盖它。  结束时间：测试结束时间，持续时间会覆盖它。因为接口调试需要，我们暂时均使用默认设置，待后面真正执行性能测试时再回来配置\n\n###  2 添加HTTP请求\n\n右键点击“线程组” -> “添加” -> “Sampler” -> “HTTP请求” \n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904170855.png)\n\n对于我们的接口<http://www.baidu.com/s?ie=utf-8&wd=jmeter>性能测试，可以参考下图填写：\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904170912.png)\n\n Http请求主要参数详解：\n\nWeb服务器  协议：向目标服务器发送HTTP请求协议，可以是HTTP或HTTPS，默认为HTTP  \n\n服务器名称或IP ：HTTP请求发送的目标服务器名称或IP  \n\n端口号：目标服务器的端口号，默认值为80  2.Http请求  方法：发送HTTP请求的方法，可用方法包括GET、POST、HEAD、PUT、OPTIONS、TRACE、DELETE等。  路径：目标URL路径（URL中去掉服务器地址、端口及参数后剩余部分）  Content encoding ：编码方式，默认为ISO-8859-1编码，这里配置为utf-8同请求一起发送参数  在请求中发送的URL参数，用户可以将URL中所有参数设置在本表中，表中每行为一个参数（对应URL中的 name=value），注意参数传入中文时需要勾选“编码”","source":"_posts/总-javaEE.md","raw":"---\ntitle: javaEE教程\ndate: 2019-08-09 20:32:59\npassword: 123\nabstract: 欢迎来到test, 请输入密码.\nmessage: 欢迎来到test, 请输入密码.\ntoc: false\nmathjax: false\ntags:  [汇总] \ncategory: 汇总\n---\n\n\n\n## 多线程\n\n### Synchronized\n\n#### Synchronized使用方式有几种\n\nSynchronized可以使用在三个地方：\n\n1. 非静态方法\n2. 静态方法\n3. 代码块\n\n首先我们先看一个普通的多线程方法\n\n```\npublic class Main6  {\n\n    public void method1() {\n        System.out.println(\"method1 start\");\n        try {\n            System.out.println(\"method1 exec\");\n            Thread.sleep(3000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        System.out.println(\"method1 completion\");\n    }\n\n    public void method2() {\n        System.out.println(\"method2 start\");\n        try {\n            System.out.println(\"method2 exec\");\n            Thread.sleep(1000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        System.out.println(\"method2 completion\");\n    }\n\n    public static void main(String[] args) {\n        Main6 m1 = new Main6();\n        Main6 m2 = new Main6();\n\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                m1.method1();\n            }\n        }).start();\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                m1.method2();\n            }\n        }).start();\n    }\n}\n```\n\n在这个方法执行的时候，method1()和method2()并行运行，但由于method2()的运行时间短，因此总是会先运行结束。 \n\n1.非静态方法 \n\n```\npublic class Main6  {\n\n    public synchronized void method1() {\n        System.out.println(\"method1 start\");\n        try {\n            System.out.println(\"method1 exec\");\n            Thread.sleep(3000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        System.out.println(\"method1 completion\");\n    }\n\n    public synchronized void method2() {\n        System.out.println(\"method2 start\");\n        try {\n            System.out.println(\"method2 exec\");\n            Thread.sleep(1000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        System.out.println(\"method2 completion\");\n    }\n\n    public static void main(String[] args) {\n        Main6 m1 = new Main6();\n        Main6 m2 = new Main6();\n\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                m1.method1();\n            }\n        }).start();\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                m1.method2();\n            }\n        }).start();\n    }\n}\n```\n\n在非静态方法上添加synchronized关键字，当我们使用同一个对象分别在不同线程中调用该方法时候，会出现如下顺序的结果：\n\nmethod1 start\nmethod1 exec\nmethod1 completion\nmethod2 start\nmethod2 exec\nmethod2 completion\n\n这是由于synchronized会获取当前调用对象的锁，当线程1在执行m1.method1();时候获取到了m1对象的锁，线程2企图执行m1.method2()方法时发现m1的锁已经被其他线程获取，因此会进入阻塞状态，直到线程1对method1()方法执行完。\n\n注意，由于调用线程1的start()方法并不是一定会立即开始执行线程1，它先会与main线程争夺cpu等资源，因此有可能method2先执行，method1进入阻塞，直到method2执行完成后才会开始执行。\n\n同时由于synchronized使用在非静态方法上获取的是当前对象的锁，因此假如线程1和2分别使用的是两个不同对象的mthod1方法和method2方法，则不会发生阻塞。\n\n2.静态方法\n\n```\npublic class Main6  {\n\n    public static synchronized void method1() {\n        System.out.println(\"method1 start\");\n        try {\n            System.out.println(\"method1 exec\");\n            Thread.sleep(3000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        System.out.println(\"method1 completion\");\n    }\n\n    public static synchronized void method2() {\n        System.out.println(\"method2 start\");\n        try {\n            System.out.println(\"method2 exec\");\n            Thread.sleep(1000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        System.out.println(\"method2 completion\");\n    }\n\n    public static void main(String[] args) {\n        Main6 m1 = new Main6();\n        Main6 m2 = new Main6();\n\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                m1.method1();\n            }\n        }).start();\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                m2.method2();\n            }\n        }).start();\n    }\n}\n```\n\n静态方法与非静态方法的不同处在于方法是属于类，而不是属于当前对象。\n\n这样即使我们调用的是不同对象的method1方法和method2方法，但是它们获取的锁是类对象的锁(Class对象的锁)，因此，不论使用的是哪个对象的method1和method2，均会发生线程阻塞的情况。只有当一个线程中的静态synchronized执行完成后才会执行另一个线程中的静态synchronized方法。\n\n3.代码块\n\n```\npublic class Main6  {\n\n    public void method1() {\n        System.out.println(\"method1 start\");\n        synchronized(this) {\n            try {\n                System.out.println(\"method1 exec\");\n                Thread.sleep(3000);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n        System.out.println(\"method1 completion\");\n    }\n\n    public void method2() {\n        System.out.println(\"method2 start\");\n        synchronized (this) {\n            try {\n                System.out.println(\"method2 exec\");\n                Thread.sleep(1000);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n        System.out.println(\"method2 completion\");\n    }\n\n    public static void main(String[] args) {\n        Main6 m1 = new Main6();new Thread(new Runnable() {\n            @Override\n            public void run() {\n                m1.method1();\n            }\n        }).start();\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                m1.method2();\n            }\n        }).start();\n    }\n}\n```\n\n输出的结果可能如下：\n\nmethod1 start\nmethod1 exec\nmethod2 start\nmethod1 completion\nmethod2 exec\nmethod2 completion\n\n当synchronized被使用在代码块上时，它所获取的锁是括号中接收的对象的锁(如样例代码中的this指代的是当前调用它的对象)，这样，假设method1方法正在执行，并且进入代码块休眠3秒，这时method2获取cpu，开始执行第一行代码打印\"method2 start\"，然后遇见代码块，尝试获取this对象的锁，却发现已经被method1获取(sleet不释放锁)，因此method2进入阻塞状态，直到method1执行完毕后释放锁，method2获取锁开始执行代码块。\n\n#### synchronized的案例分析\n\n**（1）标准访问，先打印短信还是邮件**\n\n```\npublic class Phone {\n    public synchronized void sendSMS(){\n            System.out.println(\"----sendSMS\");\n    }\n    public synchronized void sendEmail(){\n        System.out.println(\"----sendEmail\");\n    }\n    public static void main(String[] args) throws InterruptedException {\n        Phone phone = new Phone();\n        new Thread(()->{phone.sendSMS();},\"AA\").start();\n        Thread.sleep(1000); //让A先启动\n        new Thread(()->{phone.sendEmail();},\"BB\").start();\n    }\n}\n```\n\n----sendSMS\n----sendEmail\n\n由于方法上的锁是this，同样的phone对象，A先进入方法，获取到锁，B只能等待\n\n**（2）短信方法内停4秒，先打印短信还是邮件**\n\n```\npublic class Phone {\n    public synchronized void sendSMS(){\n        try {\n            Thread.sleep(4000);\n            System.out.println(\"----sendSMS\");\n        }catch (Exception e){}\n    }\n    public synchronized void sendEmail(){\n        System.out.println(\"----sendEmail\");\n    }\n    public static void main(String[] args) throws InterruptedException {\n        Phone phone = new Phone();\n        new Thread(()->{phone.sendSMS();},\"AA\").start();\n        Thread.sleep(1000); //让A先启动\n        new Thread(()->{phone.sendEmail();},\"BB\").start();\n    }\n}\n```\n\n----sendSMS\n----sendEmail\n\n由于方法上的锁是this，同样的phone对象，A先进入方法，获取到锁，且sleep方法是不释放锁的，B只能等待A先打印sendEmail\n\n**（3）新增的hello方法，先打印短信还是hello**\n\n```\npublic class Phone {\n    public synchronized void sendSMS(){\n        try {\n            Thread.sleep(4000);\n            System.out.println(\"----sendSMS\");\n        }catch (Exception e){ }\n    }\n    public void getHello(){\n        System.out.println(\"----getHello\");\n    }\n\n    public static void main(String[] args) throws InterruptedException {\n        Phone phone = new Phone();\n        new Thread(()->{phone.sendSMS();},\"AA\").start();\n        Thread.sleep(1000); //让A先启动\n        new Thread(()->{phone.getHello();},\"BB\").start();\n    }\n}\n```\n\n----getHello\n\n----sendSMS\n\n没有和锁有关系\n\n**（4）现有2部手机，先打印短信还是邮件**\n\n```\npublic class Phone {\n    public synchronized void sendSMS(){\n        try {\n            Thread.sleep(4000);\n            System.out.println(\"----sendSMS\");\n        }catch (Exception e){ }\n    }\n    public synchronized void sendEmail(){\n        System.out.println(\"----sendEmail\");\n    }\n    public static void main(String[] args) throws InterruptedException {\n        Phone phone1 = new Phone();\n        Phone phone2 = new Phone();\n        new Thread(()->{phone1.sendSMS();},\"AA\").start();\n        Thread.sleep(1000); //让A先启动\n        new Thread(()->{phone2.sendEmail();},\"BB\").start();\n    }\n}\n```\n\n----sendEmail\n----sendSMS\n\n2部手机，由于方法上的锁是this，不同的phone对象，各自维护，sendSMS睡眠了4秒，先打印sendEmail\n\n**（4）两个静态同步方法，1部手机，先打印短信还是邮件**\n\n```\npublic class Phone {\n    public static synchronized void sendSMS(){\n        try {\n            Thread.sleep(4000);\n            System.out.println(\"----sendSMS\");\n        }catch (Exception e){ }\n    }\n    public static synchronized void sendEmail(){\n        System.out.println(\"----sendEmail\");\n    }\n    public static void main(String[] args) throws InterruptedException {\n        Phone phone1 = new Phone();\n        new Thread(()->{phone1.sendSMS();},\"AA\").start();\n        Thread.sleep(1000); //让A先启动\n        new Thread(()->{phone1.sendEmail();},\"BB\").start();\n    }\n}\n```\n\n----sendSMS\n\n----sendEmail\n\n静态方法的锁是类的class字节码，只有一份，所以A先进入方法，获取到锁，B只能等待A\n\n**（4）两个静态同步方法，2部手机，先打印短信还是邮件**\n\n```\npublic class Phone {\n    public static synchronized void sendSMS(){\n        try {\n            Thread.sleep(4000);\n            System.out.println(\"----sendSMS\");\n        }catch (Exception e){ }\n    }\n    public static synchronized void sendEmail(){\n        System.out.println(\"----sendEmail\");\n    }\n    public void getHello(){\n        System.out.println(\"----getHello\");\n    }\n    public static void main(String[] args) throws InterruptedException {\n        Phone phone1 = new Phone();\n        Phone phone2 = new Phone();\n        new Thread(()->{phone1.sendSMS();},\"AA\").start();\n        Thread.sleep(1000); //让A先启动\n        new Thread(()->{phone2.sendEmail();},\"BB\").start();\n    }\n}\n```\n\n----sendSMS\n\n----sendEmail\n\n静态方法的锁是类的class字节码，虽然是不同的对象调用，但是字节码还是只有一份，所以A先进入方法，获取到锁，B只能等待A\n\n**（5）一个静态方法，一个普通方法，先打印短信还是邮件**\n\n```\npublic class Phone {\n    public static synchronized void sendSMS(){\n        try {\n            Thread.sleep(4000);\n            System.out.println(\"----sendSMS\");\n        }catch (Exception e){ }\n    }\n    public synchronized void sendEmail(){\n        System.out.println(\"----sendEmail\");\n    }\n    public static void main(String[] args) throws InterruptedException {\n        Phone phone = new Phone();\n        new Thread(()->{phone.sendSMS();},\"AA\").start();\n        Thread.sleep(1000); //让A先启动\n        new Thread(()->{phone.sendEmail();},\"BB\").start();\n    }\n}\n```\n\n\n\n\n\n\n\n#### [synchronized(this) 与synchronized(class) 之间的区别](https://www.cnblogs.com/huansky/p/8869888.html)\n\n###  ReentrantLock\n\n\n\n\n\n####  ReentrantReadWriteLock读写锁获取数据\n\n1个线程写数据，100个线程读取数据\n\n```\npublic class ReentrantReadWriteTest {\n    ReentrantReadWriteLock lock=new ReentrantReadWriteLock();\n    private Object obj;\n    public void write(Object obj){\n        lock.writeLock().lock();\n        this.obj=obj;\n        System.out.println(Thread.currentThread().getName()+\"set--\"+this.obj);\n        lock.writeLock().unlock();\n    }\n    public void get(){\n        lock.readLock().lock();\n        System.out.println(Thread.currentThread().getName()+\"--get---\"+this.obj);\n        lock.readLock().unlock();\n    }\n    public static void main(String[] args){\n        ReentrantReadWriteTest rw = new ReentrantReadWriteTest();\n        new Thread(()->{rw.write(\"测试\");},\"write\").start();\n        for (int i = 0; i < 100; i++) {\n            new Thread(()->{rw.get();},\"read--\"+i).start();\n        }\n    }\n}\n```\n\n\n\n###  CountDownLatch\n\n**CoundDownLatch**这个类能够**使一个线程等待其他线程完成各自的工作后再执行**。例如，应用程序的主线程希望在负责启动框架服务的线程已经启动所有的框架服务之后再执行。 \n\n编写20个同学离开教室之后，班长才锁门\n\n```\npublic class CountDownLatchTest {\n    public static void main(String[] args) {\n        CountDownLatch cd = new CountDownLatch(20);\n        for (int i = 0; i < 20; i++) {\n            new Thread(()->{\n                try {\n                    Thread.sleep(1000);\n                    System.out.println(Thread.currentThread().getName()+\"离开教室\");\n                    cd.countDown();\n                } catch (InterruptedException e) {}\n            },\"线程\"+i).start();\n        }\n        new Thread(()->{\n            try {\n                cd.await();\n            } catch (InterruptedException e) {}\n            System.out.println(\"班长锁门\");\n        },\"线程\").start();\n    }\n}\n```\n\n###   CyclicBarrier\n\n**CyclicBarrier**和**CountDownLatch**是非常类似的，**CyclicBarrier**核心的概念是在于设置一个等待线程的数量边界，到达了此边界之后进行执行。\n\n**CyclicBarrier**类是一个同步辅助类，它允许一组线程互相等待，直到到达某个公共屏障点（Common Barrier Point）。\n\n**CyclicBarrier**类是一种同步机制，它能够对处理一些算法的线程实现同。换句话讲，它就是一个所有线程必须等待的一个栅栏，直到所有线程都到达这里，然后所有线程才可以继续做其他事情。\n\n\n\n\n\n\n\n###   多线程代码编写\n\n####  （一）依次打印数字和字母\n\n * 12A34B56C78D910E1112F1314G1516H1718I1920J2122K2324L2526M2728N2930O3132P3334Q3536R3738S3940T4142U4344V4546W4748X4950Y5152Z\n\n   **（1）使用等待唤醒机制**\n\n```\npackage com.gzstrong.t;\npublic class NumChar {\n    private int n=1;\n    private int e=65;\n    private boolean flag=true;\n    public synchronized  void getNum(){\n        for (int i=n;i<53;i=i+2) {\n            try {\n                while (!flag){\n                    this.wait();\n                }\n                System.out.print(i+\"\"+(i+1));\n                flag=false;\n            } catch (InterruptedException e1) {\n                e1.printStackTrace();\n            }\n            this.notify();\n        }\n    }\n\n    public synchronized  void getChar() {\n        for (int i=e;i<91;i++) {\n            try {\n                while (flag){\n                    this.wait();\n                }\n                System.out.print((char)i);\n                flag=true;\n            } catch (InterruptedException e1) {\n                e1.printStackTrace();\n            }\n            this.notify();\n        }\n    }\n\n    public static void main(String[] args) {\n        NumChar numChar = new NumChar();\n        new Thread(()->{\n            numChar.getNum();\n        }).start();\n        new Thread(()->{\n            numChar.getChar();\n        }).start();\n    }\n}\n```\n\n**（2）使用ReentrantLock方式**\n\n```\npackage com.gzstrong.t;\n\nimport java.util.concurrent.locks.Condition;\nimport java.util.concurrent.locks.Lock;\nimport java.util.concurrent.locks.ReentrantLock;\n\npublic class NumCharLock {\n    private int n=1;\n    private int e=65;\n    private boolean flag=true;\n    Lock lock=new ReentrantLock();\n    Condition condition = lock.newCondition();\n    public void getNum(){\n        lock.lock();\n        for (int i=n;i<53;i=i+2) {\n            while (!flag){\n                try {\n                    condition.await();\n                } catch (InterruptedException e1) {\n                    e1.printStackTrace();\n                }\n            }\n            System.out.print(i+\"\"+(i+1));\n            flag=false;\n            condition.signal();\n        }\n        lock.unlock();\n    }\n\n    public  void getChar() {\n        lock.lock();\n        for (int i=e;i<91;i++) {\n            while (flag){\n                try {\n                    condition.await();\n                } catch (InterruptedException e1) {\n                    e1.printStackTrace();\n                }\n            }\n            System.out.print((char)i);\n            flag=true;\n            condition.signal();\n        }\n        lock.unlock();\n    }\n\n    public static void main(String[] args) {\n        NumCharLock numAA = new NumCharLock();\n        new Thread(()->{\n            numAA.getNum();\n        }).start();\n        new Thread(()->{\n            numAA.getChar();\n        }).start();\n    }\n}\n```\n\n\n\n##  Spring Cloud Alibaba学习\n\n###  一.Nacos\n\n#### 1.配置中心\n\nspringboot 启动报错\n\nthis is very likely to create a memory leak.\n\n\n\n### 二.Apollo\n\n####  (一)Apollo分布式配置中心部署\n\n**1.下载源码**\n\nhttps://github.com/ctripcorp/apollo\n\n比较重要的几个项目：\n\n- apollo-configservice：提供配置获取接口，提供配置更新推送接口，接口服务对象为Apollo客户端\n- apollo-adminservice：提供配置管理接口，提供配置修改、发布等接口，接口服务对象为Portal，以及Eureka\n\n- apollo-portal：提供Web界面供用户管理配置\n\n- apollo-client：Apollo提供的客户端程序，为应用提供配置获取、实时更新等功能\n\n**2.配置中心执行流程**\n\n- 用户在Portal操作配置发布\n- Portal调用Admin Service的接口操作发布\n- Admin Service发布配置后，发送ReleaseMessage给各个Config Service\n- Config Service收到ReleaseMessage后，通知对应的客户端\n\n**3.数据库初始化**\n下面的sql为大写格式，注意数据库的大小写敏感设置\n\n- ApolloPortalDB：执行apollo-master\\scripts\\db\\migration\\portaldb\\V1.0.0__initialization.sql\n- ApolloConfigDB：执行apollo-master\\scripts\\db\\migration\\configdb\\V1.0.0__initialization.sql\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904170710.png)\n\n**4.调整项目配置**\n\n\n\n### 三.Sentinel\n\n#### (一)Spring Cloud Alibaba整合Sentinel流控\n\n##### 1.部署Sentinel Dashboard\n\n- 下载地址：[sentinel-dashboard-1.6.0.jar](https://github.com/alibaba/Sentinel/releases/download/1.6.0/sentinel-dashboard-1.6.0.jar)\n- 其他版本：[Sentinel/releases](https://github.com/alibaba/Sentinel/releases)\n\n```shell\njava -jar sentinel-dashboard-1.6.0.jar  \n```\n\n要自定义端口号等内容的话，可以通过在启动命令中增加参数来调整，比如：`-Dserver.port=8888`\n\n默认情况下，sentinel-dashboard以8080端口启动，所以可以通过访问：`localhost:8080`来验证是否已经启动成功 \n\n> **注意**：只有1.6.0及以上版本，才有这个简单的登录页面。默认用户名和密码都是`sentinel`。对于用户登录的相关配置可以在启动命令中增加下面的参数来进行配置：\n\n- `-Dsentinel.dashboard.auth.username=sentinel`: 用于指定控制台的登录用户名为 sentinel；\n- `-Dsentinel.dashboard.auth.password=123456`: 用于指定控制台的登录密码为 123456；如果省略这两个参数，默认用户和密码均为 sentinel\n- `-Dserver.servlet.session.timeout=7200`: 用于指定 Spring Boot 服务端 session 的过期时间，如 7200 表示 7200 秒；60m 表示 60 分钟，默认为 30 分钟； \n\n#####  2.整合Sentinel\n\n（1）在gzstrong-system应用的`build.gradle`中引入Spring Cloud Alibaba的Sentinel模块： \n\n```java\n      compile(\"org.springframework.cloud:spring-cloud-starter-alibaba-sentinel:0.2.2.RELEASE\")\n```\n\n（2）在Spring Cloud应用中通过`spring.cloud.sentinel.transport.dashboard`参数配置sentinel dashboard的访问地址，比如： \n\n```java\nspring.cloud.sentinel.transport.dashboard=localhost:8080\n```\n\n（3）创建应用主类，并提供一个rest接口，比如： \n\n```java\npackage com.gzstrong;\n\nimport com.alibaba.csp.sentinel.annotation.SentinelResource;\nimport com.alibaba.csp.sentinel.annotation.aspectj.SentinelResourceAspect;\nimport com.alibaba.csp.sentinel.slots.block.BlockException;\nimport lombok.extern.slf4j.Slf4j;\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;\nimport org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration;\nimport org.springframework.cloud.client.discovery.EnableDiscoveryClient;\nimport org.springframework.cloud.openfeign.EnableFeignClients;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.RestController;\n\n@SpringBootApplication(exclude = DataSourceAutoConfiguration.class)\n@EnableDiscoveryClient\n@EnableFeignClients\npublic class SystemApp {\n    public static void main(String[] args) {\n        SpringApplication.run(SystemApp.class, args);\n    }\n\n    @Slf4j\n    @RestController\n    static class TestController {\n\n        @SentinelResource(value=\"hello-anon\",blockHandler=\"handleException\",blockHandlerClass=ExceptionUtil.class)\n        @GetMapping(\"/hello-anon\")\n        public String hello() {\n            return \"didispace.com\";\n        }\n\n    }\n\n    @Bean\n    @ConditionalOnMissingBean\n    public SentinelResourceAspect sentinelResourceAspect() {\n        return new SentinelResourceAspect();\n    }\n\n}\nclass ExceptionUtil {\n    public static String handleException(BlockException ex) {\n        return \"扛不住了啊....\";\n    }\n}\n```\n\n启动应用，然后通过postman或者curl访问几下`localhost:9097/hello-anon`接口 \n\n##  Git使用\n\n###  1.初始化仓库\n\n**查看状态**\n\ngit status  查看工作区代码相对于暂存区的差别\n\n###  2.移除版本控制\n\ngit rm -r --cached \".gradle/\"\n\n###  3.添加忽略文件规则\n\ntouch .gitignore\n\n忽略文件的规则\n\n```\n#               表示此为注释,将被Git忽略\n*.a             表示忽略所有 .a 结尾的文件\n!lib.a          表示但lib.a除外\n/TODO           表示仅仅忽略项目根目录下的 TODO 文件，不包括 subdir/TODO\nbuild/          表示忽略 build/目录下的所有文件，过滤整个build文件夹；\ndoc/*.txt       表示会忽略doc/notes.txt但不包括 doc/server/arch.txt\n \nbin/:           表示忽略当前路径下的bin文件夹，该文件夹下的所有内容都会被忽略，不忽略 bin 文件\n/bin:           表示忽略根目录下的bin文件\n/*.c:           表示忽略cat.c，不忽略 build/cat.c\ndebug/*.obj:    表示忽略debug/io.obj，不忽略 debug/common/io.obj和tools/debug/io.obj\n**/foo:         表示忽略/foo,a/foo,a/b/foo等\na/**/b:         表示忽略a/b, a/x/b,a/x/y/b等\n!/bin/run.sh    表示不忽略bin目录下的run.sh文件\n*.log:          表示忽略所有 .log 文件\nconfig.php:     表示忽略当前路径的 config.php 文件\n \n/mtk/           表示过滤整个文件夹\n*.zip           表示过滤所有.zip文件\n/mtk/do.c       表示过滤某个具体文件\n```\n\n###  4.添加到暂存区\n\ngit add .   不加参数默认为将修改操作的文件和未跟踪新添加的文件添加到git系统的暂存区，注意不包括删除\n\n###  5.提交到本地的版本库\n\ngit commit -m ‘message’  -m 参数表示注释\n\n###  6.将本地版本库的分支推送到远程服务器\n\n\n\n###  7.更新代码到本地仓库\n\ngit pull \n\n###  8.分支\n\ngit branch  查看分支\n\ngit chechout aaa 切换分支aaa   \n\ngit branck aaa 创建aaa分支\n\n## JMeter并发\n\n###  1 添加线程组\n\n右键点击“测试计划” -> “添加” -> “Threads(Users)” -> “线程组” \n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904170759.png)\n\n这里可以配置线程组名称，线程数，准备时长（Ramp-Up Period(in seconds)）循环次数，调度器等参数：\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904170826.png)\n\n线程组参数详解： \n\n1. 线程数：设置多少个线程数  \n2. Ramp-Up Period(in seconds)准备时长：线程数 需要多长时间全部启动。如果线程数为10，准备时长为2，那么需要2秒钟启动10个线程，也就是每秒钟启动5个线程。  一般为好理解设为1\n3. 循环次数：每个线程发送请求的次数。如果线程数为10，循环次数为100，那么每个线程发送100次请求。总请求数为10*100=1000 。如果勾选了“永远”，那么所有线程会一直发送请求，一到选择停止运行脚本。  \n4. Delay Thread creation until needed：直到需要时延迟线程的创建。  \n5. 调度器：设置线程组启动的开始时间和结束时间(配置调度器时，需要勾选循环次数为永远)  持续时间（秒）：测试持续时间，会覆盖结束时间  启动延迟（秒）：测试延迟启动时间，会覆盖启动时间  启动时间：测试启动时间，启动延迟会覆盖它。当启动时间已过，手动只需测试时当前时间也会覆盖它。  结束时间：测试结束时间，持续时间会覆盖它。因为接口调试需要，我们暂时均使用默认设置，待后面真正执行性能测试时再回来配置\n\n###  2 添加HTTP请求\n\n右键点击“线程组” -> “添加” -> “Sampler” -> “HTTP请求” \n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904170855.png)\n\n对于我们的接口<http://www.baidu.com/s?ie=utf-8&wd=jmeter>性能测试，可以参考下图填写：\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904170912.png)\n\n Http请求主要参数详解：\n\nWeb服务器  协议：向目标服务器发送HTTP请求协议，可以是HTTP或HTTPS，默认为HTTP  \n\n服务器名称或IP ：HTTP请求发送的目标服务器名称或IP  \n\n端口号：目标服务器的端口号，默认值为80  2.Http请求  方法：发送HTTP请求的方法，可用方法包括GET、POST、HEAD、PUT、OPTIONS、TRACE、DELETE等。  路径：目标URL路径（URL中去掉服务器地址、端口及参数后剩余部分）  Content encoding ：编码方式，默认为ISO-8859-1编码，这里配置为utf-8同请求一起发送参数  在请求中发送的URL参数，用户可以将URL中所有参数设置在本表中，表中每行为一个参数（对应URL中的 name=value），注意参数传入中文时需要勾选“编码”","slug":"总-javaEE","published":1,"updated":"2019-09-05T02:02:38.038Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck061x93i0009qguiy7xacan4","content":"<h2 id=\"多线程\"><a href=\"#多线程\" class=\"headerlink\" title=\"多线程\"></a>多线程</h2><h3 id=\"Synchronized\"><a href=\"#Synchronized\" class=\"headerlink\" title=\"Synchronized\"></a>Synchronized</h3><h4 id=\"Synchronized使用方式有几种\"><a href=\"#Synchronized使用方式有几种\" class=\"headerlink\" title=\"Synchronized使用方式有几种\"></a>Synchronized使用方式有几种</h4><p>Synchronized可以使用在三个地方：</p>\n<ol>\n<li>非静态方法</li>\n<li>静态方法</li>\n<li>代码块</li>\n</ol>\n<p>首先我们先看一个普通的多线程方法</p>\n<pre><code>public class Main6  {\n\n    public void method1() {\n        System.out.println(&quot;method1 start&quot;);\n        try {\n            System.out.println(&quot;method1 exec&quot;);\n            Thread.sleep(3000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        System.out.println(&quot;method1 completion&quot;);\n    }\n\n    public void method2() {\n        System.out.println(&quot;method2 start&quot;);\n        try {\n            System.out.println(&quot;method2 exec&quot;);\n            Thread.sleep(1000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        System.out.println(&quot;method2 completion&quot;);\n    }\n\n    public static void main(String[] args) {\n        Main6 m1 = new Main6();\n        Main6 m2 = new Main6();\n\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                m1.method1();\n            }\n        }).start();\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                m1.method2();\n            }\n        }).start();\n    }\n}</code></pre><p>在这个方法执行的时候，method1()和method2()并行运行，但由于method2()的运行时间短，因此总是会先运行结束。 </p>\n<p>1.非静态方法 </p>\n<pre><code>public class Main6  {\n\n    public synchronized void method1() {\n        System.out.println(&quot;method1 start&quot;);\n        try {\n            System.out.println(&quot;method1 exec&quot;);\n            Thread.sleep(3000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        System.out.println(&quot;method1 completion&quot;);\n    }\n\n    public synchronized void method2() {\n        System.out.println(&quot;method2 start&quot;);\n        try {\n            System.out.println(&quot;method2 exec&quot;);\n            Thread.sleep(1000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        System.out.println(&quot;method2 completion&quot;);\n    }\n\n    public static void main(String[] args) {\n        Main6 m1 = new Main6();\n        Main6 m2 = new Main6();\n\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                m1.method1();\n            }\n        }).start();\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                m1.method2();\n            }\n        }).start();\n    }\n}</code></pre><p>在非静态方法上添加synchronized关键字，当我们使用同一个对象分别在不同线程中调用该方法时候，会出现如下顺序的结果：</p>\n<p>method1 start<br>method1 exec<br>method1 completion<br>method2 start<br>method2 exec<br>method2 completion</p>\n<p>这是由于synchronized会获取当前调用对象的锁，当线程1在执行m1.method1();时候获取到了m1对象的锁，线程2企图执行m1.method2()方法时发现m1的锁已经被其他线程获取，因此会进入阻塞状态，直到线程1对method1()方法执行完。</p>\n<p>注意，由于调用线程1的start()方法并不是一定会立即开始执行线程1，它先会与main线程争夺cpu等资源，因此有可能method2先执行，method1进入阻塞，直到method2执行完成后才会开始执行。</p>\n<p>同时由于synchronized使用在非静态方法上获取的是当前对象的锁，因此假如线程1和2分别使用的是两个不同对象的mthod1方法和method2方法，则不会发生阻塞。</p>\n<p>2.静态方法</p>\n<pre><code>public class Main6  {\n\n    public static synchronized void method1() {\n        System.out.println(&quot;method1 start&quot;);\n        try {\n            System.out.println(&quot;method1 exec&quot;);\n            Thread.sleep(3000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        System.out.println(&quot;method1 completion&quot;);\n    }\n\n    public static synchronized void method2() {\n        System.out.println(&quot;method2 start&quot;);\n        try {\n            System.out.println(&quot;method2 exec&quot;);\n            Thread.sleep(1000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        System.out.println(&quot;method2 completion&quot;);\n    }\n\n    public static void main(String[] args) {\n        Main6 m1 = new Main6();\n        Main6 m2 = new Main6();\n\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                m1.method1();\n            }\n        }).start();\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                m2.method2();\n            }\n        }).start();\n    }\n}</code></pre><p>静态方法与非静态方法的不同处在于方法是属于类，而不是属于当前对象。</p>\n<p>这样即使我们调用的是不同对象的method1方法和method2方法，但是它们获取的锁是类对象的锁(Class对象的锁)，因此，不论使用的是哪个对象的method1和method2，均会发生线程阻塞的情况。只有当一个线程中的静态synchronized执行完成后才会执行另一个线程中的静态synchronized方法。</p>\n<p>3.代码块</p>\n<pre><code>public class Main6  {\n\n    public void method1() {\n        System.out.println(&quot;method1 start&quot;);\n        synchronized(this) {\n            try {\n                System.out.println(&quot;method1 exec&quot;);\n                Thread.sleep(3000);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n        System.out.println(&quot;method1 completion&quot;);\n    }\n\n    public void method2() {\n        System.out.println(&quot;method2 start&quot;);\n        synchronized (this) {\n            try {\n                System.out.println(&quot;method2 exec&quot;);\n                Thread.sleep(1000);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n        System.out.println(&quot;method2 completion&quot;);\n    }\n\n    public static void main(String[] args) {\n        Main6 m1 = new Main6();new Thread(new Runnable() {\n            @Override\n            public void run() {\n                m1.method1();\n            }\n        }).start();\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                m1.method2();\n            }\n        }).start();\n    }\n}</code></pre><p>输出的结果可能如下：</p>\n<p>method1 start<br>method1 exec<br>method2 start<br>method1 completion<br>method2 exec<br>method2 completion</p>\n<p>当synchronized被使用在代码块上时，它所获取的锁是括号中接收的对象的锁(如样例代码中的this指代的是当前调用它的对象)，这样，假设method1方法正在执行，并且进入代码块休眠3秒，这时method2获取cpu，开始执行第一行代码打印”method2 start”，然后遇见代码块，尝试获取this对象的锁，却发现已经被method1获取(sleet不释放锁)，因此method2进入阻塞状态，直到method1执行完毕后释放锁，method2获取锁开始执行代码块。</p>\n<h4 id=\"synchronized的案例分析\"><a href=\"#synchronized的案例分析\" class=\"headerlink\" title=\"synchronized的案例分析\"></a>synchronized的案例分析</h4><p><strong>（1）标准访问，先打印短信还是邮件</strong></p>\n<pre><code>public class Phone {\n    public synchronized void sendSMS(){\n            System.out.println(&quot;----sendSMS&quot;);\n    }\n    public synchronized void sendEmail(){\n        System.out.println(&quot;----sendEmail&quot;);\n    }\n    public static void main(String[] args) throws InterruptedException {\n        Phone phone = new Phone();\n        new Thread(()-&gt;{phone.sendSMS();},&quot;AA&quot;).start();\n        Thread.sleep(1000); //让A先启动\n        new Thread(()-&gt;{phone.sendEmail();},&quot;BB&quot;).start();\n    }\n}</code></pre><p>—-sendSMS<br>—-sendEmail</p>\n<p>由于方法上的锁是this，同样的phone对象，A先进入方法，获取到锁，B只能等待</p>\n<p><strong>（2）短信方法内停4秒，先打印短信还是邮件</strong></p>\n<pre><code>public class Phone {\n    public synchronized void sendSMS(){\n        try {\n            Thread.sleep(4000);\n            System.out.println(&quot;----sendSMS&quot;);\n        }catch (Exception e){}\n    }\n    public synchronized void sendEmail(){\n        System.out.println(&quot;----sendEmail&quot;);\n    }\n    public static void main(String[] args) throws InterruptedException {\n        Phone phone = new Phone();\n        new Thread(()-&gt;{phone.sendSMS();},&quot;AA&quot;).start();\n        Thread.sleep(1000); //让A先启动\n        new Thread(()-&gt;{phone.sendEmail();},&quot;BB&quot;).start();\n    }\n}</code></pre><p>—-sendSMS<br>—-sendEmail</p>\n<p>由于方法上的锁是this，同样的phone对象，A先进入方法，获取到锁，且sleep方法是不释放锁的，B只能等待A先打印sendEmail</p>\n<p><strong>（3）新增的hello方法，先打印短信还是hello</strong></p>\n<pre><code>public class Phone {\n    public synchronized void sendSMS(){\n        try {\n            Thread.sleep(4000);\n            System.out.println(&quot;----sendSMS&quot;);\n        }catch (Exception e){ }\n    }\n    public void getHello(){\n        System.out.println(&quot;----getHello&quot;);\n    }\n\n    public static void main(String[] args) throws InterruptedException {\n        Phone phone = new Phone();\n        new Thread(()-&gt;{phone.sendSMS();},&quot;AA&quot;).start();\n        Thread.sleep(1000); //让A先启动\n        new Thread(()-&gt;{phone.getHello();},&quot;BB&quot;).start();\n    }\n}</code></pre><p>—-getHello</p>\n<p>—-sendSMS</p>\n<p>没有和锁有关系</p>\n<p><strong>（4）现有2部手机，先打印短信还是邮件</strong></p>\n<pre><code>public class Phone {\n    public synchronized void sendSMS(){\n        try {\n            Thread.sleep(4000);\n            System.out.println(&quot;----sendSMS&quot;);\n        }catch (Exception e){ }\n    }\n    public synchronized void sendEmail(){\n        System.out.println(&quot;----sendEmail&quot;);\n    }\n    public static void main(String[] args) throws InterruptedException {\n        Phone phone1 = new Phone();\n        Phone phone2 = new Phone();\n        new Thread(()-&gt;{phone1.sendSMS();},&quot;AA&quot;).start();\n        Thread.sleep(1000); //让A先启动\n        new Thread(()-&gt;{phone2.sendEmail();},&quot;BB&quot;).start();\n    }\n}</code></pre><p>—-sendEmail<br>—-sendSMS</p>\n<p>2部手机，由于方法上的锁是this，不同的phone对象，各自维护，sendSMS睡眠了4秒，先打印sendEmail</p>\n<p><strong>（4）两个静态同步方法，1部手机，先打印短信还是邮件</strong></p>\n<pre><code>public class Phone {\n    public static synchronized void sendSMS(){\n        try {\n            Thread.sleep(4000);\n            System.out.println(&quot;----sendSMS&quot;);\n        }catch (Exception e){ }\n    }\n    public static synchronized void sendEmail(){\n        System.out.println(&quot;----sendEmail&quot;);\n    }\n    public static void main(String[] args) throws InterruptedException {\n        Phone phone1 = new Phone();\n        new Thread(()-&gt;{phone1.sendSMS();},&quot;AA&quot;).start();\n        Thread.sleep(1000); //让A先启动\n        new Thread(()-&gt;{phone1.sendEmail();},&quot;BB&quot;).start();\n    }\n}</code></pre><p>—-sendSMS</p>\n<p>—-sendEmail</p>\n<p>静态方法的锁是类的class字节码，只有一份，所以A先进入方法，获取到锁，B只能等待A</p>\n<p><strong>（4）两个静态同步方法，2部手机，先打印短信还是邮件</strong></p>\n<pre><code>public class Phone {\n    public static synchronized void sendSMS(){\n        try {\n            Thread.sleep(4000);\n            System.out.println(&quot;----sendSMS&quot;);\n        }catch (Exception e){ }\n    }\n    public static synchronized void sendEmail(){\n        System.out.println(&quot;----sendEmail&quot;);\n    }\n    public void getHello(){\n        System.out.println(&quot;----getHello&quot;);\n    }\n    public static void main(String[] args) throws InterruptedException {\n        Phone phone1 = new Phone();\n        Phone phone2 = new Phone();\n        new Thread(()-&gt;{phone1.sendSMS();},&quot;AA&quot;).start();\n        Thread.sleep(1000); //让A先启动\n        new Thread(()-&gt;{phone2.sendEmail();},&quot;BB&quot;).start();\n    }\n}</code></pre><p>—-sendSMS</p>\n<p>—-sendEmail</p>\n<p>静态方法的锁是类的class字节码，虽然是不同的对象调用，但是字节码还是只有一份，所以A先进入方法，获取到锁，B只能等待A</p>\n<p><strong>（5）一个静态方法，一个普通方法，先打印短信还是邮件</strong></p>\n<pre><code>public class Phone {\n    public static synchronized void sendSMS(){\n        try {\n            Thread.sleep(4000);\n            System.out.println(&quot;----sendSMS&quot;);\n        }catch (Exception e){ }\n    }\n    public synchronized void sendEmail(){\n        System.out.println(&quot;----sendEmail&quot;);\n    }\n    public static void main(String[] args) throws InterruptedException {\n        Phone phone = new Phone();\n        new Thread(()-&gt;{phone.sendSMS();},&quot;AA&quot;).start();\n        Thread.sleep(1000); //让A先启动\n        new Thread(()-&gt;{phone.sendEmail();},&quot;BB&quot;).start();\n    }\n}</code></pre><h4 id=\"synchronized-this-与synchronized-class-之间的区别\"><a href=\"#synchronized-this-与synchronized-class-之间的区别\" class=\"headerlink\" title=\"synchronized(this) 与synchronized(class) 之间的区别\"></a><a href=\"https://www.cnblogs.com/huansky/p/8869888.html\" target=\"_blank\" rel=\"noopener\">synchronized(this) 与synchronized(class) 之间的区别</a></h4><h3 id=\"ReentrantLock\"><a href=\"#ReentrantLock\" class=\"headerlink\" title=\"ReentrantLock\"></a>ReentrantLock</h3><h4 id=\"ReentrantReadWriteLock读写锁获取数据\"><a href=\"#ReentrantReadWriteLock读写锁获取数据\" class=\"headerlink\" title=\"ReentrantReadWriteLock读写锁获取数据\"></a>ReentrantReadWriteLock读写锁获取数据</h4><p>1个线程写数据，100个线程读取数据</p>\n<pre><code>public class ReentrantReadWriteTest {\n    ReentrantReadWriteLock lock=new ReentrantReadWriteLock();\n    private Object obj;\n    public void write(Object obj){\n        lock.writeLock().lock();\n        this.obj=obj;\n        System.out.println(Thread.currentThread().getName()+&quot;set--&quot;+this.obj);\n        lock.writeLock().unlock();\n    }\n    public void get(){\n        lock.readLock().lock();\n        System.out.println(Thread.currentThread().getName()+&quot;--get---&quot;+this.obj);\n        lock.readLock().unlock();\n    }\n    public static void main(String[] args){\n        ReentrantReadWriteTest rw = new ReentrantReadWriteTest();\n        new Thread(()-&gt;{rw.write(&quot;测试&quot;);},&quot;write&quot;).start();\n        for (int i = 0; i &lt; 100; i++) {\n            new Thread(()-&gt;{rw.get();},&quot;read--&quot;+i).start();\n        }\n    }\n}</code></pre><h3 id=\"CountDownLatch\"><a href=\"#CountDownLatch\" class=\"headerlink\" title=\"CountDownLatch\"></a>CountDownLatch</h3><p><strong>CoundDownLatch</strong>这个类能够<strong>使一个线程等待其他线程完成各自的工作后再执行</strong>。例如，应用程序的主线程希望在负责启动框架服务的线程已经启动所有的框架服务之后再执行。 </p>\n<p>编写20个同学离开教室之后，班长才锁门</p>\n<pre><code>public class CountDownLatchTest {\n    public static void main(String[] args) {\n        CountDownLatch cd = new CountDownLatch(20);\n        for (int i = 0; i &lt; 20; i++) {\n            new Thread(()-&gt;{\n                try {\n                    Thread.sleep(1000);\n                    System.out.println(Thread.currentThread().getName()+&quot;离开教室&quot;);\n                    cd.countDown();\n                } catch (InterruptedException e) {}\n            },&quot;线程&quot;+i).start();\n        }\n        new Thread(()-&gt;{\n            try {\n                cd.await();\n            } catch (InterruptedException e) {}\n            System.out.println(&quot;班长锁门&quot;);\n        },&quot;线程&quot;).start();\n    }\n}</code></pre><h3 id=\"CyclicBarrier\"><a href=\"#CyclicBarrier\" class=\"headerlink\" title=\"CyclicBarrier\"></a>CyclicBarrier</h3><p><strong>CyclicBarrier</strong>和<strong>CountDownLatch</strong>是非常类似的，<strong>CyclicBarrier</strong>核心的概念是在于设置一个等待线程的数量边界，到达了此边界之后进行执行。</p>\n<p><strong>CyclicBarrier</strong>类是一个同步辅助类，它允许一组线程互相等待，直到到达某个公共屏障点（Common Barrier Point）。</p>\n<p><strong>CyclicBarrier</strong>类是一种同步机制，它能够对处理一些算法的线程实现同。换句话讲，它就是一个所有线程必须等待的一个栅栏，直到所有线程都到达这里，然后所有线程才可以继续做其他事情。</p>\n<h3 id=\"多线程代码编写\"><a href=\"#多线程代码编写\" class=\"headerlink\" title=\"多线程代码编写\"></a>多线程代码编写</h3><h4 id=\"（一）依次打印数字和字母\"><a href=\"#（一）依次打印数字和字母\" class=\"headerlink\" title=\"（一）依次打印数字和字母\"></a>（一）依次打印数字和字母</h4><ul>\n<li><p>12A34B56C78D910E1112F1314G1516H1718I1920J2122K2324L2526M2728N2930O3132P3334Q3536R3738S3940T4142U4344V4546W4748X4950Y5152Z</p>\n<p><strong>（1）使用等待唤醒机制</strong></p>\n</li>\n</ul>\n<pre><code>package com.gzstrong.t;\npublic class NumChar {\n    private int n=1;\n    private int e=65;\n    private boolean flag=true;\n    public synchronized  void getNum(){\n        for (int i=n;i&lt;53;i=i+2) {\n            try {\n                while (!flag){\n                    this.wait();\n                }\n                System.out.print(i+&quot;&quot;+(i+1));\n                flag=false;\n            } catch (InterruptedException e1) {\n                e1.printStackTrace();\n            }\n            this.notify();\n        }\n    }\n\n    public synchronized  void getChar() {\n        for (int i=e;i&lt;91;i++) {\n            try {\n                while (flag){\n                    this.wait();\n                }\n                System.out.print((char)i);\n                flag=true;\n            } catch (InterruptedException e1) {\n                e1.printStackTrace();\n            }\n            this.notify();\n        }\n    }\n\n    public static void main(String[] args) {\n        NumChar numChar = new NumChar();\n        new Thread(()-&gt;{\n            numChar.getNum();\n        }).start();\n        new Thread(()-&gt;{\n            numChar.getChar();\n        }).start();\n    }\n}</code></pre><p><strong>（2）使用ReentrantLock方式</strong></p>\n<pre><code>package com.gzstrong.t;\n\nimport java.util.concurrent.locks.Condition;\nimport java.util.concurrent.locks.Lock;\nimport java.util.concurrent.locks.ReentrantLock;\n\npublic class NumCharLock {\n    private int n=1;\n    private int e=65;\n    private boolean flag=true;\n    Lock lock=new ReentrantLock();\n    Condition condition = lock.newCondition();\n    public void getNum(){\n        lock.lock();\n        for (int i=n;i&lt;53;i=i+2) {\n            while (!flag){\n                try {\n                    condition.await();\n                } catch (InterruptedException e1) {\n                    e1.printStackTrace();\n                }\n            }\n            System.out.print(i+&quot;&quot;+(i+1));\n            flag=false;\n            condition.signal();\n        }\n        lock.unlock();\n    }\n\n    public  void getChar() {\n        lock.lock();\n        for (int i=e;i&lt;91;i++) {\n            while (flag){\n                try {\n                    condition.await();\n                } catch (InterruptedException e1) {\n                    e1.printStackTrace();\n                }\n            }\n            System.out.print((char)i);\n            flag=true;\n            condition.signal();\n        }\n        lock.unlock();\n    }\n\n    public static void main(String[] args) {\n        NumCharLock numAA = new NumCharLock();\n        new Thread(()-&gt;{\n            numAA.getNum();\n        }).start();\n        new Thread(()-&gt;{\n            numAA.getChar();\n        }).start();\n    }\n}</code></pre><h2 id=\"Spring-Cloud-Alibaba学习\"><a href=\"#Spring-Cloud-Alibaba学习\" class=\"headerlink\" title=\"Spring Cloud Alibaba学习\"></a>Spring Cloud Alibaba学习</h2><h3 id=\"一-Nacos\"><a href=\"#一-Nacos\" class=\"headerlink\" title=\"一.Nacos\"></a>一.Nacos</h3><h4 id=\"1-配置中心\"><a href=\"#1-配置中心\" class=\"headerlink\" title=\"1.配置中心\"></a>1.配置中心</h4><p>springboot 启动报错</p>\n<p>this is very likely to create a memory leak.</p>\n<h3 id=\"二-Apollo\"><a href=\"#二-Apollo\" class=\"headerlink\" title=\"二.Apollo\"></a>二.Apollo</h3><h4 id=\"一-Apollo分布式配置中心部署\"><a href=\"#一-Apollo分布式配置中心部署\" class=\"headerlink\" title=\"(一)Apollo分布式配置中心部署\"></a>(一)Apollo分布式配置中心部署</h4><p><strong>1.下载源码</strong></p>\n<p><a href=\"https://github.com/ctripcorp/apollo\" target=\"_blank\" rel=\"noopener\">https://github.com/ctripcorp/apollo</a></p>\n<p>比较重要的几个项目：</p>\n<ul>\n<li><p>apollo-configservice：提供配置获取接口，提供配置更新推送接口，接口服务对象为Apollo客户端</p>\n</li>\n<li><p>apollo-adminservice：提供配置管理接口，提供配置修改、发布等接口，接口服务对象为Portal，以及Eureka</p>\n</li>\n<li><p>apollo-portal：提供Web界面供用户管理配置</p>\n</li>\n<li><p>apollo-client：Apollo提供的客户端程序，为应用提供配置获取、实时更新等功能</p>\n</li>\n</ul>\n<p><strong>2.配置中心执行流程</strong></p>\n<ul>\n<li>用户在Portal操作配置发布</li>\n<li>Portal调用Admin Service的接口操作发布</li>\n<li>Admin Service发布配置后，发送ReleaseMessage给各个Config Service</li>\n<li>Config Service收到ReleaseMessage后，通知对应的客户端</li>\n</ul>\n<p><strong>3.数据库初始化</strong><br>下面的sql为大写格式，注意数据库的大小写敏感设置</p>\n<ul>\n<li>ApolloPortalDB：执行apollo-master\\scripts\\db\\migration\\portaldb\\V1.0.0__initialization.sql</li>\n<li>ApolloConfigDB：执行apollo-master\\scripts\\db\\migration\\configdb\\V1.0.0__initialization.sql</li>\n</ul>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904170710.png\" alt></p>\n<p><strong>4.调整项目配置</strong></p>\n<h3 id=\"三-Sentinel\"><a href=\"#三-Sentinel\" class=\"headerlink\" title=\"三.Sentinel\"></a>三.Sentinel</h3><h4 id=\"一-Spring-Cloud-Alibaba整合Sentinel流控\"><a href=\"#一-Spring-Cloud-Alibaba整合Sentinel流控\" class=\"headerlink\" title=\"(一)Spring Cloud Alibaba整合Sentinel流控\"></a>(一)Spring Cloud Alibaba整合Sentinel流控</h4><h5 id=\"1-部署Sentinel-Dashboard\"><a href=\"#1-部署Sentinel-Dashboard\" class=\"headerlink\" title=\"1.部署Sentinel Dashboard\"></a>1.部署Sentinel Dashboard</h5><ul>\n<li>下载地址：<a href=\"https://github.com/alibaba/Sentinel/releases/download/1.6.0/sentinel-dashboard-1.6.0.jar\" target=\"_blank\" rel=\"noopener\">sentinel-dashboard-1.6.0.jar</a></li>\n<li>其他版本：<a href=\"https://github.com/alibaba/Sentinel/releases\" target=\"_blank\" rel=\"noopener\">Sentinel/releases</a></li>\n</ul>\n<pre><code class=\"shell\">java -jar sentinel-dashboard-1.6.0.jar  </code></pre>\n<p>要自定义端口号等内容的话，可以通过在启动命令中增加参数来调整，比如：<code>-Dserver.port=8888</code></p>\n<p>默认情况下，sentinel-dashboard以8080端口启动，所以可以通过访问：<code>localhost:8080</code>来验证是否已经启动成功 </p>\n<blockquote>\n<p><strong>注意</strong>：只有1.6.0及以上版本，才有这个简单的登录页面。默认用户名和密码都是<code>sentinel</code>。对于用户登录的相关配置可以在启动命令中增加下面的参数来进行配置：</p>\n</blockquote>\n<ul>\n<li><code>-Dsentinel.dashboard.auth.username=sentinel</code>: 用于指定控制台的登录用户名为 sentinel；</li>\n<li><code>-Dsentinel.dashboard.auth.password=123456</code>: 用于指定控制台的登录密码为 123456；如果省略这两个参数，默认用户和密码均为 sentinel</li>\n<li><code>-Dserver.servlet.session.timeout=7200</code>: 用于指定 Spring Boot 服务端 session 的过期时间，如 7200 表示 7200 秒；60m 表示 60 分钟，默认为 30 分钟； </li>\n</ul>\n<h5 id=\"2-整合Sentinel\"><a href=\"#2-整合Sentinel\" class=\"headerlink\" title=\"2.整合Sentinel\"></a>2.整合Sentinel</h5><p>（1）在gzstrong-system应用的<code>build.gradle</code>中引入Spring Cloud Alibaba的Sentinel模块： </p>\n<pre><code class=\"java\">      compile(&quot;org.springframework.cloud:spring-cloud-starter-alibaba-sentinel:0.2.2.RELEASE&quot;)</code></pre>\n<p>（2）在Spring Cloud应用中通过<code>spring.cloud.sentinel.transport.dashboard</code>参数配置sentinel dashboard的访问地址，比如： </p>\n<pre><code class=\"java\">spring.cloud.sentinel.transport.dashboard=localhost:8080</code></pre>\n<p>（3）创建应用主类，并提供一个rest接口，比如： </p>\n<pre><code class=\"java\">package com.gzstrong;\n\nimport com.alibaba.csp.sentinel.annotation.SentinelResource;\nimport com.alibaba.csp.sentinel.annotation.aspectj.SentinelResourceAspect;\nimport com.alibaba.csp.sentinel.slots.block.BlockException;\nimport lombok.extern.slf4j.Slf4j;\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;\nimport org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration;\nimport org.springframework.cloud.client.discovery.EnableDiscoveryClient;\nimport org.springframework.cloud.openfeign.EnableFeignClients;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.RestController;\n\n@SpringBootApplication(exclude = DataSourceAutoConfiguration.class)\n@EnableDiscoveryClient\n@EnableFeignClients\npublic class SystemApp {\n    public static void main(String[] args) {\n        SpringApplication.run(SystemApp.class, args);\n    }\n\n    @Slf4j\n    @RestController\n    static class TestController {\n\n        @SentinelResource(value=&quot;hello-anon&quot;,blockHandler=&quot;handleException&quot;,blockHandlerClass=ExceptionUtil.class)\n        @GetMapping(&quot;/hello-anon&quot;)\n        public String hello() {\n            return &quot;didispace.com&quot;;\n        }\n\n    }\n\n    @Bean\n    @ConditionalOnMissingBean\n    public SentinelResourceAspect sentinelResourceAspect() {\n        return new SentinelResourceAspect();\n    }\n\n}\nclass ExceptionUtil {\n    public static String handleException(BlockException ex) {\n        return &quot;扛不住了啊....&quot;;\n    }\n}</code></pre>\n<p>启动应用，然后通过postman或者curl访问几下<code>localhost:9097/hello-anon</code>接口 </p>\n<h2 id=\"Git使用\"><a href=\"#Git使用\" class=\"headerlink\" title=\"Git使用\"></a>Git使用</h2><h3 id=\"1-初始化仓库\"><a href=\"#1-初始化仓库\" class=\"headerlink\" title=\"1.初始化仓库\"></a>1.初始化仓库</h3><p><strong>查看状态</strong></p>\n<p>git status  查看工作区代码相对于暂存区的差别</p>\n<h3 id=\"2-移除版本控制\"><a href=\"#2-移除版本控制\" class=\"headerlink\" title=\"2.移除版本控制\"></a>2.移除版本控制</h3><p>git rm -r –cached “.gradle/“</p>\n<h3 id=\"3-添加忽略文件规则\"><a href=\"#3-添加忽略文件规则\" class=\"headerlink\" title=\"3.添加忽略文件规则\"></a>3.添加忽略文件规则</h3><p>touch .gitignore</p>\n<p>忽略文件的规则</p>\n<pre><code>#               表示此为注释,将被Git忽略\n*.a             表示忽略所有 .a 结尾的文件\n!lib.a          表示但lib.a除外\n/TODO           表示仅仅忽略项目根目录下的 TODO 文件，不包括 subdir/TODO\nbuild/          表示忽略 build/目录下的所有文件，过滤整个build文件夹；\ndoc/*.txt       表示会忽略doc/notes.txt但不包括 doc/server/arch.txt\n\nbin/:           表示忽略当前路径下的bin文件夹，该文件夹下的所有内容都会被忽略，不忽略 bin 文件\n/bin:           表示忽略根目录下的bin文件\n/*.c:           表示忽略cat.c，不忽略 build/cat.c\ndebug/*.obj:    表示忽略debug/io.obj，不忽略 debug/common/io.obj和tools/debug/io.obj\n**/foo:         表示忽略/foo,a/foo,a/b/foo等\na/**/b:         表示忽略a/b, a/x/b,a/x/y/b等\n!/bin/run.sh    表示不忽略bin目录下的run.sh文件\n*.log:          表示忽略所有 .log 文件\nconfig.php:     表示忽略当前路径的 config.php 文件\n\n/mtk/           表示过滤整个文件夹\n*.zip           表示过滤所有.zip文件\n/mtk/do.c       表示过滤某个具体文件</code></pre><h3 id=\"4-添加到暂存区\"><a href=\"#4-添加到暂存区\" class=\"headerlink\" title=\"4.添加到暂存区\"></a>4.添加到暂存区</h3><p>git add .   不加参数默认为将修改操作的文件和未跟踪新添加的文件添加到git系统的暂存区，注意不包括删除</p>\n<h3 id=\"5-提交到本地的版本库\"><a href=\"#5-提交到本地的版本库\" class=\"headerlink\" title=\"5.提交到本地的版本库\"></a>5.提交到本地的版本库</h3><p>git commit -m ‘message’  -m 参数表示注释</p>\n<h3 id=\"6-将本地版本库的分支推送到远程服务器\"><a href=\"#6-将本地版本库的分支推送到远程服务器\" class=\"headerlink\" title=\"6.将本地版本库的分支推送到远程服务器\"></a>6.将本地版本库的分支推送到远程服务器</h3><h3 id=\"7-更新代码到本地仓库\"><a href=\"#7-更新代码到本地仓库\" class=\"headerlink\" title=\"7.更新代码到本地仓库\"></a>7.更新代码到本地仓库</h3><p>git pull </p>\n<h3 id=\"8-分支\"><a href=\"#8-分支\" class=\"headerlink\" title=\"8.分支\"></a>8.分支</h3><p>git branch  查看分支</p>\n<p>git chechout aaa 切换分支aaa   </p>\n<p>git branck aaa 创建aaa分支</p>\n<h2 id=\"JMeter并发\"><a href=\"#JMeter并发\" class=\"headerlink\" title=\"JMeter并发\"></a>JMeter并发</h2><h3 id=\"1-添加线程组\"><a href=\"#1-添加线程组\" class=\"headerlink\" title=\"1 添加线程组\"></a>1 添加线程组</h3><p>右键点击“测试计划” -&gt; “添加” -&gt; “Threads(Users)” -&gt; “线程组” </p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904170759.png\" alt></p>\n<p>这里可以配置线程组名称，线程数，准备时长（Ramp-Up Period(in seconds)）循环次数，调度器等参数：</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904170826.png\" alt></p>\n<p>线程组参数详解： </p>\n<ol>\n<li>线程数：设置多少个线程数  </li>\n<li>Ramp-Up Period(in seconds)准备时长：线程数 需要多长时间全部启动。如果线程数为10，准备时长为2，那么需要2秒钟启动10个线程，也就是每秒钟启动5个线程。  一般为好理解设为1</li>\n<li>循环次数：每个线程发送请求的次数。如果线程数为10，循环次数为100，那么每个线程发送100次请求。总请求数为10*100=1000 。如果勾选了“永远”，那么所有线程会一直发送请求，一到选择停止运行脚本。  </li>\n<li>Delay Thread creation until needed：直到需要时延迟线程的创建。  </li>\n<li>调度器：设置线程组启动的开始时间和结束时间(配置调度器时，需要勾选循环次数为永远)  持续时间（秒）：测试持续时间，会覆盖结束时间  启动延迟（秒）：测试延迟启动时间，会覆盖启动时间  启动时间：测试启动时间，启动延迟会覆盖它。当启动时间已过，手动只需测试时当前时间也会覆盖它。  结束时间：测试结束时间，持续时间会覆盖它。因为接口调试需要，我们暂时均使用默认设置，待后面真正执行性能测试时再回来配置</li>\n</ol>\n<h3 id=\"2-添加HTTP请求\"><a href=\"#2-添加HTTP请求\" class=\"headerlink\" title=\"2 添加HTTP请求\"></a>2 添加HTTP请求</h3><p>右键点击“线程组” -&gt; “添加” -&gt; “Sampler” -&gt; “HTTP请求” </p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904170855.png\" alt></p>\n<p>对于我们的接口<a href=\"http://www.baidu.com/s?ie=utf-8&amp;wd=jmeter\" target=\"_blank\" rel=\"noopener\">http://www.baidu.com/s?ie=utf-8&amp;wd=jmeter</a>性能测试，可以参考下图填写：</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904170912.png\" alt></p>\n<p> Http请求主要参数详解：</p>\n<p>Web服务器  协议：向目标服务器发送HTTP请求协议，可以是HTTP或HTTPS，默认为HTTP  </p>\n<p>服务器名称或IP ：HTTP请求发送的目标服务器名称或IP  </p>\n<p>端口号：目标服务器的端口号，默认值为80  2.Http请求  方法：发送HTTP请求的方法，可用方法包括GET、POST、HEAD、PUT、OPTIONS、TRACE、DELETE等。  路径：目标URL路径（URL中去掉服务器地址、端口及参数后剩余部分）  Content encoding ：编码方式，默认为ISO-8859-1编码，这里配置为utf-8同请求一起发送参数  在请求中发送的URL参数，用户可以将URL中所有参数设置在本表中，表中每行为一个参数（对应URL中的 name=value），注意参数传入中文时需要勾选“编码”</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"多线程\"><a href=\"#多线程\" class=\"headerlink\" title=\"多线程\"></a>多线程</h2><h3 id=\"Synchronized\"><a href=\"#Synchronized\" class=\"headerlink\" title=\"Synchronized\"></a>Synchronized</h3><h4 id=\"Synchronized使用方式有几种\"><a href=\"#Synchronized使用方式有几种\" class=\"headerlink\" title=\"Synchronized使用方式有几种\"></a>Synchronized使用方式有几种</h4><p>Synchronized可以使用在三个地方：</p>\n<ol>\n<li>非静态方法</li>\n<li>静态方法</li>\n<li>代码块</li>\n</ol>\n<p>首先我们先看一个普通的多线程方法</p>\n<pre><code>public class Main6  {\n\n    public void method1() {\n        System.out.println(&quot;method1 start&quot;);\n        try {\n            System.out.println(&quot;method1 exec&quot;);\n            Thread.sleep(3000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        System.out.println(&quot;method1 completion&quot;);\n    }\n\n    public void method2() {\n        System.out.println(&quot;method2 start&quot;);\n        try {\n            System.out.println(&quot;method2 exec&quot;);\n            Thread.sleep(1000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        System.out.println(&quot;method2 completion&quot;);\n    }\n\n    public static void main(String[] args) {\n        Main6 m1 = new Main6();\n        Main6 m2 = new Main6();\n\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                m1.method1();\n            }\n        }).start();\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                m1.method2();\n            }\n        }).start();\n    }\n}</code></pre><p>在这个方法执行的时候，method1()和method2()并行运行，但由于method2()的运行时间短，因此总是会先运行结束。 </p>\n<p>1.非静态方法 </p>\n<pre><code>public class Main6  {\n\n    public synchronized void method1() {\n        System.out.println(&quot;method1 start&quot;);\n        try {\n            System.out.println(&quot;method1 exec&quot;);\n            Thread.sleep(3000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        System.out.println(&quot;method1 completion&quot;);\n    }\n\n    public synchronized void method2() {\n        System.out.println(&quot;method2 start&quot;);\n        try {\n            System.out.println(&quot;method2 exec&quot;);\n            Thread.sleep(1000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        System.out.println(&quot;method2 completion&quot;);\n    }\n\n    public static void main(String[] args) {\n        Main6 m1 = new Main6();\n        Main6 m2 = new Main6();\n\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                m1.method1();\n            }\n        }).start();\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                m1.method2();\n            }\n        }).start();\n    }\n}</code></pre><p>在非静态方法上添加synchronized关键字，当我们使用同一个对象分别在不同线程中调用该方法时候，会出现如下顺序的结果：</p>\n<p>method1 start<br>method1 exec<br>method1 completion<br>method2 start<br>method2 exec<br>method2 completion</p>\n<p>这是由于synchronized会获取当前调用对象的锁，当线程1在执行m1.method1();时候获取到了m1对象的锁，线程2企图执行m1.method2()方法时发现m1的锁已经被其他线程获取，因此会进入阻塞状态，直到线程1对method1()方法执行完。</p>\n<p>注意，由于调用线程1的start()方法并不是一定会立即开始执行线程1，它先会与main线程争夺cpu等资源，因此有可能method2先执行，method1进入阻塞，直到method2执行完成后才会开始执行。</p>\n<p>同时由于synchronized使用在非静态方法上获取的是当前对象的锁，因此假如线程1和2分别使用的是两个不同对象的mthod1方法和method2方法，则不会发生阻塞。</p>\n<p>2.静态方法</p>\n<pre><code>public class Main6  {\n\n    public static synchronized void method1() {\n        System.out.println(&quot;method1 start&quot;);\n        try {\n            System.out.println(&quot;method1 exec&quot;);\n            Thread.sleep(3000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        System.out.println(&quot;method1 completion&quot;);\n    }\n\n    public static synchronized void method2() {\n        System.out.println(&quot;method2 start&quot;);\n        try {\n            System.out.println(&quot;method2 exec&quot;);\n            Thread.sleep(1000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        System.out.println(&quot;method2 completion&quot;);\n    }\n\n    public static void main(String[] args) {\n        Main6 m1 = new Main6();\n        Main6 m2 = new Main6();\n\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                m1.method1();\n            }\n        }).start();\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                m2.method2();\n            }\n        }).start();\n    }\n}</code></pre><p>静态方法与非静态方法的不同处在于方法是属于类，而不是属于当前对象。</p>\n<p>这样即使我们调用的是不同对象的method1方法和method2方法，但是它们获取的锁是类对象的锁(Class对象的锁)，因此，不论使用的是哪个对象的method1和method2，均会发生线程阻塞的情况。只有当一个线程中的静态synchronized执行完成后才会执行另一个线程中的静态synchronized方法。</p>\n<p>3.代码块</p>\n<pre><code>public class Main6  {\n\n    public void method1() {\n        System.out.println(&quot;method1 start&quot;);\n        synchronized(this) {\n            try {\n                System.out.println(&quot;method1 exec&quot;);\n                Thread.sleep(3000);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n        System.out.println(&quot;method1 completion&quot;);\n    }\n\n    public void method2() {\n        System.out.println(&quot;method2 start&quot;);\n        synchronized (this) {\n            try {\n                System.out.println(&quot;method2 exec&quot;);\n                Thread.sleep(1000);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n        System.out.println(&quot;method2 completion&quot;);\n    }\n\n    public static void main(String[] args) {\n        Main6 m1 = new Main6();new Thread(new Runnable() {\n            @Override\n            public void run() {\n                m1.method1();\n            }\n        }).start();\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                m1.method2();\n            }\n        }).start();\n    }\n}</code></pre><p>输出的结果可能如下：</p>\n<p>method1 start<br>method1 exec<br>method2 start<br>method1 completion<br>method2 exec<br>method2 completion</p>\n<p>当synchronized被使用在代码块上时，它所获取的锁是括号中接收的对象的锁(如样例代码中的this指代的是当前调用它的对象)，这样，假设method1方法正在执行，并且进入代码块休眠3秒，这时method2获取cpu，开始执行第一行代码打印”method2 start”，然后遇见代码块，尝试获取this对象的锁，却发现已经被method1获取(sleet不释放锁)，因此method2进入阻塞状态，直到method1执行完毕后释放锁，method2获取锁开始执行代码块。</p>\n<h4 id=\"synchronized的案例分析\"><a href=\"#synchronized的案例分析\" class=\"headerlink\" title=\"synchronized的案例分析\"></a>synchronized的案例分析</h4><p><strong>（1）标准访问，先打印短信还是邮件</strong></p>\n<pre><code>public class Phone {\n    public synchronized void sendSMS(){\n            System.out.println(&quot;----sendSMS&quot;);\n    }\n    public synchronized void sendEmail(){\n        System.out.println(&quot;----sendEmail&quot;);\n    }\n    public static void main(String[] args) throws InterruptedException {\n        Phone phone = new Phone();\n        new Thread(()-&gt;{phone.sendSMS();},&quot;AA&quot;).start();\n        Thread.sleep(1000); //让A先启动\n        new Thread(()-&gt;{phone.sendEmail();},&quot;BB&quot;).start();\n    }\n}</code></pre><p>—-sendSMS<br>—-sendEmail</p>\n<p>由于方法上的锁是this，同样的phone对象，A先进入方法，获取到锁，B只能等待</p>\n<p><strong>（2）短信方法内停4秒，先打印短信还是邮件</strong></p>\n<pre><code>public class Phone {\n    public synchronized void sendSMS(){\n        try {\n            Thread.sleep(4000);\n            System.out.println(&quot;----sendSMS&quot;);\n        }catch (Exception e){}\n    }\n    public synchronized void sendEmail(){\n        System.out.println(&quot;----sendEmail&quot;);\n    }\n    public static void main(String[] args) throws InterruptedException {\n        Phone phone = new Phone();\n        new Thread(()-&gt;{phone.sendSMS();},&quot;AA&quot;).start();\n        Thread.sleep(1000); //让A先启动\n        new Thread(()-&gt;{phone.sendEmail();},&quot;BB&quot;).start();\n    }\n}</code></pre><p>—-sendSMS<br>—-sendEmail</p>\n<p>由于方法上的锁是this，同样的phone对象，A先进入方法，获取到锁，且sleep方法是不释放锁的，B只能等待A先打印sendEmail</p>\n<p><strong>（3）新增的hello方法，先打印短信还是hello</strong></p>\n<pre><code>public class Phone {\n    public synchronized void sendSMS(){\n        try {\n            Thread.sleep(4000);\n            System.out.println(&quot;----sendSMS&quot;);\n        }catch (Exception e){ }\n    }\n    public void getHello(){\n        System.out.println(&quot;----getHello&quot;);\n    }\n\n    public static void main(String[] args) throws InterruptedException {\n        Phone phone = new Phone();\n        new Thread(()-&gt;{phone.sendSMS();},&quot;AA&quot;).start();\n        Thread.sleep(1000); //让A先启动\n        new Thread(()-&gt;{phone.getHello();},&quot;BB&quot;).start();\n    }\n}</code></pre><p>—-getHello</p>\n<p>—-sendSMS</p>\n<p>没有和锁有关系</p>\n<p><strong>（4）现有2部手机，先打印短信还是邮件</strong></p>\n<pre><code>public class Phone {\n    public synchronized void sendSMS(){\n        try {\n            Thread.sleep(4000);\n            System.out.println(&quot;----sendSMS&quot;);\n        }catch (Exception e){ }\n    }\n    public synchronized void sendEmail(){\n        System.out.println(&quot;----sendEmail&quot;);\n    }\n    public static void main(String[] args) throws InterruptedException {\n        Phone phone1 = new Phone();\n        Phone phone2 = new Phone();\n        new Thread(()-&gt;{phone1.sendSMS();},&quot;AA&quot;).start();\n        Thread.sleep(1000); //让A先启动\n        new Thread(()-&gt;{phone2.sendEmail();},&quot;BB&quot;).start();\n    }\n}</code></pre><p>—-sendEmail<br>—-sendSMS</p>\n<p>2部手机，由于方法上的锁是this，不同的phone对象，各自维护，sendSMS睡眠了4秒，先打印sendEmail</p>\n<p><strong>（4）两个静态同步方法，1部手机，先打印短信还是邮件</strong></p>\n<pre><code>public class Phone {\n    public static synchronized void sendSMS(){\n        try {\n            Thread.sleep(4000);\n            System.out.println(&quot;----sendSMS&quot;);\n        }catch (Exception e){ }\n    }\n    public static synchronized void sendEmail(){\n        System.out.println(&quot;----sendEmail&quot;);\n    }\n    public static void main(String[] args) throws InterruptedException {\n        Phone phone1 = new Phone();\n        new Thread(()-&gt;{phone1.sendSMS();},&quot;AA&quot;).start();\n        Thread.sleep(1000); //让A先启动\n        new Thread(()-&gt;{phone1.sendEmail();},&quot;BB&quot;).start();\n    }\n}</code></pre><p>—-sendSMS</p>\n<p>—-sendEmail</p>\n<p>静态方法的锁是类的class字节码，只有一份，所以A先进入方法，获取到锁，B只能等待A</p>\n<p><strong>（4）两个静态同步方法，2部手机，先打印短信还是邮件</strong></p>\n<pre><code>public class Phone {\n    public static synchronized void sendSMS(){\n        try {\n            Thread.sleep(4000);\n            System.out.println(&quot;----sendSMS&quot;);\n        }catch (Exception e){ }\n    }\n    public static synchronized void sendEmail(){\n        System.out.println(&quot;----sendEmail&quot;);\n    }\n    public void getHello(){\n        System.out.println(&quot;----getHello&quot;);\n    }\n    public static void main(String[] args) throws InterruptedException {\n        Phone phone1 = new Phone();\n        Phone phone2 = new Phone();\n        new Thread(()-&gt;{phone1.sendSMS();},&quot;AA&quot;).start();\n        Thread.sleep(1000); //让A先启动\n        new Thread(()-&gt;{phone2.sendEmail();},&quot;BB&quot;).start();\n    }\n}</code></pre><p>—-sendSMS</p>\n<p>—-sendEmail</p>\n<p>静态方法的锁是类的class字节码，虽然是不同的对象调用，但是字节码还是只有一份，所以A先进入方法，获取到锁，B只能等待A</p>\n<p><strong>（5）一个静态方法，一个普通方法，先打印短信还是邮件</strong></p>\n<pre><code>public class Phone {\n    public static synchronized void sendSMS(){\n        try {\n            Thread.sleep(4000);\n            System.out.println(&quot;----sendSMS&quot;);\n        }catch (Exception e){ }\n    }\n    public synchronized void sendEmail(){\n        System.out.println(&quot;----sendEmail&quot;);\n    }\n    public static void main(String[] args) throws InterruptedException {\n        Phone phone = new Phone();\n        new Thread(()-&gt;{phone.sendSMS();},&quot;AA&quot;).start();\n        Thread.sleep(1000); //让A先启动\n        new Thread(()-&gt;{phone.sendEmail();},&quot;BB&quot;).start();\n    }\n}</code></pre><h4 id=\"synchronized-this-与synchronized-class-之间的区别\"><a href=\"#synchronized-this-与synchronized-class-之间的区别\" class=\"headerlink\" title=\"synchronized(this) 与synchronized(class) 之间的区别\"></a><a href=\"https://www.cnblogs.com/huansky/p/8869888.html\" target=\"_blank\" rel=\"noopener\">synchronized(this) 与synchronized(class) 之间的区别</a></h4><h3 id=\"ReentrantLock\"><a href=\"#ReentrantLock\" class=\"headerlink\" title=\"ReentrantLock\"></a>ReentrantLock</h3><h4 id=\"ReentrantReadWriteLock读写锁获取数据\"><a href=\"#ReentrantReadWriteLock读写锁获取数据\" class=\"headerlink\" title=\"ReentrantReadWriteLock读写锁获取数据\"></a>ReentrantReadWriteLock读写锁获取数据</h4><p>1个线程写数据，100个线程读取数据</p>\n<pre><code>public class ReentrantReadWriteTest {\n    ReentrantReadWriteLock lock=new ReentrantReadWriteLock();\n    private Object obj;\n    public void write(Object obj){\n        lock.writeLock().lock();\n        this.obj=obj;\n        System.out.println(Thread.currentThread().getName()+&quot;set--&quot;+this.obj);\n        lock.writeLock().unlock();\n    }\n    public void get(){\n        lock.readLock().lock();\n        System.out.println(Thread.currentThread().getName()+&quot;--get---&quot;+this.obj);\n        lock.readLock().unlock();\n    }\n    public static void main(String[] args){\n        ReentrantReadWriteTest rw = new ReentrantReadWriteTest();\n        new Thread(()-&gt;{rw.write(&quot;测试&quot;);},&quot;write&quot;).start();\n        for (int i = 0; i &lt; 100; i++) {\n            new Thread(()-&gt;{rw.get();},&quot;read--&quot;+i).start();\n        }\n    }\n}</code></pre><h3 id=\"CountDownLatch\"><a href=\"#CountDownLatch\" class=\"headerlink\" title=\"CountDownLatch\"></a>CountDownLatch</h3><p><strong>CoundDownLatch</strong>这个类能够<strong>使一个线程等待其他线程完成各自的工作后再执行</strong>。例如，应用程序的主线程希望在负责启动框架服务的线程已经启动所有的框架服务之后再执行。 </p>\n<p>编写20个同学离开教室之后，班长才锁门</p>\n<pre><code>public class CountDownLatchTest {\n    public static void main(String[] args) {\n        CountDownLatch cd = new CountDownLatch(20);\n        for (int i = 0; i &lt; 20; i++) {\n            new Thread(()-&gt;{\n                try {\n                    Thread.sleep(1000);\n                    System.out.println(Thread.currentThread().getName()+&quot;离开教室&quot;);\n                    cd.countDown();\n                } catch (InterruptedException e) {}\n            },&quot;线程&quot;+i).start();\n        }\n        new Thread(()-&gt;{\n            try {\n                cd.await();\n            } catch (InterruptedException e) {}\n            System.out.println(&quot;班长锁门&quot;);\n        },&quot;线程&quot;).start();\n    }\n}</code></pre><h3 id=\"CyclicBarrier\"><a href=\"#CyclicBarrier\" class=\"headerlink\" title=\"CyclicBarrier\"></a>CyclicBarrier</h3><p><strong>CyclicBarrier</strong>和<strong>CountDownLatch</strong>是非常类似的，<strong>CyclicBarrier</strong>核心的概念是在于设置一个等待线程的数量边界，到达了此边界之后进行执行。</p>\n<p><strong>CyclicBarrier</strong>类是一个同步辅助类，它允许一组线程互相等待，直到到达某个公共屏障点（Common Barrier Point）。</p>\n<p><strong>CyclicBarrier</strong>类是一种同步机制，它能够对处理一些算法的线程实现同。换句话讲，它就是一个所有线程必须等待的一个栅栏，直到所有线程都到达这里，然后所有线程才可以继续做其他事情。</p>\n<h3 id=\"多线程代码编写\"><a href=\"#多线程代码编写\" class=\"headerlink\" title=\"多线程代码编写\"></a>多线程代码编写</h3><h4 id=\"（一）依次打印数字和字母\"><a href=\"#（一）依次打印数字和字母\" class=\"headerlink\" title=\"（一）依次打印数字和字母\"></a>（一）依次打印数字和字母</h4><ul>\n<li><p>12A34B56C78D910E1112F1314G1516H1718I1920J2122K2324L2526M2728N2930O3132P3334Q3536R3738S3940T4142U4344V4546W4748X4950Y5152Z</p>\n<p><strong>（1）使用等待唤醒机制</strong></p>\n</li>\n</ul>\n<pre><code>package com.gzstrong.t;\npublic class NumChar {\n    private int n=1;\n    private int e=65;\n    private boolean flag=true;\n    public synchronized  void getNum(){\n        for (int i=n;i&lt;53;i=i+2) {\n            try {\n                while (!flag){\n                    this.wait();\n                }\n                System.out.print(i+&quot;&quot;+(i+1));\n                flag=false;\n            } catch (InterruptedException e1) {\n                e1.printStackTrace();\n            }\n            this.notify();\n        }\n    }\n\n    public synchronized  void getChar() {\n        for (int i=e;i&lt;91;i++) {\n            try {\n                while (flag){\n                    this.wait();\n                }\n                System.out.print((char)i);\n                flag=true;\n            } catch (InterruptedException e1) {\n                e1.printStackTrace();\n            }\n            this.notify();\n        }\n    }\n\n    public static void main(String[] args) {\n        NumChar numChar = new NumChar();\n        new Thread(()-&gt;{\n            numChar.getNum();\n        }).start();\n        new Thread(()-&gt;{\n            numChar.getChar();\n        }).start();\n    }\n}</code></pre><p><strong>（2）使用ReentrantLock方式</strong></p>\n<pre><code>package com.gzstrong.t;\n\nimport java.util.concurrent.locks.Condition;\nimport java.util.concurrent.locks.Lock;\nimport java.util.concurrent.locks.ReentrantLock;\n\npublic class NumCharLock {\n    private int n=1;\n    private int e=65;\n    private boolean flag=true;\n    Lock lock=new ReentrantLock();\n    Condition condition = lock.newCondition();\n    public void getNum(){\n        lock.lock();\n        for (int i=n;i&lt;53;i=i+2) {\n            while (!flag){\n                try {\n                    condition.await();\n                } catch (InterruptedException e1) {\n                    e1.printStackTrace();\n                }\n            }\n            System.out.print(i+&quot;&quot;+(i+1));\n            flag=false;\n            condition.signal();\n        }\n        lock.unlock();\n    }\n\n    public  void getChar() {\n        lock.lock();\n        for (int i=e;i&lt;91;i++) {\n            while (flag){\n                try {\n                    condition.await();\n                } catch (InterruptedException e1) {\n                    e1.printStackTrace();\n                }\n            }\n            System.out.print((char)i);\n            flag=true;\n            condition.signal();\n        }\n        lock.unlock();\n    }\n\n    public static void main(String[] args) {\n        NumCharLock numAA = new NumCharLock();\n        new Thread(()-&gt;{\n            numAA.getNum();\n        }).start();\n        new Thread(()-&gt;{\n            numAA.getChar();\n        }).start();\n    }\n}</code></pre><h2 id=\"Spring-Cloud-Alibaba学习\"><a href=\"#Spring-Cloud-Alibaba学习\" class=\"headerlink\" title=\"Spring Cloud Alibaba学习\"></a>Spring Cloud Alibaba学习</h2><h3 id=\"一-Nacos\"><a href=\"#一-Nacos\" class=\"headerlink\" title=\"一.Nacos\"></a>一.Nacos</h3><h4 id=\"1-配置中心\"><a href=\"#1-配置中心\" class=\"headerlink\" title=\"1.配置中心\"></a>1.配置中心</h4><p>springboot 启动报错</p>\n<p>this is very likely to create a memory leak.</p>\n<h3 id=\"二-Apollo\"><a href=\"#二-Apollo\" class=\"headerlink\" title=\"二.Apollo\"></a>二.Apollo</h3><h4 id=\"一-Apollo分布式配置中心部署\"><a href=\"#一-Apollo分布式配置中心部署\" class=\"headerlink\" title=\"(一)Apollo分布式配置中心部署\"></a>(一)Apollo分布式配置中心部署</h4><p><strong>1.下载源码</strong></p>\n<p><a href=\"https://github.com/ctripcorp/apollo\" target=\"_blank\" rel=\"noopener\">https://github.com/ctripcorp/apollo</a></p>\n<p>比较重要的几个项目：</p>\n<ul>\n<li><p>apollo-configservice：提供配置获取接口，提供配置更新推送接口，接口服务对象为Apollo客户端</p>\n</li>\n<li><p>apollo-adminservice：提供配置管理接口，提供配置修改、发布等接口，接口服务对象为Portal，以及Eureka</p>\n</li>\n<li><p>apollo-portal：提供Web界面供用户管理配置</p>\n</li>\n<li><p>apollo-client：Apollo提供的客户端程序，为应用提供配置获取、实时更新等功能</p>\n</li>\n</ul>\n<p><strong>2.配置中心执行流程</strong></p>\n<ul>\n<li>用户在Portal操作配置发布</li>\n<li>Portal调用Admin Service的接口操作发布</li>\n<li>Admin Service发布配置后，发送ReleaseMessage给各个Config Service</li>\n<li>Config Service收到ReleaseMessage后，通知对应的客户端</li>\n</ul>\n<p><strong>3.数据库初始化</strong><br>下面的sql为大写格式，注意数据库的大小写敏感设置</p>\n<ul>\n<li>ApolloPortalDB：执行apollo-master\\scripts\\db\\migration\\portaldb\\V1.0.0__initialization.sql</li>\n<li>ApolloConfigDB：执行apollo-master\\scripts\\db\\migration\\configdb\\V1.0.0__initialization.sql</li>\n</ul>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904170710.png\" alt></p>\n<p><strong>4.调整项目配置</strong></p>\n<h3 id=\"三-Sentinel\"><a href=\"#三-Sentinel\" class=\"headerlink\" title=\"三.Sentinel\"></a>三.Sentinel</h3><h4 id=\"一-Spring-Cloud-Alibaba整合Sentinel流控\"><a href=\"#一-Spring-Cloud-Alibaba整合Sentinel流控\" class=\"headerlink\" title=\"(一)Spring Cloud Alibaba整合Sentinel流控\"></a>(一)Spring Cloud Alibaba整合Sentinel流控</h4><h5 id=\"1-部署Sentinel-Dashboard\"><a href=\"#1-部署Sentinel-Dashboard\" class=\"headerlink\" title=\"1.部署Sentinel Dashboard\"></a>1.部署Sentinel Dashboard</h5><ul>\n<li>下载地址：<a href=\"https://github.com/alibaba/Sentinel/releases/download/1.6.0/sentinel-dashboard-1.6.0.jar\" target=\"_blank\" rel=\"noopener\">sentinel-dashboard-1.6.0.jar</a></li>\n<li>其他版本：<a href=\"https://github.com/alibaba/Sentinel/releases\" target=\"_blank\" rel=\"noopener\">Sentinel/releases</a></li>\n</ul>\n<pre><code class=\"shell\">java -jar sentinel-dashboard-1.6.0.jar  </code></pre>\n<p>要自定义端口号等内容的话，可以通过在启动命令中增加参数来调整，比如：<code>-Dserver.port=8888</code></p>\n<p>默认情况下，sentinel-dashboard以8080端口启动，所以可以通过访问：<code>localhost:8080</code>来验证是否已经启动成功 </p>\n<blockquote>\n<p><strong>注意</strong>：只有1.6.0及以上版本，才有这个简单的登录页面。默认用户名和密码都是<code>sentinel</code>。对于用户登录的相关配置可以在启动命令中增加下面的参数来进行配置：</p>\n</blockquote>\n<ul>\n<li><code>-Dsentinel.dashboard.auth.username=sentinel</code>: 用于指定控制台的登录用户名为 sentinel；</li>\n<li><code>-Dsentinel.dashboard.auth.password=123456</code>: 用于指定控制台的登录密码为 123456；如果省略这两个参数，默认用户和密码均为 sentinel</li>\n<li><code>-Dserver.servlet.session.timeout=7200</code>: 用于指定 Spring Boot 服务端 session 的过期时间，如 7200 表示 7200 秒；60m 表示 60 分钟，默认为 30 分钟； </li>\n</ul>\n<h5 id=\"2-整合Sentinel\"><a href=\"#2-整合Sentinel\" class=\"headerlink\" title=\"2.整合Sentinel\"></a>2.整合Sentinel</h5><p>（1）在gzstrong-system应用的<code>build.gradle</code>中引入Spring Cloud Alibaba的Sentinel模块： </p>\n<pre><code class=\"java\">      compile(&quot;org.springframework.cloud:spring-cloud-starter-alibaba-sentinel:0.2.2.RELEASE&quot;)</code></pre>\n<p>（2）在Spring Cloud应用中通过<code>spring.cloud.sentinel.transport.dashboard</code>参数配置sentinel dashboard的访问地址，比如： </p>\n<pre><code class=\"java\">spring.cloud.sentinel.transport.dashboard=localhost:8080</code></pre>\n<p>（3）创建应用主类，并提供一个rest接口，比如： </p>\n<pre><code class=\"java\">package com.gzstrong;\n\nimport com.alibaba.csp.sentinel.annotation.SentinelResource;\nimport com.alibaba.csp.sentinel.annotation.aspectj.SentinelResourceAspect;\nimport com.alibaba.csp.sentinel.slots.block.BlockException;\nimport lombok.extern.slf4j.Slf4j;\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;\nimport org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration;\nimport org.springframework.cloud.client.discovery.EnableDiscoveryClient;\nimport org.springframework.cloud.openfeign.EnableFeignClients;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.RestController;\n\n@SpringBootApplication(exclude = DataSourceAutoConfiguration.class)\n@EnableDiscoveryClient\n@EnableFeignClients\npublic class SystemApp {\n    public static void main(String[] args) {\n        SpringApplication.run(SystemApp.class, args);\n    }\n\n    @Slf4j\n    @RestController\n    static class TestController {\n\n        @SentinelResource(value=&quot;hello-anon&quot;,blockHandler=&quot;handleException&quot;,blockHandlerClass=ExceptionUtil.class)\n        @GetMapping(&quot;/hello-anon&quot;)\n        public String hello() {\n            return &quot;didispace.com&quot;;\n        }\n\n    }\n\n    @Bean\n    @ConditionalOnMissingBean\n    public SentinelResourceAspect sentinelResourceAspect() {\n        return new SentinelResourceAspect();\n    }\n\n}\nclass ExceptionUtil {\n    public static String handleException(BlockException ex) {\n        return &quot;扛不住了啊....&quot;;\n    }\n}</code></pre>\n<p>启动应用，然后通过postman或者curl访问几下<code>localhost:9097/hello-anon</code>接口 </p>\n<h2 id=\"Git使用\"><a href=\"#Git使用\" class=\"headerlink\" title=\"Git使用\"></a>Git使用</h2><h3 id=\"1-初始化仓库\"><a href=\"#1-初始化仓库\" class=\"headerlink\" title=\"1.初始化仓库\"></a>1.初始化仓库</h3><p><strong>查看状态</strong></p>\n<p>git status  查看工作区代码相对于暂存区的差别</p>\n<h3 id=\"2-移除版本控制\"><a href=\"#2-移除版本控制\" class=\"headerlink\" title=\"2.移除版本控制\"></a>2.移除版本控制</h3><p>git rm -r –cached “.gradle/“</p>\n<h3 id=\"3-添加忽略文件规则\"><a href=\"#3-添加忽略文件规则\" class=\"headerlink\" title=\"3.添加忽略文件规则\"></a>3.添加忽略文件规则</h3><p>touch .gitignore</p>\n<p>忽略文件的规则</p>\n<pre><code>#               表示此为注释,将被Git忽略\n*.a             表示忽略所有 .a 结尾的文件\n!lib.a          表示但lib.a除外\n/TODO           表示仅仅忽略项目根目录下的 TODO 文件，不包括 subdir/TODO\nbuild/          表示忽略 build/目录下的所有文件，过滤整个build文件夹；\ndoc/*.txt       表示会忽略doc/notes.txt但不包括 doc/server/arch.txt\n\nbin/:           表示忽略当前路径下的bin文件夹，该文件夹下的所有内容都会被忽略，不忽略 bin 文件\n/bin:           表示忽略根目录下的bin文件\n/*.c:           表示忽略cat.c，不忽略 build/cat.c\ndebug/*.obj:    表示忽略debug/io.obj，不忽略 debug/common/io.obj和tools/debug/io.obj\n**/foo:         表示忽略/foo,a/foo,a/b/foo等\na/**/b:         表示忽略a/b, a/x/b,a/x/y/b等\n!/bin/run.sh    表示不忽略bin目录下的run.sh文件\n*.log:          表示忽略所有 .log 文件\nconfig.php:     表示忽略当前路径的 config.php 文件\n\n/mtk/           表示过滤整个文件夹\n*.zip           表示过滤所有.zip文件\n/mtk/do.c       表示过滤某个具体文件</code></pre><h3 id=\"4-添加到暂存区\"><a href=\"#4-添加到暂存区\" class=\"headerlink\" title=\"4.添加到暂存区\"></a>4.添加到暂存区</h3><p>git add .   不加参数默认为将修改操作的文件和未跟踪新添加的文件添加到git系统的暂存区，注意不包括删除</p>\n<h3 id=\"5-提交到本地的版本库\"><a href=\"#5-提交到本地的版本库\" class=\"headerlink\" title=\"5.提交到本地的版本库\"></a>5.提交到本地的版本库</h3><p>git commit -m ‘message’  -m 参数表示注释</p>\n<h3 id=\"6-将本地版本库的分支推送到远程服务器\"><a href=\"#6-将本地版本库的分支推送到远程服务器\" class=\"headerlink\" title=\"6.将本地版本库的分支推送到远程服务器\"></a>6.将本地版本库的分支推送到远程服务器</h3><h3 id=\"7-更新代码到本地仓库\"><a href=\"#7-更新代码到本地仓库\" class=\"headerlink\" title=\"7.更新代码到本地仓库\"></a>7.更新代码到本地仓库</h3><p>git pull </p>\n<h3 id=\"8-分支\"><a href=\"#8-分支\" class=\"headerlink\" title=\"8.分支\"></a>8.分支</h3><p>git branch  查看分支</p>\n<p>git chechout aaa 切换分支aaa   </p>\n<p>git branck aaa 创建aaa分支</p>\n<h2 id=\"JMeter并发\"><a href=\"#JMeter并发\" class=\"headerlink\" title=\"JMeter并发\"></a>JMeter并发</h2><h3 id=\"1-添加线程组\"><a href=\"#1-添加线程组\" class=\"headerlink\" title=\"1 添加线程组\"></a>1 添加线程组</h3><p>右键点击“测试计划” -&gt; “添加” -&gt; “Threads(Users)” -&gt; “线程组” </p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904170759.png\" alt></p>\n<p>这里可以配置线程组名称，线程数，准备时长（Ramp-Up Period(in seconds)）循环次数，调度器等参数：</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904170826.png\" alt></p>\n<p>线程组参数详解： </p>\n<ol>\n<li>线程数：设置多少个线程数  </li>\n<li>Ramp-Up Period(in seconds)准备时长：线程数 需要多长时间全部启动。如果线程数为10，准备时长为2，那么需要2秒钟启动10个线程，也就是每秒钟启动5个线程。  一般为好理解设为1</li>\n<li>循环次数：每个线程发送请求的次数。如果线程数为10，循环次数为100，那么每个线程发送100次请求。总请求数为10*100=1000 。如果勾选了“永远”，那么所有线程会一直发送请求，一到选择停止运行脚本。  </li>\n<li>Delay Thread creation until needed：直到需要时延迟线程的创建。  </li>\n<li>调度器：设置线程组启动的开始时间和结束时间(配置调度器时，需要勾选循环次数为永远)  持续时间（秒）：测试持续时间，会覆盖结束时间  启动延迟（秒）：测试延迟启动时间，会覆盖启动时间  启动时间：测试启动时间，启动延迟会覆盖它。当启动时间已过，手动只需测试时当前时间也会覆盖它。  结束时间：测试结束时间，持续时间会覆盖它。因为接口调试需要，我们暂时均使用默认设置，待后面真正执行性能测试时再回来配置</li>\n</ol>\n<h3 id=\"2-添加HTTP请求\"><a href=\"#2-添加HTTP请求\" class=\"headerlink\" title=\"2 添加HTTP请求\"></a>2 添加HTTP请求</h3><p>右键点击“线程组” -&gt; “添加” -&gt; “Sampler” -&gt; “HTTP请求” </p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904170855.png\" alt></p>\n<p>对于我们的接口<a href=\"http://www.baidu.com/s?ie=utf-8&amp;wd=jmeter\" target=\"_blank\" rel=\"noopener\">http://www.baidu.com/s?ie=utf-8&amp;wd=jmeter</a>性能测试，可以参考下图填写：</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904170912.png\" alt></p>\n<p> Http请求主要参数详解：</p>\n<p>Web服务器  协议：向目标服务器发送HTTP请求协议，可以是HTTP或HTTPS，默认为HTTP  </p>\n<p>服务器名称或IP ：HTTP请求发送的目标服务器名称或IP  </p>\n<p>端口号：目标服务器的端口号，默认值为80  2.Http请求  方法：发送HTTP请求的方法，可用方法包括GET、POST、HEAD、PUT、OPTIONS、TRACE、DELETE等。  路径：目标URL路径（URL中去掉服务器地址、端口及参数后剩余部分）  Content encoding ：编码方式，默认为ISO-8859-1编码，这里配置为utf-8同请求一起发送参数  在请求中发送的URL参数，用户可以将URL中所有参数设置在本表中，表中每行为一个参数（对应URL中的 name=value），注意参数传入中文时需要勾选“编码”</p>\n"},{"title":"activiti学习笔记","date":"2019-08-09T12:32:59.000Z","password":123,"abstract":"欢迎来到test, 请输入密码.","message":"欢迎来到test, 请输入密码.","toc":false,"mathjax":false,"_content":"\n#  activiti学习笔记\n\n##   一、Activiti获取ProcessEngine的三种方法\n\n###  1.1 ProcessEngineConfiguration获取\n\n```java\npublic static void config() {\n        //获取config对象\n        ProcessEngineConfiguration processEngineConfiguration = ProcessEngineConfiguration.createStandaloneProcessEngineConfiguration();\n        //Jdbc设置\n        String jdbcDriver = \"com.mysql.jdbc.Driver\";\n        processEngineConfiguration.setJdbcDriver(jdbcDriver);\n        String jdbcUrl = \"jdbc:mysql://localhost:3306/activiti?useUnicode=true&characterEncoding=utf-8\";\n        processEngineConfiguration.setJdbcUrl(jdbcUrl);\n        String jdbcUsername = \"root\";\n        processEngineConfiguration.setJdbcUsername(jdbcUsername);\n        String jdbcPassword = \"root\";\n        processEngineConfiguration.setJdbcPassword(jdbcPassword);\n        //DB_SCHEMA_UPDATE_FALSE = \"false\";不自动创建新表\n        // DB_SCHEMA_UPDATE_CREATE_DROP = \"create-drop\";每次运行创建新表\n        // DB_SCHEMA_UPDATE_TRUE = \"true\";设置自动对表结构进行改进和升级\n        //设置是否自动更新\n   processEngineConfiguration.setDatabaseSchemaUpdate(ProcessEngineConfiguration.DB_SCHEMA_UPDATE_TRUE);\n        //获取引擎对象\n        ProcessEngine processEngine = processEngineConfiguration.buildProcessEngine();\n        processEngine.close();\n    }\n\n```\n\n###  1.2 ProcessEngineConfiguration载入xml文件\n\nxml文件： \n\n```xml\n<beans xmlns=\"http://www.springframework.org/schema/beans\"     xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:tx=\"http://www.springframework.org/schema/tx\"\n      xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n      xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\n   http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-2.5.xsd\n   http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.0.xsd\">\n<!--这里的类太多别导错了 -->\n<bean id=\"processEngineConfiguration\" class=\"org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration\">\n    <!-- 配置流程引擎配置对象 -->\n    <property name=\"jdbcDriver\" value=\"com.mysql.jdbc.Driver\"></property>\n    <property name=\"jdbcUrl\" value=\"jdbc:mysql://localhost:3306/activiti?useUnicode=true&amp;characterEncoding=utf-8\"></property>\n    <property name=\"jdbcUsername\" value=\"root\"></property>\n    <property name=\"jdbcPassword\" value=\"123456\"></property>\n    <!-- 注入数据源信息 -->\n    <property name=\"databaseSchemaUpdate\" value=\"true\"></property>\n</bean>\n<bean id=\"processEngine\" class=\"org.activiti.spring.ProcessEngineFactoryBean\">\n    <!-- 注入自动建表设置 -->\n    <property name=\"processEngineConfiguration\" ref=\"processEngineConfiguration\"></property>\n</bean>\n</beans>\n```\n\njava代码加载xml文件\n\n```java\npublic void configByConf() {\n   //载入资源\n   ProcessEngineConfiguration processEngineConfiguration =      ProcessEngineConfiguration.createProcessEngineConfigurationFromResource(\"activiti.cfg.xml\");\n        //创建引擎\n   ProcessEngine processEngine = processEngineConfiguration.buildProcessEngine();\n   processEngine.getRepositoryService();\n}\n```\n\n###  1.3 默认载入activiti.cfg.xml进行获取\n\n```java\npublic void configByDefault() {\n   //通过获取载入默认获取\n   ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();\n   processEngine.close();\n}\n```\n\n这里的xml文件名必须设置为activiti.cfg.xml\n\n \n\n##  二、流程定义\n\n`部署流程 `-->`启动流程实例 `\n\n###  2.1 设计流程定义文档\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182142.png)\n\n###  2.2 bpmn文件\n\n\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<definitions xmlns=\"http://www.omg.org/spec/BPMN/20100524/MODEL\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:activiti=\"http://activiti.org/bpmn\" xmlns:bpmndi=\"http://www.omg.org/spec/BPMN/20100524/DI\" xmlns:omgdc=\"http://www.omg.org/spec/DD/20100524/DC\" xmlns:omgdi=\"http://www.omg.org/spec/DD/20100524/DI\" typeLanguage=\"http://www.w3.org/2001/XMLSchema\" expressionLanguage=\"http://www.w3.org/1999/XPath\" targetNamespace=\"http://www.activiti.org/test\">\n  <process id=\"helloworld\" name=\"helloworldProcess\" isExecutable=\"true\">\n    <startEvent id=\"startevent1\" name=\"Start\"></startEvent>\n    <endEvent id=\"endevent1\" name=\"End\"></endEvent>\n    <userTask id=\"usertask1\" name=\"提交申请\" activiti:assignee=\"张三\"></userTask>\n    <userTask id=\"usertask2\" name=\"审批【部门经理】\" activiti:assignee=\"李四\"></userTask>\n    <userTask id=\"usertask3\" name=\"审批【总经理】\" activiti:assignee=\"王五\"></userTask>\n    <sequenceFlow id=\"flow1\" sourceRef=\"startevent1\" targetRef=\"usertask1\"></sequenceFlow>\n    <sequenceFlow id=\"flow2\" sourceRef=\"usertask1\" targetRef=\"usertask2\"></sequenceFlow>\n    <sequenceFlow id=\"flow3\" sourceRef=\"usertask2\" targetRef=\"usertask3\"></sequenceFlow>\n    <sequenceFlow id=\"flow4\" sourceRef=\"usertask3\" targetRef=\"endevent1\"></sequenceFlow>\n  </process>\n  <bpmndi:BPMNDiagram id=\"BPMNDiagram_helloworld\">\n    <bpmndi:BPMNPlane bpmnElement=\"helloworld\" id=\"BPMNPlane_helloworld\">\n      <bpmndi:BPMNShape bpmnElement=\"startevent1\" id=\"BPMNShape_startevent1\">\n        <omgdc:Bounds height=\"35.0\" width=\"35.0\" x=\"330.0\" y=\"20.0\"></omgdc:Bounds>\n      </bpmndi:BPMNShape>\n      <bpmndi:BPMNShape bpmnElement=\"endevent1\" id=\"BPMNShape_endevent1\">\n        <omgdc:Bounds height=\"35.0\" width=\"35.0\" x=\"330.0\" y=\"380.0\"></omgdc:Bounds>\n      </bpmndi:BPMNShape>\n      <bpmndi:BPMNShape bpmnElement=\"usertask1\" id=\"BPMNShape_usertask1\">\n        <omgdc:Bounds height=\"55.0\" width=\"105.0\" x=\"295.0\" y=\"100.0\"></omgdc:Bounds>\n      </bpmndi:BPMNShape>\n      <bpmndi:BPMNShape bpmnElement=\"usertask2\" id=\"BPMNShape_usertask2\">\n        <omgdc:Bounds height=\"55.0\" width=\"105.0\" x=\"295.0\" y=\"200.0\"></omgdc:Bounds>\n      </bpmndi:BPMNShape>\n      <bpmndi:BPMNShape bpmnElement=\"usertask3\" id=\"BPMNShape_usertask3\">\n        <omgdc:Bounds height=\"55.0\" width=\"105.0\" x=\"295.0\" y=\"290.0\"></omgdc:Bounds>\n      </bpmndi:BPMNShape>\n      <bpmndi:BPMNEdge bpmnElement=\"flow1\" id=\"BPMNEdge_flow1\">\n        <omgdi:waypoint x=\"347.0\" y=\"55.0\"></omgdi:waypoint>\n        <omgdi:waypoint x=\"347.0\" y=\"100.0\"></omgdi:waypoint>\n      </bpmndi:BPMNEdge>\n      <bpmndi:BPMNEdge bpmnElement=\"flow2\" id=\"BPMNEdge_flow2\">\n        <omgdi:waypoint x=\"347.0\" y=\"155.0\"></omgdi:waypoint>\n        <omgdi:waypoint x=\"347.0\" y=\"200.0\"></omgdi:waypoint>\n      </bpmndi:BPMNEdge>\n      <bpmndi:BPMNEdge bpmnElement=\"flow3\" id=\"BPMNEdge_flow3\">\n        <omgdi:waypoint x=\"347.0\" y=\"255.0\"></omgdi:waypoint>\n        <omgdi:waypoint x=\"347.0\" y=\"290.0\"></omgdi:waypoint>\n      </bpmndi:BPMNEdge>\n      <bpmndi:BPMNEdge bpmnElement=\"flow4\" id=\"BPMNEdge_flow4\">\n        <omgdi:waypoint x=\"347.0\" y=\"345.0\"></omgdi:waypoint>\n        <omgdi:waypoint x=\"347.0\" y=\"380.0\"></omgdi:waypoint>\n      </bpmndi:BPMNEdge>\n    </bpmndi:BPMNPlane>\n  </bpmndi:BPMNDiagram>\n</definitions>\n```\n\n###  2.3 部署流程定义\n\n(1) 部署流程定义\n\n```java\npublic void deploymentProcessDefinition_classpath(){\n\tDeployment deployment = processEngine.getRepositoryService()\n\t\t\t\t\t.createDeployment().name(\"流程定义\")\n                      //从classpath的资源中加载，一次只能加载一个文件\n\t\t\t\t\t.addClasspathResource(\"diagrams/helloworld.bpmn\")\n\t\t\t\t\t.addClasspathResource(\"diagrams/helloworld.png\").deploy();//完成部署\n\tSystem.out.println(\"部署ID：\"+deployment.getId());\n\tSystem.out.println(\"部署名称：\"+deployment.getName());\n}\n```\n\n(2) ZipInputStream的部署方式\n\n```\npublic static void main(String[] args) throws Exception{\n    DeploymentBuilder deployment = rs.createDeployment();\n    FileInputStream fis = new FileInputStream(new File(\"\"));\n    ZipInputStream zis = new ZipInputStream(fis);\n    deployment.addZipInputStream(zis);\n    deployment.deploy();\n}\n```\n\n### 2.4 流程部署后数据库的变化\n\n- act_ge_bytearray（资源文件表）        存储流程定义相关的部署信息。即流程定义文档的存放地。每部署一次就会增加两条记录，一条是关于bpmn规则文件的，一条是图片的（如果部署时只指定了bpmn一个文件，activiti会在部署时解析bpmn文件内容自动生成流程图）。两个文件不是很大，都是以二进制形式存储在数据库中。\n\n-  act_re_procdef（流程定义表）    存放流程定义的属性信息，部署每个新的流程定义都会在这张表中增加一条记录。    注意：当流程定义的key相同的情况下，使用的是版本升级    \n\n​       其中`act_re_deployment`的id会和`act_ge_bytearray`的deployment_id_关联\n\n- act_re_deployment（流程部署表）       存放流程定义的显示名和部署时间，每部署一次增加一条记录\n\n流程部署之后act_ge_bytearray插入两条记录\n\n| ID_   | REV_ | NAME_                  | DEPLOYMENT_ID_ | BYTES_   | GENERATED_ |\n| ----- | ---- | ---------------------- | -------------- | -------- | ---------- |\n| ID    | 版本 | 名称                   | 部署ID         | 字节     | 不详       |\n| 10002 | 1    | simple.bpmn            | 10001          | blob文件 | 1          |\n| 10003 | 1    | simple.myProcess_1.png | 10001          | blob文件 | 1          |\n\nact_re_procdef（流程定义表）       存放流程定义的显示名和部署时间，每部署一次增加一条记录\n\n| ID_                 | REV_ | CATEGORY_ | NAME_ | KEY_        | VERSION_ | DEPLOYMENT_ID_ | RESOURCE_NAME_ | DGRM_RESOURCE_NAME_    | DESCRIPTION_ | HAS_START_FORM_KEY_ | HAS_GRAPHICAL_NOTATION_ | SUSPENSION_STATE_ | TENANT_ID_ | ENGINE_VERSION_ |\n| ------------------- | ---- | --------- | ----- | ----------- | -------- | -------------- | -------------- | ---------------------- | ------------ | ------------------- | ----------------------- | ----------------- | ---------- | --------------- |\n| 流程定义id          |      |           |       | 流程key     | 版本     | 流程部署id     | 流程资源名称   | 流程资源图片           | 描述         |                     |                         |                   |            |                 |\n| myProcess_1:1:10004 | 1    | Examples  |       | myProcess_1 | 1        | 10001          | simple.bpmn    | simple.myProcess_1.png |              | 0                   | 1                       | 1                 |            |                 |\n\nact_re_deployment（流程部署表）       存放流程定义的显示名和部署时间，每部署一次增加一条记录\n\n| ID_    | NAME_    | CATEGORY_ | KEY_    | TENANT_ID_ | DEPLOY_TIME_   | ENGINE_VERSION_ |\n| ------ | -------- | --------- | ------- | ---------- | -------------- | --------------- |\n| 部署id | 部署名称 | 部署类型  | 部署key |            | 部署时间       |                 |\n| 10001  |          |           |         |            | 2019/4/3 16:35 |                 |\n\n###  2.5 根据名称查询流程部署\n\n```java\npublic void testQueryDeploymentByName(){\n        ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();\n        List<Deployment> deployments = processEngine.getRepositoryService()\n                .createDeploymentQuery()\n                .orderByDeploymenTime()//按照部署时间排序\n                .desc()//按照降序排序\n                .deploymentName(\"请假流程\")\n                .list();\n        for (Deployment deployment : deployments) {\n            System.out.println(deployment.getId());\n        }\n    }\n```\n\n###  2.6 查询所有的部署流程\n\n```java\npublic void queryAllDeplyoment(){\n        //得到流程引擎\n        ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();\n        List<Deployment> lists = processEngine.getRepositoryService()\n                .createDeploymentQuery()\n                .orderByDeploymenTime()//按照部署时间排序\n                .desc()//按照降序排序\n                .list();\n        for (Deployment deployment:lists) {\n            System.out.println(deployment.getId() +\"    部署名称\" + deployment.getName());\n        }\n}\n```\n\n###  2.7 查看所有流程定义\n\n```java\npublic void findProcessDefinition(){\n\tList<ProcessDefinition> list = RepositoryService.createProcessDefinitionQuery()//创建一个流程定义的查询\n\t\t\t/**指定查询条件,where条件*/\n//\t\t\t.deploymentId(deploymentId)//使用部署对象ID查询\n//\t\t\t.processDefinitionId(processDefinitionId)//使用流程定义ID查询\n//\t\t\t.processDefinitionKey(processDefinitionKey)//使用流程定义的key查询\n//\t\t\t.processDefinitionNameLike(processDefinitionNameLike)//使用流程定义的名称模糊查询\n\t\t\t.orderByProcessDefinitionVersion().asc()//按照版本的升序排列\n//\t\t\t.orderByProcessDefinitionName().desc()//按照流程定义的名称降序排列\n\t\t\t.list();//返回一个集合列表，封装流程定义\n//\t\t\t.singleResult();//返回惟一结果集\n//\t\t\t.count();//返回结果集数量\n//\t\t\t.listPage(firstResult, maxResults);//分页查询\n\tif(list!=null && list.size()>0){\n\t\tfor(ProcessDefinition pd:list){\n\t\t\tSystem.out.println(\"流程定义ID:\"+pd.getId());//流程定义的key+版本+随机生成数\n\t\t\tSystem.out.println(\"流程定义的名称:\"+pd.getName());//对应helloworld.bpmn文件中的name属性值\n\t\t\tSystem.out.println(\"流程定义的key:\"+pd.getKey());//对应helloworld.bpmn文件中的id属性值\n\t\t\tSystem.out.println(\"流程定义的版本:\"+pd.getVersion());//当流程定义的key值相同的相同下，版本升级，默认1\n\t\t\tSystem.out.println(\"资源名称bpmn文件:\"+pd.getResourceName());\n\t\t\tSystem.out.println(\"资源名称png文件:\"+pd.getDiagramResourceName());\n\t\t\tSystem.out.println(\"部署对象ID：\"+pd.getDeploymentId());\n\t\t}\n\t}\t\t\t\n}\n```\n\n###  2.8 删除流程定义\n\n```java\npublic void deleteProcessDefinition(){\n\tString deploymentId = \"601\"; //使用部署ID，完成删除\n\t//不带级联的删除 只能删除没有启动的流程，如果流程启动，就会抛出异常\n    RepositoryService().deleteDeployment(deploymentId);\n\t//级联删除  不管流程是否启动，都能可以删除\n\tRepositoryService().deleteDeployment(deploymentId, true);\n}\n```\n\n说明：    \n\n-  因为删除的是流程定义，而流程定义的部署是属于仓库服务的，所以应该先得到RepositoryService。    \n\n- 如果该流程定义下没有正在运行的流程，则可以用普通删除。如果是有关联的信息，用级联删除。项目开发中使用级联删除的情况比较多，删除操作一般只开放给超级管理员使用。\n\n###  2.9 查看流程图\n\n```java\npublic void viewPic() throws IOException{\n\t/**将生成图片放到文件夹下*/\n\tString deploymentId = \"801\";\n\t//获取图片资源名称\n\tList<String> list = repositoryService.getDeploymentResourceNames(deploymentId);\n\t//定义图片资源的名称\n\tString resourceName = \"\";\n\tif(list!=null && list.size()>0){\n\t\tfor(String name:list){\n\t\t\tif(name.indexOf(\".png\")>=0){\n\t\t\t\tresourceName = name;\n\t\t\t}\n\t\t}\n\t}\t\n\t//获取图片的输入流\n\tInputStream in = repositoryService.getResourceAsStream(deploymentId, resourceName);\n\t//将图片生成到D盘的目录下\n\tFile file = new File(\"D:/\"+resourceName);\n\t//将输入流的图片写到D盘下\n\tFileUtils.copyInputStreamToFile(in, file);\n}\n```\n\n###  2.10 流程定义的暂停挂起\n\n**测试暂停流程定义执行步骤如下：**\n\n在程序中，我们需要暂停一个流程定义，停止所有的该流程定义下的流程实例，并且不允许发起这个流程定义的流程实例，那么我们就需要挂起这个流程定义\n\n　　1，启动一个流程实例（该流程定义未挂起前）\n\n　　2，挂起上面流程实例对应的流程定义\n\n　　3，完成上述流程实例的下一个任务节点（观察效果，是否会和流程实例挂起一样）\n\n（1）根据流程实例的id来挂起这个流程定义\n\n```\npublic void testSuspendProcessDefinition(){        \n     String processDefinitionKey =\"purchasingflow\";\n     //根据流程定义的key暂停一个流程定义\n     repositoryService.suspendProcessDefinitionByKey(processDefinitionKey );\n}\n```\n\n（2）完成这个流程实例的下一个节点，通过taskService来结束下一个任务节点\n\n　　这时候，我们发现这个流程实例居然是可以继续执行的，并且可以执行到结束，带着这个疑问，我们再启动一个流程实例看看\n\n（3）重新启动这个流程定义下的流程实例\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182230.png)\n\n报错说不可以启动这个被挂起流程定义的流程实例\n\n##  三、流程实例\n\n###  3.1 根据流程部署id启动流程实例\n\n```java\npublic void startProcess(String deploymentId){\n    ProcessDefinition pd=repositoryService.createProcessDefinitionQuery()\n        .deploymentId(deploymentId)\n        .singleResult();\n    ProcessInstance pi=runtimeService.startProcessInstanceById(pd.getId());\n}\n```\n\n###  3.2 根据流程id启动流程实例,可以设置一个流程变量\n\n```java\n/**\n* 流程变量\n* 给<userTask id=\"请假申请\" name=\"申请\" activiti:assignee=\"#{student}\"></userTask>的student赋值\n*/\npublic void startProcess(){\n    Map<String, Object> variables = new HashMap<String, Object>();\n    variables.put(\"student\", \"小明\");\n    ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();\n    runtimeService.startProcessInstanceById(\"shenqing1:1:1304\",variables);\n}\n```\n\n###  3.3 启动流程实例之后数据库的变化\n\n首先向act_ru_execution表中插入一条记录，记录的是这个流程定义的执行实例，其中id和proc_inst_id相同都是流程执行实例id，也就是本次执行这个流程定义的id，包含流程定义的id外键(simpleProcess:1:5004)。\n\n| ID_   | REV_ | PROC_INST_ID_ | BUSINESS_KEY_ | PARENT_ID_ | PROC_DEF_ID_        | SUPER_EXEC_ | ROOT_PROC_INST_ID_ | ACT_ID_ | IS_ACTIVE_ | IS_CONCURRENT_ | IS_SCOPE_ | IS_EVENT_SCOPE_ | IS_MI_ROOT_ | SUSPENSION_STATE_ | START_TIME_       |\n| ----- | ---- | ------------- | ------------- | ---------- | ------------------- | ----------- | ------------------ | ------- | ---------- | -------------- | --------- | --------------- | ----------- | ----------------- | ----------------- |\n|       |      |               |               |            |                     |             |                    |         |            |                |           |                 |             |                   |                   |\n| 12501 | 1    | 12501         |               |            | myProcess_1:1:10004 |             | 12501              |         | 1          | 0              | 1         | 0               | 0           | 1                 | 2019-4-3 17:25:30 |\n| 12503 | 1    | 12501         |               | 12501      | myProcess_1:1:10004 |             | 12501              | _3      | 1          | 0              | 0         | 0               | 0           | 1                 | 2019-4-3 17:25:30 |\n\n然后向act_ru_task插入一条记录，记录的是第一个任务的信息，也就是开始执行第一个任务。包括act_ru_execution表中的execution_id外键和proc_inst_id外键，也就是本次执行实例id。\n\n| ID_   | REV_ | EXECUTION_ID_ | PROC_INST_ID_ | PROC_DEF_ID_        | NAME_    | PARENT_TASK_ID_ | DESCRIPTION_ | TASK_DEF_KEY_ | OWNER_ | ASSIGNEE_ | DELEGATION_ | PRIORITY_ | CREATE_TIME_   | DUE_DATE_ | CATEGORY_ | SUSPENSION_STATE_ |\n| ----- | ---- | ------------- | ------------- | ------------------- | -------- | --------------- | ------------ | ------------- | ------ | --------- | ----------- | --------- | -------------- | --------- | --------- | ----------------- |\n|       |      |               |               |                     |          |                 |              |               |        |           |             |           |                |           |           |                   |\n| 12506 | 1    | 12503         | 12501         | myProcess_1:1:10004 | UserTask |                 |              | _3            |        | a         |             | 50        | 2019/4/3 17:07 |           |           | 1                 |\n\n然后向act_hi_procinst表插入一条记录，记录的是本次执行实例：\n\n| ID_   | PROC_INST_ID_ | BUSINESS_KEY_ | PROC_DEF_ID_        | START_TIME_    | END_TIME_ | DURATION_ | START_USER_ID_ | START_ACT_ID_ | END_ACT_ID_ | SUPER_PROCESS_INSTANCE_ID_ | DELETE_REASON_ | TENANT_ID_ | NAME_ |\n| ----- | ------------- | ------------- | ------------------- | -------------- | --------- | --------- | -------------- | ------------- | ----------- | -------------------------- | -------------- | ---------- | ----- |\n|       |               |               |                     |                |           |           |                |               |             |                            |                |            |       |\n| 12501 | 12501         |               | myProcess_1:1:10004 | 2019/4/3 17:07 |           |           |                | _2            |             |                            |                |            |       |\n\n然后向act_hi_taskinst表中插入一条记录，记录的是任务的历史记录：\n\n| ID_   | PROC_DEF_ID_        | TASK_DEF_KEY_ | PROC_INST_ID_ | EXECUTION_ID_ | NAME_    | PARENT_TASK_ID_ | DESCRIPTION_ | OWNER_ | ASSIGNEE_ | START_TIME_    | CLAIM_TIME_ | END_TIME_ | DURATION_ | DELETE_REASON_ | PRIORITY_ | DUE_DATE_ | FORM_KEY_ | CATEGORY_ | TENANT_ID_ |\n| ----- | ------------------- | ------------- | ------------- | ------------- | -------- | --------------- | ------------ | ------ | --------- | -------------- | ----------- | --------- | --------- | -------------- | --------- | --------- | --------- | --------- | ---------- |\n|       |                     |               |               |               |          |                 |              |        |           |                |             |           |           |                |           |           |           |           |            |\n| 12506 | myProcess_1:1:10004 | _3            | 12501         | 12503         | UserTask |                 |              |        | a         | 2019/4/3 17:07 |             |           |           |                | 50        |           |           |           |            |\n\n###  3.4 流程实例的暂停挂起\n\n**测试暂停流程实例执行步骤如下：**\n\n　　1，通过流程定义的key或者id启动一个流程实例\n\n　　2，根据流程实例的id来挂起这个流程实例\n\n　　3，得到下一个节点的对应的任务的id，调用taskService来完成这个任务观察效果\n\n 　   4，重新激活这个流程实例\n\n　　5，继续完成这个流程实例\n\n（1）通过上面发起的流程实例的id挂起这个流程实例 \n\n```java\npublic void testSuspendProcessInstance(){\n    String processInstanceId=\"1801\";\n    //根据一个流程实例的id挂起该流程实例\n    runtimeService.suspendProcessInstanceById(processInstanceId);\n}\n```\n\n（2）任务的下一处理人来完成这个实例 \n\n```java\npublic void completeProcessInstance(){\n    //任务的id，后期整合后会通过当前登录人身份查询到该用户的任务，然后获取到该id\n    String taskId=\"1804\";\n    //根据任务id完成该任务\n    taskService.complete(taskId);\n}\n```\n\n执行完报错：\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904183119.png)\n\n　　上面的信息说明无法完成一个已经被挂起的任务\n\n（3）激活这个流程实例 \n\n```\npublic void testActivateProcessInstance(){\n    String processInstanceId=\"1801\";\n    runtimeService.activateProcessInstanceById(processInstanceId);\n}\n```\n\n5，重新完成这个任务，执行ok \n\n\n\n##  四、任务管理\n\n###  4.1 根据办理人查询任务\n\n`根据任务的执行人查询正在执行任务(通过act_ru_task数据表) `\n\n```java\npublic void testQueryTaskByAssignee(){\n        ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();\n        //当前班主任小毛人这个人当前正在执行的所有的任务\n        List<Task> tasks = processEngine.getTaskService()\n                .createTaskQuery()\n                .orderByTaskCreateTime()\n                .desc()\n                .taskAssignee(\"小毛\")\n                .list();\n        for (Task task : tasks) {\n            System.out.println(task.getName());\n            System.out.println(task.getAssignee());\n        }\n    }\n```\n\n###  4.2 个人任务的三种指派方式\n\n**（1）方式一**\n\n定义流程图时直接指定完成任务人（项目开发中任务的办理人不要放置XML文件中，不够灵活，较少使用） \n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904183158.png)\n\n定义的bpmn文件中定义任务办理人的名称\n\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<definitions xmlns=\"http://www.omg.org/spec/BPMN/20100524/MODEL\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:activiti=\"http://activiti.org/bpmn\" xmlns:bpmndi=\"http://www.omg.org/spec/BPMN/20100524/DI\" xmlns:omgdc=\"http://www.omg.org/spec/DD/20100524/DC\" xmlns:omgdi=\"http://www.omg.org/spec/DD/20100524/DI\" typeLanguage=\"http://www.w3.org/2001/XMLSchema\" expressionLanguage=\"http://www.w3.org/1999/XPath\" targetNamespace=\"http://www.activiti.org/test\">\n  <process id=\"personalAssignee1\" name=\"PersonalAssignee1\" isExecutable=\"true\">\n    <startEvent id=\"startevent1\" name=\"Start\"></startEvent>\n    <userTask id=\"usertask1\" name=\"审批\" activiti:assignee=\"crystal\"></userTask>\n    <sequenceFlow id=\"flow1\" sourceRef=\"startevent1\" targetRef=\"usertask1\"></sequenceFlow>\n    <endEvent id=\"endevent1\" name=\"End\"></endEvent>\n    <sequenceFlow id=\"flow2\" sourceRef=\"usertask1\" targetRef=\"endevent1\"></sequenceFlow>\n  </process>\n  <bpmndi:BPMNDiagram id=\"BPMNDiagram_personalAssignee1\">\n    <bpmndi:BPMNPlane bpmnElement=\"personalAssignee1\" id=\"BPMNPlane_personalAssignee1\">\n      <bpmndi:BPMNShape bpmnElement=\"startevent1\" id=\"BPMNShape_startevent1\">\n        <omgdc:Bounds height=\"35.0\" width=\"35.0\" x=\"360.0\" y=\"20.0\"></omgdc:Bounds>\n      </bpmndi:BPMNShape>\n      <bpmndi:BPMNShape bpmnElement=\"usertask1\" id=\"BPMNShape_usertask1\">\n        <omgdc:Bounds height=\"55.0\" width=\"105.0\" x=\"325.0\" y=\"100.0\"></omgdc:Bounds>\n      </bpmndi:BPMNShape>\n      <bpmndi:BPMNShape bpmnElement=\"endevent1\" id=\"BPMNShape_endevent1\">\n        <omgdc:Bounds height=\"35.0\" width=\"35.0\" x=\"360.0\" y=\"200.0\"></omgdc:Bounds>\n      </bpmndi:BPMNShape>\n      <bpmndi:BPMNEdge bpmnElement=\"flow1\" id=\"BPMNEdge_flow1\"></bpmndi:BPMNEdge>\n      <bpmndi:BPMNEdge bpmnElement=\"flow2\" id=\"BPMNEdge_flow2\"></bpmndi:BPMNEdge>\n    </bpmndi:BPMNPlane>\n  </bpmndi:BPMNDiagram>\n</definitions>\n\n```\n\n重点代码  **activiti:assignee=\"crystal\"**\n\n启动流程实例\n\n```java\npublic void start() {\n    ProcessInstance pi = runtimeService().startProcessInstanceByKey(\"task\");\n}\n```\n\n**（2）方式二**\n\n定义流程图时配置任务节点变量，完成任务之前由流程变量指定任务办理人。在开发中，可以在页面中指定下一个任务的办理人，通过流程变量设置下一个任务的办理人。\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904183224.png)\n\n定义的bpmn文件中定义任务办理人的名称\n\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<definitions xmlns=\"http://www.omg.org/spec/BPMN/20100524/MODEL\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:activiti=\"http://activiti.org/bpmn\" xmlns:bpmndi=\"http://www.omg.org/spec/BPMN/20100524/DI\" xmlns:omgdc=\"http://www.omg.org/spec/DD/20100524/DC\" xmlns:omgdi=\"http://www.omg.org/spec/DD/20100524/DI\" typeLanguage=\"http://www.w3.org/2001/XMLSchema\" expressionLanguage=\"http://www.w3.org/1999/XPath\" targetNamespace=\"http://www.activiti.org/test\">\n  <process id=\"personalTask2\" name=\"PersonalTask2\" isExecutable=\"true\">\n    <startEvent id=\"startevent1\" name=\"Start\"></startEvent>\n    <userTask id=\"usertask1\" name=\"审批\" activiti:assignee=\"#{userId}\"></userTask>\n    <sequenceFlow id=\"flow1\" sourceRef=\"startevent1\" targetRef=\"usertask1\"></sequenceFlow>\n    <endEvent id=\"endevent1\" name=\"End\"></endEvent>\n    <sequenceFlow id=\"flow2\" sourceRef=\"usertask1\" targetRef=\"endevent1\"></sequenceFlow>\n  </process>\n  <bpmndi:BPMNDiagram id=\"BPMNDiagram_personalTask2\">\n    <bpmndi:BPMNPlane bpmnElement=\"personalTask2\" id=\"BPMNPlane_personalTask2\">\n      <bpmndi:BPMNShape bpmnElement=\"startevent1\" id=\"BPMNShape_startevent1\">\n        <omgdc:Bounds height=\"35.0\" width=\"35.0\" x=\"380.0\" y=\"40.0\"></omgdc:Bounds>\n      </bpmndi:BPMNShape>\n      <bpmndi:BPMNShape bpmnElement=\"usertask1\" id=\"BPMNShape_usertask1\">\n        <omgdc:Bounds height=\"55.0\" width=\"105.0\" x=\"345.0\" y=\"110.0\"></omgdc:Bounds>\n      </bpmndi:BPMNShape>\n      <bpmndi:BPMNShape bpmnElement=\"endevent1\" id=\"BPMNShape_endevent1\">\n        <omgdc:Bounds height=\"35.0\" width=\"35.0\" x=\"380.0\" y=\"210.0\"></omgdc:Bounds>\n      </bpmndi:BPMNShape>\n      <bpmndi:BPMNEdge bpmnElement=\"flow1\" id=\"BPMNEdge_flow1\"></bpmndi:BPMNEdge>\n      <bpmndi:BPMNEdge bpmnElement=\"flow2\" id=\"BPMNEdge_flow2\"></bpmndi:BPMNEdge>\n    </bpmndi:BPMNPlane>\n  </bpmndi:BPMNDiagram>\n</definitions>\n```\n\n重点代码  **activiti:assignee=\"#{userId}\"**\n\n启动流程实例，需要设置流程变量\n\n```java\npublic void start() {\n    Map<String, Object> variables = new HashMap<String, Object>();\n    variables.put(\"userId\", \"crystal\");\n    ProcessInstance pi = runtimeService().startProcessInstanceByKey(\"task\",variables);\n}\n```\n\n**（3）方式三**\n\n流程图中不指定任务办理人，添加监听类，需要实现TaskListener接口\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904183040.png)\n\n定义的bpmn文件中定义任务办理人的名称\n\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<definitions xmlns=\"http://www.omg.org/spec/BPMN/20100524/MODEL\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:activiti=\"http://activiti.org/bpmn\" xmlns:bpmndi=\"http://www.omg.org/spec/BPMN/20100524/DI\" xmlns:omgdc=\"http://www.omg.org/spec/DD/20100524/DC\" xmlns:omgdi=\"http://www.omg.org/spec/DD/20100524/DI\" typeLanguage=\"http://www.w3.org/2001/XMLSchema\" expressionLanguage=\"http://www.w3.org/1999/XPath\" targetNamespace=\"http://www.activiti.org/test\">\n  <process id=\"personalTask3\" name=\"PersonalTask3\" isExecutable=\"true\">\n    <startEvent id=\"startevent1\" name=\"Start\"></startEvent>\n    <userTask id=\"usertask1\" name=\"审批\">\n      <extensionElements>\n        <activiti:taskListener event=\"create\" class=\"com.activiti.test.TaskListenerImpl\"></activiti:taskListener>\n      </extensionElements>\n    </userTask>\n    <sequenceFlow id=\"flow1\" sourceRef=\"startevent1\" targetRef=\"usertask1\"></sequenceFlow>\n    <endEvent id=\"endevent1\" name=\"End\"></endEvent>\n    <sequenceFlow id=\"flow2\" sourceRef=\"usertask1\" targetRef=\"endevent1\"></sequenceFlow>\n  </process>\n  <bpmndi:BPMNDiagram id=\"BPMNDiagram_personalTask3\">\n    <bpmndi:BPMNPlane bpmnElement=\"personalTask3\" id=\"BPMNPlane_personalTask3\">\n      <bpmndi:BPMNShape bpmnElement=\"startevent1\" id=\"BPMNShape_startevent1\">\n        <omgdc:Bounds height=\"35.0\" width=\"35.0\" x=\"310.0\" y=\"20.0\"></omgdc:Bounds>\n      </bpmndi:BPMNShape>\n      <bpmndi:BPMNShape bpmnElement=\"usertask1\" id=\"BPMNShape_usertask1\">\n        <omgdc:Bounds height=\"55.0\" width=\"105.0\" x=\"275.0\" y=\"100.0\"></omgdc:Bounds>\n      </bpmndi:BPMNShape>\n      <bpmndi:BPMNShape bpmnElement=\"endevent1\" id=\"BPMNShape_endevent1\">\n        <omgdc:Bounds height=\"35.0\" width=\"35.0\" x=\"310.0\" y=\"200.0\"></omgdc:Bounds>\n      </bpmndi:BPMNShape>\n      <bpmndi:BPMNEdge bpmnElement=\"flow1\" id=\"BPMNEdge_flow1\"></bpmndi:BPMNEdge>\n      <bpmndi:BPMNEdge bpmnElement=\"flow2\" id=\"BPMNEdge_flow2\"></bpmndi:BPMNEdge>\n    </bpmndi:BPMNPlane>\n  </bpmndi:BPMNDiagram>\n</definitions>\n```\n\n重点代码\n\n`<activiti:taskListener event=\"create\" class=\"com.activiti.test.TaskListenerImpl\"></activiti:taskListener>`\n\n监听类 TaskListenerImpl.java\n\n```java\npackage com.activiti.test;\nimport org.activiti.engine.delegate.DelegateTask;\nimport org.activiti.engine.delegate.TaskListener;\npublic class TaskListenerImpl implements TaskListener {\n    /**\n     * 指定个人任务和组任务的办理人\n     */\n    @Override\n    public void notify(DelegateTask delegateTask) {\n        delegateTask.setAssignee(\"crystal\");// 指派个人任务\n    }\n}\n```\n\n启动流程实例\n\n```java\npublic void start() {\n    ProcessInstance pi = runtimeService().startProcessInstanceByKey(\"task\");\n}\n```\n\n总结：\n\n```java\n个人任务及三种分配方式： \n  1.在taskProcess.bpmn中直接写 assignee=”crystal” \n  2.在taskProcess.bpmn中写 assignee=“#{userID}”，变量的值要是String的（使用流程变量指定办理人）。 \n  3.使用TaskListener接口，要使类实现该接口\n    在类中定义： delegateTask.setAssignee(assignee);// 指定个人任务的办理人 \n  4.使用任务ID和办理人重新指定办理人： taskService.setAssignee(taskId, userId);\n```\n\n\n\n###  4.3 组任务的三种指派方式\n\n**方式一：直接指定办理人**\n\n（1）.在任务节点设置办理人\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182327.png)\n\n（2）bpmn中的代码片段\n\n```\n <userTask activiti:candidateUsers=\"小a,小b,小c\" activiti:exclusive=\"true\" id=\"usertask1\" name=\"提交申请\"/>\n```\n\n（3）部署流程和启动流程\n\n```java\npublic void test(){\n    repositoryService.createDeployment().addClasspathResource(\"test1.bpmn\").deploy();//部署流程\n    ProcessInstance pi = runtimeService.startProcessInstanceByKey(\"helloword\");//启动流程\n}\n```\n\n（4）查询我的个人任务，没有执行结果\n\n```java\n public void queryTask(String assignee) {\n     List<Task> list = taskService.createTaskQuery().orderByTaskCreateTime()\n     \t\t.desc().taskAssignee(assignee).list();\n     if (list != null && list.size() > 0) {\n         for (Task task : list) {\n             System.out.println(\"任务ID：\" + task.getId());\n             System.out.println(\"任务的办理人：\" + task.getAssignee());\n             System.out.println(\"任务名称：\" + task.getName());\n             System.out.println(\"任务的创建时间：\" + task.getCreateTime());\n             System.out.println(\"流程实例ID：\" + task.getProcessInstanceId());\n             System.out.println(\"#######################################\");\n         }\n     }\n}\n```\n\n（5）查询组任务，可以查到查询结果\n\n```\n public void findGroupTaskList(String candidateUser) {\n        List<Task> list = taskService.createTaskQuery().taskCandidateUser(candidateUser).list();\n        if (list != null && list.size() > 0) {\n            for (Task task : list) {\n                System.out.println(\"任务ID：\" + task.getId());\n                System.out.println(\"任务的办理人：\" + task.getAssignee());\n                System.out.println(\"任务名称：\" + task.getName());\n                System.out.println(\"任务的创建时间：\" + task.getCreateTime());\n                System.out.println(\"流程实例ID：\" + task.getProcessInstanceId());\n                System.out.println(\"#######################################\");\n            }\n        }\n    }\n```\n\n查询结果如下\n\n> 任务ID：15010\n> 任务的办理人：null\n> 任务名称：提交申请\n> 任务的创建时间：Thu Apr 04 10:50:00 CST 2019\n> 流程实例ID：15005\n\n（6）查询正在执行的组任务列表\n\n```java\npublic void findGroupCandidate(String taskId) {\n    List<IdentityLink> list = taskService.getIdentityLinksForTask(taskId);\n        if (list != null && list.size() > 0) {\n        for (IdentityLink identityLink : list) {\n            System.out.println(\"任务ID：\" + identityLink.getTaskId());\n            System.out.println(\"流程实例ID：\"+ identityLink.getProcessInstanceId());\n            System.out.println(\"用户ID：\" + identityLink.getUserId());\n            System.out.println(\"工作流角色ID：\" + identityLink.getGroupId());\n            System.out.println(\"#########################################\");\n        }\n    }\n}\n```\n\n执行结果\n\n> 任务ID：15010\n> 流程实例ID：null\n> 用户ID：小a\n> 工作流角色ID：null\n>\n> 任务ID：15010\n> 流程实例ID：null\n> 用户ID：小b\n> 工作流角色ID：null\n>\n> 任务ID：15010\n> 流程实例ID：null\n> 用户ID：小c\n> 工作流角色ID：null\n\n（7）查询历史的组任务列表\n\n```java\npublic void findHistoryGroupCandidate(String processInstanceId) {\n    String processInstanceId = \"3705\";\n    List<HistoricIdentityLink> list = historyService\n        \t.getHistoricIdentityLinksForProcessInstance(processInstanceId);\n    if (list != null && list.size() > 0) {\n        for (HistoricIdentityLink identityLink : list) {\n            System.out.println(\"任务ID：\" + identityLink.getTaskId());\n            System.out.println(\"流程实例ID：\"+ identityLink.getProcessInstanceId());\n            System.out.println(\"用户ID：\" + identityLink.getUserId());\n            System.out.println(\"工作流角色ID：\" + identityLink.getGroupId());\n            System.out.println(\"#########################################\");\n        }\n    }\n}\n```\n\n说明：     \n\n- 小A，小B，小C是组任务的办理人     \n- 但是这样分配组任务的办理人不够灵活，因为项目开发中任务的办理人不要放置XML文件中。     \n- act_ru_identitylink表存放组任务的办理人，表示正在执行的任务     \n- act_hi_identitylink表存放所有任务的办理人，包括个人任务和组任务**，**表示历史任务\n\n**方式二：使用流程变量**\n\n （1）在任务节点设置变量\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904183359.png)\n\n（2）bpmn中的代码片段\n\n```\n<userTask activiti:candidateUsers=\"#{userIDs}\" activiti:exclusive=\"true\" id=\"usertask1\" name=\"提交申请\"/>\n```\n\n（3）部署流程和启动流程\n\n启动流程实例的同时，设置流程变量，使用流程变量的方式设置下一个任务的办理人\n\n 流程变量的名称，是task.bpmn中定义activiti:candidateUsers=\"#{userIDs}\"的userIDs  流程变量的值，就是任务的办理人（组任务）\n\n```java\npublic void test(){\n    repositoryService.createDeployment().addClasspathResource(\"test1.bpmn\").deploy();//部署流程\n\tMap<String, Object> variables = new HashMap<String, Object>();\n\tvariables.put(\"userIDs\", \"小a,小b,小c\");\n\tProcessInstance pi = runtimeService.startProcessInstanceByKey(\"helloword\",variables);//使用流程定义的key的最新版本启动流程\n}\n```\n\n**方式三：使用监听器**\n\n（1）设置监听器变量\n\n![img](https://img-blog.csdn.net/20151227154130920)\n\n \n\n（2）编写监听器类\n\n```\npublic class TaskListenerImpl implements TaskListener {\n\t/**\n\t * 可以设置任务的办理人（个人组人和组任务）\n\t */\n\t@Override\n\tpublic void notify(DelegateTask delegateTask) {\n\t\t//指定组任务\n\t\tdelegateTask.addCandidateUser(\"孙悟空\");\n\t\tdelegateTask.addCandidateUser(\"猪八戒\");\n\t}\n}\n```\n\n（3）测试代码\n\n```java\n/**将组任务指定个人任务(拾取任务)*/\npublic void claim(){\n    String taskId = \"6308\";\n    //个人任务的办理人\n    String userId = \"唐僧\";\n    taskService.claim(taskId, userId);\n}\n\n/**将个人任务再回退到组任务（前提：之前这个任务是组任务）*/\npublic void setAssignee(){\n    String taskId = \"6308\";\n    taskService.setAssignee(taskId, null);\n}\n\n/**向组任务中添加成员*/\npublic void addGroupUser(){\n    String taskId = \"6308\";\n    //新增组任务的成员\n    String userId = \"如来\";\n    taskService.addCandidateUser(taskId, userId);\n}\n\n/**向组任务中删除成员*/\npublic void deleteGroupUser(){\n    String taskId = \"6308\";\n    //新增组任务的成员\n    String userId = \"猪八戒\";\n    taskService.deleteCandidateUser(taskId, userId);\n}\n```\n\n总结：      以上就是分配组任务的三种方式，和分配个人任务相对应，同样有三种方式，与个人任务的操作相比，组任务操作增加了组任务分配个人任务（认领任务），个人任务分配给组任务，以及向组任务添加人员和向组任务删除人员的操作。\n\n###  4.4 工作流提供的用户角色\n\n（1）设置用户角色\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182357.png)\n\n这个【部门经理】相当于一个用户角色，一个角色可以对应多个人，比如有三个人：张三、李四是部门经理，王五是总经理，那我们可以把这三个人录入的我们自己的用户表中，那么工作流也给我们提供了至少三张表：用户表，角色表，用户角色关联表那我们就可以把部门经理这个角色与张三、李四关联起来\n\n（2）具体做法：1、添加用户角色组  2、创建角色3、创建用户4、创建角色用户关联关系测试代码如下：\n\n```java\npublic void addUser(){\t\n\t\t//创建角色(两个角色)\n\t\tidentityService.saveGroup(new GroupEntity(\"部门经理\"));\n\t\tidentityService.saveGroup(new GroupEntity(\"总经理\"));\n\t\t\n\t\t//创建用户（三个用户）\n\t\tidentityService.saveUser(new UserEntity(\"张三\"));\n\t\tidentityService.saveUser(new UserEntity(\"李四\"));\n\t\tidentityService.saveUser(new UserEntity(\"王五\"));\n\t\t\n\t\t//创建用户角色关联关系\n\t\tidentityService.createMembership(\"张三\", \"部门经理\");\n\t\tidentityService.createMembership(\"李四\", \"部门经理\");\n\t\tidentityService.createMembership(\"王五\", \"总经理\");\n}\n```\n\n（3）部署流程定义\n\n```\npublic void deployementAndStart(){\n\tDeployment deployment = repositoryService.createDeployment().name(\"组任务\")\n\t\t\t\t\t.addClasspathResource(\"diagrams/group.bpmn\")\n\t\t\t\t\t.addClasspathResource(\"diagrams/group.png\").deploy();\n\tProcessInstance pi = runtimeService.startProcessInstanceByKey(\"group\");//启动流程  \n}\t\t\t\t\n```\n\n（4）查询张三或者李四的任务\n\n```\npublic void findGroupTask(){\n\t\tString candidateUser = \"张三\";\n\t\tList<Task> list =taskService.createTaskQuery().taskCandidateUser(candidateUser).list();\n\t\tif(list!=null && list.size()>0){  \n\t        for(Task task:list){  \n\t            System.out.println(\"任务ID：\"+task.getId());  \n\t            System.out.println(\"任务的办理人：\"+task.getAssignee());  \n\t            System.out.println(\"任务名称：\"+task.getName());  \n\t            System.out.println(\"任务的创建时间：\"+task.getCreateTime());  \n\t            System.out.println(\"流程实例ID：\"+task.getProcessInstanceId());  \n\t            System.out.println(\"#######################################\");  \n\t        }  \n\t     }\n}\n```\n\n执行结果\n\n>  任务ID：167504 \n>\n>  任务的办理人：null \n>\n>  任务名称：审核 \n>\n>  任务的创建时间：Thu Jul 07 10:21:27 GMT+08:00 2016 \n>\n>  流程实例ID：167501 \n\n（5）候选者不一定真正的参与任务的办理，所以我们需要拾取任务，将组任务分配给个人任务,即指定任务办理人字段\n\n```java\npublic void cliam(){\n\t\t//将组任务分配给个人任务\n\t\tString taskId =\"167504\";\n\t\t//分配的个人任务（可以是组任务中的成员，也可以是非组任务的成员）\n\t\tString userId =\"张三\";\n\t\ttaskService.claim(taskId, userId);\n\t\t//当执行完查询正执行的任务表（act_ru_task）可发现ASSIGNEE_字段（指定任务办理人）值为'张三'\n\t    //此时任务就指定给了张三，再用李四去查个人组任务就查询不出来任何任务【组任务最终也是需要指定一个人办理的，所以需要拾取任务】\n}\n\n```\n\n（6）张三完成任务\n\n```java\npublic void completeTask(){\n\tString taskId =\"167504\";\n\ttaskService.complete(taskId);\n}\n\n```\n\n当我们部署完流程定义，启动流程实例之后，我们可以查看您一下几张数据表：**表act_ru_task**\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904183255.png)\n\n 可以看见任务办理人的字段值为null,所以可能有两种情况可能没有办理人或者可能这个任务是组任务\n\n**表act_ru_identitylink**   正在执行的任务办理人表\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904183326.png)\n\n在这个表可以看见Task_ID 的值为167504就是正在执行的任务ID，流程实例字段为空，所以这个任务是组任务，处理这个组任务的角色ID为部门经理而张三和李四都是这个角色的用户，所以张三李四都可以查到这个任务，也可以进行任务的拾取，分配等操作。\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182422.png)\n\n需要说明的是在我们自己项目开发的时候，我们一般都是不用工作流自带的用户表、角色表，用户角色关联表都是自己来建，因为自带的表提供的字段不全。\n\n###  4.5 任务签收与反签收\n\n```java\n//任务签收\npublic void claim(String taskId) {\n   String userId = \"1111\";\n   taskService.claim(taskId, userId);\n}\n\n//任务反签收\npublic String unclaim(String taskId) {\n    taskService.unclaim(taskId);\n}\n```\n\n### 4.6 驳回申请\n\n\n\n### 4.7  流程变量的设置和获取\n\n**设置流程变量**\n\n流程变量的设置方式有两种，一是通过基本类型设置，第二种是通过JavaBean类型设置。\n\n**（1）基本类型**\n\n```\n\tpublic void setProcessVariables(){\n\t\tString processInstanceId = \"1301\";//流程实例ID\n\t\tString assignee = \"张三\";//任务办理人\n\t\t//查询当前办理人的任务ID\n\t\tTask task = taskService.createTaskQuery()\n\t\t\t\t.processInstanceId(processInstanceId)//使用流程实例ID\n\t\t\t\t.taskAssignee(assignee)//任务办理人\n\t\t\t\t.singleResult();\n\t\t//设置流程变量【基本类型】\n\t\ttaskService.setVariable(task.getId(), \"请假人\", assignee);\n\t\ttaskService.setVariableLocal(task.getId(), \"请假天数\",3);\n\t\ttaskService.setVariable(task.getId(), \"请假日期\", new Date());\n\t}\n```\n\n对应数据库表：act_ru_variable\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182451.png)\n\n**（2）JavaBean类型**\n\n```\npublic class Person{\n\tprivate Integer id;\n\tprivate String name;\n\tprivate String education;\n}\n```\n\n然后，通过JavaBean设置流程变量。这里要注意的是，Javabean类型设置获取流程变量，除了需要这个javabean实现了Serializable接口外，还要求流程变量对象的属性不能发生编号，否则抛出异常。 \n\n```java\npublic void setProcessVariables(){\n    String processInstanceId = \"1301\";//流程实例ID\n    String assignee = \"张三\";//任务办理人\n    //查询当前办理人的任务ID\n    Task task = taskService.createTaskQuery()\n        .processInstanceId(processInstanceId).taskAssignee(assignee).singleResult();\n    //设置流程变量【javabean类型】\n    Person p = new Person();\n    p.setId(1);\n    p.setName(\"周江霄\");\n    taskService.setVariable(task.getId(), \"人员信息\", p);\n}\n```\n\n数据库对应表：act_ru_variable，细心的你可以看到，通过JavaBean设置的流程变量，在act_ru_variable中存储的类型为serializable，变量真正存储的地方在act_ge_bytearray中\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182524.png) \n\n **获取流程变量**\n\n**（1）基本类型**\n\n```java\npublic void getProcessVariables(){\n\t\tString processInstanceId = \"1301\";//流程实例ID\n\t\tString assignee = \"张三\";//任务办理人\n\t\tTaskService taskService = processEngine.getTaskService();\n\t\t//获取当前办理人的任务ID\n\t\tTask task = taskService.createTaskQuery()\n\t\t\t\t.processInstanceId(processInstanceId)\n\t\t\t\t.taskAssignee(assignee)\n\t\t\t\t.singleResult();\n\t\tString person = (String) taskService.getVariable(task.getId(), \"请假人\");\n\t\tInteger day = (Integer) taskService.getVariableLocal(task.getId(), \"请假天数\");\n\t\tDate date = (Date) taskService.getVariable(task.getId(), \"请假日期\");\n\t\tSystem.out.println(person+\"  \"+day+\"   \"+date);\n}\n```\n\n**（2）JavaBean类型**\n\n```java\n/**获取流程变量*/\n\t@Test\n\tpublic void getProcessVariables(){\n\t\tString processInstanceId = \"1301\";//流程实例ID\n\t\tString assignee = \"张三\";//任务办理人\n\t\t//获取当前办理人的任务ID\n\t\tTask task = taskService.createTaskQuery()\n\t\t\t\t.processInstanceId(processInstanceId)\n\t\t\t\t.taskAssignee(assignee)\n\t\t\t\t.singleResult();\n\t\t//获取流程变量【javaBean类型】\n\t\tPerson p = (Person) taskService.getVariable(task.getId(), \"人员信息\");\n\t\tSystem.out.println(p.getId()+\"  \"+p.getName());\n\t\tSystem.out.println(\"获取成功~~\");\n\t}\n```\n\n  **查询历史流程变量** \n\n```\n/**查询历史的流程变量*/\npublic void getHistoryProcessVariables(){\n\tList<HistoricVariableInstance> list = processEngine.getHistoryService()\n\t\t\t\t.createHistoricVariableInstanceQuery()//创建一个历史的流程变量查询\n\t\t\t\t.variableName(\"请假天数\").list();\n\tif(list != null && list.size()>0){\n\t\tfor(HistoricVariableInstance hiv : list){\n\t\t\t\tSystem.out.println(\n\t\t\t\thiv.getTaskId()+\"  \"+hiv.getVariableName()+\"\n\t\t\t\t\"+hiv.getValue()+\"\t\t\"+hiv.getVariableTypeName());\n\t\t}\n\t}\t\t\t\t\n}\n```\n\n对应数据库表：act_ru_execution\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182542.png)\n\n### 4.8 查询所有的正在执行的任务 \n\n```java\npublic void testQueryTask(){\n        ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();\n        List<Task> tasks = processEngine.getTaskService()\n                .createTaskQuery()\n                .list();\n        for (Task task : tasks) {\n            System.out.println(task.getName());\n        }\n}\n```\n\n### 4.9 完成任务\n\n```\npublic void complete(){\n\t\tTask task=taskService.createTaskQuery()\n            .processInstanceId(pi.getId()).taskDefinitionKey(\"task\").singleResult();\n\t\ttaskService.setVariable(task.getId(), \"var1\", \"var1\");\n         taskService.complete(task.getId());\n }\n```\n\n以上代码是查询流程本次执行实例下名为task1的任务\n\n给任务设置全局变量，如果调用的是taskService.setVariableLocal方法，则任务执行完毕后，相关变量数据就会删除，然后再完成任务。\n\n首先向act_ru_variable表中插入变量信息，包含本次流程执行实例的两个id外键，但不包括任务的id，因为setVariable方法设置的是全局变量，也就是整个流程都会有效的变量\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182930.png)     \n\n此时整个流程执行完毕，act_ru_task，act_ru_execution和act_ru_variable表全被清空\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182951.png)\n\n## 五、历史任务\n\n### 5.1 查已完成任务和当前在执行的任务 \n\n```java\npublic void findHistoryTask(){\n        ProcessEngine defaultProcessEngine = ProcessEngines.getDefaultProcessEngine();\n        //如果只想获取到已经执行完成的，那么就要加入completed这个过滤条件\n        List<HistoricTaskInstance> historicTaskInstances1 = defaultProcessEngine.getHistoryService()\n                .createHistoricTaskInstanceQuery()\n                .taskDeleteReason(\"completed\")\n                .list();\n        //如果只想获取到已经执行完成的，那么就要加入completed这个过滤条件\n        List<HistoricTaskInstance> historicTaskInstances2 = defaultProcessEngine.getHistoryService()\n                .createHistoricTaskInstanceQuery()\n                .list();\n        System.out.println(\"执行完成的任务：\" + historicTaskInstances1.size());\n        System.out.println(\"所有的总任务数（执行完和当前未执行完）：\" +historicTaskInstances2.size());\n    }\n```\n\n\n\nActiviti 个人任务（三种指派方式） https://blog.csdn.net/caoyue_new/article/details/52180539\n\n\n\n六：关于流程实例的相关API\n\n**涉及到的表：**   \n\n**act_hi_actinst  **\n\n1、说明 *         act:activiti  *         hi:history  *         actinst:activity instance  *            流程图上出现的每一个元素都称为activity  *            流程图上正在执行的元素或者已经执行完成的元素称为activity instance  *      2、字段 *         proc_def_id:pdid  *         proc_inst_id:流程实例ID  *         execution_id_:执行ID  *         act_id_:activity  *         act_name  *         act_type  \n\n**act_hi_procinst **\n\n**      1、说明 *         procinst:process instance  历史的流程实例 *            正在执行的流程实例也在这张表中 *         如果end_time_为null，说明正在执行，如果有值，说明该流程实例已经结束了 *    _\n\n**act_hi_taskinst**\n\n     1、说明 *          taskinst:task instance  历史任务 *             正在执行的任务也在这张表中 *             如果end_time_为null,说明该任务正在执行 *             如果end_time不为null,说明该任务已经执行完毕了 *    **act_ru_execution**\n\n_      1、说明 *         ru:runtime  *         代表正在执行的流程实例表 *         如果当期正在执行的流程实例结束以后，该行在这张表中就被删除掉了，所以该表也是一个临时表 *      2、字段 *         proc_inst_id_:piid  流程实例ID，如果不存在并发的情况下，piid和executionID是一样的 *         act_id:当前正在执行的流程实例(如果不考虑并发的情况)的正在执行的activity有一个，所以act_id就是当前正在执行的流程实例的正在执行的 *           节点 *    **act_ru_task**_\n\n1、代表正在执行的任务表    该表是一个临时表，如果当前任务被完成以后，任务在这张表中就被删除掉了 \n\n2、字段 \n\n id_:  主键    任务ID      execution_id_:执行ID    *              根据该ID查询出来的任务肯定是一个 *          proc_inst_id:piid  *              根据该id查询出来的任务 *                 如果没有并发，则是一个 *                 如果有并发，则是多个 *          name_:任务的名称 *          assignee_:任务的执行人**\n\n\n\n## 六、工作流采购流程如何与业务关联\n\n实例.采购流程的监控\n\n- 查询当前获任务和业务关联\n\n- 查询已经结束的流程\n- 查询当前采购流程节点的位置图展示（在流程定义的节点上标出当前节点的位置，使用红色的框标出）\n- 查询某个流程下的历史任务（从流程开始到运行结束）\n- 查询某个用户所办理的历史任\n\n2.流程变量\n\n- 全局变量\n- 局部变量\n\n3.连线分支\n\n设置连线的condition条件实现分支\n\n### 6.1 流程定义图的画法\n\n流程图注意的东西\n\n（1）流程定义key  \n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182636.png)\n\n（2）流程变量 ：\n\n分支条件：**$**(price>=1000) 和**$**(price<1000)\n\n![1567592826450](C:\\Users\\Administrator\\AppData\\Local\\Temp\\1567592826450.png)\n\n（3）人员设置流程变量\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182721.png)\n\n其他和部门经理的设置方法一样\n\n部门经理审批的代办人流程变量  **$**{u} \n\n总经理审批的代办人流程变量  **$**{m} \n\n财务审批的代办人流程变量  **$**{c} \n\n（4）order.bpmn文件\n\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\n<definitions xmlns=\"http://www.omg.org/spec/BPMN/20100524/MODEL\" xmlns:activiti=\"http://activiti.org/bpmn\" xmlns:bpmndi=\"http://www.omg.org/spec/BPMN/20100524/DI\" xmlns:dc=\"http://www.omg.org/spec/DD/20100524/DC\" xmlns:di=\"http://www.omg.org/spec/DD/20100524/DI\" xmlns:tns=\"Examples\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" expressionLanguage=\"http://www.w3.org/1999/XPath\" id=\"m1539757531057\" name=\"\" targetNamespace=\"Examples\" typeLanguage=\"http://www.w3.org/2001/XMLSchema\">\n  <process id=\"orderKey\" isClosed=\"false\" isExecutable=\"true\" processType=\"None\">\n    <startEvent id=\"_2\" name=\"StartEvent\"/>\n    <userTask activiti:assignee=\"#{u}\" activiti:exclusive=\"true\" id=\"_3\" name=\"部门经理审批\"/>\n    <sequenceFlow id=\"_7\" sourceRef=\"_2\" targetRef=\"_3\"/>\n    <userTask activiti:assignee=\"${c}\" activiti:exclusive=\"true\" id=\"_4\" name=\"财务审批\"/>\n    <userTask activiti:assignee=\"${m}\" activiti:exclusive=\"true\" id=\"_5\" name=\"总经理审批\"/>\n    <endEvent id=\"_6\" name=\"EndEvent\"/>\n    <sequenceFlow id=\"_8\" sourceRef=\"_4\" targetRef=\"_6\"/>\n    <sequenceFlow id=\"_9\" sourceRef=\"_3\" targetRef=\"_4\">\n      <conditionExpression xsi:type=\"tFormalExpression\"><![CDATA[${price < 1000} ]]></conditionExpression>\n    </sequenceFlow>\n    <sequenceFlow id=\"_10\" sourceRef=\"_3\" targetRef=\"_5\">\n      <conditionExpression xsi:type=\"tFormalExpression\"><![CDATA[${price >= 1000} ]]></conditionExpression>\n    </sequenceFlow>\n    <sequenceFlow id=\"_11\" sourceRef=\"_5\" targetRef=\"_4\"/>\n  </process>\n  <bpmndi:BPMNDiagram documentation=\"background=#32424A;count=1;horizontalcount=1;orientation=0;width=842.4;height=1195.2;imageableWidth=832.4;imageableHeight=1185.2;imageableX=5.0;imageableY=5.0\" id=\"Diagram-_1\" name=\"New Diagram\">\n    <bpmndi:BPMNPlane bpmnElement=\"orderKey\">\n      <bpmndi:BPMNShape bpmnElement=\"_2\" id=\"Shape-_2\">\n        <dc:Bounds height=\"32.0\" width=\"32.0\" x=\"100.0\" y=\"10.0\"/>\n        <bpmndi:BPMNLabel>\n          <dc:Bounds height=\"32.0\" width=\"32.0\" x=\"0.0\" y=\"0.0\"/>\n        </bpmndi:BPMNLabel>\n      </bpmndi:BPMNShape>\n      <bpmndi:BPMNShape bpmnElement=\"_3\" id=\"Shape-_3\">\n        <dc:Bounds height=\"55.0\" width=\"85.0\" x=\"75.0\" y=\"95.0\"/>\n        <bpmndi:BPMNLabel>\n          <dc:Bounds height=\"55.0\" width=\"85.0\" x=\"0.0\" y=\"0.0\"/>\n        </bpmndi:BPMNLabel>\n      </bpmndi:BPMNShape>\n      <bpmndi:BPMNShape bpmnElement=\"_4\" id=\"Shape-_4\">\n        <dc:Bounds height=\"55.0\" width=\"85.0\" x=\"70.0\" y=\"220.0\"/>\n        <bpmndi:BPMNLabel>\n          <dc:Bounds height=\"55.0\" width=\"85.0\" x=\"0.0\" y=\"0.0\"/>\n        </bpmndi:BPMNLabel>\n      </bpmndi:BPMNShape>\n      <bpmndi:BPMNShape bpmnElement=\"_5\" id=\"Shape-_5\">\n        <dc:Bounds height=\"55.0\" width=\"85.0\" x=\"295.0\" y=\"95.0\"/>\n        <bpmndi:BPMNLabel>\n          <dc:Bounds height=\"55.0\" width=\"85.0\" x=\"0.0\" y=\"0.0\"/>\n        </bpmndi:BPMNLabel>\n      </bpmndi:BPMNShape>\n      <bpmndi:BPMNShape bpmnElement=\"_6\" id=\"Shape-_6\">\n        <dc:Bounds height=\"32.0\" width=\"32.0\" x=\"95.0\" y=\"380.0\"/>\n        <bpmndi:BPMNLabel>\n          <dc:Bounds height=\"32.0\" width=\"32.0\" x=\"0.0\" y=\"0.0\"/>\n        </bpmndi:BPMNLabel>\n      </bpmndi:BPMNShape>\n      <bpmndi:BPMNEdge bpmnElement=\"_7\" id=\"BPMNEdge__7\" sourceElement=\"_2\" targetElement=\"_3\">\n        <di:waypoint x=\"116.0\" y=\"42.0\"/>\n        <di:waypoint x=\"116.0\" y=\"95.0\"/>\n        <bpmndi:BPMNLabel>\n          <dc:Bounds height=\"0.0\" width=\"0.0\" x=\"0.0\" y=\"0.0\"/>\n        </bpmndi:BPMNLabel>\n      </bpmndi:BPMNEdge>\n      <bpmndi:BPMNEdge bpmnElement=\"_8\" id=\"BPMNEdge__8\" sourceElement=\"_4\" targetElement=\"_6\">\n        <di:waypoint x=\"111.0\" y=\"275.0\"/>\n        <di:waypoint x=\"111.0\" y=\"380.0\"/>\n        <bpmndi:BPMNLabel>\n          <dc:Bounds height=\"0.0\" width=\"0.0\" x=\"0.0\" y=\"0.0\"/>\n        </bpmndi:BPMNLabel>\n      </bpmndi:BPMNEdge>\n      <bpmndi:BPMNEdge bpmnElement=\"_9\" id=\"BPMNEdge__9\" sourceElement=\"_3\" targetElement=\"_4\">\n        <di:waypoint x=\"115.0\" y=\"150.0\"/>\n        <di:waypoint x=\"115.0\" y=\"220.0\"/>\n        <bpmndi:BPMNLabel>\n          <dc:Bounds height=\"0.0\" width=\"0.0\" x=\"0.0\" y=\"0.0\"/>\n        </bpmndi:BPMNLabel>\n      </bpmndi:BPMNEdge>\n      <bpmndi:BPMNEdge bpmnElement=\"_11\" id=\"BPMNEdge__11\" sourceElement=\"_5\" targetElement=\"_4\">\n        <di:waypoint x=\"340.0\" y=\"150.0\"/>\n        <di:waypoint x=\"340.0\" y=\"190.0\"/>\n        <di:waypoint x=\"155.0\" y=\"247.5\"/>\n        <bpmndi:BPMNLabel>\n          <dc:Bounds height=\"0.0\" width=\"0.0\" x=\"0.0\" y=\"0.0\"/>\n        </bpmndi:BPMNLabel>\n      </bpmndi:BPMNEdge>\n      <bpmndi:BPMNEdge bpmnElement=\"_10\" id=\"BPMNEdge__10\" sourceElement=\"_3\" targetElement=\"_5\">\n        <di:waypoint x=\"160.0\" y=\"122.5\"/>\n        <di:waypoint x=\"295.0\" y=\"122.5\"/>\n        <bpmndi:BPMNLabel>\n          <dc:Bounds height=\"0.0\" width=\"0.0\" x=\"0.0\" y=\"0.0\"/>\n        </bpmndi:BPMNLabel>\n      </bpmndi:BPMNEdge>\n    </bpmndi:BPMNPlane>\n  </bpmndi:BPMNDiagram>\n</definitions>\n\n```\n\n> 关键点  <process id=\"orderKey\" isClosed=\"false\" isExecutable=\"true\" processType=\"None\">\n\n###  6.2流程定义的部署\n\nactivitiService.java\n\n```java\npublic void deployByClassPath(String bpmnName) {\n        Deployment deploy =       repositoryService.createDeployment().addClasspathResource(bpmnName+\".bpmn\").deploy();\n        printDeploy(deploy);\n    }\n```\n\n```java\n@RequestMapping(\"/deploy\")\n@ResponseBody\npublic String deploy(String bpmnName) {\n    activitiService.deployByClassPath(bpmnName);\n    activitiService.queryDeployList();\n    return \"deploy\";\n}\n```\n\n###  6.3 流程实例启动时关联业务\n\n使用activiti自带表act_ru_execution中的BUSINESS_KEY字段我存在业务的唯一表示 \n\n```java\n/**\n* 流程变量\n* 给<userTask activiti:assignee=\"#{u}\" activiti:exclusive=\"true\" name=\"部门经理审批\"/>的u赋值\n* 给<userTask activiti:assignee=\"#{m}\" activiti:exclusive=\"true\" name=\"总经理审批\"/>的u赋值\n* 给<userTask activiti:assignee=\"#{c}\" activiti:exclusive=\"true\" name=\"财务审批\"/>的u赋值\n* 给<conditionExpression xsi:type=\"tFormalExpression\"><![CDATA[${price < 1000}]]>\n* </conditionExpression>的price赋值\n* 同时设置业务key bussinessKey\n*/\npublic <T> void startProcess(String processDefinitionId,T t){\n    HashMap<String, Object> map = new HashMap<>();\n    map.put(\"u\", \"u\");\n    map.put(\"m\", \"m\");\n    map.put(\"c\", \"c\");\n    map.put(\"price\", \"1200\");// 分别测试流程走的分支条件 map.put(\"price\", \"300\");\n    runtimeService.startProcessInstanceByKey(key, map);\n    String bussinessKey= t.getClass().getName()+\":\"+t.getId();\n    runtimeService.startProcessInstanceById(processDefinitionId,bussinessKey,map);\n}\n```\n\n启动流程是第二个参数就是表act_ru_execution中的BUSINESS_KEY字段，我一般喜欢使用业务名+ id来存储当前业务\n\n###  6.4 查询当前获任务和业务关联\n\n通过task获得当前流程，通过当前流程获取当前流程的业务id\n\n查询属性：流程实例id，当前节点，采购名称，采购金额\n\n```java\n/**\n     * \n     * @param assignee 任务办理人\n     */\npublic void getTaskDetailByAassignee(String assignee){\n    List<Task> tasks = taskService.createTaskQuery().taskAssignee(assignee).list();\n    for (Task task : tasks) {\n        String processInstanceId = task.getProcessInstanceId();\n        ProcessInstance processInstance = runtimeService.createProcessInstanceQuery().processInstanceId(processInstanceId).singleResult();\n        String businessKey = processInstance.getBusinessKey();\n        //当前运行的流程节点\n        String activityId = processInstance.getActivityId();\n        System.out.println(\"processInstanceId:\"+processInstanceId+\" businessKey:\"+businessKey+\" activityId:\"+activityId);\n        //业务主键id\n        Integer id;\n        if(StringUtils.isNotEmpty(businessKey)){\n            id=Integer.parseInt(businessKey.split(\":\")[1]);\n            //根据id查询出业务信息\n        }\n    }\n}\n```\n\n\n\n###  6.5 查询已经结束的流程\n\n通过task获得当前流程，通过当前流程获取当前流程的业务id\n\n查询属性：流程实例id，执行开始时间，执行结束时间，采购名称，采购金额\n\n\n\n###  6.6 包含流程变量条件的流程\n\n\n\n###  6.6 对采购单的金额进行统计查询 如统计金额的总和\n\n（1）先查询已经结束的流程，用关联sql的方式 不好\n\n（2）最直接的方法，只从业务系统中查询采购单的信息，并统计。因为统计的数据是业务数据，业务系统只负责业务数据。但是面临的一个问题是，并不知道业务系统中的哪些采购单是已经结束了的。\n\n如果，在采购单业务表中加入一个字段status，则表中有采购单结束的标识。\n\n实现方法：\n\n**方法1：** taskListener监听器的方法\n\n在流程定义的最后一个节点定义一个监听器，此监听器在完成任务的时候执行，在监听器中更新采购单业务表中的status字段的值，如：complete完成。\n\n**方法2：**executionListener监听器的方法\n\n在endevent节点上添加executionListener监听器的方法，监听事件选择end\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182803.png)\n\n\n\n## 七、业务开发总结\n\n觉得不需要用activitEntity保存那么多的属性id  processInstanceId和 只需要  查询task列表的时候可以返回一个List<Hashmap>，其实可以不需要 因为有businessEntity\n\n1.新建一个activitEntity.java包含两个字段id和流程实例Id\n\n```\npublic ActivitEntity{\n\tprivate String id;\n\tprivate String processInstanceId;\n}\n```\n\n2.业务表单继承ActivitEntity基类\n\n3.保存业务表单的时候启动一个流程，创建采购单时，在填写新增记录保存时，启动流程实例。\n\n4.业务service层执行的时候，要确定业务key，uuid以及启动流程之后返回的流程实例id\n\n5.启动流程的时候，如果用流程定义Id的话，感觉不太好，应为部署的问题，所以建议使用startBykey的方式\n\n```\npublic ActivitService{\n\tprivate void saveOrder(){\n        Order order=new Order();\n        String id=UUid.gen();\n        order.setId(id);\n        //String businessKey=Order.getClass().getName()+\":\"+id;//业务key 用类名和id组合 order:id\n        Map<String, Object> variables=new Hash<>();\n        //String processDefinitionId=\"11\";\n        String processDefinitionKey=\"从部署bpmn文件中获取\"  //有工具类可以获取到这key 网络搜素一下\n        //调用服务的方式\n        //ActivitClient.startProcess(processDefinitionId,order,variables)\n        ActivitClient.startProcess(processDefinitionKey,order,variables)\n\t}\n}\n\n\npublic <T extends ActivitEntity> void startProcess(String processDefinitionKey,T t,Map<String, Object> variables){\n        String bussinessKey= t.getClass().getName()+\":\"+t.getId(); //业务key 用类名和id组合 order:id\n       \n         //runtimeService.startProcessInstanceById(processDefinitionId,bussinessKey,variables);\n         runtimeService.startProcessInstanceByKey(processDefinitionKey,bussinessKey,variables);\n}\n```\n\n6.为防止对采购单的业务数据进行修改，所以，创建采购单的人要提交申请，在提交申请之前，是可以对数据进行修改的，提交申请之后，数据不能修改，同时任务流向下一个节点。\n\n7.待提交的采购单如何查询\n\n利用activiti的taskservice查询出当前用户的代办任务\n\n任务的名称，任务的待办人，任务申请人，任务提交的时间，采购金额，采购类型\n\n8.提交采购单  当前任务的taskid  taskService.coomplete(taskid);\n\n\n\n9.审核业务（另起数据表--审核表---字段包含 id,采购单,采购申请人,采购类型，审核意见，审核状态0不同意，1通过，审核时间）\n\n进入审核页面  填写审核信息  提交审核  \n\n业务逻辑 ：保存审核意见到审核表中，然后再用activit完成任务\n\n\n\n\n\n\n\n\n\n","source":"_posts/我的activiti学习.md","raw":"---\ntitle: activiti学习笔记\ndate: 2019-08-09 20:32:59\npassword: 123\nabstract: 欢迎来到test, 请输入密码.\nmessage: 欢迎来到test, 请输入密码.\ntoc: false\nmathjax: false\ntags:  [activiti] \ncategory: javaEE\n\n---\n\n#  activiti学习笔记\n\n##   一、Activiti获取ProcessEngine的三种方法\n\n###  1.1 ProcessEngineConfiguration获取\n\n```java\npublic static void config() {\n        //获取config对象\n        ProcessEngineConfiguration processEngineConfiguration = ProcessEngineConfiguration.createStandaloneProcessEngineConfiguration();\n        //Jdbc设置\n        String jdbcDriver = \"com.mysql.jdbc.Driver\";\n        processEngineConfiguration.setJdbcDriver(jdbcDriver);\n        String jdbcUrl = \"jdbc:mysql://localhost:3306/activiti?useUnicode=true&characterEncoding=utf-8\";\n        processEngineConfiguration.setJdbcUrl(jdbcUrl);\n        String jdbcUsername = \"root\";\n        processEngineConfiguration.setJdbcUsername(jdbcUsername);\n        String jdbcPassword = \"root\";\n        processEngineConfiguration.setJdbcPassword(jdbcPassword);\n        //DB_SCHEMA_UPDATE_FALSE = \"false\";不自动创建新表\n        // DB_SCHEMA_UPDATE_CREATE_DROP = \"create-drop\";每次运行创建新表\n        // DB_SCHEMA_UPDATE_TRUE = \"true\";设置自动对表结构进行改进和升级\n        //设置是否自动更新\n   processEngineConfiguration.setDatabaseSchemaUpdate(ProcessEngineConfiguration.DB_SCHEMA_UPDATE_TRUE);\n        //获取引擎对象\n        ProcessEngine processEngine = processEngineConfiguration.buildProcessEngine();\n        processEngine.close();\n    }\n\n```\n\n###  1.2 ProcessEngineConfiguration载入xml文件\n\nxml文件： \n\n```xml\n<beans xmlns=\"http://www.springframework.org/schema/beans\"     xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:tx=\"http://www.springframework.org/schema/tx\"\n      xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n      xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\n   http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-2.5.xsd\n   http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.0.xsd\">\n<!--这里的类太多别导错了 -->\n<bean id=\"processEngineConfiguration\" class=\"org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration\">\n    <!-- 配置流程引擎配置对象 -->\n    <property name=\"jdbcDriver\" value=\"com.mysql.jdbc.Driver\"></property>\n    <property name=\"jdbcUrl\" value=\"jdbc:mysql://localhost:3306/activiti?useUnicode=true&amp;characterEncoding=utf-8\"></property>\n    <property name=\"jdbcUsername\" value=\"root\"></property>\n    <property name=\"jdbcPassword\" value=\"123456\"></property>\n    <!-- 注入数据源信息 -->\n    <property name=\"databaseSchemaUpdate\" value=\"true\"></property>\n</bean>\n<bean id=\"processEngine\" class=\"org.activiti.spring.ProcessEngineFactoryBean\">\n    <!-- 注入自动建表设置 -->\n    <property name=\"processEngineConfiguration\" ref=\"processEngineConfiguration\"></property>\n</bean>\n</beans>\n```\n\njava代码加载xml文件\n\n```java\npublic void configByConf() {\n   //载入资源\n   ProcessEngineConfiguration processEngineConfiguration =      ProcessEngineConfiguration.createProcessEngineConfigurationFromResource(\"activiti.cfg.xml\");\n        //创建引擎\n   ProcessEngine processEngine = processEngineConfiguration.buildProcessEngine();\n   processEngine.getRepositoryService();\n}\n```\n\n###  1.3 默认载入activiti.cfg.xml进行获取\n\n```java\npublic void configByDefault() {\n   //通过获取载入默认获取\n   ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();\n   processEngine.close();\n}\n```\n\n这里的xml文件名必须设置为activiti.cfg.xml\n\n \n\n##  二、流程定义\n\n`部署流程 `-->`启动流程实例 `\n\n###  2.1 设计流程定义文档\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182142.png)\n\n###  2.2 bpmn文件\n\n\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<definitions xmlns=\"http://www.omg.org/spec/BPMN/20100524/MODEL\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:activiti=\"http://activiti.org/bpmn\" xmlns:bpmndi=\"http://www.omg.org/spec/BPMN/20100524/DI\" xmlns:omgdc=\"http://www.omg.org/spec/DD/20100524/DC\" xmlns:omgdi=\"http://www.omg.org/spec/DD/20100524/DI\" typeLanguage=\"http://www.w3.org/2001/XMLSchema\" expressionLanguage=\"http://www.w3.org/1999/XPath\" targetNamespace=\"http://www.activiti.org/test\">\n  <process id=\"helloworld\" name=\"helloworldProcess\" isExecutable=\"true\">\n    <startEvent id=\"startevent1\" name=\"Start\"></startEvent>\n    <endEvent id=\"endevent1\" name=\"End\"></endEvent>\n    <userTask id=\"usertask1\" name=\"提交申请\" activiti:assignee=\"张三\"></userTask>\n    <userTask id=\"usertask2\" name=\"审批【部门经理】\" activiti:assignee=\"李四\"></userTask>\n    <userTask id=\"usertask3\" name=\"审批【总经理】\" activiti:assignee=\"王五\"></userTask>\n    <sequenceFlow id=\"flow1\" sourceRef=\"startevent1\" targetRef=\"usertask1\"></sequenceFlow>\n    <sequenceFlow id=\"flow2\" sourceRef=\"usertask1\" targetRef=\"usertask2\"></sequenceFlow>\n    <sequenceFlow id=\"flow3\" sourceRef=\"usertask2\" targetRef=\"usertask3\"></sequenceFlow>\n    <sequenceFlow id=\"flow4\" sourceRef=\"usertask3\" targetRef=\"endevent1\"></sequenceFlow>\n  </process>\n  <bpmndi:BPMNDiagram id=\"BPMNDiagram_helloworld\">\n    <bpmndi:BPMNPlane bpmnElement=\"helloworld\" id=\"BPMNPlane_helloworld\">\n      <bpmndi:BPMNShape bpmnElement=\"startevent1\" id=\"BPMNShape_startevent1\">\n        <omgdc:Bounds height=\"35.0\" width=\"35.0\" x=\"330.0\" y=\"20.0\"></omgdc:Bounds>\n      </bpmndi:BPMNShape>\n      <bpmndi:BPMNShape bpmnElement=\"endevent1\" id=\"BPMNShape_endevent1\">\n        <omgdc:Bounds height=\"35.0\" width=\"35.0\" x=\"330.0\" y=\"380.0\"></omgdc:Bounds>\n      </bpmndi:BPMNShape>\n      <bpmndi:BPMNShape bpmnElement=\"usertask1\" id=\"BPMNShape_usertask1\">\n        <omgdc:Bounds height=\"55.0\" width=\"105.0\" x=\"295.0\" y=\"100.0\"></omgdc:Bounds>\n      </bpmndi:BPMNShape>\n      <bpmndi:BPMNShape bpmnElement=\"usertask2\" id=\"BPMNShape_usertask2\">\n        <omgdc:Bounds height=\"55.0\" width=\"105.0\" x=\"295.0\" y=\"200.0\"></omgdc:Bounds>\n      </bpmndi:BPMNShape>\n      <bpmndi:BPMNShape bpmnElement=\"usertask3\" id=\"BPMNShape_usertask3\">\n        <omgdc:Bounds height=\"55.0\" width=\"105.0\" x=\"295.0\" y=\"290.0\"></omgdc:Bounds>\n      </bpmndi:BPMNShape>\n      <bpmndi:BPMNEdge bpmnElement=\"flow1\" id=\"BPMNEdge_flow1\">\n        <omgdi:waypoint x=\"347.0\" y=\"55.0\"></omgdi:waypoint>\n        <omgdi:waypoint x=\"347.0\" y=\"100.0\"></omgdi:waypoint>\n      </bpmndi:BPMNEdge>\n      <bpmndi:BPMNEdge bpmnElement=\"flow2\" id=\"BPMNEdge_flow2\">\n        <omgdi:waypoint x=\"347.0\" y=\"155.0\"></omgdi:waypoint>\n        <omgdi:waypoint x=\"347.0\" y=\"200.0\"></omgdi:waypoint>\n      </bpmndi:BPMNEdge>\n      <bpmndi:BPMNEdge bpmnElement=\"flow3\" id=\"BPMNEdge_flow3\">\n        <omgdi:waypoint x=\"347.0\" y=\"255.0\"></omgdi:waypoint>\n        <omgdi:waypoint x=\"347.0\" y=\"290.0\"></omgdi:waypoint>\n      </bpmndi:BPMNEdge>\n      <bpmndi:BPMNEdge bpmnElement=\"flow4\" id=\"BPMNEdge_flow4\">\n        <omgdi:waypoint x=\"347.0\" y=\"345.0\"></omgdi:waypoint>\n        <omgdi:waypoint x=\"347.0\" y=\"380.0\"></omgdi:waypoint>\n      </bpmndi:BPMNEdge>\n    </bpmndi:BPMNPlane>\n  </bpmndi:BPMNDiagram>\n</definitions>\n```\n\n###  2.3 部署流程定义\n\n(1) 部署流程定义\n\n```java\npublic void deploymentProcessDefinition_classpath(){\n\tDeployment deployment = processEngine.getRepositoryService()\n\t\t\t\t\t.createDeployment().name(\"流程定义\")\n                      //从classpath的资源中加载，一次只能加载一个文件\n\t\t\t\t\t.addClasspathResource(\"diagrams/helloworld.bpmn\")\n\t\t\t\t\t.addClasspathResource(\"diagrams/helloworld.png\").deploy();//完成部署\n\tSystem.out.println(\"部署ID：\"+deployment.getId());\n\tSystem.out.println(\"部署名称：\"+deployment.getName());\n}\n```\n\n(2) ZipInputStream的部署方式\n\n```\npublic static void main(String[] args) throws Exception{\n    DeploymentBuilder deployment = rs.createDeployment();\n    FileInputStream fis = new FileInputStream(new File(\"\"));\n    ZipInputStream zis = new ZipInputStream(fis);\n    deployment.addZipInputStream(zis);\n    deployment.deploy();\n}\n```\n\n### 2.4 流程部署后数据库的变化\n\n- act_ge_bytearray（资源文件表）        存储流程定义相关的部署信息。即流程定义文档的存放地。每部署一次就会增加两条记录，一条是关于bpmn规则文件的，一条是图片的（如果部署时只指定了bpmn一个文件，activiti会在部署时解析bpmn文件内容自动生成流程图）。两个文件不是很大，都是以二进制形式存储在数据库中。\n\n-  act_re_procdef（流程定义表）    存放流程定义的属性信息，部署每个新的流程定义都会在这张表中增加一条记录。    注意：当流程定义的key相同的情况下，使用的是版本升级    \n\n​       其中`act_re_deployment`的id会和`act_ge_bytearray`的deployment_id_关联\n\n- act_re_deployment（流程部署表）       存放流程定义的显示名和部署时间，每部署一次增加一条记录\n\n流程部署之后act_ge_bytearray插入两条记录\n\n| ID_   | REV_ | NAME_                  | DEPLOYMENT_ID_ | BYTES_   | GENERATED_ |\n| ----- | ---- | ---------------------- | -------------- | -------- | ---------- |\n| ID    | 版本 | 名称                   | 部署ID         | 字节     | 不详       |\n| 10002 | 1    | simple.bpmn            | 10001          | blob文件 | 1          |\n| 10003 | 1    | simple.myProcess_1.png | 10001          | blob文件 | 1          |\n\nact_re_procdef（流程定义表）       存放流程定义的显示名和部署时间，每部署一次增加一条记录\n\n| ID_                 | REV_ | CATEGORY_ | NAME_ | KEY_        | VERSION_ | DEPLOYMENT_ID_ | RESOURCE_NAME_ | DGRM_RESOURCE_NAME_    | DESCRIPTION_ | HAS_START_FORM_KEY_ | HAS_GRAPHICAL_NOTATION_ | SUSPENSION_STATE_ | TENANT_ID_ | ENGINE_VERSION_ |\n| ------------------- | ---- | --------- | ----- | ----------- | -------- | -------------- | -------------- | ---------------------- | ------------ | ------------------- | ----------------------- | ----------------- | ---------- | --------------- |\n| 流程定义id          |      |           |       | 流程key     | 版本     | 流程部署id     | 流程资源名称   | 流程资源图片           | 描述         |                     |                         |                   |            |                 |\n| myProcess_1:1:10004 | 1    | Examples  |       | myProcess_1 | 1        | 10001          | simple.bpmn    | simple.myProcess_1.png |              | 0                   | 1                       | 1                 |            |                 |\n\nact_re_deployment（流程部署表）       存放流程定义的显示名和部署时间，每部署一次增加一条记录\n\n| ID_    | NAME_    | CATEGORY_ | KEY_    | TENANT_ID_ | DEPLOY_TIME_   | ENGINE_VERSION_ |\n| ------ | -------- | --------- | ------- | ---------- | -------------- | --------------- |\n| 部署id | 部署名称 | 部署类型  | 部署key |            | 部署时间       |                 |\n| 10001  |          |           |         |            | 2019/4/3 16:35 |                 |\n\n###  2.5 根据名称查询流程部署\n\n```java\npublic void testQueryDeploymentByName(){\n        ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();\n        List<Deployment> deployments = processEngine.getRepositoryService()\n                .createDeploymentQuery()\n                .orderByDeploymenTime()//按照部署时间排序\n                .desc()//按照降序排序\n                .deploymentName(\"请假流程\")\n                .list();\n        for (Deployment deployment : deployments) {\n            System.out.println(deployment.getId());\n        }\n    }\n```\n\n###  2.6 查询所有的部署流程\n\n```java\npublic void queryAllDeplyoment(){\n        //得到流程引擎\n        ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();\n        List<Deployment> lists = processEngine.getRepositoryService()\n                .createDeploymentQuery()\n                .orderByDeploymenTime()//按照部署时间排序\n                .desc()//按照降序排序\n                .list();\n        for (Deployment deployment:lists) {\n            System.out.println(deployment.getId() +\"    部署名称\" + deployment.getName());\n        }\n}\n```\n\n###  2.7 查看所有流程定义\n\n```java\npublic void findProcessDefinition(){\n\tList<ProcessDefinition> list = RepositoryService.createProcessDefinitionQuery()//创建一个流程定义的查询\n\t\t\t/**指定查询条件,where条件*/\n//\t\t\t.deploymentId(deploymentId)//使用部署对象ID查询\n//\t\t\t.processDefinitionId(processDefinitionId)//使用流程定义ID查询\n//\t\t\t.processDefinitionKey(processDefinitionKey)//使用流程定义的key查询\n//\t\t\t.processDefinitionNameLike(processDefinitionNameLike)//使用流程定义的名称模糊查询\n\t\t\t.orderByProcessDefinitionVersion().asc()//按照版本的升序排列\n//\t\t\t.orderByProcessDefinitionName().desc()//按照流程定义的名称降序排列\n\t\t\t.list();//返回一个集合列表，封装流程定义\n//\t\t\t.singleResult();//返回惟一结果集\n//\t\t\t.count();//返回结果集数量\n//\t\t\t.listPage(firstResult, maxResults);//分页查询\n\tif(list!=null && list.size()>0){\n\t\tfor(ProcessDefinition pd:list){\n\t\t\tSystem.out.println(\"流程定义ID:\"+pd.getId());//流程定义的key+版本+随机生成数\n\t\t\tSystem.out.println(\"流程定义的名称:\"+pd.getName());//对应helloworld.bpmn文件中的name属性值\n\t\t\tSystem.out.println(\"流程定义的key:\"+pd.getKey());//对应helloworld.bpmn文件中的id属性值\n\t\t\tSystem.out.println(\"流程定义的版本:\"+pd.getVersion());//当流程定义的key值相同的相同下，版本升级，默认1\n\t\t\tSystem.out.println(\"资源名称bpmn文件:\"+pd.getResourceName());\n\t\t\tSystem.out.println(\"资源名称png文件:\"+pd.getDiagramResourceName());\n\t\t\tSystem.out.println(\"部署对象ID：\"+pd.getDeploymentId());\n\t\t}\n\t}\t\t\t\n}\n```\n\n###  2.8 删除流程定义\n\n```java\npublic void deleteProcessDefinition(){\n\tString deploymentId = \"601\"; //使用部署ID，完成删除\n\t//不带级联的删除 只能删除没有启动的流程，如果流程启动，就会抛出异常\n    RepositoryService().deleteDeployment(deploymentId);\n\t//级联删除  不管流程是否启动，都能可以删除\n\tRepositoryService().deleteDeployment(deploymentId, true);\n}\n```\n\n说明：    \n\n-  因为删除的是流程定义，而流程定义的部署是属于仓库服务的，所以应该先得到RepositoryService。    \n\n- 如果该流程定义下没有正在运行的流程，则可以用普通删除。如果是有关联的信息，用级联删除。项目开发中使用级联删除的情况比较多，删除操作一般只开放给超级管理员使用。\n\n###  2.9 查看流程图\n\n```java\npublic void viewPic() throws IOException{\n\t/**将生成图片放到文件夹下*/\n\tString deploymentId = \"801\";\n\t//获取图片资源名称\n\tList<String> list = repositoryService.getDeploymentResourceNames(deploymentId);\n\t//定义图片资源的名称\n\tString resourceName = \"\";\n\tif(list!=null && list.size()>0){\n\t\tfor(String name:list){\n\t\t\tif(name.indexOf(\".png\")>=0){\n\t\t\t\tresourceName = name;\n\t\t\t}\n\t\t}\n\t}\t\n\t//获取图片的输入流\n\tInputStream in = repositoryService.getResourceAsStream(deploymentId, resourceName);\n\t//将图片生成到D盘的目录下\n\tFile file = new File(\"D:/\"+resourceName);\n\t//将输入流的图片写到D盘下\n\tFileUtils.copyInputStreamToFile(in, file);\n}\n```\n\n###  2.10 流程定义的暂停挂起\n\n**测试暂停流程定义执行步骤如下：**\n\n在程序中，我们需要暂停一个流程定义，停止所有的该流程定义下的流程实例，并且不允许发起这个流程定义的流程实例，那么我们就需要挂起这个流程定义\n\n　　1，启动一个流程实例（该流程定义未挂起前）\n\n　　2，挂起上面流程实例对应的流程定义\n\n　　3，完成上述流程实例的下一个任务节点（观察效果，是否会和流程实例挂起一样）\n\n（1）根据流程实例的id来挂起这个流程定义\n\n```\npublic void testSuspendProcessDefinition(){        \n     String processDefinitionKey =\"purchasingflow\";\n     //根据流程定义的key暂停一个流程定义\n     repositoryService.suspendProcessDefinitionByKey(processDefinitionKey );\n}\n```\n\n（2）完成这个流程实例的下一个节点，通过taskService来结束下一个任务节点\n\n　　这时候，我们发现这个流程实例居然是可以继续执行的，并且可以执行到结束，带着这个疑问，我们再启动一个流程实例看看\n\n（3）重新启动这个流程定义下的流程实例\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182230.png)\n\n报错说不可以启动这个被挂起流程定义的流程实例\n\n##  三、流程实例\n\n###  3.1 根据流程部署id启动流程实例\n\n```java\npublic void startProcess(String deploymentId){\n    ProcessDefinition pd=repositoryService.createProcessDefinitionQuery()\n        .deploymentId(deploymentId)\n        .singleResult();\n    ProcessInstance pi=runtimeService.startProcessInstanceById(pd.getId());\n}\n```\n\n###  3.2 根据流程id启动流程实例,可以设置一个流程变量\n\n```java\n/**\n* 流程变量\n* 给<userTask id=\"请假申请\" name=\"申请\" activiti:assignee=\"#{student}\"></userTask>的student赋值\n*/\npublic void startProcess(){\n    Map<String, Object> variables = new HashMap<String, Object>();\n    variables.put(\"student\", \"小明\");\n    ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();\n    runtimeService.startProcessInstanceById(\"shenqing1:1:1304\",variables);\n}\n```\n\n###  3.3 启动流程实例之后数据库的变化\n\n首先向act_ru_execution表中插入一条记录，记录的是这个流程定义的执行实例，其中id和proc_inst_id相同都是流程执行实例id，也就是本次执行这个流程定义的id，包含流程定义的id外键(simpleProcess:1:5004)。\n\n| ID_   | REV_ | PROC_INST_ID_ | BUSINESS_KEY_ | PARENT_ID_ | PROC_DEF_ID_        | SUPER_EXEC_ | ROOT_PROC_INST_ID_ | ACT_ID_ | IS_ACTIVE_ | IS_CONCURRENT_ | IS_SCOPE_ | IS_EVENT_SCOPE_ | IS_MI_ROOT_ | SUSPENSION_STATE_ | START_TIME_       |\n| ----- | ---- | ------------- | ------------- | ---------- | ------------------- | ----------- | ------------------ | ------- | ---------- | -------------- | --------- | --------------- | ----------- | ----------------- | ----------------- |\n|       |      |               |               |            |                     |             |                    |         |            |                |           |                 |             |                   |                   |\n| 12501 | 1    | 12501         |               |            | myProcess_1:1:10004 |             | 12501              |         | 1          | 0              | 1         | 0               | 0           | 1                 | 2019-4-3 17:25:30 |\n| 12503 | 1    | 12501         |               | 12501      | myProcess_1:1:10004 |             | 12501              | _3      | 1          | 0              | 0         | 0               | 0           | 1                 | 2019-4-3 17:25:30 |\n\n然后向act_ru_task插入一条记录，记录的是第一个任务的信息，也就是开始执行第一个任务。包括act_ru_execution表中的execution_id外键和proc_inst_id外键，也就是本次执行实例id。\n\n| ID_   | REV_ | EXECUTION_ID_ | PROC_INST_ID_ | PROC_DEF_ID_        | NAME_    | PARENT_TASK_ID_ | DESCRIPTION_ | TASK_DEF_KEY_ | OWNER_ | ASSIGNEE_ | DELEGATION_ | PRIORITY_ | CREATE_TIME_   | DUE_DATE_ | CATEGORY_ | SUSPENSION_STATE_ |\n| ----- | ---- | ------------- | ------------- | ------------------- | -------- | --------------- | ------------ | ------------- | ------ | --------- | ----------- | --------- | -------------- | --------- | --------- | ----------------- |\n|       |      |               |               |                     |          |                 |              |               |        |           |             |           |                |           |           |                   |\n| 12506 | 1    | 12503         | 12501         | myProcess_1:1:10004 | UserTask |                 |              | _3            |        | a         |             | 50        | 2019/4/3 17:07 |           |           | 1                 |\n\n然后向act_hi_procinst表插入一条记录，记录的是本次执行实例：\n\n| ID_   | PROC_INST_ID_ | BUSINESS_KEY_ | PROC_DEF_ID_        | START_TIME_    | END_TIME_ | DURATION_ | START_USER_ID_ | START_ACT_ID_ | END_ACT_ID_ | SUPER_PROCESS_INSTANCE_ID_ | DELETE_REASON_ | TENANT_ID_ | NAME_ |\n| ----- | ------------- | ------------- | ------------------- | -------------- | --------- | --------- | -------------- | ------------- | ----------- | -------------------------- | -------------- | ---------- | ----- |\n|       |               |               |                     |                |           |           |                |               |             |                            |                |            |       |\n| 12501 | 12501         |               | myProcess_1:1:10004 | 2019/4/3 17:07 |           |           |                | _2            |             |                            |                |            |       |\n\n然后向act_hi_taskinst表中插入一条记录，记录的是任务的历史记录：\n\n| ID_   | PROC_DEF_ID_        | TASK_DEF_KEY_ | PROC_INST_ID_ | EXECUTION_ID_ | NAME_    | PARENT_TASK_ID_ | DESCRIPTION_ | OWNER_ | ASSIGNEE_ | START_TIME_    | CLAIM_TIME_ | END_TIME_ | DURATION_ | DELETE_REASON_ | PRIORITY_ | DUE_DATE_ | FORM_KEY_ | CATEGORY_ | TENANT_ID_ |\n| ----- | ------------------- | ------------- | ------------- | ------------- | -------- | --------------- | ------------ | ------ | --------- | -------------- | ----------- | --------- | --------- | -------------- | --------- | --------- | --------- | --------- | ---------- |\n|       |                     |               |               |               |          |                 |              |        |           |                |             |           |           |                |           |           |           |           |            |\n| 12506 | myProcess_1:1:10004 | _3            | 12501         | 12503         | UserTask |                 |              |        | a         | 2019/4/3 17:07 |             |           |           |                | 50        |           |           |           |            |\n\n###  3.4 流程实例的暂停挂起\n\n**测试暂停流程实例执行步骤如下：**\n\n　　1，通过流程定义的key或者id启动一个流程实例\n\n　　2，根据流程实例的id来挂起这个流程实例\n\n　　3，得到下一个节点的对应的任务的id，调用taskService来完成这个任务观察效果\n\n 　   4，重新激活这个流程实例\n\n　　5，继续完成这个流程实例\n\n（1）通过上面发起的流程实例的id挂起这个流程实例 \n\n```java\npublic void testSuspendProcessInstance(){\n    String processInstanceId=\"1801\";\n    //根据一个流程实例的id挂起该流程实例\n    runtimeService.suspendProcessInstanceById(processInstanceId);\n}\n```\n\n（2）任务的下一处理人来完成这个实例 \n\n```java\npublic void completeProcessInstance(){\n    //任务的id，后期整合后会通过当前登录人身份查询到该用户的任务，然后获取到该id\n    String taskId=\"1804\";\n    //根据任务id完成该任务\n    taskService.complete(taskId);\n}\n```\n\n执行完报错：\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904183119.png)\n\n　　上面的信息说明无法完成一个已经被挂起的任务\n\n（3）激活这个流程实例 \n\n```\npublic void testActivateProcessInstance(){\n    String processInstanceId=\"1801\";\n    runtimeService.activateProcessInstanceById(processInstanceId);\n}\n```\n\n5，重新完成这个任务，执行ok \n\n\n\n##  四、任务管理\n\n###  4.1 根据办理人查询任务\n\n`根据任务的执行人查询正在执行任务(通过act_ru_task数据表) `\n\n```java\npublic void testQueryTaskByAssignee(){\n        ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();\n        //当前班主任小毛人这个人当前正在执行的所有的任务\n        List<Task> tasks = processEngine.getTaskService()\n                .createTaskQuery()\n                .orderByTaskCreateTime()\n                .desc()\n                .taskAssignee(\"小毛\")\n                .list();\n        for (Task task : tasks) {\n            System.out.println(task.getName());\n            System.out.println(task.getAssignee());\n        }\n    }\n```\n\n###  4.2 个人任务的三种指派方式\n\n**（1）方式一**\n\n定义流程图时直接指定完成任务人（项目开发中任务的办理人不要放置XML文件中，不够灵活，较少使用） \n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904183158.png)\n\n定义的bpmn文件中定义任务办理人的名称\n\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<definitions xmlns=\"http://www.omg.org/spec/BPMN/20100524/MODEL\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:activiti=\"http://activiti.org/bpmn\" xmlns:bpmndi=\"http://www.omg.org/spec/BPMN/20100524/DI\" xmlns:omgdc=\"http://www.omg.org/spec/DD/20100524/DC\" xmlns:omgdi=\"http://www.omg.org/spec/DD/20100524/DI\" typeLanguage=\"http://www.w3.org/2001/XMLSchema\" expressionLanguage=\"http://www.w3.org/1999/XPath\" targetNamespace=\"http://www.activiti.org/test\">\n  <process id=\"personalAssignee1\" name=\"PersonalAssignee1\" isExecutable=\"true\">\n    <startEvent id=\"startevent1\" name=\"Start\"></startEvent>\n    <userTask id=\"usertask1\" name=\"审批\" activiti:assignee=\"crystal\"></userTask>\n    <sequenceFlow id=\"flow1\" sourceRef=\"startevent1\" targetRef=\"usertask1\"></sequenceFlow>\n    <endEvent id=\"endevent1\" name=\"End\"></endEvent>\n    <sequenceFlow id=\"flow2\" sourceRef=\"usertask1\" targetRef=\"endevent1\"></sequenceFlow>\n  </process>\n  <bpmndi:BPMNDiagram id=\"BPMNDiagram_personalAssignee1\">\n    <bpmndi:BPMNPlane bpmnElement=\"personalAssignee1\" id=\"BPMNPlane_personalAssignee1\">\n      <bpmndi:BPMNShape bpmnElement=\"startevent1\" id=\"BPMNShape_startevent1\">\n        <omgdc:Bounds height=\"35.0\" width=\"35.0\" x=\"360.0\" y=\"20.0\"></omgdc:Bounds>\n      </bpmndi:BPMNShape>\n      <bpmndi:BPMNShape bpmnElement=\"usertask1\" id=\"BPMNShape_usertask1\">\n        <omgdc:Bounds height=\"55.0\" width=\"105.0\" x=\"325.0\" y=\"100.0\"></omgdc:Bounds>\n      </bpmndi:BPMNShape>\n      <bpmndi:BPMNShape bpmnElement=\"endevent1\" id=\"BPMNShape_endevent1\">\n        <omgdc:Bounds height=\"35.0\" width=\"35.0\" x=\"360.0\" y=\"200.0\"></omgdc:Bounds>\n      </bpmndi:BPMNShape>\n      <bpmndi:BPMNEdge bpmnElement=\"flow1\" id=\"BPMNEdge_flow1\"></bpmndi:BPMNEdge>\n      <bpmndi:BPMNEdge bpmnElement=\"flow2\" id=\"BPMNEdge_flow2\"></bpmndi:BPMNEdge>\n    </bpmndi:BPMNPlane>\n  </bpmndi:BPMNDiagram>\n</definitions>\n\n```\n\n重点代码  **activiti:assignee=\"crystal\"**\n\n启动流程实例\n\n```java\npublic void start() {\n    ProcessInstance pi = runtimeService().startProcessInstanceByKey(\"task\");\n}\n```\n\n**（2）方式二**\n\n定义流程图时配置任务节点变量，完成任务之前由流程变量指定任务办理人。在开发中，可以在页面中指定下一个任务的办理人，通过流程变量设置下一个任务的办理人。\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904183224.png)\n\n定义的bpmn文件中定义任务办理人的名称\n\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<definitions xmlns=\"http://www.omg.org/spec/BPMN/20100524/MODEL\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:activiti=\"http://activiti.org/bpmn\" xmlns:bpmndi=\"http://www.omg.org/spec/BPMN/20100524/DI\" xmlns:omgdc=\"http://www.omg.org/spec/DD/20100524/DC\" xmlns:omgdi=\"http://www.omg.org/spec/DD/20100524/DI\" typeLanguage=\"http://www.w3.org/2001/XMLSchema\" expressionLanguage=\"http://www.w3.org/1999/XPath\" targetNamespace=\"http://www.activiti.org/test\">\n  <process id=\"personalTask2\" name=\"PersonalTask2\" isExecutable=\"true\">\n    <startEvent id=\"startevent1\" name=\"Start\"></startEvent>\n    <userTask id=\"usertask1\" name=\"审批\" activiti:assignee=\"#{userId}\"></userTask>\n    <sequenceFlow id=\"flow1\" sourceRef=\"startevent1\" targetRef=\"usertask1\"></sequenceFlow>\n    <endEvent id=\"endevent1\" name=\"End\"></endEvent>\n    <sequenceFlow id=\"flow2\" sourceRef=\"usertask1\" targetRef=\"endevent1\"></sequenceFlow>\n  </process>\n  <bpmndi:BPMNDiagram id=\"BPMNDiagram_personalTask2\">\n    <bpmndi:BPMNPlane bpmnElement=\"personalTask2\" id=\"BPMNPlane_personalTask2\">\n      <bpmndi:BPMNShape bpmnElement=\"startevent1\" id=\"BPMNShape_startevent1\">\n        <omgdc:Bounds height=\"35.0\" width=\"35.0\" x=\"380.0\" y=\"40.0\"></omgdc:Bounds>\n      </bpmndi:BPMNShape>\n      <bpmndi:BPMNShape bpmnElement=\"usertask1\" id=\"BPMNShape_usertask1\">\n        <omgdc:Bounds height=\"55.0\" width=\"105.0\" x=\"345.0\" y=\"110.0\"></omgdc:Bounds>\n      </bpmndi:BPMNShape>\n      <bpmndi:BPMNShape bpmnElement=\"endevent1\" id=\"BPMNShape_endevent1\">\n        <omgdc:Bounds height=\"35.0\" width=\"35.0\" x=\"380.0\" y=\"210.0\"></omgdc:Bounds>\n      </bpmndi:BPMNShape>\n      <bpmndi:BPMNEdge bpmnElement=\"flow1\" id=\"BPMNEdge_flow1\"></bpmndi:BPMNEdge>\n      <bpmndi:BPMNEdge bpmnElement=\"flow2\" id=\"BPMNEdge_flow2\"></bpmndi:BPMNEdge>\n    </bpmndi:BPMNPlane>\n  </bpmndi:BPMNDiagram>\n</definitions>\n```\n\n重点代码  **activiti:assignee=\"#{userId}\"**\n\n启动流程实例，需要设置流程变量\n\n```java\npublic void start() {\n    Map<String, Object> variables = new HashMap<String, Object>();\n    variables.put(\"userId\", \"crystal\");\n    ProcessInstance pi = runtimeService().startProcessInstanceByKey(\"task\",variables);\n}\n```\n\n**（3）方式三**\n\n流程图中不指定任务办理人，添加监听类，需要实现TaskListener接口\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904183040.png)\n\n定义的bpmn文件中定义任务办理人的名称\n\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<definitions xmlns=\"http://www.omg.org/spec/BPMN/20100524/MODEL\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:activiti=\"http://activiti.org/bpmn\" xmlns:bpmndi=\"http://www.omg.org/spec/BPMN/20100524/DI\" xmlns:omgdc=\"http://www.omg.org/spec/DD/20100524/DC\" xmlns:omgdi=\"http://www.omg.org/spec/DD/20100524/DI\" typeLanguage=\"http://www.w3.org/2001/XMLSchema\" expressionLanguage=\"http://www.w3.org/1999/XPath\" targetNamespace=\"http://www.activiti.org/test\">\n  <process id=\"personalTask3\" name=\"PersonalTask3\" isExecutable=\"true\">\n    <startEvent id=\"startevent1\" name=\"Start\"></startEvent>\n    <userTask id=\"usertask1\" name=\"审批\">\n      <extensionElements>\n        <activiti:taskListener event=\"create\" class=\"com.activiti.test.TaskListenerImpl\"></activiti:taskListener>\n      </extensionElements>\n    </userTask>\n    <sequenceFlow id=\"flow1\" sourceRef=\"startevent1\" targetRef=\"usertask1\"></sequenceFlow>\n    <endEvent id=\"endevent1\" name=\"End\"></endEvent>\n    <sequenceFlow id=\"flow2\" sourceRef=\"usertask1\" targetRef=\"endevent1\"></sequenceFlow>\n  </process>\n  <bpmndi:BPMNDiagram id=\"BPMNDiagram_personalTask3\">\n    <bpmndi:BPMNPlane bpmnElement=\"personalTask3\" id=\"BPMNPlane_personalTask3\">\n      <bpmndi:BPMNShape bpmnElement=\"startevent1\" id=\"BPMNShape_startevent1\">\n        <omgdc:Bounds height=\"35.0\" width=\"35.0\" x=\"310.0\" y=\"20.0\"></omgdc:Bounds>\n      </bpmndi:BPMNShape>\n      <bpmndi:BPMNShape bpmnElement=\"usertask1\" id=\"BPMNShape_usertask1\">\n        <omgdc:Bounds height=\"55.0\" width=\"105.0\" x=\"275.0\" y=\"100.0\"></omgdc:Bounds>\n      </bpmndi:BPMNShape>\n      <bpmndi:BPMNShape bpmnElement=\"endevent1\" id=\"BPMNShape_endevent1\">\n        <omgdc:Bounds height=\"35.0\" width=\"35.0\" x=\"310.0\" y=\"200.0\"></omgdc:Bounds>\n      </bpmndi:BPMNShape>\n      <bpmndi:BPMNEdge bpmnElement=\"flow1\" id=\"BPMNEdge_flow1\"></bpmndi:BPMNEdge>\n      <bpmndi:BPMNEdge bpmnElement=\"flow2\" id=\"BPMNEdge_flow2\"></bpmndi:BPMNEdge>\n    </bpmndi:BPMNPlane>\n  </bpmndi:BPMNDiagram>\n</definitions>\n```\n\n重点代码\n\n`<activiti:taskListener event=\"create\" class=\"com.activiti.test.TaskListenerImpl\"></activiti:taskListener>`\n\n监听类 TaskListenerImpl.java\n\n```java\npackage com.activiti.test;\nimport org.activiti.engine.delegate.DelegateTask;\nimport org.activiti.engine.delegate.TaskListener;\npublic class TaskListenerImpl implements TaskListener {\n    /**\n     * 指定个人任务和组任务的办理人\n     */\n    @Override\n    public void notify(DelegateTask delegateTask) {\n        delegateTask.setAssignee(\"crystal\");// 指派个人任务\n    }\n}\n```\n\n启动流程实例\n\n```java\npublic void start() {\n    ProcessInstance pi = runtimeService().startProcessInstanceByKey(\"task\");\n}\n```\n\n总结：\n\n```java\n个人任务及三种分配方式： \n  1.在taskProcess.bpmn中直接写 assignee=”crystal” \n  2.在taskProcess.bpmn中写 assignee=“#{userID}”，变量的值要是String的（使用流程变量指定办理人）。 \n  3.使用TaskListener接口，要使类实现该接口\n    在类中定义： delegateTask.setAssignee(assignee);// 指定个人任务的办理人 \n  4.使用任务ID和办理人重新指定办理人： taskService.setAssignee(taskId, userId);\n```\n\n\n\n###  4.3 组任务的三种指派方式\n\n**方式一：直接指定办理人**\n\n（1）.在任务节点设置办理人\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182327.png)\n\n（2）bpmn中的代码片段\n\n```\n <userTask activiti:candidateUsers=\"小a,小b,小c\" activiti:exclusive=\"true\" id=\"usertask1\" name=\"提交申请\"/>\n```\n\n（3）部署流程和启动流程\n\n```java\npublic void test(){\n    repositoryService.createDeployment().addClasspathResource(\"test1.bpmn\").deploy();//部署流程\n    ProcessInstance pi = runtimeService.startProcessInstanceByKey(\"helloword\");//启动流程\n}\n```\n\n（4）查询我的个人任务，没有执行结果\n\n```java\n public void queryTask(String assignee) {\n     List<Task> list = taskService.createTaskQuery().orderByTaskCreateTime()\n     \t\t.desc().taskAssignee(assignee).list();\n     if (list != null && list.size() > 0) {\n         for (Task task : list) {\n             System.out.println(\"任务ID：\" + task.getId());\n             System.out.println(\"任务的办理人：\" + task.getAssignee());\n             System.out.println(\"任务名称：\" + task.getName());\n             System.out.println(\"任务的创建时间：\" + task.getCreateTime());\n             System.out.println(\"流程实例ID：\" + task.getProcessInstanceId());\n             System.out.println(\"#######################################\");\n         }\n     }\n}\n```\n\n（5）查询组任务，可以查到查询结果\n\n```\n public void findGroupTaskList(String candidateUser) {\n        List<Task> list = taskService.createTaskQuery().taskCandidateUser(candidateUser).list();\n        if (list != null && list.size() > 0) {\n            for (Task task : list) {\n                System.out.println(\"任务ID：\" + task.getId());\n                System.out.println(\"任务的办理人：\" + task.getAssignee());\n                System.out.println(\"任务名称：\" + task.getName());\n                System.out.println(\"任务的创建时间：\" + task.getCreateTime());\n                System.out.println(\"流程实例ID：\" + task.getProcessInstanceId());\n                System.out.println(\"#######################################\");\n            }\n        }\n    }\n```\n\n查询结果如下\n\n> 任务ID：15010\n> 任务的办理人：null\n> 任务名称：提交申请\n> 任务的创建时间：Thu Apr 04 10:50:00 CST 2019\n> 流程实例ID：15005\n\n（6）查询正在执行的组任务列表\n\n```java\npublic void findGroupCandidate(String taskId) {\n    List<IdentityLink> list = taskService.getIdentityLinksForTask(taskId);\n        if (list != null && list.size() > 0) {\n        for (IdentityLink identityLink : list) {\n            System.out.println(\"任务ID：\" + identityLink.getTaskId());\n            System.out.println(\"流程实例ID：\"+ identityLink.getProcessInstanceId());\n            System.out.println(\"用户ID：\" + identityLink.getUserId());\n            System.out.println(\"工作流角色ID：\" + identityLink.getGroupId());\n            System.out.println(\"#########################################\");\n        }\n    }\n}\n```\n\n执行结果\n\n> 任务ID：15010\n> 流程实例ID：null\n> 用户ID：小a\n> 工作流角色ID：null\n>\n> 任务ID：15010\n> 流程实例ID：null\n> 用户ID：小b\n> 工作流角色ID：null\n>\n> 任务ID：15010\n> 流程实例ID：null\n> 用户ID：小c\n> 工作流角色ID：null\n\n（7）查询历史的组任务列表\n\n```java\npublic void findHistoryGroupCandidate(String processInstanceId) {\n    String processInstanceId = \"3705\";\n    List<HistoricIdentityLink> list = historyService\n        \t.getHistoricIdentityLinksForProcessInstance(processInstanceId);\n    if (list != null && list.size() > 0) {\n        for (HistoricIdentityLink identityLink : list) {\n            System.out.println(\"任务ID：\" + identityLink.getTaskId());\n            System.out.println(\"流程实例ID：\"+ identityLink.getProcessInstanceId());\n            System.out.println(\"用户ID：\" + identityLink.getUserId());\n            System.out.println(\"工作流角色ID：\" + identityLink.getGroupId());\n            System.out.println(\"#########################################\");\n        }\n    }\n}\n```\n\n说明：     \n\n- 小A，小B，小C是组任务的办理人     \n- 但是这样分配组任务的办理人不够灵活，因为项目开发中任务的办理人不要放置XML文件中。     \n- act_ru_identitylink表存放组任务的办理人，表示正在执行的任务     \n- act_hi_identitylink表存放所有任务的办理人，包括个人任务和组任务**，**表示历史任务\n\n**方式二：使用流程变量**\n\n （1）在任务节点设置变量\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904183359.png)\n\n（2）bpmn中的代码片段\n\n```\n<userTask activiti:candidateUsers=\"#{userIDs}\" activiti:exclusive=\"true\" id=\"usertask1\" name=\"提交申请\"/>\n```\n\n（3）部署流程和启动流程\n\n启动流程实例的同时，设置流程变量，使用流程变量的方式设置下一个任务的办理人\n\n 流程变量的名称，是task.bpmn中定义activiti:candidateUsers=\"#{userIDs}\"的userIDs  流程变量的值，就是任务的办理人（组任务）\n\n```java\npublic void test(){\n    repositoryService.createDeployment().addClasspathResource(\"test1.bpmn\").deploy();//部署流程\n\tMap<String, Object> variables = new HashMap<String, Object>();\n\tvariables.put(\"userIDs\", \"小a,小b,小c\");\n\tProcessInstance pi = runtimeService.startProcessInstanceByKey(\"helloword\",variables);//使用流程定义的key的最新版本启动流程\n}\n```\n\n**方式三：使用监听器**\n\n（1）设置监听器变量\n\n![img](https://img-blog.csdn.net/20151227154130920)\n\n \n\n（2）编写监听器类\n\n```\npublic class TaskListenerImpl implements TaskListener {\n\t/**\n\t * 可以设置任务的办理人（个人组人和组任务）\n\t */\n\t@Override\n\tpublic void notify(DelegateTask delegateTask) {\n\t\t//指定组任务\n\t\tdelegateTask.addCandidateUser(\"孙悟空\");\n\t\tdelegateTask.addCandidateUser(\"猪八戒\");\n\t}\n}\n```\n\n（3）测试代码\n\n```java\n/**将组任务指定个人任务(拾取任务)*/\npublic void claim(){\n    String taskId = \"6308\";\n    //个人任务的办理人\n    String userId = \"唐僧\";\n    taskService.claim(taskId, userId);\n}\n\n/**将个人任务再回退到组任务（前提：之前这个任务是组任务）*/\npublic void setAssignee(){\n    String taskId = \"6308\";\n    taskService.setAssignee(taskId, null);\n}\n\n/**向组任务中添加成员*/\npublic void addGroupUser(){\n    String taskId = \"6308\";\n    //新增组任务的成员\n    String userId = \"如来\";\n    taskService.addCandidateUser(taskId, userId);\n}\n\n/**向组任务中删除成员*/\npublic void deleteGroupUser(){\n    String taskId = \"6308\";\n    //新增组任务的成员\n    String userId = \"猪八戒\";\n    taskService.deleteCandidateUser(taskId, userId);\n}\n```\n\n总结：      以上就是分配组任务的三种方式，和分配个人任务相对应，同样有三种方式，与个人任务的操作相比，组任务操作增加了组任务分配个人任务（认领任务），个人任务分配给组任务，以及向组任务添加人员和向组任务删除人员的操作。\n\n###  4.4 工作流提供的用户角色\n\n（1）设置用户角色\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182357.png)\n\n这个【部门经理】相当于一个用户角色，一个角色可以对应多个人，比如有三个人：张三、李四是部门经理，王五是总经理，那我们可以把这三个人录入的我们自己的用户表中，那么工作流也给我们提供了至少三张表：用户表，角色表，用户角色关联表那我们就可以把部门经理这个角色与张三、李四关联起来\n\n（2）具体做法：1、添加用户角色组  2、创建角色3、创建用户4、创建角色用户关联关系测试代码如下：\n\n```java\npublic void addUser(){\t\n\t\t//创建角色(两个角色)\n\t\tidentityService.saveGroup(new GroupEntity(\"部门经理\"));\n\t\tidentityService.saveGroup(new GroupEntity(\"总经理\"));\n\t\t\n\t\t//创建用户（三个用户）\n\t\tidentityService.saveUser(new UserEntity(\"张三\"));\n\t\tidentityService.saveUser(new UserEntity(\"李四\"));\n\t\tidentityService.saveUser(new UserEntity(\"王五\"));\n\t\t\n\t\t//创建用户角色关联关系\n\t\tidentityService.createMembership(\"张三\", \"部门经理\");\n\t\tidentityService.createMembership(\"李四\", \"部门经理\");\n\t\tidentityService.createMembership(\"王五\", \"总经理\");\n}\n```\n\n（3）部署流程定义\n\n```\npublic void deployementAndStart(){\n\tDeployment deployment = repositoryService.createDeployment().name(\"组任务\")\n\t\t\t\t\t.addClasspathResource(\"diagrams/group.bpmn\")\n\t\t\t\t\t.addClasspathResource(\"diagrams/group.png\").deploy();\n\tProcessInstance pi = runtimeService.startProcessInstanceByKey(\"group\");//启动流程  \n}\t\t\t\t\n```\n\n（4）查询张三或者李四的任务\n\n```\npublic void findGroupTask(){\n\t\tString candidateUser = \"张三\";\n\t\tList<Task> list =taskService.createTaskQuery().taskCandidateUser(candidateUser).list();\n\t\tif(list!=null && list.size()>0){  \n\t        for(Task task:list){  \n\t            System.out.println(\"任务ID：\"+task.getId());  \n\t            System.out.println(\"任务的办理人：\"+task.getAssignee());  \n\t            System.out.println(\"任务名称：\"+task.getName());  \n\t            System.out.println(\"任务的创建时间：\"+task.getCreateTime());  \n\t            System.out.println(\"流程实例ID：\"+task.getProcessInstanceId());  \n\t            System.out.println(\"#######################################\");  \n\t        }  \n\t     }\n}\n```\n\n执行结果\n\n>  任务ID：167504 \n>\n>  任务的办理人：null \n>\n>  任务名称：审核 \n>\n>  任务的创建时间：Thu Jul 07 10:21:27 GMT+08:00 2016 \n>\n>  流程实例ID：167501 \n\n（5）候选者不一定真正的参与任务的办理，所以我们需要拾取任务，将组任务分配给个人任务,即指定任务办理人字段\n\n```java\npublic void cliam(){\n\t\t//将组任务分配给个人任务\n\t\tString taskId =\"167504\";\n\t\t//分配的个人任务（可以是组任务中的成员，也可以是非组任务的成员）\n\t\tString userId =\"张三\";\n\t\ttaskService.claim(taskId, userId);\n\t\t//当执行完查询正执行的任务表（act_ru_task）可发现ASSIGNEE_字段（指定任务办理人）值为'张三'\n\t    //此时任务就指定给了张三，再用李四去查个人组任务就查询不出来任何任务【组任务最终也是需要指定一个人办理的，所以需要拾取任务】\n}\n\n```\n\n（6）张三完成任务\n\n```java\npublic void completeTask(){\n\tString taskId =\"167504\";\n\ttaskService.complete(taskId);\n}\n\n```\n\n当我们部署完流程定义，启动流程实例之后，我们可以查看您一下几张数据表：**表act_ru_task**\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904183255.png)\n\n 可以看见任务办理人的字段值为null,所以可能有两种情况可能没有办理人或者可能这个任务是组任务\n\n**表act_ru_identitylink**   正在执行的任务办理人表\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904183326.png)\n\n在这个表可以看见Task_ID 的值为167504就是正在执行的任务ID，流程实例字段为空，所以这个任务是组任务，处理这个组任务的角色ID为部门经理而张三和李四都是这个角色的用户，所以张三李四都可以查到这个任务，也可以进行任务的拾取，分配等操作。\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182422.png)\n\n需要说明的是在我们自己项目开发的时候，我们一般都是不用工作流自带的用户表、角色表，用户角色关联表都是自己来建，因为自带的表提供的字段不全。\n\n###  4.5 任务签收与反签收\n\n```java\n//任务签收\npublic void claim(String taskId) {\n   String userId = \"1111\";\n   taskService.claim(taskId, userId);\n}\n\n//任务反签收\npublic String unclaim(String taskId) {\n    taskService.unclaim(taskId);\n}\n```\n\n### 4.6 驳回申请\n\n\n\n### 4.7  流程变量的设置和获取\n\n**设置流程变量**\n\n流程变量的设置方式有两种，一是通过基本类型设置，第二种是通过JavaBean类型设置。\n\n**（1）基本类型**\n\n```\n\tpublic void setProcessVariables(){\n\t\tString processInstanceId = \"1301\";//流程实例ID\n\t\tString assignee = \"张三\";//任务办理人\n\t\t//查询当前办理人的任务ID\n\t\tTask task = taskService.createTaskQuery()\n\t\t\t\t.processInstanceId(processInstanceId)//使用流程实例ID\n\t\t\t\t.taskAssignee(assignee)//任务办理人\n\t\t\t\t.singleResult();\n\t\t//设置流程变量【基本类型】\n\t\ttaskService.setVariable(task.getId(), \"请假人\", assignee);\n\t\ttaskService.setVariableLocal(task.getId(), \"请假天数\",3);\n\t\ttaskService.setVariable(task.getId(), \"请假日期\", new Date());\n\t}\n```\n\n对应数据库表：act_ru_variable\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182451.png)\n\n**（2）JavaBean类型**\n\n```\npublic class Person{\n\tprivate Integer id;\n\tprivate String name;\n\tprivate String education;\n}\n```\n\n然后，通过JavaBean设置流程变量。这里要注意的是，Javabean类型设置获取流程变量，除了需要这个javabean实现了Serializable接口外，还要求流程变量对象的属性不能发生编号，否则抛出异常。 \n\n```java\npublic void setProcessVariables(){\n    String processInstanceId = \"1301\";//流程实例ID\n    String assignee = \"张三\";//任务办理人\n    //查询当前办理人的任务ID\n    Task task = taskService.createTaskQuery()\n        .processInstanceId(processInstanceId).taskAssignee(assignee).singleResult();\n    //设置流程变量【javabean类型】\n    Person p = new Person();\n    p.setId(1);\n    p.setName(\"周江霄\");\n    taskService.setVariable(task.getId(), \"人员信息\", p);\n}\n```\n\n数据库对应表：act_ru_variable，细心的你可以看到，通过JavaBean设置的流程变量，在act_ru_variable中存储的类型为serializable，变量真正存储的地方在act_ge_bytearray中\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182524.png) \n\n **获取流程变量**\n\n**（1）基本类型**\n\n```java\npublic void getProcessVariables(){\n\t\tString processInstanceId = \"1301\";//流程实例ID\n\t\tString assignee = \"张三\";//任务办理人\n\t\tTaskService taskService = processEngine.getTaskService();\n\t\t//获取当前办理人的任务ID\n\t\tTask task = taskService.createTaskQuery()\n\t\t\t\t.processInstanceId(processInstanceId)\n\t\t\t\t.taskAssignee(assignee)\n\t\t\t\t.singleResult();\n\t\tString person = (String) taskService.getVariable(task.getId(), \"请假人\");\n\t\tInteger day = (Integer) taskService.getVariableLocal(task.getId(), \"请假天数\");\n\t\tDate date = (Date) taskService.getVariable(task.getId(), \"请假日期\");\n\t\tSystem.out.println(person+\"  \"+day+\"   \"+date);\n}\n```\n\n**（2）JavaBean类型**\n\n```java\n/**获取流程变量*/\n\t@Test\n\tpublic void getProcessVariables(){\n\t\tString processInstanceId = \"1301\";//流程实例ID\n\t\tString assignee = \"张三\";//任务办理人\n\t\t//获取当前办理人的任务ID\n\t\tTask task = taskService.createTaskQuery()\n\t\t\t\t.processInstanceId(processInstanceId)\n\t\t\t\t.taskAssignee(assignee)\n\t\t\t\t.singleResult();\n\t\t//获取流程变量【javaBean类型】\n\t\tPerson p = (Person) taskService.getVariable(task.getId(), \"人员信息\");\n\t\tSystem.out.println(p.getId()+\"  \"+p.getName());\n\t\tSystem.out.println(\"获取成功~~\");\n\t}\n```\n\n  **查询历史流程变量** \n\n```\n/**查询历史的流程变量*/\npublic void getHistoryProcessVariables(){\n\tList<HistoricVariableInstance> list = processEngine.getHistoryService()\n\t\t\t\t.createHistoricVariableInstanceQuery()//创建一个历史的流程变量查询\n\t\t\t\t.variableName(\"请假天数\").list();\n\tif(list != null && list.size()>0){\n\t\tfor(HistoricVariableInstance hiv : list){\n\t\t\t\tSystem.out.println(\n\t\t\t\thiv.getTaskId()+\"  \"+hiv.getVariableName()+\"\n\t\t\t\t\"+hiv.getValue()+\"\t\t\"+hiv.getVariableTypeName());\n\t\t}\n\t}\t\t\t\t\n}\n```\n\n对应数据库表：act_ru_execution\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182542.png)\n\n### 4.8 查询所有的正在执行的任务 \n\n```java\npublic void testQueryTask(){\n        ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();\n        List<Task> tasks = processEngine.getTaskService()\n                .createTaskQuery()\n                .list();\n        for (Task task : tasks) {\n            System.out.println(task.getName());\n        }\n}\n```\n\n### 4.9 完成任务\n\n```\npublic void complete(){\n\t\tTask task=taskService.createTaskQuery()\n            .processInstanceId(pi.getId()).taskDefinitionKey(\"task\").singleResult();\n\t\ttaskService.setVariable(task.getId(), \"var1\", \"var1\");\n         taskService.complete(task.getId());\n }\n```\n\n以上代码是查询流程本次执行实例下名为task1的任务\n\n给任务设置全局变量，如果调用的是taskService.setVariableLocal方法，则任务执行完毕后，相关变量数据就会删除，然后再完成任务。\n\n首先向act_ru_variable表中插入变量信息，包含本次流程执行实例的两个id外键，但不包括任务的id，因为setVariable方法设置的是全局变量，也就是整个流程都会有效的变量\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182930.png)     \n\n此时整个流程执行完毕，act_ru_task，act_ru_execution和act_ru_variable表全被清空\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182951.png)\n\n## 五、历史任务\n\n### 5.1 查已完成任务和当前在执行的任务 \n\n```java\npublic void findHistoryTask(){\n        ProcessEngine defaultProcessEngine = ProcessEngines.getDefaultProcessEngine();\n        //如果只想获取到已经执行完成的，那么就要加入completed这个过滤条件\n        List<HistoricTaskInstance> historicTaskInstances1 = defaultProcessEngine.getHistoryService()\n                .createHistoricTaskInstanceQuery()\n                .taskDeleteReason(\"completed\")\n                .list();\n        //如果只想获取到已经执行完成的，那么就要加入completed这个过滤条件\n        List<HistoricTaskInstance> historicTaskInstances2 = defaultProcessEngine.getHistoryService()\n                .createHistoricTaskInstanceQuery()\n                .list();\n        System.out.println(\"执行完成的任务：\" + historicTaskInstances1.size());\n        System.out.println(\"所有的总任务数（执行完和当前未执行完）：\" +historicTaskInstances2.size());\n    }\n```\n\n\n\nActiviti 个人任务（三种指派方式） https://blog.csdn.net/caoyue_new/article/details/52180539\n\n\n\n六：关于流程实例的相关API\n\n**涉及到的表：**   \n\n**act_hi_actinst  **\n\n1、说明 *         act:activiti  *         hi:history  *         actinst:activity instance  *            流程图上出现的每一个元素都称为activity  *            流程图上正在执行的元素或者已经执行完成的元素称为activity instance  *      2、字段 *         proc_def_id:pdid  *         proc_inst_id:流程实例ID  *         execution_id_:执行ID  *         act_id_:activity  *         act_name  *         act_type  \n\n**act_hi_procinst **\n\n**      1、说明 *         procinst:process instance  历史的流程实例 *            正在执行的流程实例也在这张表中 *         如果end_time_为null，说明正在执行，如果有值，说明该流程实例已经结束了 *    _\n\n**act_hi_taskinst**\n\n     1、说明 *          taskinst:task instance  历史任务 *             正在执行的任务也在这张表中 *             如果end_time_为null,说明该任务正在执行 *             如果end_time不为null,说明该任务已经执行完毕了 *    **act_ru_execution**\n\n_      1、说明 *         ru:runtime  *         代表正在执行的流程实例表 *         如果当期正在执行的流程实例结束以后，该行在这张表中就被删除掉了，所以该表也是一个临时表 *      2、字段 *         proc_inst_id_:piid  流程实例ID，如果不存在并发的情况下，piid和executionID是一样的 *         act_id:当前正在执行的流程实例(如果不考虑并发的情况)的正在执行的activity有一个，所以act_id就是当前正在执行的流程实例的正在执行的 *           节点 *    **act_ru_task**_\n\n1、代表正在执行的任务表    该表是一个临时表，如果当前任务被完成以后，任务在这张表中就被删除掉了 \n\n2、字段 \n\n id_:  主键    任务ID      execution_id_:执行ID    *              根据该ID查询出来的任务肯定是一个 *          proc_inst_id:piid  *              根据该id查询出来的任务 *                 如果没有并发，则是一个 *                 如果有并发，则是多个 *          name_:任务的名称 *          assignee_:任务的执行人**\n\n\n\n## 六、工作流采购流程如何与业务关联\n\n实例.采购流程的监控\n\n- 查询当前获任务和业务关联\n\n- 查询已经结束的流程\n- 查询当前采购流程节点的位置图展示（在流程定义的节点上标出当前节点的位置，使用红色的框标出）\n- 查询某个流程下的历史任务（从流程开始到运行结束）\n- 查询某个用户所办理的历史任\n\n2.流程变量\n\n- 全局变量\n- 局部变量\n\n3.连线分支\n\n设置连线的condition条件实现分支\n\n### 6.1 流程定义图的画法\n\n流程图注意的东西\n\n（1）流程定义key  \n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182636.png)\n\n（2）流程变量 ：\n\n分支条件：**$**(price>=1000) 和**$**(price<1000)\n\n![1567592826450](C:\\Users\\Administrator\\AppData\\Local\\Temp\\1567592826450.png)\n\n（3）人员设置流程变量\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182721.png)\n\n其他和部门经理的设置方法一样\n\n部门经理审批的代办人流程变量  **$**{u} \n\n总经理审批的代办人流程变量  **$**{m} \n\n财务审批的代办人流程变量  **$**{c} \n\n（4）order.bpmn文件\n\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\n<definitions xmlns=\"http://www.omg.org/spec/BPMN/20100524/MODEL\" xmlns:activiti=\"http://activiti.org/bpmn\" xmlns:bpmndi=\"http://www.omg.org/spec/BPMN/20100524/DI\" xmlns:dc=\"http://www.omg.org/spec/DD/20100524/DC\" xmlns:di=\"http://www.omg.org/spec/DD/20100524/DI\" xmlns:tns=\"Examples\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" expressionLanguage=\"http://www.w3.org/1999/XPath\" id=\"m1539757531057\" name=\"\" targetNamespace=\"Examples\" typeLanguage=\"http://www.w3.org/2001/XMLSchema\">\n  <process id=\"orderKey\" isClosed=\"false\" isExecutable=\"true\" processType=\"None\">\n    <startEvent id=\"_2\" name=\"StartEvent\"/>\n    <userTask activiti:assignee=\"#{u}\" activiti:exclusive=\"true\" id=\"_3\" name=\"部门经理审批\"/>\n    <sequenceFlow id=\"_7\" sourceRef=\"_2\" targetRef=\"_3\"/>\n    <userTask activiti:assignee=\"${c}\" activiti:exclusive=\"true\" id=\"_4\" name=\"财务审批\"/>\n    <userTask activiti:assignee=\"${m}\" activiti:exclusive=\"true\" id=\"_5\" name=\"总经理审批\"/>\n    <endEvent id=\"_6\" name=\"EndEvent\"/>\n    <sequenceFlow id=\"_8\" sourceRef=\"_4\" targetRef=\"_6\"/>\n    <sequenceFlow id=\"_9\" sourceRef=\"_3\" targetRef=\"_4\">\n      <conditionExpression xsi:type=\"tFormalExpression\"><![CDATA[${price < 1000} ]]></conditionExpression>\n    </sequenceFlow>\n    <sequenceFlow id=\"_10\" sourceRef=\"_3\" targetRef=\"_5\">\n      <conditionExpression xsi:type=\"tFormalExpression\"><![CDATA[${price >= 1000} ]]></conditionExpression>\n    </sequenceFlow>\n    <sequenceFlow id=\"_11\" sourceRef=\"_5\" targetRef=\"_4\"/>\n  </process>\n  <bpmndi:BPMNDiagram documentation=\"background=#32424A;count=1;horizontalcount=1;orientation=0;width=842.4;height=1195.2;imageableWidth=832.4;imageableHeight=1185.2;imageableX=5.0;imageableY=5.0\" id=\"Diagram-_1\" name=\"New Diagram\">\n    <bpmndi:BPMNPlane bpmnElement=\"orderKey\">\n      <bpmndi:BPMNShape bpmnElement=\"_2\" id=\"Shape-_2\">\n        <dc:Bounds height=\"32.0\" width=\"32.0\" x=\"100.0\" y=\"10.0\"/>\n        <bpmndi:BPMNLabel>\n          <dc:Bounds height=\"32.0\" width=\"32.0\" x=\"0.0\" y=\"0.0\"/>\n        </bpmndi:BPMNLabel>\n      </bpmndi:BPMNShape>\n      <bpmndi:BPMNShape bpmnElement=\"_3\" id=\"Shape-_3\">\n        <dc:Bounds height=\"55.0\" width=\"85.0\" x=\"75.0\" y=\"95.0\"/>\n        <bpmndi:BPMNLabel>\n          <dc:Bounds height=\"55.0\" width=\"85.0\" x=\"0.0\" y=\"0.0\"/>\n        </bpmndi:BPMNLabel>\n      </bpmndi:BPMNShape>\n      <bpmndi:BPMNShape bpmnElement=\"_4\" id=\"Shape-_4\">\n        <dc:Bounds height=\"55.0\" width=\"85.0\" x=\"70.0\" y=\"220.0\"/>\n        <bpmndi:BPMNLabel>\n          <dc:Bounds height=\"55.0\" width=\"85.0\" x=\"0.0\" y=\"0.0\"/>\n        </bpmndi:BPMNLabel>\n      </bpmndi:BPMNShape>\n      <bpmndi:BPMNShape bpmnElement=\"_5\" id=\"Shape-_5\">\n        <dc:Bounds height=\"55.0\" width=\"85.0\" x=\"295.0\" y=\"95.0\"/>\n        <bpmndi:BPMNLabel>\n          <dc:Bounds height=\"55.0\" width=\"85.0\" x=\"0.0\" y=\"0.0\"/>\n        </bpmndi:BPMNLabel>\n      </bpmndi:BPMNShape>\n      <bpmndi:BPMNShape bpmnElement=\"_6\" id=\"Shape-_6\">\n        <dc:Bounds height=\"32.0\" width=\"32.0\" x=\"95.0\" y=\"380.0\"/>\n        <bpmndi:BPMNLabel>\n          <dc:Bounds height=\"32.0\" width=\"32.0\" x=\"0.0\" y=\"0.0\"/>\n        </bpmndi:BPMNLabel>\n      </bpmndi:BPMNShape>\n      <bpmndi:BPMNEdge bpmnElement=\"_7\" id=\"BPMNEdge__7\" sourceElement=\"_2\" targetElement=\"_3\">\n        <di:waypoint x=\"116.0\" y=\"42.0\"/>\n        <di:waypoint x=\"116.0\" y=\"95.0\"/>\n        <bpmndi:BPMNLabel>\n          <dc:Bounds height=\"0.0\" width=\"0.0\" x=\"0.0\" y=\"0.0\"/>\n        </bpmndi:BPMNLabel>\n      </bpmndi:BPMNEdge>\n      <bpmndi:BPMNEdge bpmnElement=\"_8\" id=\"BPMNEdge__8\" sourceElement=\"_4\" targetElement=\"_6\">\n        <di:waypoint x=\"111.0\" y=\"275.0\"/>\n        <di:waypoint x=\"111.0\" y=\"380.0\"/>\n        <bpmndi:BPMNLabel>\n          <dc:Bounds height=\"0.0\" width=\"0.0\" x=\"0.0\" y=\"0.0\"/>\n        </bpmndi:BPMNLabel>\n      </bpmndi:BPMNEdge>\n      <bpmndi:BPMNEdge bpmnElement=\"_9\" id=\"BPMNEdge__9\" sourceElement=\"_3\" targetElement=\"_4\">\n        <di:waypoint x=\"115.0\" y=\"150.0\"/>\n        <di:waypoint x=\"115.0\" y=\"220.0\"/>\n        <bpmndi:BPMNLabel>\n          <dc:Bounds height=\"0.0\" width=\"0.0\" x=\"0.0\" y=\"0.0\"/>\n        </bpmndi:BPMNLabel>\n      </bpmndi:BPMNEdge>\n      <bpmndi:BPMNEdge bpmnElement=\"_11\" id=\"BPMNEdge__11\" sourceElement=\"_5\" targetElement=\"_4\">\n        <di:waypoint x=\"340.0\" y=\"150.0\"/>\n        <di:waypoint x=\"340.0\" y=\"190.0\"/>\n        <di:waypoint x=\"155.0\" y=\"247.5\"/>\n        <bpmndi:BPMNLabel>\n          <dc:Bounds height=\"0.0\" width=\"0.0\" x=\"0.0\" y=\"0.0\"/>\n        </bpmndi:BPMNLabel>\n      </bpmndi:BPMNEdge>\n      <bpmndi:BPMNEdge bpmnElement=\"_10\" id=\"BPMNEdge__10\" sourceElement=\"_3\" targetElement=\"_5\">\n        <di:waypoint x=\"160.0\" y=\"122.5\"/>\n        <di:waypoint x=\"295.0\" y=\"122.5\"/>\n        <bpmndi:BPMNLabel>\n          <dc:Bounds height=\"0.0\" width=\"0.0\" x=\"0.0\" y=\"0.0\"/>\n        </bpmndi:BPMNLabel>\n      </bpmndi:BPMNEdge>\n    </bpmndi:BPMNPlane>\n  </bpmndi:BPMNDiagram>\n</definitions>\n\n```\n\n> 关键点  <process id=\"orderKey\" isClosed=\"false\" isExecutable=\"true\" processType=\"None\">\n\n###  6.2流程定义的部署\n\nactivitiService.java\n\n```java\npublic void deployByClassPath(String bpmnName) {\n        Deployment deploy =       repositoryService.createDeployment().addClasspathResource(bpmnName+\".bpmn\").deploy();\n        printDeploy(deploy);\n    }\n```\n\n```java\n@RequestMapping(\"/deploy\")\n@ResponseBody\npublic String deploy(String bpmnName) {\n    activitiService.deployByClassPath(bpmnName);\n    activitiService.queryDeployList();\n    return \"deploy\";\n}\n```\n\n###  6.3 流程实例启动时关联业务\n\n使用activiti自带表act_ru_execution中的BUSINESS_KEY字段我存在业务的唯一表示 \n\n```java\n/**\n* 流程变量\n* 给<userTask activiti:assignee=\"#{u}\" activiti:exclusive=\"true\" name=\"部门经理审批\"/>的u赋值\n* 给<userTask activiti:assignee=\"#{m}\" activiti:exclusive=\"true\" name=\"总经理审批\"/>的u赋值\n* 给<userTask activiti:assignee=\"#{c}\" activiti:exclusive=\"true\" name=\"财务审批\"/>的u赋值\n* 给<conditionExpression xsi:type=\"tFormalExpression\"><![CDATA[${price < 1000}]]>\n* </conditionExpression>的price赋值\n* 同时设置业务key bussinessKey\n*/\npublic <T> void startProcess(String processDefinitionId,T t){\n    HashMap<String, Object> map = new HashMap<>();\n    map.put(\"u\", \"u\");\n    map.put(\"m\", \"m\");\n    map.put(\"c\", \"c\");\n    map.put(\"price\", \"1200\");// 分别测试流程走的分支条件 map.put(\"price\", \"300\");\n    runtimeService.startProcessInstanceByKey(key, map);\n    String bussinessKey= t.getClass().getName()+\":\"+t.getId();\n    runtimeService.startProcessInstanceById(processDefinitionId,bussinessKey,map);\n}\n```\n\n启动流程是第二个参数就是表act_ru_execution中的BUSINESS_KEY字段，我一般喜欢使用业务名+ id来存储当前业务\n\n###  6.4 查询当前获任务和业务关联\n\n通过task获得当前流程，通过当前流程获取当前流程的业务id\n\n查询属性：流程实例id，当前节点，采购名称，采购金额\n\n```java\n/**\n     * \n     * @param assignee 任务办理人\n     */\npublic void getTaskDetailByAassignee(String assignee){\n    List<Task> tasks = taskService.createTaskQuery().taskAssignee(assignee).list();\n    for (Task task : tasks) {\n        String processInstanceId = task.getProcessInstanceId();\n        ProcessInstance processInstance = runtimeService.createProcessInstanceQuery().processInstanceId(processInstanceId).singleResult();\n        String businessKey = processInstance.getBusinessKey();\n        //当前运行的流程节点\n        String activityId = processInstance.getActivityId();\n        System.out.println(\"processInstanceId:\"+processInstanceId+\" businessKey:\"+businessKey+\" activityId:\"+activityId);\n        //业务主键id\n        Integer id;\n        if(StringUtils.isNotEmpty(businessKey)){\n            id=Integer.parseInt(businessKey.split(\":\")[1]);\n            //根据id查询出业务信息\n        }\n    }\n}\n```\n\n\n\n###  6.5 查询已经结束的流程\n\n通过task获得当前流程，通过当前流程获取当前流程的业务id\n\n查询属性：流程实例id，执行开始时间，执行结束时间，采购名称，采购金额\n\n\n\n###  6.6 包含流程变量条件的流程\n\n\n\n###  6.6 对采购单的金额进行统计查询 如统计金额的总和\n\n（1）先查询已经结束的流程，用关联sql的方式 不好\n\n（2）最直接的方法，只从业务系统中查询采购单的信息，并统计。因为统计的数据是业务数据，业务系统只负责业务数据。但是面临的一个问题是，并不知道业务系统中的哪些采购单是已经结束了的。\n\n如果，在采购单业务表中加入一个字段status，则表中有采购单结束的标识。\n\n实现方法：\n\n**方法1：** taskListener监听器的方法\n\n在流程定义的最后一个节点定义一个监听器，此监听器在完成任务的时候执行，在监听器中更新采购单业务表中的status字段的值，如：complete完成。\n\n**方法2：**executionListener监听器的方法\n\n在endevent节点上添加executionListener监听器的方法，监听事件选择end\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182803.png)\n\n\n\n## 七、业务开发总结\n\n觉得不需要用activitEntity保存那么多的属性id  processInstanceId和 只需要  查询task列表的时候可以返回一个List<Hashmap>，其实可以不需要 因为有businessEntity\n\n1.新建一个activitEntity.java包含两个字段id和流程实例Id\n\n```\npublic ActivitEntity{\n\tprivate String id;\n\tprivate String processInstanceId;\n}\n```\n\n2.业务表单继承ActivitEntity基类\n\n3.保存业务表单的时候启动一个流程，创建采购单时，在填写新增记录保存时，启动流程实例。\n\n4.业务service层执行的时候，要确定业务key，uuid以及启动流程之后返回的流程实例id\n\n5.启动流程的时候，如果用流程定义Id的话，感觉不太好，应为部署的问题，所以建议使用startBykey的方式\n\n```\npublic ActivitService{\n\tprivate void saveOrder(){\n        Order order=new Order();\n        String id=UUid.gen();\n        order.setId(id);\n        //String businessKey=Order.getClass().getName()+\":\"+id;//业务key 用类名和id组合 order:id\n        Map<String, Object> variables=new Hash<>();\n        //String processDefinitionId=\"11\";\n        String processDefinitionKey=\"从部署bpmn文件中获取\"  //有工具类可以获取到这key 网络搜素一下\n        //调用服务的方式\n        //ActivitClient.startProcess(processDefinitionId,order,variables)\n        ActivitClient.startProcess(processDefinitionKey,order,variables)\n\t}\n}\n\n\npublic <T extends ActivitEntity> void startProcess(String processDefinitionKey,T t,Map<String, Object> variables){\n        String bussinessKey= t.getClass().getName()+\":\"+t.getId(); //业务key 用类名和id组合 order:id\n       \n         //runtimeService.startProcessInstanceById(processDefinitionId,bussinessKey,variables);\n         runtimeService.startProcessInstanceByKey(processDefinitionKey,bussinessKey,variables);\n}\n```\n\n6.为防止对采购单的业务数据进行修改，所以，创建采购单的人要提交申请，在提交申请之前，是可以对数据进行修改的，提交申请之后，数据不能修改，同时任务流向下一个节点。\n\n7.待提交的采购单如何查询\n\n利用activiti的taskservice查询出当前用户的代办任务\n\n任务的名称，任务的待办人，任务申请人，任务提交的时间，采购金额，采购类型\n\n8.提交采购单  当前任务的taskid  taskService.coomplete(taskid);\n\n\n\n9.审核业务（另起数据表--审核表---字段包含 id,采购单,采购申请人,采购类型，审核意见，审核状态0不同意，1通过，审核时间）\n\n进入审核页面  填写审核信息  提交审核  \n\n业务逻辑 ：保存审核意见到审核表中，然后再用activit完成任务\n\n\n\n\n\n\n\n\n\n","slug":"我的activiti学习","published":1,"updated":"2019-09-04T10:35:28.111Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck061x94u000wqguiycpxkpaj","content":"<h1 id=\"activiti学习笔记\"><a href=\"#activiti学习笔记\" class=\"headerlink\" title=\"activiti学习笔记\"></a>activiti学习笔记</h1><h2 id=\"一、Activiti获取ProcessEngine的三种方法\"><a href=\"#一、Activiti获取ProcessEngine的三种方法\" class=\"headerlink\" title=\"一、Activiti获取ProcessEngine的三种方法\"></a>一、Activiti获取ProcessEngine的三种方法</h2><h3 id=\"1-1-ProcessEngineConfiguration获取\"><a href=\"#1-1-ProcessEngineConfiguration获取\" class=\"headerlink\" title=\"1.1 ProcessEngineConfiguration获取\"></a>1.1 ProcessEngineConfiguration获取</h3><pre><code class=\"java\">public static void config() {\n        //获取config对象\n        ProcessEngineConfiguration processEngineConfiguration = ProcessEngineConfiguration.createStandaloneProcessEngineConfiguration();\n        //Jdbc设置\n        String jdbcDriver = &quot;com.mysql.jdbc.Driver&quot;;\n        processEngineConfiguration.setJdbcDriver(jdbcDriver);\n        String jdbcUrl = &quot;jdbc:mysql://localhost:3306/activiti?useUnicode=true&amp;characterEncoding=utf-8&quot;;\n        processEngineConfiguration.setJdbcUrl(jdbcUrl);\n        String jdbcUsername = &quot;root&quot;;\n        processEngineConfiguration.setJdbcUsername(jdbcUsername);\n        String jdbcPassword = &quot;root&quot;;\n        processEngineConfiguration.setJdbcPassword(jdbcPassword);\n        //DB_SCHEMA_UPDATE_FALSE = &quot;false&quot;;不自动创建新表\n        // DB_SCHEMA_UPDATE_CREATE_DROP = &quot;create-drop&quot;;每次运行创建新表\n        // DB_SCHEMA_UPDATE_TRUE = &quot;true&quot;;设置自动对表结构进行改进和升级\n        //设置是否自动更新\n   processEngineConfiguration.setDatabaseSchemaUpdate(ProcessEngineConfiguration.DB_SCHEMA_UPDATE_TRUE);\n        //获取引擎对象\n        ProcessEngine processEngine = processEngineConfiguration.buildProcessEngine();\n        processEngine.close();\n    }\n</code></pre>\n<h3 id=\"1-2-ProcessEngineConfiguration载入xml文件\"><a href=\"#1-2-ProcessEngineConfiguration载入xml文件\" class=\"headerlink\" title=\"1.2 ProcessEngineConfiguration载入xml文件\"></a>1.2 ProcessEngineConfiguration载入xml文件</h3><p>xml文件： </p>\n<pre><code class=\"xml\">&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;     xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot;\n      xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\n      xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\n   http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-2.5.xsd\n   http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.0.xsd&quot;&gt;\n&lt;!--这里的类太多别导错了 --&gt;\n&lt;bean id=&quot;processEngineConfiguration&quot; class=&quot;org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration&quot;&gt;\n    &lt;!-- 配置流程引擎配置对象 --&gt;\n    &lt;property name=&quot;jdbcDriver&quot; value=&quot;com.mysql.jdbc.Driver&quot;&gt;&lt;/property&gt;\n    &lt;property name=&quot;jdbcUrl&quot; value=&quot;jdbc:mysql://localhost:3306/activiti?useUnicode=true&amp;amp;characterEncoding=utf-8&quot;&gt;&lt;/property&gt;\n    &lt;property name=&quot;jdbcUsername&quot; value=&quot;root&quot;&gt;&lt;/property&gt;\n    &lt;property name=&quot;jdbcPassword&quot; value=&quot;123456&quot;&gt;&lt;/property&gt;\n    &lt;!-- 注入数据源信息 --&gt;\n    &lt;property name=&quot;databaseSchemaUpdate&quot; value=&quot;true&quot;&gt;&lt;/property&gt;\n&lt;/bean&gt;\n&lt;bean id=&quot;processEngine&quot; class=&quot;org.activiti.spring.ProcessEngineFactoryBean&quot;&gt;\n    &lt;!-- 注入自动建表设置 --&gt;\n    &lt;property name=&quot;processEngineConfiguration&quot; ref=&quot;processEngineConfiguration&quot;&gt;&lt;/property&gt;\n&lt;/bean&gt;\n&lt;/beans&gt;</code></pre>\n<p>java代码加载xml文件</p>\n<pre><code class=\"java\">public void configByConf() {\n   //载入资源\n   ProcessEngineConfiguration processEngineConfiguration =      ProcessEngineConfiguration.createProcessEngineConfigurationFromResource(&quot;activiti.cfg.xml&quot;);\n        //创建引擎\n   ProcessEngine processEngine = processEngineConfiguration.buildProcessEngine();\n   processEngine.getRepositoryService();\n}</code></pre>\n<h3 id=\"1-3-默认载入activiti-cfg-xml进行获取\"><a href=\"#1-3-默认载入activiti-cfg-xml进行获取\" class=\"headerlink\" title=\"1.3 默认载入activiti.cfg.xml进行获取\"></a>1.3 默认载入activiti.cfg.xml进行获取</h3><pre><code class=\"java\">public void configByDefault() {\n   //通过获取载入默认获取\n   ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();\n   processEngine.close();\n}</code></pre>\n<p>这里的xml文件名必须设置为activiti.cfg.xml</p>\n<h2 id=\"二、流程定义\"><a href=\"#二、流程定义\" class=\"headerlink\" title=\"二、流程定义\"></a>二、流程定义</h2><p><code>部署流程</code>–&gt;<code>启动流程实例</code></p>\n<h3 id=\"2-1-设计流程定义文档\"><a href=\"#2-1-设计流程定义文档\" class=\"headerlink\" title=\"2.1 设计流程定义文档\"></a>2.1 设计流程定义文档</h3><p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182142.png\" alt></p>\n<h3 id=\"2-2-bpmn文件\"><a href=\"#2-2-bpmn文件\" class=\"headerlink\" title=\"2.2 bpmn文件\"></a>2.2 bpmn文件</h3><pre><code class=\"xml\">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n&lt;definitions xmlns=&quot;http://www.omg.org/spec/BPMN/20100524/MODEL&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:activiti=&quot;http://activiti.org/bpmn&quot; xmlns:bpmndi=&quot;http://www.omg.org/spec/BPMN/20100524/DI&quot; xmlns:omgdc=&quot;http://www.omg.org/spec/DD/20100524/DC&quot; xmlns:omgdi=&quot;http://www.omg.org/spec/DD/20100524/DI&quot; typeLanguage=&quot;http://www.w3.org/2001/XMLSchema&quot; expressionLanguage=&quot;http://www.w3.org/1999/XPath&quot; targetNamespace=&quot;http://www.activiti.org/test&quot;&gt;\n  &lt;process id=&quot;helloworld&quot; name=&quot;helloworldProcess&quot; isExecutable=&quot;true&quot;&gt;\n    &lt;startEvent id=&quot;startevent1&quot; name=&quot;Start&quot;&gt;&lt;/startEvent&gt;\n    &lt;endEvent id=&quot;endevent1&quot; name=&quot;End&quot;&gt;&lt;/endEvent&gt;\n    &lt;userTask id=&quot;usertask1&quot; name=&quot;提交申请&quot; activiti:assignee=&quot;张三&quot;&gt;&lt;/userTask&gt;\n    &lt;userTask id=&quot;usertask2&quot; name=&quot;审批【部门经理】&quot; activiti:assignee=&quot;李四&quot;&gt;&lt;/userTask&gt;\n    &lt;userTask id=&quot;usertask3&quot; name=&quot;审批【总经理】&quot; activiti:assignee=&quot;王五&quot;&gt;&lt;/userTask&gt;\n    &lt;sequenceFlow id=&quot;flow1&quot; sourceRef=&quot;startevent1&quot; targetRef=&quot;usertask1&quot;&gt;&lt;/sequenceFlow&gt;\n    &lt;sequenceFlow id=&quot;flow2&quot; sourceRef=&quot;usertask1&quot; targetRef=&quot;usertask2&quot;&gt;&lt;/sequenceFlow&gt;\n    &lt;sequenceFlow id=&quot;flow3&quot; sourceRef=&quot;usertask2&quot; targetRef=&quot;usertask3&quot;&gt;&lt;/sequenceFlow&gt;\n    &lt;sequenceFlow id=&quot;flow4&quot; sourceRef=&quot;usertask3&quot; targetRef=&quot;endevent1&quot;&gt;&lt;/sequenceFlow&gt;\n  &lt;/process&gt;\n  &lt;bpmndi:BPMNDiagram id=&quot;BPMNDiagram_helloworld&quot;&gt;\n    &lt;bpmndi:BPMNPlane bpmnElement=&quot;helloworld&quot; id=&quot;BPMNPlane_helloworld&quot;&gt;\n      &lt;bpmndi:BPMNShape bpmnElement=&quot;startevent1&quot; id=&quot;BPMNShape_startevent1&quot;&gt;\n        &lt;omgdc:Bounds height=&quot;35.0&quot; width=&quot;35.0&quot; x=&quot;330.0&quot; y=&quot;20.0&quot;&gt;&lt;/omgdc:Bounds&gt;\n      &lt;/bpmndi:BPMNShape&gt;\n      &lt;bpmndi:BPMNShape bpmnElement=&quot;endevent1&quot; id=&quot;BPMNShape_endevent1&quot;&gt;\n        &lt;omgdc:Bounds height=&quot;35.0&quot; width=&quot;35.0&quot; x=&quot;330.0&quot; y=&quot;380.0&quot;&gt;&lt;/omgdc:Bounds&gt;\n      &lt;/bpmndi:BPMNShape&gt;\n      &lt;bpmndi:BPMNShape bpmnElement=&quot;usertask1&quot; id=&quot;BPMNShape_usertask1&quot;&gt;\n        &lt;omgdc:Bounds height=&quot;55.0&quot; width=&quot;105.0&quot; x=&quot;295.0&quot; y=&quot;100.0&quot;&gt;&lt;/omgdc:Bounds&gt;\n      &lt;/bpmndi:BPMNShape&gt;\n      &lt;bpmndi:BPMNShape bpmnElement=&quot;usertask2&quot; id=&quot;BPMNShape_usertask2&quot;&gt;\n        &lt;omgdc:Bounds height=&quot;55.0&quot; width=&quot;105.0&quot; x=&quot;295.0&quot; y=&quot;200.0&quot;&gt;&lt;/omgdc:Bounds&gt;\n      &lt;/bpmndi:BPMNShape&gt;\n      &lt;bpmndi:BPMNShape bpmnElement=&quot;usertask3&quot; id=&quot;BPMNShape_usertask3&quot;&gt;\n        &lt;omgdc:Bounds height=&quot;55.0&quot; width=&quot;105.0&quot; x=&quot;295.0&quot; y=&quot;290.0&quot;&gt;&lt;/omgdc:Bounds&gt;\n      &lt;/bpmndi:BPMNShape&gt;\n      &lt;bpmndi:BPMNEdge bpmnElement=&quot;flow1&quot; id=&quot;BPMNEdge_flow1&quot;&gt;\n        &lt;omgdi:waypoint x=&quot;347.0&quot; y=&quot;55.0&quot;&gt;&lt;/omgdi:waypoint&gt;\n        &lt;omgdi:waypoint x=&quot;347.0&quot; y=&quot;100.0&quot;&gt;&lt;/omgdi:waypoint&gt;\n      &lt;/bpmndi:BPMNEdge&gt;\n      &lt;bpmndi:BPMNEdge bpmnElement=&quot;flow2&quot; id=&quot;BPMNEdge_flow2&quot;&gt;\n        &lt;omgdi:waypoint x=&quot;347.0&quot; y=&quot;155.0&quot;&gt;&lt;/omgdi:waypoint&gt;\n        &lt;omgdi:waypoint x=&quot;347.0&quot; y=&quot;200.0&quot;&gt;&lt;/omgdi:waypoint&gt;\n      &lt;/bpmndi:BPMNEdge&gt;\n      &lt;bpmndi:BPMNEdge bpmnElement=&quot;flow3&quot; id=&quot;BPMNEdge_flow3&quot;&gt;\n        &lt;omgdi:waypoint x=&quot;347.0&quot; y=&quot;255.0&quot;&gt;&lt;/omgdi:waypoint&gt;\n        &lt;omgdi:waypoint x=&quot;347.0&quot; y=&quot;290.0&quot;&gt;&lt;/omgdi:waypoint&gt;\n      &lt;/bpmndi:BPMNEdge&gt;\n      &lt;bpmndi:BPMNEdge bpmnElement=&quot;flow4&quot; id=&quot;BPMNEdge_flow4&quot;&gt;\n        &lt;omgdi:waypoint x=&quot;347.0&quot; y=&quot;345.0&quot;&gt;&lt;/omgdi:waypoint&gt;\n        &lt;omgdi:waypoint x=&quot;347.0&quot; y=&quot;380.0&quot;&gt;&lt;/omgdi:waypoint&gt;\n      &lt;/bpmndi:BPMNEdge&gt;\n    &lt;/bpmndi:BPMNPlane&gt;\n  &lt;/bpmndi:BPMNDiagram&gt;\n&lt;/definitions&gt;</code></pre>\n<h3 id=\"2-3-部署流程定义\"><a href=\"#2-3-部署流程定义\" class=\"headerlink\" title=\"2.3 部署流程定义\"></a>2.3 部署流程定义</h3><p>(1) 部署流程定义</p>\n<pre><code class=\"java\">public void deploymentProcessDefinition_classpath(){\n    Deployment deployment = processEngine.getRepositoryService()\n                    .createDeployment().name(&quot;流程定义&quot;)\n                      //从classpath的资源中加载，一次只能加载一个文件\n                    .addClasspathResource(&quot;diagrams/helloworld.bpmn&quot;)\n                    .addClasspathResource(&quot;diagrams/helloworld.png&quot;).deploy();//完成部署\n    System.out.println(&quot;部署ID：&quot;+deployment.getId());\n    System.out.println(&quot;部署名称：&quot;+deployment.getName());\n}</code></pre>\n<p>(2) ZipInputStream的部署方式</p>\n<pre><code>public static void main(String[] args) throws Exception{\n    DeploymentBuilder deployment = rs.createDeployment();\n    FileInputStream fis = new FileInputStream(new File(&quot;&quot;));\n    ZipInputStream zis = new ZipInputStream(fis);\n    deployment.addZipInputStream(zis);\n    deployment.deploy();\n}</code></pre><h3 id=\"2-4-流程部署后数据库的变化\"><a href=\"#2-4-流程部署后数据库的变化\" class=\"headerlink\" title=\"2.4 流程部署后数据库的变化\"></a>2.4 流程部署后数据库的变化</h3><ul>\n<li><p>act_ge_bytearray（资源文件表）        存储流程定义相关的部署信息。即流程定义文档的存放地。每部署一次就会增加两条记录，一条是关于bpmn规则文件的，一条是图片的（如果部署时只指定了bpmn一个文件，activiti会在部署时解析bpmn文件内容自动生成流程图）。两个文件不是很大，都是以二进制形式存储在数据库中。</p>\n</li>\n<li><p>act_re_procdef（流程定义表）    存放流程定义的属性信息，部署每个新的流程定义都会在这张表中增加一条记录。    注意：当流程定义的key相同的情况下，使用的是版本升级    </p>\n</li>\n</ul>\n<p>​       其中<code>act_re_deployment</code>的id会和<code>act_ge_bytearray</code>的deployment_id_关联</p>\n<ul>\n<li>act_re_deployment（流程部署表）       存放流程定义的显示名和部署时间，每部署一次增加一条记录</li>\n</ul>\n<p>流程部署之后act_ge_bytearray插入两条记录</p>\n<table>\n<thead>\n<tr>\n<th>ID_</th>\n<th>REV_</th>\n<th>NAME_</th>\n<th>DEPLOYMENT_ID_</th>\n<th>BYTES_</th>\n<th>GENERATED_</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>ID</td>\n<td>版本</td>\n<td>名称</td>\n<td>部署ID</td>\n<td>字节</td>\n<td>不详</td>\n</tr>\n<tr>\n<td>10002</td>\n<td>1</td>\n<td>simple.bpmn</td>\n<td>10001</td>\n<td>blob文件</td>\n<td>1</td>\n</tr>\n<tr>\n<td>10003</td>\n<td>1</td>\n<td>simple.myProcess_1.png</td>\n<td>10001</td>\n<td>blob文件</td>\n<td>1</td>\n</tr>\n</tbody></table>\n<p>act_re_procdef（流程定义表）       存放流程定义的显示名和部署时间，每部署一次增加一条记录</p>\n<table>\n<thead>\n<tr>\n<th>ID_</th>\n<th>REV_</th>\n<th>CATEGORY_</th>\n<th>NAME_</th>\n<th>KEY_</th>\n<th>VERSION_</th>\n<th>DEPLOYMENT_ID_</th>\n<th>RESOURCE_NAME_</th>\n<th>DGRM_RESOURCE_NAME_</th>\n<th>DESCRIPTION_</th>\n<th>HAS_START_FORM_KEY_</th>\n<th>HAS_GRAPHICAL_NOTATION_</th>\n<th>SUSPENSION_STATE_</th>\n<th>TENANT_ID_</th>\n<th>ENGINE_VERSION_</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>流程定义id</td>\n<td></td>\n<td></td>\n<td></td>\n<td>流程key</td>\n<td>版本</td>\n<td>流程部署id</td>\n<td>流程资源名称</td>\n<td>流程资源图片</td>\n<td>描述</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>myProcess_1:1:10004</td>\n<td>1</td>\n<td>Examples</td>\n<td></td>\n<td>myProcess_1</td>\n<td>1</td>\n<td>10001</td>\n<td>simple.bpmn</td>\n<td>simple.myProcess_1.png</td>\n<td></td>\n<td>0</td>\n<td>1</td>\n<td>1</td>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n<p>act_re_deployment（流程部署表）       存放流程定义的显示名和部署时间，每部署一次增加一条记录</p>\n<table>\n<thead>\n<tr>\n<th>ID_</th>\n<th>NAME_</th>\n<th>CATEGORY_</th>\n<th>KEY_</th>\n<th>TENANT_ID_</th>\n<th>DEPLOY_TIME_</th>\n<th>ENGINE_VERSION_</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>部署id</td>\n<td>部署名称</td>\n<td>部署类型</td>\n<td>部署key</td>\n<td></td>\n<td>部署时间</td>\n<td></td>\n</tr>\n<tr>\n<td>10001</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td>2019/4/3 16:35</td>\n<td></td>\n</tr>\n</tbody></table>\n<h3 id=\"2-5-根据名称查询流程部署\"><a href=\"#2-5-根据名称查询流程部署\" class=\"headerlink\" title=\"2.5 根据名称查询流程部署\"></a>2.5 根据名称查询流程部署</h3><pre><code class=\"java\">public void testQueryDeploymentByName(){\n        ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();\n        List&lt;Deployment&gt; deployments = processEngine.getRepositoryService()\n                .createDeploymentQuery()\n                .orderByDeploymenTime()//按照部署时间排序\n                .desc()//按照降序排序\n                .deploymentName(&quot;请假流程&quot;)\n                .list();\n        for (Deployment deployment : deployments) {\n            System.out.println(deployment.getId());\n        }\n    }</code></pre>\n<h3 id=\"2-6-查询所有的部署流程\"><a href=\"#2-6-查询所有的部署流程\" class=\"headerlink\" title=\"2.6 查询所有的部署流程\"></a>2.6 查询所有的部署流程</h3><pre><code class=\"java\">public void queryAllDeplyoment(){\n        //得到流程引擎\n        ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();\n        List&lt;Deployment&gt; lists = processEngine.getRepositoryService()\n                .createDeploymentQuery()\n                .orderByDeploymenTime()//按照部署时间排序\n                .desc()//按照降序排序\n                .list();\n        for (Deployment deployment:lists) {\n            System.out.println(deployment.getId() +&quot;    部署名称&quot; + deployment.getName());\n        }\n}</code></pre>\n<h3 id=\"2-7-查看所有流程定义\"><a href=\"#2-7-查看所有流程定义\" class=\"headerlink\" title=\"2.7 查看所有流程定义\"></a>2.7 查看所有流程定义</h3><pre><code class=\"java\">public void findProcessDefinition(){\n    List&lt;ProcessDefinition&gt; list = RepositoryService.createProcessDefinitionQuery()//创建一个流程定义的查询\n            /**指定查询条件,where条件*/\n//            .deploymentId(deploymentId)//使用部署对象ID查询\n//            .processDefinitionId(processDefinitionId)//使用流程定义ID查询\n//            .processDefinitionKey(processDefinitionKey)//使用流程定义的key查询\n//            .processDefinitionNameLike(processDefinitionNameLike)//使用流程定义的名称模糊查询\n            .orderByProcessDefinitionVersion().asc()//按照版本的升序排列\n//            .orderByProcessDefinitionName().desc()//按照流程定义的名称降序排列\n            .list();//返回一个集合列表，封装流程定义\n//            .singleResult();//返回惟一结果集\n//            .count();//返回结果集数量\n//            .listPage(firstResult, maxResults);//分页查询\n    if(list!=null &amp;&amp; list.size()&gt;0){\n        for(ProcessDefinition pd:list){\n            System.out.println(&quot;流程定义ID:&quot;+pd.getId());//流程定义的key+版本+随机生成数\n            System.out.println(&quot;流程定义的名称:&quot;+pd.getName());//对应helloworld.bpmn文件中的name属性值\n            System.out.println(&quot;流程定义的key:&quot;+pd.getKey());//对应helloworld.bpmn文件中的id属性值\n            System.out.println(&quot;流程定义的版本:&quot;+pd.getVersion());//当流程定义的key值相同的相同下，版本升级，默认1\n            System.out.println(&quot;资源名称bpmn文件:&quot;+pd.getResourceName());\n            System.out.println(&quot;资源名称png文件:&quot;+pd.getDiagramResourceName());\n            System.out.println(&quot;部署对象ID：&quot;+pd.getDeploymentId());\n        }\n    }            \n}</code></pre>\n<h3 id=\"2-8-删除流程定义\"><a href=\"#2-8-删除流程定义\" class=\"headerlink\" title=\"2.8 删除流程定义\"></a>2.8 删除流程定义</h3><pre><code class=\"java\">public void deleteProcessDefinition(){\n    String deploymentId = &quot;601&quot;; //使用部署ID，完成删除\n    //不带级联的删除 只能删除没有启动的流程，如果流程启动，就会抛出异常\n    RepositoryService().deleteDeployment(deploymentId);\n    //级联删除  不管流程是否启动，都能可以删除\n    RepositoryService().deleteDeployment(deploymentId, true);\n}</code></pre>\n<p>说明：    </p>\n<ul>\n<li><p>因为删除的是流程定义，而流程定义的部署是属于仓库服务的，所以应该先得到RepositoryService。    </p>\n</li>\n<li><p>如果该流程定义下没有正在运行的流程，则可以用普通删除。如果是有关联的信息，用级联删除。项目开发中使用级联删除的情况比较多，删除操作一般只开放给超级管理员使用。</p>\n</li>\n</ul>\n<h3 id=\"2-9-查看流程图\"><a href=\"#2-9-查看流程图\" class=\"headerlink\" title=\"2.9 查看流程图\"></a>2.9 查看流程图</h3><pre><code class=\"java\">public void viewPic() throws IOException{\n    /**将生成图片放到文件夹下*/\n    String deploymentId = &quot;801&quot;;\n    //获取图片资源名称\n    List&lt;String&gt; list = repositoryService.getDeploymentResourceNames(deploymentId);\n    //定义图片资源的名称\n    String resourceName = &quot;&quot;;\n    if(list!=null &amp;&amp; list.size()&gt;0){\n        for(String name:list){\n            if(name.indexOf(&quot;.png&quot;)&gt;=0){\n                resourceName = name;\n            }\n        }\n    }    \n    //获取图片的输入流\n    InputStream in = repositoryService.getResourceAsStream(deploymentId, resourceName);\n    //将图片生成到D盘的目录下\n    File file = new File(&quot;D:/&quot;+resourceName);\n    //将输入流的图片写到D盘下\n    FileUtils.copyInputStreamToFile(in, file);\n}</code></pre>\n<h3 id=\"2-10-流程定义的暂停挂起\"><a href=\"#2-10-流程定义的暂停挂起\" class=\"headerlink\" title=\"2.10 流程定义的暂停挂起\"></a>2.10 流程定义的暂停挂起</h3><p><strong>测试暂停流程定义执行步骤如下：</strong></p>\n<p>在程序中，我们需要暂停一个流程定义，停止所有的该流程定义下的流程实例，并且不允许发起这个流程定义的流程实例，那么我们就需要挂起这个流程定义</p>\n<p>　　1，启动一个流程实例（该流程定义未挂起前）</p>\n<p>　　2，挂起上面流程实例对应的流程定义</p>\n<p>　　3，完成上述流程实例的下一个任务节点（观察效果，是否会和流程实例挂起一样）</p>\n<p>（1）根据流程实例的id来挂起这个流程定义</p>\n<pre><code>public void testSuspendProcessDefinition(){        \n     String processDefinitionKey =&quot;purchasingflow&quot;;\n     //根据流程定义的key暂停一个流程定义\n     repositoryService.suspendProcessDefinitionByKey(processDefinitionKey );\n}</code></pre><p>（2）完成这个流程实例的下一个节点，通过taskService来结束下一个任务节点</p>\n<p>　　这时候，我们发现这个流程实例居然是可以继续执行的，并且可以执行到结束，带着这个疑问，我们再启动一个流程实例看看</p>\n<p>（3）重新启动这个流程定义下的流程实例</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182230.png\" alt></p>\n<p>报错说不可以启动这个被挂起流程定义的流程实例</p>\n<h2 id=\"三、流程实例\"><a href=\"#三、流程实例\" class=\"headerlink\" title=\"三、流程实例\"></a>三、流程实例</h2><h3 id=\"3-1-根据流程部署id启动流程实例\"><a href=\"#3-1-根据流程部署id启动流程实例\" class=\"headerlink\" title=\"3.1 根据流程部署id启动流程实例\"></a>3.1 根据流程部署id启动流程实例</h3><pre><code class=\"java\">public void startProcess(String deploymentId){\n    ProcessDefinition pd=repositoryService.createProcessDefinitionQuery()\n        .deploymentId(deploymentId)\n        .singleResult();\n    ProcessInstance pi=runtimeService.startProcessInstanceById(pd.getId());\n}</code></pre>\n<h3 id=\"3-2-根据流程id启动流程实例-可以设置一个流程变量\"><a href=\"#3-2-根据流程id启动流程实例-可以设置一个流程变量\" class=\"headerlink\" title=\"3.2 根据流程id启动流程实例,可以设置一个流程变量\"></a>3.2 根据流程id启动流程实例,可以设置一个流程变量</h3><pre><code class=\"java\">/**\n* 流程变量\n* 给&lt;userTask id=&quot;请假申请&quot; name=&quot;申请&quot; activiti:assignee=&quot;#{student}&quot;&gt;&lt;/userTask&gt;的student赋值\n*/\npublic void startProcess(){\n    Map&lt;String, Object&gt; variables = new HashMap&lt;String, Object&gt;();\n    variables.put(&quot;student&quot;, &quot;小明&quot;);\n    ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();\n    runtimeService.startProcessInstanceById(&quot;shenqing1:1:1304&quot;,variables);\n}</code></pre>\n<h3 id=\"3-3-启动流程实例之后数据库的变化\"><a href=\"#3-3-启动流程实例之后数据库的变化\" class=\"headerlink\" title=\"3.3 启动流程实例之后数据库的变化\"></a>3.3 启动流程实例之后数据库的变化</h3><p>首先向act_ru_execution表中插入一条记录，记录的是这个流程定义的执行实例，其中id和proc_inst_id相同都是流程执行实例id，也就是本次执行这个流程定义的id，包含流程定义的id外键(simpleProcess:1:5004)。</p>\n<table>\n<thead>\n<tr>\n<th>ID_</th>\n<th>REV_</th>\n<th>PROC_INST_ID_</th>\n<th>BUSINESS_KEY_</th>\n<th>PARENT_ID_</th>\n<th>PROC_DEF_ID_</th>\n<th>SUPER_EXEC_</th>\n<th>ROOT_PROC_INST_ID_</th>\n<th>ACT_ID_</th>\n<th>IS_ACTIVE_</th>\n<th>IS_CONCURRENT_</th>\n<th>IS_SCOPE_</th>\n<th>IS_EVENT_SCOPE_</th>\n<th>IS_MI_ROOT_</th>\n<th>SUSPENSION_STATE_</th>\n<th>START_TIME_</th>\n</tr>\n</thead>\n<tbody><tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>12501</td>\n<td>1</td>\n<td>12501</td>\n<td></td>\n<td></td>\n<td>myProcess_1:1:10004</td>\n<td></td>\n<td>12501</td>\n<td></td>\n<td>1</td>\n<td>0</td>\n<td>1</td>\n<td>0</td>\n<td>0</td>\n<td>1</td>\n<td>2019-4-3 17:25:30</td>\n</tr>\n<tr>\n<td>12503</td>\n<td>1</td>\n<td>12501</td>\n<td></td>\n<td>12501</td>\n<td>myProcess_1:1:10004</td>\n<td></td>\n<td>12501</td>\n<td>_3</td>\n<td>1</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>1</td>\n<td>2019-4-3 17:25:30</td>\n</tr>\n</tbody></table>\n<p>然后向act_ru_task插入一条记录，记录的是第一个任务的信息，也就是开始执行第一个任务。包括act_ru_execution表中的execution_id外键和proc_inst_id外键，也就是本次执行实例id。</p>\n<table>\n<thead>\n<tr>\n<th>ID_</th>\n<th>REV_</th>\n<th>EXECUTION_ID_</th>\n<th>PROC_INST_ID_</th>\n<th>PROC_DEF_ID_</th>\n<th>NAME_</th>\n<th>PARENT_TASK_ID_</th>\n<th>DESCRIPTION_</th>\n<th>TASK_DEF_KEY_</th>\n<th>OWNER_</th>\n<th>ASSIGNEE_</th>\n<th>DELEGATION_</th>\n<th>PRIORITY_</th>\n<th>CREATE_TIME_</th>\n<th>DUE_DATE_</th>\n<th>CATEGORY_</th>\n<th>SUSPENSION_STATE_</th>\n</tr>\n</thead>\n<tbody><tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>12506</td>\n<td>1</td>\n<td>12503</td>\n<td>12501</td>\n<td>myProcess_1:1:10004</td>\n<td>UserTask</td>\n<td></td>\n<td></td>\n<td>_3</td>\n<td></td>\n<td>a</td>\n<td></td>\n<td>50</td>\n<td>2019/4/3 17:07</td>\n<td></td>\n<td></td>\n<td>1</td>\n</tr>\n</tbody></table>\n<p>然后向act_hi_procinst表插入一条记录，记录的是本次执行实例：</p>\n<table>\n<thead>\n<tr>\n<th>ID_</th>\n<th>PROC_INST_ID_</th>\n<th>BUSINESS_KEY_</th>\n<th>PROC_DEF_ID_</th>\n<th>START_TIME_</th>\n<th>END_TIME_</th>\n<th>DURATION_</th>\n<th>START_USER_ID_</th>\n<th>START_ACT_ID_</th>\n<th>END_ACT_ID_</th>\n<th>SUPER_PROCESS_INSTANCE_ID_</th>\n<th>DELETE_REASON_</th>\n<th>TENANT_ID_</th>\n<th>NAME_</th>\n</tr>\n</thead>\n<tbody><tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>12501</td>\n<td>12501</td>\n<td></td>\n<td>myProcess_1:1:10004</td>\n<td>2019/4/3 17:07</td>\n<td></td>\n<td></td>\n<td></td>\n<td>_2</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n<p>然后向act_hi_taskinst表中插入一条记录，记录的是任务的历史记录：</p>\n<table>\n<thead>\n<tr>\n<th>ID_</th>\n<th>PROC_DEF_ID_</th>\n<th>TASK_DEF_KEY_</th>\n<th>PROC_INST_ID_</th>\n<th>EXECUTION_ID_</th>\n<th>NAME_</th>\n<th>PARENT_TASK_ID_</th>\n<th>DESCRIPTION_</th>\n<th>OWNER_</th>\n<th>ASSIGNEE_</th>\n<th>START_TIME_</th>\n<th>CLAIM_TIME_</th>\n<th>END_TIME_</th>\n<th>DURATION_</th>\n<th>DELETE_REASON_</th>\n<th>PRIORITY_</th>\n<th>DUE_DATE_</th>\n<th>FORM_KEY_</th>\n<th>CATEGORY_</th>\n<th>TENANT_ID_</th>\n</tr>\n</thead>\n<tbody><tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>12506</td>\n<td>myProcess_1:1:10004</td>\n<td>_3</td>\n<td>12501</td>\n<td>12503</td>\n<td>UserTask</td>\n<td></td>\n<td></td>\n<td></td>\n<td>a</td>\n<td>2019/4/3 17:07</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td>50</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n<h3 id=\"3-4-流程实例的暂停挂起\"><a href=\"#3-4-流程实例的暂停挂起\" class=\"headerlink\" title=\"3.4 流程实例的暂停挂起\"></a>3.4 流程实例的暂停挂起</h3><p><strong>测试暂停流程实例执行步骤如下：</strong></p>\n<p>　　1，通过流程定义的key或者id启动一个流程实例</p>\n<p>　　2，根据流程实例的id来挂起这个流程实例</p>\n<p>　　3，得到下一个节点的对应的任务的id，调用taskService来完成这个任务观察效果</p>\n<p> 　   4，重新激活这个流程实例</p>\n<p>　　5，继续完成这个流程实例</p>\n<p>（1）通过上面发起的流程实例的id挂起这个流程实例 </p>\n<pre><code class=\"java\">public void testSuspendProcessInstance(){\n    String processInstanceId=&quot;1801&quot;;\n    //根据一个流程实例的id挂起该流程实例\n    runtimeService.suspendProcessInstanceById(processInstanceId);\n}</code></pre>\n<p>（2）任务的下一处理人来完成这个实例 </p>\n<pre><code class=\"java\">public void completeProcessInstance(){\n    //任务的id，后期整合后会通过当前登录人身份查询到该用户的任务，然后获取到该id\n    String taskId=&quot;1804&quot;;\n    //根据任务id完成该任务\n    taskService.complete(taskId);\n}</code></pre>\n<p>执行完报错：</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904183119.png\" alt></p>\n<p>　　上面的信息说明无法完成一个已经被挂起的任务</p>\n<p>（3）激活这个流程实例 </p>\n<pre><code>public void testActivateProcessInstance(){\n    String processInstanceId=&quot;1801&quot;;\n    runtimeService.activateProcessInstanceById(processInstanceId);\n}</code></pre><p>5，重新完成这个任务，执行ok </p>\n<h2 id=\"四、任务管理\"><a href=\"#四、任务管理\" class=\"headerlink\" title=\"四、任务管理\"></a>四、任务管理</h2><h3 id=\"4-1-根据办理人查询任务\"><a href=\"#4-1-根据办理人查询任务\" class=\"headerlink\" title=\"4.1 根据办理人查询任务\"></a>4.1 根据办理人查询任务</h3><p><code>根据任务的执行人查询正在执行任务(通过act_ru_task数据表)</code></p>\n<pre><code class=\"java\">public void testQueryTaskByAssignee(){\n        ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();\n        //当前班主任小毛人这个人当前正在执行的所有的任务\n        List&lt;Task&gt; tasks = processEngine.getTaskService()\n                .createTaskQuery()\n                .orderByTaskCreateTime()\n                .desc()\n                .taskAssignee(&quot;小毛&quot;)\n                .list();\n        for (Task task : tasks) {\n            System.out.println(task.getName());\n            System.out.println(task.getAssignee());\n        }\n    }</code></pre>\n<h3 id=\"4-2-个人任务的三种指派方式\"><a href=\"#4-2-个人任务的三种指派方式\" class=\"headerlink\" title=\"4.2 个人任务的三种指派方式\"></a>4.2 个人任务的三种指派方式</h3><p><strong>（1）方式一</strong></p>\n<p>定义流程图时直接指定完成任务人（项目开发中任务的办理人不要放置XML文件中，不够灵活，较少使用） </p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904183158.png\" alt></p>\n<p>定义的bpmn文件中定义任务办理人的名称</p>\n<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n&lt;definitions xmlns=&quot;http://www.omg.org/spec/BPMN/20100524/MODEL&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:xsd=&quot;http://www.w3.org/2001/XMLSchema&quot; xmlns:activiti=&quot;http://activiti.org/bpmn&quot; xmlns:bpmndi=&quot;http://www.omg.org/spec/BPMN/20100524/DI&quot; xmlns:omgdc=&quot;http://www.omg.org/spec/DD/20100524/DC&quot; xmlns:omgdi=&quot;http://www.omg.org/spec/DD/20100524/DI&quot; typeLanguage=&quot;http://www.w3.org/2001/XMLSchema&quot; expressionLanguage=&quot;http://www.w3.org/1999/XPath&quot; targetNamespace=&quot;http://www.activiti.org/test&quot;&gt;\n  &lt;process id=&quot;personalAssignee1&quot; name=&quot;PersonalAssignee1&quot; isExecutable=&quot;true&quot;&gt;\n    &lt;startEvent id=&quot;startevent1&quot; name=&quot;Start&quot;&gt;&lt;/startEvent&gt;\n    &lt;userTask id=&quot;usertask1&quot; name=&quot;审批&quot; activiti:assignee=&quot;crystal&quot;&gt;&lt;/userTask&gt;\n    &lt;sequenceFlow id=&quot;flow1&quot; sourceRef=&quot;startevent1&quot; targetRef=&quot;usertask1&quot;&gt;&lt;/sequenceFlow&gt;\n    &lt;endEvent id=&quot;endevent1&quot; name=&quot;End&quot;&gt;&lt;/endEvent&gt;\n    &lt;sequenceFlow id=&quot;flow2&quot; sourceRef=&quot;usertask1&quot; targetRef=&quot;endevent1&quot;&gt;&lt;/sequenceFlow&gt;\n  &lt;/process&gt;\n  &lt;bpmndi:BPMNDiagram id=&quot;BPMNDiagram_personalAssignee1&quot;&gt;\n    &lt;bpmndi:BPMNPlane bpmnElement=&quot;personalAssignee1&quot; id=&quot;BPMNPlane_personalAssignee1&quot;&gt;\n      &lt;bpmndi:BPMNShape bpmnElement=&quot;startevent1&quot; id=&quot;BPMNShape_startevent1&quot;&gt;\n        &lt;omgdc:Bounds height=&quot;35.0&quot; width=&quot;35.0&quot; x=&quot;360.0&quot; y=&quot;20.0&quot;&gt;&lt;/omgdc:Bounds&gt;\n      &lt;/bpmndi:BPMNShape&gt;\n      &lt;bpmndi:BPMNShape bpmnElement=&quot;usertask1&quot; id=&quot;BPMNShape_usertask1&quot;&gt;\n        &lt;omgdc:Bounds height=&quot;55.0&quot; width=&quot;105.0&quot; x=&quot;325.0&quot; y=&quot;100.0&quot;&gt;&lt;/omgdc:Bounds&gt;\n      &lt;/bpmndi:BPMNShape&gt;\n      &lt;bpmndi:BPMNShape bpmnElement=&quot;endevent1&quot; id=&quot;BPMNShape_endevent1&quot;&gt;\n        &lt;omgdc:Bounds height=&quot;35.0&quot; width=&quot;35.0&quot; x=&quot;360.0&quot; y=&quot;200.0&quot;&gt;&lt;/omgdc:Bounds&gt;\n      &lt;/bpmndi:BPMNShape&gt;\n      &lt;bpmndi:BPMNEdge bpmnElement=&quot;flow1&quot; id=&quot;BPMNEdge_flow1&quot;&gt;&lt;/bpmndi:BPMNEdge&gt;\n      &lt;bpmndi:BPMNEdge bpmnElement=&quot;flow2&quot; id=&quot;BPMNEdge_flow2&quot;&gt;&lt;/bpmndi:BPMNEdge&gt;\n    &lt;/bpmndi:BPMNPlane&gt;\n  &lt;/bpmndi:BPMNDiagram&gt;\n&lt;/definitions&gt;\n</code></pre><p>重点代码  <strong>activiti:assignee=”crystal”</strong></p>\n<p>启动流程实例</p>\n<pre><code class=\"java\">public void start() {\n    ProcessInstance pi = runtimeService().startProcessInstanceByKey(&quot;task&quot;);\n}</code></pre>\n<p><strong>（2）方式二</strong></p>\n<p>定义流程图时配置任务节点变量，完成任务之前由流程变量指定任务办理人。在开发中，可以在页面中指定下一个任务的办理人，通过流程变量设置下一个任务的办理人。</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904183224.png\" alt></p>\n<p>定义的bpmn文件中定义任务办理人的名称</p>\n<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n&lt;definitions xmlns=&quot;http://www.omg.org/spec/BPMN/20100524/MODEL&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:xsd=&quot;http://www.w3.org/2001/XMLSchema&quot; xmlns:activiti=&quot;http://activiti.org/bpmn&quot; xmlns:bpmndi=&quot;http://www.omg.org/spec/BPMN/20100524/DI&quot; xmlns:omgdc=&quot;http://www.omg.org/spec/DD/20100524/DC&quot; xmlns:omgdi=&quot;http://www.omg.org/spec/DD/20100524/DI&quot; typeLanguage=&quot;http://www.w3.org/2001/XMLSchema&quot; expressionLanguage=&quot;http://www.w3.org/1999/XPath&quot; targetNamespace=&quot;http://www.activiti.org/test&quot;&gt;\n  &lt;process id=&quot;personalTask2&quot; name=&quot;PersonalTask2&quot; isExecutable=&quot;true&quot;&gt;\n    &lt;startEvent id=&quot;startevent1&quot; name=&quot;Start&quot;&gt;&lt;/startEvent&gt;\n    &lt;userTask id=&quot;usertask1&quot; name=&quot;审批&quot; activiti:assignee=&quot;#{userId}&quot;&gt;&lt;/userTask&gt;\n    &lt;sequenceFlow id=&quot;flow1&quot; sourceRef=&quot;startevent1&quot; targetRef=&quot;usertask1&quot;&gt;&lt;/sequenceFlow&gt;\n    &lt;endEvent id=&quot;endevent1&quot; name=&quot;End&quot;&gt;&lt;/endEvent&gt;\n    &lt;sequenceFlow id=&quot;flow2&quot; sourceRef=&quot;usertask1&quot; targetRef=&quot;endevent1&quot;&gt;&lt;/sequenceFlow&gt;\n  &lt;/process&gt;\n  &lt;bpmndi:BPMNDiagram id=&quot;BPMNDiagram_personalTask2&quot;&gt;\n    &lt;bpmndi:BPMNPlane bpmnElement=&quot;personalTask2&quot; id=&quot;BPMNPlane_personalTask2&quot;&gt;\n      &lt;bpmndi:BPMNShape bpmnElement=&quot;startevent1&quot; id=&quot;BPMNShape_startevent1&quot;&gt;\n        &lt;omgdc:Bounds height=&quot;35.0&quot; width=&quot;35.0&quot; x=&quot;380.0&quot; y=&quot;40.0&quot;&gt;&lt;/omgdc:Bounds&gt;\n      &lt;/bpmndi:BPMNShape&gt;\n      &lt;bpmndi:BPMNShape bpmnElement=&quot;usertask1&quot; id=&quot;BPMNShape_usertask1&quot;&gt;\n        &lt;omgdc:Bounds height=&quot;55.0&quot; width=&quot;105.0&quot; x=&quot;345.0&quot; y=&quot;110.0&quot;&gt;&lt;/omgdc:Bounds&gt;\n      &lt;/bpmndi:BPMNShape&gt;\n      &lt;bpmndi:BPMNShape bpmnElement=&quot;endevent1&quot; id=&quot;BPMNShape_endevent1&quot;&gt;\n        &lt;omgdc:Bounds height=&quot;35.0&quot; width=&quot;35.0&quot; x=&quot;380.0&quot; y=&quot;210.0&quot;&gt;&lt;/omgdc:Bounds&gt;\n      &lt;/bpmndi:BPMNShape&gt;\n      &lt;bpmndi:BPMNEdge bpmnElement=&quot;flow1&quot; id=&quot;BPMNEdge_flow1&quot;&gt;&lt;/bpmndi:BPMNEdge&gt;\n      &lt;bpmndi:BPMNEdge bpmnElement=&quot;flow2&quot; id=&quot;BPMNEdge_flow2&quot;&gt;&lt;/bpmndi:BPMNEdge&gt;\n    &lt;/bpmndi:BPMNPlane&gt;\n  &lt;/bpmndi:BPMNDiagram&gt;\n&lt;/definitions&gt;</code></pre><p>重点代码  <strong>activiti:assignee=”#{userId}”</strong></p>\n<p>启动流程实例，需要设置流程变量</p>\n<pre><code class=\"java\">public void start() {\n    Map&lt;String, Object&gt; variables = new HashMap&lt;String, Object&gt;();\n    variables.put(&quot;userId&quot;, &quot;crystal&quot;);\n    ProcessInstance pi = runtimeService().startProcessInstanceByKey(&quot;task&quot;,variables);\n}</code></pre>\n<p><strong>（3）方式三</strong></p>\n<p>流程图中不指定任务办理人，添加监听类，需要实现TaskListener接口</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904183040.png\" alt></p>\n<p>定义的bpmn文件中定义任务办理人的名称</p>\n<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n&lt;definitions xmlns=&quot;http://www.omg.org/spec/BPMN/20100524/MODEL&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:xsd=&quot;http://www.w3.org/2001/XMLSchema&quot; xmlns:activiti=&quot;http://activiti.org/bpmn&quot; xmlns:bpmndi=&quot;http://www.omg.org/spec/BPMN/20100524/DI&quot; xmlns:omgdc=&quot;http://www.omg.org/spec/DD/20100524/DC&quot; xmlns:omgdi=&quot;http://www.omg.org/spec/DD/20100524/DI&quot; typeLanguage=&quot;http://www.w3.org/2001/XMLSchema&quot; expressionLanguage=&quot;http://www.w3.org/1999/XPath&quot; targetNamespace=&quot;http://www.activiti.org/test&quot;&gt;\n  &lt;process id=&quot;personalTask3&quot; name=&quot;PersonalTask3&quot; isExecutable=&quot;true&quot;&gt;\n    &lt;startEvent id=&quot;startevent1&quot; name=&quot;Start&quot;&gt;&lt;/startEvent&gt;\n    &lt;userTask id=&quot;usertask1&quot; name=&quot;审批&quot;&gt;\n      &lt;extensionElements&gt;\n        &lt;activiti:taskListener event=&quot;create&quot; class=&quot;com.activiti.test.TaskListenerImpl&quot;&gt;&lt;/activiti:taskListener&gt;\n      &lt;/extensionElements&gt;\n    &lt;/userTask&gt;\n    &lt;sequenceFlow id=&quot;flow1&quot; sourceRef=&quot;startevent1&quot; targetRef=&quot;usertask1&quot;&gt;&lt;/sequenceFlow&gt;\n    &lt;endEvent id=&quot;endevent1&quot; name=&quot;End&quot;&gt;&lt;/endEvent&gt;\n    &lt;sequenceFlow id=&quot;flow2&quot; sourceRef=&quot;usertask1&quot; targetRef=&quot;endevent1&quot;&gt;&lt;/sequenceFlow&gt;\n  &lt;/process&gt;\n  &lt;bpmndi:BPMNDiagram id=&quot;BPMNDiagram_personalTask3&quot;&gt;\n    &lt;bpmndi:BPMNPlane bpmnElement=&quot;personalTask3&quot; id=&quot;BPMNPlane_personalTask3&quot;&gt;\n      &lt;bpmndi:BPMNShape bpmnElement=&quot;startevent1&quot; id=&quot;BPMNShape_startevent1&quot;&gt;\n        &lt;omgdc:Bounds height=&quot;35.0&quot; width=&quot;35.0&quot; x=&quot;310.0&quot; y=&quot;20.0&quot;&gt;&lt;/omgdc:Bounds&gt;\n      &lt;/bpmndi:BPMNShape&gt;\n      &lt;bpmndi:BPMNShape bpmnElement=&quot;usertask1&quot; id=&quot;BPMNShape_usertask1&quot;&gt;\n        &lt;omgdc:Bounds height=&quot;55.0&quot; width=&quot;105.0&quot; x=&quot;275.0&quot; y=&quot;100.0&quot;&gt;&lt;/omgdc:Bounds&gt;\n      &lt;/bpmndi:BPMNShape&gt;\n      &lt;bpmndi:BPMNShape bpmnElement=&quot;endevent1&quot; id=&quot;BPMNShape_endevent1&quot;&gt;\n        &lt;omgdc:Bounds height=&quot;35.0&quot; width=&quot;35.0&quot; x=&quot;310.0&quot; y=&quot;200.0&quot;&gt;&lt;/omgdc:Bounds&gt;\n      &lt;/bpmndi:BPMNShape&gt;\n      &lt;bpmndi:BPMNEdge bpmnElement=&quot;flow1&quot; id=&quot;BPMNEdge_flow1&quot;&gt;&lt;/bpmndi:BPMNEdge&gt;\n      &lt;bpmndi:BPMNEdge bpmnElement=&quot;flow2&quot; id=&quot;BPMNEdge_flow2&quot;&gt;&lt;/bpmndi:BPMNEdge&gt;\n    &lt;/bpmndi:BPMNPlane&gt;\n  &lt;/bpmndi:BPMNDiagram&gt;\n&lt;/definitions&gt;</code></pre><p>重点代码</p>\n<p><code>&lt;activiti:taskListener event=&quot;create&quot; class=&quot;com.activiti.test.TaskListenerImpl&quot;&gt;&lt;/activiti:taskListener&gt;</code></p>\n<p>监听类 TaskListenerImpl.java</p>\n<pre><code class=\"java\">package com.activiti.test;\nimport org.activiti.engine.delegate.DelegateTask;\nimport org.activiti.engine.delegate.TaskListener;\npublic class TaskListenerImpl implements TaskListener {\n    /**\n     * 指定个人任务和组任务的办理人\n     */\n    @Override\n    public void notify(DelegateTask delegateTask) {\n        delegateTask.setAssignee(&quot;crystal&quot;);// 指派个人任务\n    }\n}</code></pre>\n<p>启动流程实例</p>\n<pre><code class=\"java\">public void start() {\n    ProcessInstance pi = runtimeService().startProcessInstanceByKey(&quot;task&quot;);\n}</code></pre>\n<p>总结：</p>\n<pre><code class=\"java\">个人任务及三种分配方式： \n  1.在taskProcess.bpmn中直接写 assignee=”crystal” \n  2.在taskProcess.bpmn中写 assignee=“#{userID}”，变量的值要是String的（使用流程变量指定办理人）。 \n  3.使用TaskListener接口，要使类实现该接口\n    在类中定义： delegateTask.setAssignee(assignee);// 指定个人任务的办理人 \n  4.使用任务ID和办理人重新指定办理人： taskService.setAssignee(taskId, userId);</code></pre>\n<h3 id=\"4-3-组任务的三种指派方式\"><a href=\"#4-3-组任务的三种指派方式\" class=\"headerlink\" title=\"4.3 组任务的三种指派方式\"></a>4.3 组任务的三种指派方式</h3><p><strong>方式一：直接指定办理人</strong></p>\n<p>（1）.在任务节点设置办理人</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182327.png\" alt></p>\n<p>（2）bpmn中的代码片段</p>\n<pre><code> &lt;userTask activiti:candidateUsers=&quot;小a,小b,小c&quot; activiti:exclusive=&quot;true&quot; id=&quot;usertask1&quot; name=&quot;提交申请&quot;/&gt;</code></pre><p>（3）部署流程和启动流程</p>\n<pre><code class=\"java\">public void test(){\n    repositoryService.createDeployment().addClasspathResource(&quot;test1.bpmn&quot;).deploy();//部署流程\n    ProcessInstance pi = runtimeService.startProcessInstanceByKey(&quot;helloword&quot;);//启动流程\n}</code></pre>\n<p>（4）查询我的个人任务，没有执行结果</p>\n<pre><code class=\"java\"> public void queryTask(String assignee) {\n     List&lt;Task&gt; list = taskService.createTaskQuery().orderByTaskCreateTime()\n             .desc().taskAssignee(assignee).list();\n     if (list != null &amp;&amp; list.size() &gt; 0) {\n         for (Task task : list) {\n             System.out.println(&quot;任务ID：&quot; + task.getId());\n             System.out.println(&quot;任务的办理人：&quot; + task.getAssignee());\n             System.out.println(&quot;任务名称：&quot; + task.getName());\n             System.out.println(&quot;任务的创建时间：&quot; + task.getCreateTime());\n             System.out.println(&quot;流程实例ID：&quot; + task.getProcessInstanceId());\n             System.out.println(&quot;#######################################&quot;);\n         }\n     }\n}</code></pre>\n<p>（5）查询组任务，可以查到查询结果</p>\n<pre><code> public void findGroupTaskList(String candidateUser) {\n        List&lt;Task&gt; list = taskService.createTaskQuery().taskCandidateUser(candidateUser).list();\n        if (list != null &amp;&amp; list.size() &gt; 0) {\n            for (Task task : list) {\n                System.out.println(&quot;任务ID：&quot; + task.getId());\n                System.out.println(&quot;任务的办理人：&quot; + task.getAssignee());\n                System.out.println(&quot;任务名称：&quot; + task.getName());\n                System.out.println(&quot;任务的创建时间：&quot; + task.getCreateTime());\n                System.out.println(&quot;流程实例ID：&quot; + task.getProcessInstanceId());\n                System.out.println(&quot;#######################################&quot;);\n            }\n        }\n    }</code></pre><p>查询结果如下</p>\n<blockquote>\n<p>任务ID：15010<br>任务的办理人：null<br>任务名称：提交申请<br>任务的创建时间：Thu Apr 04 10:50:00 CST 2019<br>流程实例ID：15005</p>\n</blockquote>\n<p>（6）查询正在执行的组任务列表</p>\n<pre><code class=\"java\">public void findGroupCandidate(String taskId) {\n    List&lt;IdentityLink&gt; list = taskService.getIdentityLinksForTask(taskId);\n        if (list != null &amp;&amp; list.size() &gt; 0) {\n        for (IdentityLink identityLink : list) {\n            System.out.println(&quot;任务ID：&quot; + identityLink.getTaskId());\n            System.out.println(&quot;流程实例ID：&quot;+ identityLink.getProcessInstanceId());\n            System.out.println(&quot;用户ID：&quot; + identityLink.getUserId());\n            System.out.println(&quot;工作流角色ID：&quot; + identityLink.getGroupId());\n            System.out.println(&quot;#########################################&quot;);\n        }\n    }\n}</code></pre>\n<p>执行结果</p>\n<blockquote>\n<p>任务ID：15010<br>流程实例ID：null<br>用户ID：小a<br>工作流角色ID：null</p>\n<p>任务ID：15010<br>流程实例ID：null<br>用户ID：小b<br>工作流角色ID：null</p>\n<p>任务ID：15010<br>流程实例ID：null<br>用户ID：小c<br>工作流角色ID：null</p>\n</blockquote>\n<p>（7）查询历史的组任务列表</p>\n<pre><code class=\"java\">public void findHistoryGroupCandidate(String processInstanceId) {\n    String processInstanceId = &quot;3705&quot;;\n    List&lt;HistoricIdentityLink&gt; list = historyService\n            .getHistoricIdentityLinksForProcessInstance(processInstanceId);\n    if (list != null &amp;&amp; list.size() &gt; 0) {\n        for (HistoricIdentityLink identityLink : list) {\n            System.out.println(&quot;任务ID：&quot; + identityLink.getTaskId());\n            System.out.println(&quot;流程实例ID：&quot;+ identityLink.getProcessInstanceId());\n            System.out.println(&quot;用户ID：&quot; + identityLink.getUserId());\n            System.out.println(&quot;工作流角色ID：&quot; + identityLink.getGroupId());\n            System.out.println(&quot;#########################################&quot;);\n        }\n    }\n}</code></pre>\n<p>说明：     </p>\n<ul>\n<li>小A，小B，小C是组任务的办理人     </li>\n<li>但是这样分配组任务的办理人不够灵活，因为项目开发中任务的办理人不要放置XML文件中。     </li>\n<li>act_ru_identitylink表存放组任务的办理人，表示正在执行的任务     </li>\n<li>act_hi_identitylink表存放所有任务的办理人，包括个人任务和组任务<strong>，</strong>表示历史任务</li>\n</ul>\n<p><strong>方式二：使用流程变量</strong></p>\n<p> （1）在任务节点设置变量</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904183359.png\" alt></p>\n<p>（2）bpmn中的代码片段</p>\n<pre><code>&lt;userTask activiti:candidateUsers=&quot;#{userIDs}&quot; activiti:exclusive=&quot;true&quot; id=&quot;usertask1&quot; name=&quot;提交申请&quot;/&gt;</code></pre><p>（3）部署流程和启动流程</p>\n<p>启动流程实例的同时，设置流程变量，使用流程变量的方式设置下一个任务的办理人</p>\n<p> 流程变量的名称，是task.bpmn中定义activiti:candidateUsers=”#{userIDs}”的userIDs  流程变量的值，就是任务的办理人（组任务）</p>\n<pre><code class=\"java\">public void test(){\n    repositoryService.createDeployment().addClasspathResource(&quot;test1.bpmn&quot;).deploy();//部署流程\n    Map&lt;String, Object&gt; variables = new HashMap&lt;String, Object&gt;();\n    variables.put(&quot;userIDs&quot;, &quot;小a,小b,小c&quot;);\n    ProcessInstance pi = runtimeService.startProcessInstanceByKey(&quot;helloword&quot;,variables);//使用流程定义的key的最新版本启动流程\n}</code></pre>\n<p><strong>方式三：使用监听器</strong></p>\n<p>（1）设置监听器变量</p>\n<p><img src=\"https://img-blog.csdn.net/20151227154130920\" alt=\"img\"></p>\n<p>（2）编写监听器类</p>\n<pre><code>public class TaskListenerImpl implements TaskListener {\n    /**\n     * 可以设置任务的办理人（个人组人和组任务）\n     */\n    @Override\n    public void notify(DelegateTask delegateTask) {\n        //指定组任务\n        delegateTask.addCandidateUser(&quot;孙悟空&quot;);\n        delegateTask.addCandidateUser(&quot;猪八戒&quot;);\n    }\n}</code></pre><p>（3）测试代码</p>\n<pre><code class=\"java\">/**将组任务指定个人任务(拾取任务)*/\npublic void claim(){\n    String taskId = &quot;6308&quot;;\n    //个人任务的办理人\n    String userId = &quot;唐僧&quot;;\n    taskService.claim(taskId, userId);\n}\n\n/**将个人任务再回退到组任务（前提：之前这个任务是组任务）*/\npublic void setAssignee(){\n    String taskId = &quot;6308&quot;;\n    taskService.setAssignee(taskId, null);\n}\n\n/**向组任务中添加成员*/\npublic void addGroupUser(){\n    String taskId = &quot;6308&quot;;\n    //新增组任务的成员\n    String userId = &quot;如来&quot;;\n    taskService.addCandidateUser(taskId, userId);\n}\n\n/**向组任务中删除成员*/\npublic void deleteGroupUser(){\n    String taskId = &quot;6308&quot;;\n    //新增组任务的成员\n    String userId = &quot;猪八戒&quot;;\n    taskService.deleteCandidateUser(taskId, userId);\n}</code></pre>\n<p>总结：      以上就是分配组任务的三种方式，和分配个人任务相对应，同样有三种方式，与个人任务的操作相比，组任务操作增加了组任务分配个人任务（认领任务），个人任务分配给组任务，以及向组任务添加人员和向组任务删除人员的操作。</p>\n<h3 id=\"4-4-工作流提供的用户角色\"><a href=\"#4-4-工作流提供的用户角色\" class=\"headerlink\" title=\"4.4 工作流提供的用户角色\"></a>4.4 工作流提供的用户角色</h3><p>（1）设置用户角色</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182357.png\" alt></p>\n<p>这个【部门经理】相当于一个用户角色，一个角色可以对应多个人，比如有三个人：张三、李四是部门经理，王五是总经理，那我们可以把这三个人录入的我们自己的用户表中，那么工作流也给我们提供了至少三张表：用户表，角色表，用户角色关联表那我们就可以把部门经理这个角色与张三、李四关联起来</p>\n<p>（2）具体做法：1、添加用户角色组  2、创建角色3、创建用户4、创建角色用户关联关系测试代码如下：</p>\n<pre><code class=\"java\">public void addUser(){    \n        //创建角色(两个角色)\n        identityService.saveGroup(new GroupEntity(&quot;部门经理&quot;));\n        identityService.saveGroup(new GroupEntity(&quot;总经理&quot;));\n\n        //创建用户（三个用户）\n        identityService.saveUser(new UserEntity(&quot;张三&quot;));\n        identityService.saveUser(new UserEntity(&quot;李四&quot;));\n        identityService.saveUser(new UserEntity(&quot;王五&quot;));\n\n        //创建用户角色关联关系\n        identityService.createMembership(&quot;张三&quot;, &quot;部门经理&quot;);\n        identityService.createMembership(&quot;李四&quot;, &quot;部门经理&quot;);\n        identityService.createMembership(&quot;王五&quot;, &quot;总经理&quot;);\n}</code></pre>\n<p>（3）部署流程定义</p>\n<pre><code>public void deployementAndStart(){\n    Deployment deployment = repositoryService.createDeployment().name(&quot;组任务&quot;)\n                    .addClasspathResource(&quot;diagrams/group.bpmn&quot;)\n                    .addClasspathResource(&quot;diagrams/group.png&quot;).deploy();\n    ProcessInstance pi = runtimeService.startProcessInstanceByKey(&quot;group&quot;);//启动流程  \n}                </code></pre><p>（4）查询张三或者李四的任务</p>\n<pre><code>public void findGroupTask(){\n        String candidateUser = &quot;张三&quot;;\n        List&lt;Task&gt; list =taskService.createTaskQuery().taskCandidateUser(candidateUser).list();\n        if(list!=null &amp;&amp; list.size()&gt;0){  \n            for(Task task:list){  \n                System.out.println(&quot;任务ID：&quot;+task.getId());  \n                System.out.println(&quot;任务的办理人：&quot;+task.getAssignee());  \n                System.out.println(&quot;任务名称：&quot;+task.getName());  \n                System.out.println(&quot;任务的创建时间：&quot;+task.getCreateTime());  \n                System.out.println(&quot;流程实例ID：&quot;+task.getProcessInstanceId());  \n                System.out.println(&quot;#######################################&quot;);  \n            }  \n         }\n}</code></pre><p>执行结果</p>\n<blockquote>\n<p> 任务ID：167504 </p>\n<p> 任务的办理人：null </p>\n<p> 任务名称：审核 </p>\n<p> 任务的创建时间：Thu Jul 07 10:21:27 GMT+08:00 2016 </p>\n<p> 流程实例ID：167501 </p>\n</blockquote>\n<p>（5）候选者不一定真正的参与任务的办理，所以我们需要拾取任务，将组任务分配给个人任务,即指定任务办理人字段</p>\n<pre><code class=\"java\">public void cliam(){\n        //将组任务分配给个人任务\n        String taskId =&quot;167504&quot;;\n        //分配的个人任务（可以是组任务中的成员，也可以是非组任务的成员）\n        String userId =&quot;张三&quot;;\n        taskService.claim(taskId, userId);\n        //当执行完查询正执行的任务表（act_ru_task）可发现ASSIGNEE_字段（指定任务办理人）值为&#39;张三&#39;\n        //此时任务就指定给了张三，再用李四去查个人组任务就查询不出来任何任务【组任务最终也是需要指定一个人办理的，所以需要拾取任务】\n}\n</code></pre>\n<p>（6）张三完成任务</p>\n<pre><code class=\"java\">public void completeTask(){\n    String taskId =&quot;167504&quot;;\n    taskService.complete(taskId);\n}\n</code></pre>\n<p>当我们部署完流程定义，启动流程实例之后，我们可以查看您一下几张数据表：<strong>表act_ru_task</strong></p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904183255.png\" alt></p>\n<p> 可以看见任务办理人的字段值为null,所以可能有两种情况可能没有办理人或者可能这个任务是组任务</p>\n<p><strong>表act_ru_identitylink</strong>   正在执行的任务办理人表</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904183326.png\" alt></p>\n<p>在这个表可以看见Task_ID 的值为167504就是正在执行的任务ID，流程实例字段为空，所以这个任务是组任务，处理这个组任务的角色ID为部门经理而张三和李四都是这个角色的用户，所以张三李四都可以查到这个任务，也可以进行任务的拾取，分配等操作。</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182422.png\" alt></p>\n<p>需要说明的是在我们自己项目开发的时候，我们一般都是不用工作流自带的用户表、角色表，用户角色关联表都是自己来建，因为自带的表提供的字段不全。</p>\n<h3 id=\"4-5-任务签收与反签收\"><a href=\"#4-5-任务签收与反签收\" class=\"headerlink\" title=\"4.5 任务签收与反签收\"></a>4.5 任务签收与反签收</h3><pre><code class=\"java\">//任务签收\npublic void claim(String taskId) {\n   String userId = &quot;1111&quot;;\n   taskService.claim(taskId, userId);\n}\n\n//任务反签收\npublic String unclaim(String taskId) {\n    taskService.unclaim(taskId);\n}</code></pre>\n<h3 id=\"4-6-驳回申请\"><a href=\"#4-6-驳回申请\" class=\"headerlink\" title=\"4.6 驳回申请\"></a>4.6 驳回申请</h3><h3 id=\"4-7-流程变量的设置和获取\"><a href=\"#4-7-流程变量的设置和获取\" class=\"headerlink\" title=\"4.7  流程变量的设置和获取\"></a>4.7  流程变量的设置和获取</h3><p><strong>设置流程变量</strong></p>\n<p>流程变量的设置方式有两种，一是通过基本类型设置，第二种是通过JavaBean类型设置。</p>\n<p><strong>（1）基本类型</strong></p>\n<pre><code>    public void setProcessVariables(){\n        String processInstanceId = &quot;1301&quot;;//流程实例ID\n        String assignee = &quot;张三&quot;;//任务办理人\n        //查询当前办理人的任务ID\n        Task task = taskService.createTaskQuery()\n                .processInstanceId(processInstanceId)//使用流程实例ID\n                .taskAssignee(assignee)//任务办理人\n                .singleResult();\n        //设置流程变量【基本类型】\n        taskService.setVariable(task.getId(), &quot;请假人&quot;, assignee);\n        taskService.setVariableLocal(task.getId(), &quot;请假天数&quot;,3);\n        taskService.setVariable(task.getId(), &quot;请假日期&quot;, new Date());\n    }</code></pre><p>对应数据库表：act_ru_variable</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182451.png\" alt></p>\n<p><strong>（2）JavaBean类型</strong></p>\n<pre><code>public class Person{\n    private Integer id;\n    private String name;\n    private String education;\n}</code></pre><p>然后，通过JavaBean设置流程变量。这里要注意的是，Javabean类型设置获取流程变量，除了需要这个javabean实现了Serializable接口外，还要求流程变量对象的属性不能发生编号，否则抛出异常。 </p>\n<pre><code class=\"java\">public void setProcessVariables(){\n    String processInstanceId = &quot;1301&quot;;//流程实例ID\n    String assignee = &quot;张三&quot;;//任务办理人\n    //查询当前办理人的任务ID\n    Task task = taskService.createTaskQuery()\n        .processInstanceId(processInstanceId).taskAssignee(assignee).singleResult();\n    //设置流程变量【javabean类型】\n    Person p = new Person();\n    p.setId(1);\n    p.setName(&quot;周江霄&quot;);\n    taskService.setVariable(task.getId(), &quot;人员信息&quot;, p);\n}</code></pre>\n<p>数据库对应表：act_ru_variable，细心的你可以看到，通过JavaBean设置的流程变量，在act_ru_variable中存储的类型为serializable，变量真正存储的地方在act_ge_bytearray中</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182524.png\" alt> </p>\n<p> <strong>获取流程变量</strong></p>\n<p><strong>（1）基本类型</strong></p>\n<pre><code class=\"java\">public void getProcessVariables(){\n        String processInstanceId = &quot;1301&quot;;//流程实例ID\n        String assignee = &quot;张三&quot;;//任务办理人\n        TaskService taskService = processEngine.getTaskService();\n        //获取当前办理人的任务ID\n        Task task = taskService.createTaskQuery()\n                .processInstanceId(processInstanceId)\n                .taskAssignee(assignee)\n                .singleResult();\n        String person = (String) taskService.getVariable(task.getId(), &quot;请假人&quot;);\n        Integer day = (Integer) taskService.getVariableLocal(task.getId(), &quot;请假天数&quot;);\n        Date date = (Date) taskService.getVariable(task.getId(), &quot;请假日期&quot;);\n        System.out.println(person+&quot;  &quot;+day+&quot;   &quot;+date);\n}</code></pre>\n<p><strong>（2）JavaBean类型</strong></p>\n<pre><code class=\"java\">/**获取流程变量*/\n    @Test\n    public void getProcessVariables(){\n        String processInstanceId = &quot;1301&quot;;//流程实例ID\n        String assignee = &quot;张三&quot;;//任务办理人\n        //获取当前办理人的任务ID\n        Task task = taskService.createTaskQuery()\n                .processInstanceId(processInstanceId)\n                .taskAssignee(assignee)\n                .singleResult();\n        //获取流程变量【javaBean类型】\n        Person p = (Person) taskService.getVariable(task.getId(), &quot;人员信息&quot;);\n        System.out.println(p.getId()+&quot;  &quot;+p.getName());\n        System.out.println(&quot;获取成功~~&quot;);\n    }</code></pre>\n<p>  <strong>查询历史流程变量</strong> </p>\n<pre><code>/**查询历史的流程变量*/\npublic void getHistoryProcessVariables(){\n    List&lt;HistoricVariableInstance&gt; list = processEngine.getHistoryService()\n                .createHistoricVariableInstanceQuery()//创建一个历史的流程变量查询\n                .variableName(&quot;请假天数&quot;).list();\n    if(list != null &amp;&amp; list.size()&gt;0){\n        for(HistoricVariableInstance hiv : list){\n                System.out.println(\n                hiv.getTaskId()+&quot;  &quot;+hiv.getVariableName()+&quot;\n                &quot;+hiv.getValue()+&quot;        &quot;+hiv.getVariableTypeName());\n        }\n    }                \n}</code></pre><p>对应数据库表：act_ru_execution</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182542.png\" alt></p>\n<h3 id=\"4-8-查询所有的正在执行的任务\"><a href=\"#4-8-查询所有的正在执行的任务\" class=\"headerlink\" title=\"4.8 查询所有的正在执行的任务\"></a>4.8 查询所有的正在执行的任务</h3><pre><code class=\"java\">public void testQueryTask(){\n        ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();\n        List&lt;Task&gt; tasks = processEngine.getTaskService()\n                .createTaskQuery()\n                .list();\n        for (Task task : tasks) {\n            System.out.println(task.getName());\n        }\n}</code></pre>\n<h3 id=\"4-9-完成任务\"><a href=\"#4-9-完成任务\" class=\"headerlink\" title=\"4.9 完成任务\"></a>4.9 完成任务</h3><pre><code>public void complete(){\n        Task task=taskService.createTaskQuery()\n            .processInstanceId(pi.getId()).taskDefinitionKey(&quot;task&quot;).singleResult();\n        taskService.setVariable(task.getId(), &quot;var1&quot;, &quot;var1&quot;);\n         taskService.complete(task.getId());\n }</code></pre><p>以上代码是查询流程本次执行实例下名为task1的任务</p>\n<p>给任务设置全局变量，如果调用的是taskService.setVariableLocal方法，则任务执行完毕后，相关变量数据就会删除，然后再完成任务。</p>\n<p>首先向act_ru_variable表中插入变量信息，包含本次流程执行实例的两个id外键，但不包括任务的id，因为setVariable方法设置的是全局变量，也就是整个流程都会有效的变量</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182930.png\" alt>     </p>\n<p>此时整个流程执行完毕，act_ru_task，act_ru_execution和act_ru_variable表全被清空</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182951.png\" alt></p>\n<h2 id=\"五、历史任务\"><a href=\"#五、历史任务\" class=\"headerlink\" title=\"五、历史任务\"></a>五、历史任务</h2><h3 id=\"5-1-查已完成任务和当前在执行的任务\"><a href=\"#5-1-查已完成任务和当前在执行的任务\" class=\"headerlink\" title=\"5.1 查已完成任务和当前在执行的任务\"></a>5.1 查已完成任务和当前在执行的任务</h3><pre><code class=\"java\">public void findHistoryTask(){\n        ProcessEngine defaultProcessEngine = ProcessEngines.getDefaultProcessEngine();\n        //如果只想获取到已经执行完成的，那么就要加入completed这个过滤条件\n        List&lt;HistoricTaskInstance&gt; historicTaskInstances1 = defaultProcessEngine.getHistoryService()\n                .createHistoricTaskInstanceQuery()\n                .taskDeleteReason(&quot;completed&quot;)\n                .list();\n        //如果只想获取到已经执行完成的，那么就要加入completed这个过滤条件\n        List&lt;HistoricTaskInstance&gt; historicTaskInstances2 = defaultProcessEngine.getHistoryService()\n                .createHistoricTaskInstanceQuery()\n                .list();\n        System.out.println(&quot;执行完成的任务：&quot; + historicTaskInstances1.size());\n        System.out.println(&quot;所有的总任务数（执行完和当前未执行完）：&quot; +historicTaskInstances2.size());\n    }</code></pre>\n<p>Activiti 个人任务（三种指派方式） <a href=\"https://blog.csdn.net/caoyue_new/article/details/52180539\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/caoyue_new/article/details/52180539</a></p>\n<p>六：关于流程实例的相关API</p>\n<p><strong>涉及到的表：</strong>   </p>\n<p>*<em>act_hi_actinst  *</em></p>\n<p>1、说明 *         act:activiti  *         hi:history  *         actinst:activity instance  *            流程图上出现的每一个元素都称为activity  *            流程图上正在执行的元素或者已经执行完成的元素称为activity instance  *      2、字段 *         proc_def_id:pdid  *         proc_inst_id:流程实例ID  *         execution_id_:执行ID  *         act_id_:activity  *         act_name  *         act_type  </p>\n<p>*<em>act_hi_procinst *</em></p>\n<p>**      1、说明 *         procinst:process instance  历史的流程实例 *            正在执行的流程实例也在这张表中 *         如果end_time_为null，说明正在执行，如果有值，说明该流程实例已经结束了 *    _</p>\n<p><strong>act_hi_taskinst</strong></p>\n<pre><code> 1、说明 *          taskinst:task instance  历史任务 *             正在执行的任务也在这张表中 *             如果end_time_为null,说明该任务正在执行 *             如果end_time不为null,说明该任务已经执行完毕了 *    **act_ru_execution**</code></pre><p>_      1、说明 *         ru:runtime  *         代表正在执行的流程实例表 *         如果当期正在执行的流程实例结束以后，该行在这张表中就被删除掉了，所以该表也是一个临时表 *      2、字段 *         proc_inst_id_:piid  流程实例ID，如果不存在并发的情况下，piid和executionID是一样的 *         act_id:当前正在执行的流程实例(如果不考虑并发的情况)的正在执行的activity有一个，所以act_id就是当前正在执行的流程实例的正在执行的 *           节点 *    <strong>act_ru_task</strong>_</p>\n<p>1、代表正在执行的任务表    该表是一个临时表，如果当前任务被完成以后，任务在这张表中就被删除掉了 </p>\n<p>2、字段 </p>\n<p> id_:  主键    任务ID      execution_id_:执行ID    *              根据该ID查询出来的任务肯定是一个 *          proc_inst_id:piid  *              根据该id查询出来的任务 *                 如果没有并发，则是一个 *                 如果有并发，则是多个 *          name_:任务的名称 *          assignee_:任务的执行人**</p>\n<h2 id=\"六、工作流采购流程如何与业务关联\"><a href=\"#六、工作流采购流程如何与业务关联\" class=\"headerlink\" title=\"六、工作流采购流程如何与业务关联\"></a>六、工作流采购流程如何与业务关联</h2><p>实例.采购流程的监控</p>\n<ul>\n<li><p>查询当前获任务和业务关联</p>\n</li>\n<li><p>查询已经结束的流程</p>\n</li>\n<li><p>查询当前采购流程节点的位置图展示（在流程定义的节点上标出当前节点的位置，使用红色的框标出）</p>\n</li>\n<li><p>查询某个流程下的历史任务（从流程开始到运行结束）</p>\n</li>\n<li><p>查询某个用户所办理的历史任</p>\n</li>\n</ul>\n<p>2.流程变量</p>\n<ul>\n<li>全局变量</li>\n<li>局部变量</li>\n</ul>\n<p>3.连线分支</p>\n<p>设置连线的condition条件实现分支</p>\n<h3 id=\"6-1-流程定义图的画法\"><a href=\"#6-1-流程定义图的画法\" class=\"headerlink\" title=\"6.1 流程定义图的画法\"></a>6.1 流程定义图的画法</h3><p>流程图注意的东西</p>\n<p>（1）流程定义key  </p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182636.png\" alt></p>\n<p>（2）流程变量 ：</p>\n<p>分支条件：<strong>$</strong>(price&gt;=1000) 和<strong>$</strong>(price&lt;1000)</p>\n<p><img src=\"C:%5CUsers%5CAdministrator%5CAppData%5CLocal%5CTemp%5C1567592826450.png\" alt=\"1567592826450\"></p>\n<p>（3）人员设置流程变量</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182721.png\" alt></p>\n<p>其他和部门经理的设置方法一样</p>\n<p>部门经理审批的代办人流程变量  <strong>$</strong>{u} </p>\n<p>总经理审批的代办人流程变量  <strong>$</strong>{m} </p>\n<p>财务审批的代办人流程变量  <strong>$</strong>{c} </p>\n<p>（4）order.bpmn文件</p>\n<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;yes&quot;?&gt;\n&lt;definitions xmlns=&quot;http://www.omg.org/spec/BPMN/20100524/MODEL&quot; xmlns:activiti=&quot;http://activiti.org/bpmn&quot; xmlns:bpmndi=&quot;http://www.omg.org/spec/BPMN/20100524/DI&quot; xmlns:dc=&quot;http://www.omg.org/spec/DD/20100524/DC&quot; xmlns:di=&quot;http://www.omg.org/spec/DD/20100524/DI&quot; xmlns:tns=&quot;Examples&quot; xmlns:xsd=&quot;http://www.w3.org/2001/XMLSchema&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; expressionLanguage=&quot;http://www.w3.org/1999/XPath&quot; id=&quot;m1539757531057&quot; name=&quot;&quot; targetNamespace=&quot;Examples&quot; typeLanguage=&quot;http://www.w3.org/2001/XMLSchema&quot;&gt;\n  &lt;process id=&quot;orderKey&quot; isClosed=&quot;false&quot; isExecutable=&quot;true&quot; processType=&quot;None&quot;&gt;\n    &lt;startEvent id=&quot;_2&quot; name=&quot;StartEvent&quot;/&gt;\n    &lt;userTask activiti:assignee=&quot;#{u}&quot; activiti:exclusive=&quot;true&quot; id=&quot;_3&quot; name=&quot;部门经理审批&quot;/&gt;\n    &lt;sequenceFlow id=&quot;_7&quot; sourceRef=&quot;_2&quot; targetRef=&quot;_3&quot;/&gt;\n    &lt;userTask activiti:assignee=&quot;${c}&quot; activiti:exclusive=&quot;true&quot; id=&quot;_4&quot; name=&quot;财务审批&quot;/&gt;\n    &lt;userTask activiti:assignee=&quot;${m}&quot; activiti:exclusive=&quot;true&quot; id=&quot;_5&quot; name=&quot;总经理审批&quot;/&gt;\n    &lt;endEvent id=&quot;_6&quot; name=&quot;EndEvent&quot;/&gt;\n    &lt;sequenceFlow id=&quot;_8&quot; sourceRef=&quot;_4&quot; targetRef=&quot;_6&quot;/&gt;\n    &lt;sequenceFlow id=&quot;_9&quot; sourceRef=&quot;_3&quot; targetRef=&quot;_4&quot;&gt;\n      &lt;conditionExpression xsi:type=&quot;tFormalExpression&quot;&gt;&lt;![CDATA[${price &lt; 1000} ]]&gt;&lt;/conditionExpression&gt;\n    &lt;/sequenceFlow&gt;\n    &lt;sequenceFlow id=&quot;_10&quot; sourceRef=&quot;_3&quot; targetRef=&quot;_5&quot;&gt;\n      &lt;conditionExpression xsi:type=&quot;tFormalExpression&quot;&gt;&lt;![CDATA[${price &gt;= 1000} ]]&gt;&lt;/conditionExpression&gt;\n    &lt;/sequenceFlow&gt;\n    &lt;sequenceFlow id=&quot;_11&quot; sourceRef=&quot;_5&quot; targetRef=&quot;_4&quot;/&gt;\n  &lt;/process&gt;\n  &lt;bpmndi:BPMNDiagram documentation=&quot;background=#32424A;count=1;horizontalcount=1;orientation=0;width=842.4;height=1195.2;imageableWidth=832.4;imageableHeight=1185.2;imageableX=5.0;imageableY=5.0&quot; id=&quot;Diagram-_1&quot; name=&quot;New Diagram&quot;&gt;\n    &lt;bpmndi:BPMNPlane bpmnElement=&quot;orderKey&quot;&gt;\n      &lt;bpmndi:BPMNShape bpmnElement=&quot;_2&quot; id=&quot;Shape-_2&quot;&gt;\n        &lt;dc:Bounds height=&quot;32.0&quot; width=&quot;32.0&quot; x=&quot;100.0&quot; y=&quot;10.0&quot;/&gt;\n        &lt;bpmndi:BPMNLabel&gt;\n          &lt;dc:Bounds height=&quot;32.0&quot; width=&quot;32.0&quot; x=&quot;0.0&quot; y=&quot;0.0&quot;/&gt;\n        &lt;/bpmndi:BPMNLabel&gt;\n      &lt;/bpmndi:BPMNShape&gt;\n      &lt;bpmndi:BPMNShape bpmnElement=&quot;_3&quot; id=&quot;Shape-_3&quot;&gt;\n        &lt;dc:Bounds height=&quot;55.0&quot; width=&quot;85.0&quot; x=&quot;75.0&quot; y=&quot;95.0&quot;/&gt;\n        &lt;bpmndi:BPMNLabel&gt;\n          &lt;dc:Bounds height=&quot;55.0&quot; width=&quot;85.0&quot; x=&quot;0.0&quot; y=&quot;0.0&quot;/&gt;\n        &lt;/bpmndi:BPMNLabel&gt;\n      &lt;/bpmndi:BPMNShape&gt;\n      &lt;bpmndi:BPMNShape bpmnElement=&quot;_4&quot; id=&quot;Shape-_4&quot;&gt;\n        &lt;dc:Bounds height=&quot;55.0&quot; width=&quot;85.0&quot; x=&quot;70.0&quot; y=&quot;220.0&quot;/&gt;\n        &lt;bpmndi:BPMNLabel&gt;\n          &lt;dc:Bounds height=&quot;55.0&quot; width=&quot;85.0&quot; x=&quot;0.0&quot; y=&quot;0.0&quot;/&gt;\n        &lt;/bpmndi:BPMNLabel&gt;\n      &lt;/bpmndi:BPMNShape&gt;\n      &lt;bpmndi:BPMNShape bpmnElement=&quot;_5&quot; id=&quot;Shape-_5&quot;&gt;\n        &lt;dc:Bounds height=&quot;55.0&quot; width=&quot;85.0&quot; x=&quot;295.0&quot; y=&quot;95.0&quot;/&gt;\n        &lt;bpmndi:BPMNLabel&gt;\n          &lt;dc:Bounds height=&quot;55.0&quot; width=&quot;85.0&quot; x=&quot;0.0&quot; y=&quot;0.0&quot;/&gt;\n        &lt;/bpmndi:BPMNLabel&gt;\n      &lt;/bpmndi:BPMNShape&gt;\n      &lt;bpmndi:BPMNShape bpmnElement=&quot;_6&quot; id=&quot;Shape-_6&quot;&gt;\n        &lt;dc:Bounds height=&quot;32.0&quot; width=&quot;32.0&quot; x=&quot;95.0&quot; y=&quot;380.0&quot;/&gt;\n        &lt;bpmndi:BPMNLabel&gt;\n          &lt;dc:Bounds height=&quot;32.0&quot; width=&quot;32.0&quot; x=&quot;0.0&quot; y=&quot;0.0&quot;/&gt;\n        &lt;/bpmndi:BPMNLabel&gt;\n      &lt;/bpmndi:BPMNShape&gt;\n      &lt;bpmndi:BPMNEdge bpmnElement=&quot;_7&quot; id=&quot;BPMNEdge__7&quot; sourceElement=&quot;_2&quot; targetElement=&quot;_3&quot;&gt;\n        &lt;di:waypoint x=&quot;116.0&quot; y=&quot;42.0&quot;/&gt;\n        &lt;di:waypoint x=&quot;116.0&quot; y=&quot;95.0&quot;/&gt;\n        &lt;bpmndi:BPMNLabel&gt;\n          &lt;dc:Bounds height=&quot;0.0&quot; width=&quot;0.0&quot; x=&quot;0.0&quot; y=&quot;0.0&quot;/&gt;\n        &lt;/bpmndi:BPMNLabel&gt;\n      &lt;/bpmndi:BPMNEdge&gt;\n      &lt;bpmndi:BPMNEdge bpmnElement=&quot;_8&quot; id=&quot;BPMNEdge__8&quot; sourceElement=&quot;_4&quot; targetElement=&quot;_6&quot;&gt;\n        &lt;di:waypoint x=&quot;111.0&quot; y=&quot;275.0&quot;/&gt;\n        &lt;di:waypoint x=&quot;111.0&quot; y=&quot;380.0&quot;/&gt;\n        &lt;bpmndi:BPMNLabel&gt;\n          &lt;dc:Bounds height=&quot;0.0&quot; width=&quot;0.0&quot; x=&quot;0.0&quot; y=&quot;0.0&quot;/&gt;\n        &lt;/bpmndi:BPMNLabel&gt;\n      &lt;/bpmndi:BPMNEdge&gt;\n      &lt;bpmndi:BPMNEdge bpmnElement=&quot;_9&quot; id=&quot;BPMNEdge__9&quot; sourceElement=&quot;_3&quot; targetElement=&quot;_4&quot;&gt;\n        &lt;di:waypoint x=&quot;115.0&quot; y=&quot;150.0&quot;/&gt;\n        &lt;di:waypoint x=&quot;115.0&quot; y=&quot;220.0&quot;/&gt;\n        &lt;bpmndi:BPMNLabel&gt;\n          &lt;dc:Bounds height=&quot;0.0&quot; width=&quot;0.0&quot; x=&quot;0.0&quot; y=&quot;0.0&quot;/&gt;\n        &lt;/bpmndi:BPMNLabel&gt;\n      &lt;/bpmndi:BPMNEdge&gt;\n      &lt;bpmndi:BPMNEdge bpmnElement=&quot;_11&quot; id=&quot;BPMNEdge__11&quot; sourceElement=&quot;_5&quot; targetElement=&quot;_4&quot;&gt;\n        &lt;di:waypoint x=&quot;340.0&quot; y=&quot;150.0&quot;/&gt;\n        &lt;di:waypoint x=&quot;340.0&quot; y=&quot;190.0&quot;/&gt;\n        &lt;di:waypoint x=&quot;155.0&quot; y=&quot;247.5&quot;/&gt;\n        &lt;bpmndi:BPMNLabel&gt;\n          &lt;dc:Bounds height=&quot;0.0&quot; width=&quot;0.0&quot; x=&quot;0.0&quot; y=&quot;0.0&quot;/&gt;\n        &lt;/bpmndi:BPMNLabel&gt;\n      &lt;/bpmndi:BPMNEdge&gt;\n      &lt;bpmndi:BPMNEdge bpmnElement=&quot;_10&quot; id=&quot;BPMNEdge__10&quot; sourceElement=&quot;_3&quot; targetElement=&quot;_5&quot;&gt;\n        &lt;di:waypoint x=&quot;160.0&quot; y=&quot;122.5&quot;/&gt;\n        &lt;di:waypoint x=&quot;295.0&quot; y=&quot;122.5&quot;/&gt;\n        &lt;bpmndi:BPMNLabel&gt;\n          &lt;dc:Bounds height=&quot;0.0&quot; width=&quot;0.0&quot; x=&quot;0.0&quot; y=&quot;0.0&quot;/&gt;\n        &lt;/bpmndi:BPMNLabel&gt;\n      &lt;/bpmndi:BPMNEdge&gt;\n    &lt;/bpmndi:BPMNPlane&gt;\n  &lt;/bpmndi:BPMNDiagram&gt;\n&lt;/definitions&gt;\n</code></pre><blockquote>\n<p>关键点  <process id=\"orderKey\" isclosed=\"false\" isexecutable=\"true\" processtype=\"None\"></process></p>\n</blockquote>\n<h3 id=\"6-2流程定义的部署\"><a href=\"#6-2流程定义的部署\" class=\"headerlink\" title=\"6.2流程定义的部署\"></a>6.2流程定义的部署</h3><p>activitiService.java</p>\n<pre><code class=\"java\">public void deployByClassPath(String bpmnName) {\n        Deployment deploy =       repositoryService.createDeployment().addClasspathResource(bpmnName+&quot;.bpmn&quot;).deploy();\n        printDeploy(deploy);\n    }</code></pre>\n<pre><code class=\"java\">@RequestMapping(&quot;/deploy&quot;)\n@ResponseBody\npublic String deploy(String bpmnName) {\n    activitiService.deployByClassPath(bpmnName);\n    activitiService.queryDeployList();\n    return &quot;deploy&quot;;\n}</code></pre>\n<h3 id=\"6-3-流程实例启动时关联业务\"><a href=\"#6-3-流程实例启动时关联业务\" class=\"headerlink\" title=\"6.3 流程实例启动时关联业务\"></a>6.3 流程实例启动时关联业务</h3><p>使用activiti自带表act_ru_execution中的BUSINESS_KEY字段我存在业务的唯一表示 </p>\n<pre><code class=\"java\">/**\n* 流程变量\n* 给&lt;userTask activiti:assignee=&quot;#{u}&quot; activiti:exclusive=&quot;true&quot; name=&quot;部门经理审批&quot;/&gt;的u赋值\n* 给&lt;userTask activiti:assignee=&quot;#{m}&quot; activiti:exclusive=&quot;true&quot; name=&quot;总经理审批&quot;/&gt;的u赋值\n* 给&lt;userTask activiti:assignee=&quot;#{c}&quot; activiti:exclusive=&quot;true&quot; name=&quot;财务审批&quot;/&gt;的u赋值\n* 给&lt;conditionExpression xsi:type=&quot;tFormalExpression&quot;&gt;&lt;![CDATA[${price &lt; 1000}]]&gt;\n* &lt;/conditionExpression&gt;的price赋值\n* 同时设置业务key bussinessKey\n*/\npublic &lt;T&gt; void startProcess(String processDefinitionId,T t){\n    HashMap&lt;String, Object&gt; map = new HashMap&lt;&gt;();\n    map.put(&quot;u&quot;, &quot;u&quot;);\n    map.put(&quot;m&quot;, &quot;m&quot;);\n    map.put(&quot;c&quot;, &quot;c&quot;);\n    map.put(&quot;price&quot;, &quot;1200&quot;);// 分别测试流程走的分支条件 map.put(&quot;price&quot;, &quot;300&quot;);\n    runtimeService.startProcessInstanceByKey(key, map);\n    String bussinessKey= t.getClass().getName()+&quot;:&quot;+t.getId();\n    runtimeService.startProcessInstanceById(processDefinitionId,bussinessKey,map);\n}</code></pre>\n<p>启动流程是第二个参数就是表act_ru_execution中的BUSINESS_KEY字段，我一般喜欢使用业务名+ id来存储当前业务</p>\n<h3 id=\"6-4-查询当前获任务和业务关联\"><a href=\"#6-4-查询当前获任务和业务关联\" class=\"headerlink\" title=\"6.4 查询当前获任务和业务关联\"></a>6.4 查询当前获任务和业务关联</h3><p>通过task获得当前流程，通过当前流程获取当前流程的业务id</p>\n<p>查询属性：流程实例id，当前节点，采购名称，采购金额</p>\n<pre><code class=\"java\">/**\n     * \n     * @param assignee 任务办理人\n     */\npublic void getTaskDetailByAassignee(String assignee){\n    List&lt;Task&gt; tasks = taskService.createTaskQuery().taskAssignee(assignee).list();\n    for (Task task : tasks) {\n        String processInstanceId = task.getProcessInstanceId();\n        ProcessInstance processInstance = runtimeService.createProcessInstanceQuery().processInstanceId(processInstanceId).singleResult();\n        String businessKey = processInstance.getBusinessKey();\n        //当前运行的流程节点\n        String activityId = processInstance.getActivityId();\n        System.out.println(&quot;processInstanceId:&quot;+processInstanceId+&quot; businessKey:&quot;+businessKey+&quot; activityId:&quot;+activityId);\n        //业务主键id\n        Integer id;\n        if(StringUtils.isNotEmpty(businessKey)){\n            id=Integer.parseInt(businessKey.split(&quot;:&quot;)[1]);\n            //根据id查询出业务信息\n        }\n    }\n}</code></pre>\n<h3 id=\"6-5-查询已经结束的流程\"><a href=\"#6-5-查询已经结束的流程\" class=\"headerlink\" title=\"6.5 查询已经结束的流程\"></a>6.5 查询已经结束的流程</h3><p>通过task获得当前流程，通过当前流程获取当前流程的业务id</p>\n<p>查询属性：流程实例id，执行开始时间，执行结束时间，采购名称，采购金额</p>\n<h3 id=\"6-6-包含流程变量条件的流程\"><a href=\"#6-6-包含流程变量条件的流程\" class=\"headerlink\" title=\"6.6 包含流程变量条件的流程\"></a>6.6 包含流程变量条件的流程</h3><h3 id=\"6-6-对采购单的金额进行统计查询-如统计金额的总和\"><a href=\"#6-6-对采购单的金额进行统计查询-如统计金额的总和\" class=\"headerlink\" title=\"6.6 对采购单的金额进行统计查询 如统计金额的总和\"></a>6.6 对采购单的金额进行统计查询 如统计金额的总和</h3><p>（1）先查询已经结束的流程，用关联sql的方式 不好</p>\n<p>（2）最直接的方法，只从业务系统中查询采购单的信息，并统计。因为统计的数据是业务数据，业务系统只负责业务数据。但是面临的一个问题是，并不知道业务系统中的哪些采购单是已经结束了的。</p>\n<p>如果，在采购单业务表中加入一个字段status，则表中有采购单结束的标识。</p>\n<p>实现方法：</p>\n<p><strong>方法1：</strong> taskListener监听器的方法</p>\n<p>在流程定义的最后一个节点定义一个监听器，此监听器在完成任务的时候执行，在监听器中更新采购单业务表中的status字段的值，如：complete完成。</p>\n<p><strong>方法2：</strong>executionListener监听器的方法</p>\n<p>在endevent节点上添加executionListener监听器的方法，监听事件选择end</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182803.png\" alt></p>\n<h2 id=\"七、业务开发总结\"><a href=\"#七、业务开发总结\" class=\"headerlink\" title=\"七、业务开发总结\"></a>七、业务开发总结</h2><p>觉得不需要用activitEntity保存那么多的属性id  processInstanceId和 只需要  查询task列表的时候可以返回一个List<hashmap>，其实可以不需要 因为有businessEntity</hashmap></p>\n<p>1.新建一个activitEntity.java包含两个字段id和流程实例Id</p>\n<pre><code>public ActivitEntity{\n    private String id;\n    private String processInstanceId;\n}</code></pre><p>2.业务表单继承ActivitEntity基类</p>\n<p>3.保存业务表单的时候启动一个流程，创建采购单时，在填写新增记录保存时，启动流程实例。</p>\n<p>4.业务service层执行的时候，要确定业务key，uuid以及启动流程之后返回的流程实例id</p>\n<p>5.启动流程的时候，如果用流程定义Id的话，感觉不太好，应为部署的问题，所以建议使用startBykey的方式</p>\n<pre><code>public ActivitService{\n    private void saveOrder(){\n        Order order=new Order();\n        String id=UUid.gen();\n        order.setId(id);\n        //String businessKey=Order.getClass().getName()+&quot;:&quot;+id;//业务key 用类名和id组合 order:id\n        Map&lt;String, Object&gt; variables=new Hash&lt;&gt;();\n        //String processDefinitionId=&quot;11&quot;;\n        String processDefinitionKey=&quot;从部署bpmn文件中获取&quot;  //有工具类可以获取到这key 网络搜素一下\n        //调用服务的方式\n        //ActivitClient.startProcess(processDefinitionId,order,variables)\n        ActivitClient.startProcess(processDefinitionKey,order,variables)\n    }\n}\n\n\npublic &lt;T extends ActivitEntity&gt; void startProcess(String processDefinitionKey,T t,Map&lt;String, Object&gt; variables){\n        String bussinessKey= t.getClass().getName()+&quot;:&quot;+t.getId(); //业务key 用类名和id组合 order:id\n\n         //runtimeService.startProcessInstanceById(processDefinitionId,bussinessKey,variables);\n         runtimeService.startProcessInstanceByKey(processDefinitionKey,bussinessKey,variables);\n}</code></pre><p>6.为防止对采购单的业务数据进行修改，所以，创建采购单的人要提交申请，在提交申请之前，是可以对数据进行修改的，提交申请之后，数据不能修改，同时任务流向下一个节点。</p>\n<p>7.待提交的采购单如何查询</p>\n<p>利用activiti的taskservice查询出当前用户的代办任务</p>\n<p>任务的名称，任务的待办人，任务申请人，任务提交的时间，采购金额，采购类型</p>\n<p>8.提交采购单  当前任务的taskid  taskService.coomplete(taskid);</p>\n<p>9.审核业务（另起数据表–审核表—字段包含 id,采购单,采购申请人,采购类型，审核意见，审核状态0不同意，1通过，审核时间）</p>\n<p>进入审核页面  填写审核信息  提交审核  </p>\n<p>业务逻辑 ：保存审核意见到审核表中，然后再用activit完成任务</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"activiti学习笔记\"><a href=\"#activiti学习笔记\" class=\"headerlink\" title=\"activiti学习笔记\"></a>activiti学习笔记</h1><h2 id=\"一、Activiti获取ProcessEngine的三种方法\"><a href=\"#一、Activiti获取ProcessEngine的三种方法\" class=\"headerlink\" title=\"一、Activiti获取ProcessEngine的三种方法\"></a>一、Activiti获取ProcessEngine的三种方法</h2><h3 id=\"1-1-ProcessEngineConfiguration获取\"><a href=\"#1-1-ProcessEngineConfiguration获取\" class=\"headerlink\" title=\"1.1 ProcessEngineConfiguration获取\"></a>1.1 ProcessEngineConfiguration获取</h3><pre><code class=\"java\">public static void config() {\n        //获取config对象\n        ProcessEngineConfiguration processEngineConfiguration = ProcessEngineConfiguration.createStandaloneProcessEngineConfiguration();\n        //Jdbc设置\n        String jdbcDriver = &quot;com.mysql.jdbc.Driver&quot;;\n        processEngineConfiguration.setJdbcDriver(jdbcDriver);\n        String jdbcUrl = &quot;jdbc:mysql://localhost:3306/activiti?useUnicode=true&amp;characterEncoding=utf-8&quot;;\n        processEngineConfiguration.setJdbcUrl(jdbcUrl);\n        String jdbcUsername = &quot;root&quot;;\n        processEngineConfiguration.setJdbcUsername(jdbcUsername);\n        String jdbcPassword = &quot;root&quot;;\n        processEngineConfiguration.setJdbcPassword(jdbcPassword);\n        //DB_SCHEMA_UPDATE_FALSE = &quot;false&quot;;不自动创建新表\n        // DB_SCHEMA_UPDATE_CREATE_DROP = &quot;create-drop&quot;;每次运行创建新表\n        // DB_SCHEMA_UPDATE_TRUE = &quot;true&quot;;设置自动对表结构进行改进和升级\n        //设置是否自动更新\n   processEngineConfiguration.setDatabaseSchemaUpdate(ProcessEngineConfiguration.DB_SCHEMA_UPDATE_TRUE);\n        //获取引擎对象\n        ProcessEngine processEngine = processEngineConfiguration.buildProcessEngine();\n        processEngine.close();\n    }\n</code></pre>\n<h3 id=\"1-2-ProcessEngineConfiguration载入xml文件\"><a href=\"#1-2-ProcessEngineConfiguration载入xml文件\" class=\"headerlink\" title=\"1.2 ProcessEngineConfiguration载入xml文件\"></a>1.2 ProcessEngineConfiguration载入xml文件</h3><p>xml文件： </p>\n<pre><code class=\"xml\">&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;     xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot;\n      xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\n      xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\n   http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-2.5.xsd\n   http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.0.xsd&quot;&gt;\n&lt;!--这里的类太多别导错了 --&gt;\n&lt;bean id=&quot;processEngineConfiguration&quot; class=&quot;org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration&quot;&gt;\n    &lt;!-- 配置流程引擎配置对象 --&gt;\n    &lt;property name=&quot;jdbcDriver&quot; value=&quot;com.mysql.jdbc.Driver&quot;&gt;&lt;/property&gt;\n    &lt;property name=&quot;jdbcUrl&quot; value=&quot;jdbc:mysql://localhost:3306/activiti?useUnicode=true&amp;amp;characterEncoding=utf-8&quot;&gt;&lt;/property&gt;\n    &lt;property name=&quot;jdbcUsername&quot; value=&quot;root&quot;&gt;&lt;/property&gt;\n    &lt;property name=&quot;jdbcPassword&quot; value=&quot;123456&quot;&gt;&lt;/property&gt;\n    &lt;!-- 注入数据源信息 --&gt;\n    &lt;property name=&quot;databaseSchemaUpdate&quot; value=&quot;true&quot;&gt;&lt;/property&gt;\n&lt;/bean&gt;\n&lt;bean id=&quot;processEngine&quot; class=&quot;org.activiti.spring.ProcessEngineFactoryBean&quot;&gt;\n    &lt;!-- 注入自动建表设置 --&gt;\n    &lt;property name=&quot;processEngineConfiguration&quot; ref=&quot;processEngineConfiguration&quot;&gt;&lt;/property&gt;\n&lt;/bean&gt;\n&lt;/beans&gt;</code></pre>\n<p>java代码加载xml文件</p>\n<pre><code class=\"java\">public void configByConf() {\n   //载入资源\n   ProcessEngineConfiguration processEngineConfiguration =      ProcessEngineConfiguration.createProcessEngineConfigurationFromResource(&quot;activiti.cfg.xml&quot;);\n        //创建引擎\n   ProcessEngine processEngine = processEngineConfiguration.buildProcessEngine();\n   processEngine.getRepositoryService();\n}</code></pre>\n<h3 id=\"1-3-默认载入activiti-cfg-xml进行获取\"><a href=\"#1-3-默认载入activiti-cfg-xml进行获取\" class=\"headerlink\" title=\"1.3 默认载入activiti.cfg.xml进行获取\"></a>1.3 默认载入activiti.cfg.xml进行获取</h3><pre><code class=\"java\">public void configByDefault() {\n   //通过获取载入默认获取\n   ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();\n   processEngine.close();\n}</code></pre>\n<p>这里的xml文件名必须设置为activiti.cfg.xml</p>\n<h2 id=\"二、流程定义\"><a href=\"#二、流程定义\" class=\"headerlink\" title=\"二、流程定义\"></a>二、流程定义</h2><p><code>部署流程</code>–&gt;<code>启动流程实例</code></p>\n<h3 id=\"2-1-设计流程定义文档\"><a href=\"#2-1-设计流程定义文档\" class=\"headerlink\" title=\"2.1 设计流程定义文档\"></a>2.1 设计流程定义文档</h3><p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182142.png\" alt></p>\n<h3 id=\"2-2-bpmn文件\"><a href=\"#2-2-bpmn文件\" class=\"headerlink\" title=\"2.2 bpmn文件\"></a>2.2 bpmn文件</h3><pre><code class=\"xml\">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n&lt;definitions xmlns=&quot;http://www.omg.org/spec/BPMN/20100524/MODEL&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:activiti=&quot;http://activiti.org/bpmn&quot; xmlns:bpmndi=&quot;http://www.omg.org/spec/BPMN/20100524/DI&quot; xmlns:omgdc=&quot;http://www.omg.org/spec/DD/20100524/DC&quot; xmlns:omgdi=&quot;http://www.omg.org/spec/DD/20100524/DI&quot; typeLanguage=&quot;http://www.w3.org/2001/XMLSchema&quot; expressionLanguage=&quot;http://www.w3.org/1999/XPath&quot; targetNamespace=&quot;http://www.activiti.org/test&quot;&gt;\n  &lt;process id=&quot;helloworld&quot; name=&quot;helloworldProcess&quot; isExecutable=&quot;true&quot;&gt;\n    &lt;startEvent id=&quot;startevent1&quot; name=&quot;Start&quot;&gt;&lt;/startEvent&gt;\n    &lt;endEvent id=&quot;endevent1&quot; name=&quot;End&quot;&gt;&lt;/endEvent&gt;\n    &lt;userTask id=&quot;usertask1&quot; name=&quot;提交申请&quot; activiti:assignee=&quot;张三&quot;&gt;&lt;/userTask&gt;\n    &lt;userTask id=&quot;usertask2&quot; name=&quot;审批【部门经理】&quot; activiti:assignee=&quot;李四&quot;&gt;&lt;/userTask&gt;\n    &lt;userTask id=&quot;usertask3&quot; name=&quot;审批【总经理】&quot; activiti:assignee=&quot;王五&quot;&gt;&lt;/userTask&gt;\n    &lt;sequenceFlow id=&quot;flow1&quot; sourceRef=&quot;startevent1&quot; targetRef=&quot;usertask1&quot;&gt;&lt;/sequenceFlow&gt;\n    &lt;sequenceFlow id=&quot;flow2&quot; sourceRef=&quot;usertask1&quot; targetRef=&quot;usertask2&quot;&gt;&lt;/sequenceFlow&gt;\n    &lt;sequenceFlow id=&quot;flow3&quot; sourceRef=&quot;usertask2&quot; targetRef=&quot;usertask3&quot;&gt;&lt;/sequenceFlow&gt;\n    &lt;sequenceFlow id=&quot;flow4&quot; sourceRef=&quot;usertask3&quot; targetRef=&quot;endevent1&quot;&gt;&lt;/sequenceFlow&gt;\n  &lt;/process&gt;\n  &lt;bpmndi:BPMNDiagram id=&quot;BPMNDiagram_helloworld&quot;&gt;\n    &lt;bpmndi:BPMNPlane bpmnElement=&quot;helloworld&quot; id=&quot;BPMNPlane_helloworld&quot;&gt;\n      &lt;bpmndi:BPMNShape bpmnElement=&quot;startevent1&quot; id=&quot;BPMNShape_startevent1&quot;&gt;\n        &lt;omgdc:Bounds height=&quot;35.0&quot; width=&quot;35.0&quot; x=&quot;330.0&quot; y=&quot;20.0&quot;&gt;&lt;/omgdc:Bounds&gt;\n      &lt;/bpmndi:BPMNShape&gt;\n      &lt;bpmndi:BPMNShape bpmnElement=&quot;endevent1&quot; id=&quot;BPMNShape_endevent1&quot;&gt;\n        &lt;omgdc:Bounds height=&quot;35.0&quot; width=&quot;35.0&quot; x=&quot;330.0&quot; y=&quot;380.0&quot;&gt;&lt;/omgdc:Bounds&gt;\n      &lt;/bpmndi:BPMNShape&gt;\n      &lt;bpmndi:BPMNShape bpmnElement=&quot;usertask1&quot; id=&quot;BPMNShape_usertask1&quot;&gt;\n        &lt;omgdc:Bounds height=&quot;55.0&quot; width=&quot;105.0&quot; x=&quot;295.0&quot; y=&quot;100.0&quot;&gt;&lt;/omgdc:Bounds&gt;\n      &lt;/bpmndi:BPMNShape&gt;\n      &lt;bpmndi:BPMNShape bpmnElement=&quot;usertask2&quot; id=&quot;BPMNShape_usertask2&quot;&gt;\n        &lt;omgdc:Bounds height=&quot;55.0&quot; width=&quot;105.0&quot; x=&quot;295.0&quot; y=&quot;200.0&quot;&gt;&lt;/omgdc:Bounds&gt;\n      &lt;/bpmndi:BPMNShape&gt;\n      &lt;bpmndi:BPMNShape bpmnElement=&quot;usertask3&quot; id=&quot;BPMNShape_usertask3&quot;&gt;\n        &lt;omgdc:Bounds height=&quot;55.0&quot; width=&quot;105.0&quot; x=&quot;295.0&quot; y=&quot;290.0&quot;&gt;&lt;/omgdc:Bounds&gt;\n      &lt;/bpmndi:BPMNShape&gt;\n      &lt;bpmndi:BPMNEdge bpmnElement=&quot;flow1&quot; id=&quot;BPMNEdge_flow1&quot;&gt;\n        &lt;omgdi:waypoint x=&quot;347.0&quot; y=&quot;55.0&quot;&gt;&lt;/omgdi:waypoint&gt;\n        &lt;omgdi:waypoint x=&quot;347.0&quot; y=&quot;100.0&quot;&gt;&lt;/omgdi:waypoint&gt;\n      &lt;/bpmndi:BPMNEdge&gt;\n      &lt;bpmndi:BPMNEdge bpmnElement=&quot;flow2&quot; id=&quot;BPMNEdge_flow2&quot;&gt;\n        &lt;omgdi:waypoint x=&quot;347.0&quot; y=&quot;155.0&quot;&gt;&lt;/omgdi:waypoint&gt;\n        &lt;omgdi:waypoint x=&quot;347.0&quot; y=&quot;200.0&quot;&gt;&lt;/omgdi:waypoint&gt;\n      &lt;/bpmndi:BPMNEdge&gt;\n      &lt;bpmndi:BPMNEdge bpmnElement=&quot;flow3&quot; id=&quot;BPMNEdge_flow3&quot;&gt;\n        &lt;omgdi:waypoint x=&quot;347.0&quot; y=&quot;255.0&quot;&gt;&lt;/omgdi:waypoint&gt;\n        &lt;omgdi:waypoint x=&quot;347.0&quot; y=&quot;290.0&quot;&gt;&lt;/omgdi:waypoint&gt;\n      &lt;/bpmndi:BPMNEdge&gt;\n      &lt;bpmndi:BPMNEdge bpmnElement=&quot;flow4&quot; id=&quot;BPMNEdge_flow4&quot;&gt;\n        &lt;omgdi:waypoint x=&quot;347.0&quot; y=&quot;345.0&quot;&gt;&lt;/omgdi:waypoint&gt;\n        &lt;omgdi:waypoint x=&quot;347.0&quot; y=&quot;380.0&quot;&gt;&lt;/omgdi:waypoint&gt;\n      &lt;/bpmndi:BPMNEdge&gt;\n    &lt;/bpmndi:BPMNPlane&gt;\n  &lt;/bpmndi:BPMNDiagram&gt;\n&lt;/definitions&gt;</code></pre>\n<h3 id=\"2-3-部署流程定义\"><a href=\"#2-3-部署流程定义\" class=\"headerlink\" title=\"2.3 部署流程定义\"></a>2.3 部署流程定义</h3><p>(1) 部署流程定义</p>\n<pre><code class=\"java\">public void deploymentProcessDefinition_classpath(){\n    Deployment deployment = processEngine.getRepositoryService()\n                    .createDeployment().name(&quot;流程定义&quot;)\n                      //从classpath的资源中加载，一次只能加载一个文件\n                    .addClasspathResource(&quot;diagrams/helloworld.bpmn&quot;)\n                    .addClasspathResource(&quot;diagrams/helloworld.png&quot;).deploy();//完成部署\n    System.out.println(&quot;部署ID：&quot;+deployment.getId());\n    System.out.println(&quot;部署名称：&quot;+deployment.getName());\n}</code></pre>\n<p>(2) ZipInputStream的部署方式</p>\n<pre><code>public static void main(String[] args) throws Exception{\n    DeploymentBuilder deployment = rs.createDeployment();\n    FileInputStream fis = new FileInputStream(new File(&quot;&quot;));\n    ZipInputStream zis = new ZipInputStream(fis);\n    deployment.addZipInputStream(zis);\n    deployment.deploy();\n}</code></pre><h3 id=\"2-4-流程部署后数据库的变化\"><a href=\"#2-4-流程部署后数据库的变化\" class=\"headerlink\" title=\"2.4 流程部署后数据库的变化\"></a>2.4 流程部署后数据库的变化</h3><ul>\n<li><p>act_ge_bytearray（资源文件表）        存储流程定义相关的部署信息。即流程定义文档的存放地。每部署一次就会增加两条记录，一条是关于bpmn规则文件的，一条是图片的（如果部署时只指定了bpmn一个文件，activiti会在部署时解析bpmn文件内容自动生成流程图）。两个文件不是很大，都是以二进制形式存储在数据库中。</p>\n</li>\n<li><p>act_re_procdef（流程定义表）    存放流程定义的属性信息，部署每个新的流程定义都会在这张表中增加一条记录。    注意：当流程定义的key相同的情况下，使用的是版本升级    </p>\n</li>\n</ul>\n<p>​       其中<code>act_re_deployment</code>的id会和<code>act_ge_bytearray</code>的deployment_id_关联</p>\n<ul>\n<li>act_re_deployment（流程部署表）       存放流程定义的显示名和部署时间，每部署一次增加一条记录</li>\n</ul>\n<p>流程部署之后act_ge_bytearray插入两条记录</p>\n<table>\n<thead>\n<tr>\n<th>ID_</th>\n<th>REV_</th>\n<th>NAME_</th>\n<th>DEPLOYMENT_ID_</th>\n<th>BYTES_</th>\n<th>GENERATED_</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>ID</td>\n<td>版本</td>\n<td>名称</td>\n<td>部署ID</td>\n<td>字节</td>\n<td>不详</td>\n</tr>\n<tr>\n<td>10002</td>\n<td>1</td>\n<td>simple.bpmn</td>\n<td>10001</td>\n<td>blob文件</td>\n<td>1</td>\n</tr>\n<tr>\n<td>10003</td>\n<td>1</td>\n<td>simple.myProcess_1.png</td>\n<td>10001</td>\n<td>blob文件</td>\n<td>1</td>\n</tr>\n</tbody></table>\n<p>act_re_procdef（流程定义表）       存放流程定义的显示名和部署时间，每部署一次增加一条记录</p>\n<table>\n<thead>\n<tr>\n<th>ID_</th>\n<th>REV_</th>\n<th>CATEGORY_</th>\n<th>NAME_</th>\n<th>KEY_</th>\n<th>VERSION_</th>\n<th>DEPLOYMENT_ID_</th>\n<th>RESOURCE_NAME_</th>\n<th>DGRM_RESOURCE_NAME_</th>\n<th>DESCRIPTION_</th>\n<th>HAS_START_FORM_KEY_</th>\n<th>HAS_GRAPHICAL_NOTATION_</th>\n<th>SUSPENSION_STATE_</th>\n<th>TENANT_ID_</th>\n<th>ENGINE_VERSION_</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>流程定义id</td>\n<td></td>\n<td></td>\n<td></td>\n<td>流程key</td>\n<td>版本</td>\n<td>流程部署id</td>\n<td>流程资源名称</td>\n<td>流程资源图片</td>\n<td>描述</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>myProcess_1:1:10004</td>\n<td>1</td>\n<td>Examples</td>\n<td></td>\n<td>myProcess_1</td>\n<td>1</td>\n<td>10001</td>\n<td>simple.bpmn</td>\n<td>simple.myProcess_1.png</td>\n<td></td>\n<td>0</td>\n<td>1</td>\n<td>1</td>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n<p>act_re_deployment（流程部署表）       存放流程定义的显示名和部署时间，每部署一次增加一条记录</p>\n<table>\n<thead>\n<tr>\n<th>ID_</th>\n<th>NAME_</th>\n<th>CATEGORY_</th>\n<th>KEY_</th>\n<th>TENANT_ID_</th>\n<th>DEPLOY_TIME_</th>\n<th>ENGINE_VERSION_</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>部署id</td>\n<td>部署名称</td>\n<td>部署类型</td>\n<td>部署key</td>\n<td></td>\n<td>部署时间</td>\n<td></td>\n</tr>\n<tr>\n<td>10001</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td>2019/4/3 16:35</td>\n<td></td>\n</tr>\n</tbody></table>\n<h3 id=\"2-5-根据名称查询流程部署\"><a href=\"#2-5-根据名称查询流程部署\" class=\"headerlink\" title=\"2.5 根据名称查询流程部署\"></a>2.5 根据名称查询流程部署</h3><pre><code class=\"java\">public void testQueryDeploymentByName(){\n        ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();\n        List&lt;Deployment&gt; deployments = processEngine.getRepositoryService()\n                .createDeploymentQuery()\n                .orderByDeploymenTime()//按照部署时间排序\n                .desc()//按照降序排序\n                .deploymentName(&quot;请假流程&quot;)\n                .list();\n        for (Deployment deployment : deployments) {\n            System.out.println(deployment.getId());\n        }\n    }</code></pre>\n<h3 id=\"2-6-查询所有的部署流程\"><a href=\"#2-6-查询所有的部署流程\" class=\"headerlink\" title=\"2.6 查询所有的部署流程\"></a>2.6 查询所有的部署流程</h3><pre><code class=\"java\">public void queryAllDeplyoment(){\n        //得到流程引擎\n        ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();\n        List&lt;Deployment&gt; lists = processEngine.getRepositoryService()\n                .createDeploymentQuery()\n                .orderByDeploymenTime()//按照部署时间排序\n                .desc()//按照降序排序\n                .list();\n        for (Deployment deployment:lists) {\n            System.out.println(deployment.getId() +&quot;    部署名称&quot; + deployment.getName());\n        }\n}</code></pre>\n<h3 id=\"2-7-查看所有流程定义\"><a href=\"#2-7-查看所有流程定义\" class=\"headerlink\" title=\"2.7 查看所有流程定义\"></a>2.7 查看所有流程定义</h3><pre><code class=\"java\">public void findProcessDefinition(){\n    List&lt;ProcessDefinition&gt; list = RepositoryService.createProcessDefinitionQuery()//创建一个流程定义的查询\n            /**指定查询条件,where条件*/\n//            .deploymentId(deploymentId)//使用部署对象ID查询\n//            .processDefinitionId(processDefinitionId)//使用流程定义ID查询\n//            .processDefinitionKey(processDefinitionKey)//使用流程定义的key查询\n//            .processDefinitionNameLike(processDefinitionNameLike)//使用流程定义的名称模糊查询\n            .orderByProcessDefinitionVersion().asc()//按照版本的升序排列\n//            .orderByProcessDefinitionName().desc()//按照流程定义的名称降序排列\n            .list();//返回一个集合列表，封装流程定义\n//            .singleResult();//返回惟一结果集\n//            .count();//返回结果集数量\n//            .listPage(firstResult, maxResults);//分页查询\n    if(list!=null &amp;&amp; list.size()&gt;0){\n        for(ProcessDefinition pd:list){\n            System.out.println(&quot;流程定义ID:&quot;+pd.getId());//流程定义的key+版本+随机生成数\n            System.out.println(&quot;流程定义的名称:&quot;+pd.getName());//对应helloworld.bpmn文件中的name属性值\n            System.out.println(&quot;流程定义的key:&quot;+pd.getKey());//对应helloworld.bpmn文件中的id属性值\n            System.out.println(&quot;流程定义的版本:&quot;+pd.getVersion());//当流程定义的key值相同的相同下，版本升级，默认1\n            System.out.println(&quot;资源名称bpmn文件:&quot;+pd.getResourceName());\n            System.out.println(&quot;资源名称png文件:&quot;+pd.getDiagramResourceName());\n            System.out.println(&quot;部署对象ID：&quot;+pd.getDeploymentId());\n        }\n    }            \n}</code></pre>\n<h3 id=\"2-8-删除流程定义\"><a href=\"#2-8-删除流程定义\" class=\"headerlink\" title=\"2.8 删除流程定义\"></a>2.8 删除流程定义</h3><pre><code class=\"java\">public void deleteProcessDefinition(){\n    String deploymentId = &quot;601&quot;; //使用部署ID，完成删除\n    //不带级联的删除 只能删除没有启动的流程，如果流程启动，就会抛出异常\n    RepositoryService().deleteDeployment(deploymentId);\n    //级联删除  不管流程是否启动，都能可以删除\n    RepositoryService().deleteDeployment(deploymentId, true);\n}</code></pre>\n<p>说明：    </p>\n<ul>\n<li><p>因为删除的是流程定义，而流程定义的部署是属于仓库服务的，所以应该先得到RepositoryService。    </p>\n</li>\n<li><p>如果该流程定义下没有正在运行的流程，则可以用普通删除。如果是有关联的信息，用级联删除。项目开发中使用级联删除的情况比较多，删除操作一般只开放给超级管理员使用。</p>\n</li>\n</ul>\n<h3 id=\"2-9-查看流程图\"><a href=\"#2-9-查看流程图\" class=\"headerlink\" title=\"2.9 查看流程图\"></a>2.9 查看流程图</h3><pre><code class=\"java\">public void viewPic() throws IOException{\n    /**将生成图片放到文件夹下*/\n    String deploymentId = &quot;801&quot;;\n    //获取图片资源名称\n    List&lt;String&gt; list = repositoryService.getDeploymentResourceNames(deploymentId);\n    //定义图片资源的名称\n    String resourceName = &quot;&quot;;\n    if(list!=null &amp;&amp; list.size()&gt;0){\n        for(String name:list){\n            if(name.indexOf(&quot;.png&quot;)&gt;=0){\n                resourceName = name;\n            }\n        }\n    }    \n    //获取图片的输入流\n    InputStream in = repositoryService.getResourceAsStream(deploymentId, resourceName);\n    //将图片生成到D盘的目录下\n    File file = new File(&quot;D:/&quot;+resourceName);\n    //将输入流的图片写到D盘下\n    FileUtils.copyInputStreamToFile(in, file);\n}</code></pre>\n<h3 id=\"2-10-流程定义的暂停挂起\"><a href=\"#2-10-流程定义的暂停挂起\" class=\"headerlink\" title=\"2.10 流程定义的暂停挂起\"></a>2.10 流程定义的暂停挂起</h3><p><strong>测试暂停流程定义执行步骤如下：</strong></p>\n<p>在程序中，我们需要暂停一个流程定义，停止所有的该流程定义下的流程实例，并且不允许发起这个流程定义的流程实例，那么我们就需要挂起这个流程定义</p>\n<p>　　1，启动一个流程实例（该流程定义未挂起前）</p>\n<p>　　2，挂起上面流程实例对应的流程定义</p>\n<p>　　3，完成上述流程实例的下一个任务节点（观察效果，是否会和流程实例挂起一样）</p>\n<p>（1）根据流程实例的id来挂起这个流程定义</p>\n<pre><code>public void testSuspendProcessDefinition(){        \n     String processDefinitionKey =&quot;purchasingflow&quot;;\n     //根据流程定义的key暂停一个流程定义\n     repositoryService.suspendProcessDefinitionByKey(processDefinitionKey );\n}</code></pre><p>（2）完成这个流程实例的下一个节点，通过taskService来结束下一个任务节点</p>\n<p>　　这时候，我们发现这个流程实例居然是可以继续执行的，并且可以执行到结束，带着这个疑问，我们再启动一个流程实例看看</p>\n<p>（3）重新启动这个流程定义下的流程实例</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182230.png\" alt></p>\n<p>报错说不可以启动这个被挂起流程定义的流程实例</p>\n<h2 id=\"三、流程实例\"><a href=\"#三、流程实例\" class=\"headerlink\" title=\"三、流程实例\"></a>三、流程实例</h2><h3 id=\"3-1-根据流程部署id启动流程实例\"><a href=\"#3-1-根据流程部署id启动流程实例\" class=\"headerlink\" title=\"3.1 根据流程部署id启动流程实例\"></a>3.1 根据流程部署id启动流程实例</h3><pre><code class=\"java\">public void startProcess(String deploymentId){\n    ProcessDefinition pd=repositoryService.createProcessDefinitionQuery()\n        .deploymentId(deploymentId)\n        .singleResult();\n    ProcessInstance pi=runtimeService.startProcessInstanceById(pd.getId());\n}</code></pre>\n<h3 id=\"3-2-根据流程id启动流程实例-可以设置一个流程变量\"><a href=\"#3-2-根据流程id启动流程实例-可以设置一个流程变量\" class=\"headerlink\" title=\"3.2 根据流程id启动流程实例,可以设置一个流程变量\"></a>3.2 根据流程id启动流程实例,可以设置一个流程变量</h3><pre><code class=\"java\">/**\n* 流程变量\n* 给&lt;userTask id=&quot;请假申请&quot; name=&quot;申请&quot; activiti:assignee=&quot;#{student}&quot;&gt;&lt;/userTask&gt;的student赋值\n*/\npublic void startProcess(){\n    Map&lt;String, Object&gt; variables = new HashMap&lt;String, Object&gt;();\n    variables.put(&quot;student&quot;, &quot;小明&quot;);\n    ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();\n    runtimeService.startProcessInstanceById(&quot;shenqing1:1:1304&quot;,variables);\n}</code></pre>\n<h3 id=\"3-3-启动流程实例之后数据库的变化\"><a href=\"#3-3-启动流程实例之后数据库的变化\" class=\"headerlink\" title=\"3.3 启动流程实例之后数据库的变化\"></a>3.3 启动流程实例之后数据库的变化</h3><p>首先向act_ru_execution表中插入一条记录，记录的是这个流程定义的执行实例，其中id和proc_inst_id相同都是流程执行实例id，也就是本次执行这个流程定义的id，包含流程定义的id外键(simpleProcess:1:5004)。</p>\n<table>\n<thead>\n<tr>\n<th>ID_</th>\n<th>REV_</th>\n<th>PROC_INST_ID_</th>\n<th>BUSINESS_KEY_</th>\n<th>PARENT_ID_</th>\n<th>PROC_DEF_ID_</th>\n<th>SUPER_EXEC_</th>\n<th>ROOT_PROC_INST_ID_</th>\n<th>ACT_ID_</th>\n<th>IS_ACTIVE_</th>\n<th>IS_CONCURRENT_</th>\n<th>IS_SCOPE_</th>\n<th>IS_EVENT_SCOPE_</th>\n<th>IS_MI_ROOT_</th>\n<th>SUSPENSION_STATE_</th>\n<th>START_TIME_</th>\n</tr>\n</thead>\n<tbody><tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>12501</td>\n<td>1</td>\n<td>12501</td>\n<td></td>\n<td></td>\n<td>myProcess_1:1:10004</td>\n<td></td>\n<td>12501</td>\n<td></td>\n<td>1</td>\n<td>0</td>\n<td>1</td>\n<td>0</td>\n<td>0</td>\n<td>1</td>\n<td>2019-4-3 17:25:30</td>\n</tr>\n<tr>\n<td>12503</td>\n<td>1</td>\n<td>12501</td>\n<td></td>\n<td>12501</td>\n<td>myProcess_1:1:10004</td>\n<td></td>\n<td>12501</td>\n<td>_3</td>\n<td>1</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>0</td>\n<td>1</td>\n<td>2019-4-3 17:25:30</td>\n</tr>\n</tbody></table>\n<p>然后向act_ru_task插入一条记录，记录的是第一个任务的信息，也就是开始执行第一个任务。包括act_ru_execution表中的execution_id外键和proc_inst_id外键，也就是本次执行实例id。</p>\n<table>\n<thead>\n<tr>\n<th>ID_</th>\n<th>REV_</th>\n<th>EXECUTION_ID_</th>\n<th>PROC_INST_ID_</th>\n<th>PROC_DEF_ID_</th>\n<th>NAME_</th>\n<th>PARENT_TASK_ID_</th>\n<th>DESCRIPTION_</th>\n<th>TASK_DEF_KEY_</th>\n<th>OWNER_</th>\n<th>ASSIGNEE_</th>\n<th>DELEGATION_</th>\n<th>PRIORITY_</th>\n<th>CREATE_TIME_</th>\n<th>DUE_DATE_</th>\n<th>CATEGORY_</th>\n<th>SUSPENSION_STATE_</th>\n</tr>\n</thead>\n<tbody><tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>12506</td>\n<td>1</td>\n<td>12503</td>\n<td>12501</td>\n<td>myProcess_1:1:10004</td>\n<td>UserTask</td>\n<td></td>\n<td></td>\n<td>_3</td>\n<td></td>\n<td>a</td>\n<td></td>\n<td>50</td>\n<td>2019/4/3 17:07</td>\n<td></td>\n<td></td>\n<td>1</td>\n</tr>\n</tbody></table>\n<p>然后向act_hi_procinst表插入一条记录，记录的是本次执行实例：</p>\n<table>\n<thead>\n<tr>\n<th>ID_</th>\n<th>PROC_INST_ID_</th>\n<th>BUSINESS_KEY_</th>\n<th>PROC_DEF_ID_</th>\n<th>START_TIME_</th>\n<th>END_TIME_</th>\n<th>DURATION_</th>\n<th>START_USER_ID_</th>\n<th>START_ACT_ID_</th>\n<th>END_ACT_ID_</th>\n<th>SUPER_PROCESS_INSTANCE_ID_</th>\n<th>DELETE_REASON_</th>\n<th>TENANT_ID_</th>\n<th>NAME_</th>\n</tr>\n</thead>\n<tbody><tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>12501</td>\n<td>12501</td>\n<td></td>\n<td>myProcess_1:1:10004</td>\n<td>2019/4/3 17:07</td>\n<td></td>\n<td></td>\n<td></td>\n<td>_2</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n<p>然后向act_hi_taskinst表中插入一条记录，记录的是任务的历史记录：</p>\n<table>\n<thead>\n<tr>\n<th>ID_</th>\n<th>PROC_DEF_ID_</th>\n<th>TASK_DEF_KEY_</th>\n<th>PROC_INST_ID_</th>\n<th>EXECUTION_ID_</th>\n<th>NAME_</th>\n<th>PARENT_TASK_ID_</th>\n<th>DESCRIPTION_</th>\n<th>OWNER_</th>\n<th>ASSIGNEE_</th>\n<th>START_TIME_</th>\n<th>CLAIM_TIME_</th>\n<th>END_TIME_</th>\n<th>DURATION_</th>\n<th>DELETE_REASON_</th>\n<th>PRIORITY_</th>\n<th>DUE_DATE_</th>\n<th>FORM_KEY_</th>\n<th>CATEGORY_</th>\n<th>TENANT_ID_</th>\n</tr>\n</thead>\n<tbody><tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>12506</td>\n<td>myProcess_1:1:10004</td>\n<td>_3</td>\n<td>12501</td>\n<td>12503</td>\n<td>UserTask</td>\n<td></td>\n<td></td>\n<td></td>\n<td>a</td>\n<td>2019/4/3 17:07</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td>50</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n<h3 id=\"3-4-流程实例的暂停挂起\"><a href=\"#3-4-流程实例的暂停挂起\" class=\"headerlink\" title=\"3.4 流程实例的暂停挂起\"></a>3.4 流程实例的暂停挂起</h3><p><strong>测试暂停流程实例执行步骤如下：</strong></p>\n<p>　　1，通过流程定义的key或者id启动一个流程实例</p>\n<p>　　2，根据流程实例的id来挂起这个流程实例</p>\n<p>　　3，得到下一个节点的对应的任务的id，调用taskService来完成这个任务观察效果</p>\n<p> 　   4，重新激活这个流程实例</p>\n<p>　　5，继续完成这个流程实例</p>\n<p>（1）通过上面发起的流程实例的id挂起这个流程实例 </p>\n<pre><code class=\"java\">public void testSuspendProcessInstance(){\n    String processInstanceId=&quot;1801&quot;;\n    //根据一个流程实例的id挂起该流程实例\n    runtimeService.suspendProcessInstanceById(processInstanceId);\n}</code></pre>\n<p>（2）任务的下一处理人来完成这个实例 </p>\n<pre><code class=\"java\">public void completeProcessInstance(){\n    //任务的id，后期整合后会通过当前登录人身份查询到该用户的任务，然后获取到该id\n    String taskId=&quot;1804&quot;;\n    //根据任务id完成该任务\n    taskService.complete(taskId);\n}</code></pre>\n<p>执行完报错：</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904183119.png\" alt></p>\n<p>　　上面的信息说明无法完成一个已经被挂起的任务</p>\n<p>（3）激活这个流程实例 </p>\n<pre><code>public void testActivateProcessInstance(){\n    String processInstanceId=&quot;1801&quot;;\n    runtimeService.activateProcessInstanceById(processInstanceId);\n}</code></pre><p>5，重新完成这个任务，执行ok </p>\n<h2 id=\"四、任务管理\"><a href=\"#四、任务管理\" class=\"headerlink\" title=\"四、任务管理\"></a>四、任务管理</h2><h3 id=\"4-1-根据办理人查询任务\"><a href=\"#4-1-根据办理人查询任务\" class=\"headerlink\" title=\"4.1 根据办理人查询任务\"></a>4.1 根据办理人查询任务</h3><p><code>根据任务的执行人查询正在执行任务(通过act_ru_task数据表)</code></p>\n<pre><code class=\"java\">public void testQueryTaskByAssignee(){\n        ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();\n        //当前班主任小毛人这个人当前正在执行的所有的任务\n        List&lt;Task&gt; tasks = processEngine.getTaskService()\n                .createTaskQuery()\n                .orderByTaskCreateTime()\n                .desc()\n                .taskAssignee(&quot;小毛&quot;)\n                .list();\n        for (Task task : tasks) {\n            System.out.println(task.getName());\n            System.out.println(task.getAssignee());\n        }\n    }</code></pre>\n<h3 id=\"4-2-个人任务的三种指派方式\"><a href=\"#4-2-个人任务的三种指派方式\" class=\"headerlink\" title=\"4.2 个人任务的三种指派方式\"></a>4.2 个人任务的三种指派方式</h3><p><strong>（1）方式一</strong></p>\n<p>定义流程图时直接指定完成任务人（项目开发中任务的办理人不要放置XML文件中，不够灵活，较少使用） </p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904183158.png\" alt></p>\n<p>定义的bpmn文件中定义任务办理人的名称</p>\n<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n&lt;definitions xmlns=&quot;http://www.omg.org/spec/BPMN/20100524/MODEL&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:xsd=&quot;http://www.w3.org/2001/XMLSchema&quot; xmlns:activiti=&quot;http://activiti.org/bpmn&quot; xmlns:bpmndi=&quot;http://www.omg.org/spec/BPMN/20100524/DI&quot; xmlns:omgdc=&quot;http://www.omg.org/spec/DD/20100524/DC&quot; xmlns:omgdi=&quot;http://www.omg.org/spec/DD/20100524/DI&quot; typeLanguage=&quot;http://www.w3.org/2001/XMLSchema&quot; expressionLanguage=&quot;http://www.w3.org/1999/XPath&quot; targetNamespace=&quot;http://www.activiti.org/test&quot;&gt;\n  &lt;process id=&quot;personalAssignee1&quot; name=&quot;PersonalAssignee1&quot; isExecutable=&quot;true&quot;&gt;\n    &lt;startEvent id=&quot;startevent1&quot; name=&quot;Start&quot;&gt;&lt;/startEvent&gt;\n    &lt;userTask id=&quot;usertask1&quot; name=&quot;审批&quot; activiti:assignee=&quot;crystal&quot;&gt;&lt;/userTask&gt;\n    &lt;sequenceFlow id=&quot;flow1&quot; sourceRef=&quot;startevent1&quot; targetRef=&quot;usertask1&quot;&gt;&lt;/sequenceFlow&gt;\n    &lt;endEvent id=&quot;endevent1&quot; name=&quot;End&quot;&gt;&lt;/endEvent&gt;\n    &lt;sequenceFlow id=&quot;flow2&quot; sourceRef=&quot;usertask1&quot; targetRef=&quot;endevent1&quot;&gt;&lt;/sequenceFlow&gt;\n  &lt;/process&gt;\n  &lt;bpmndi:BPMNDiagram id=&quot;BPMNDiagram_personalAssignee1&quot;&gt;\n    &lt;bpmndi:BPMNPlane bpmnElement=&quot;personalAssignee1&quot; id=&quot;BPMNPlane_personalAssignee1&quot;&gt;\n      &lt;bpmndi:BPMNShape bpmnElement=&quot;startevent1&quot; id=&quot;BPMNShape_startevent1&quot;&gt;\n        &lt;omgdc:Bounds height=&quot;35.0&quot; width=&quot;35.0&quot; x=&quot;360.0&quot; y=&quot;20.0&quot;&gt;&lt;/omgdc:Bounds&gt;\n      &lt;/bpmndi:BPMNShape&gt;\n      &lt;bpmndi:BPMNShape bpmnElement=&quot;usertask1&quot; id=&quot;BPMNShape_usertask1&quot;&gt;\n        &lt;omgdc:Bounds height=&quot;55.0&quot; width=&quot;105.0&quot; x=&quot;325.0&quot; y=&quot;100.0&quot;&gt;&lt;/omgdc:Bounds&gt;\n      &lt;/bpmndi:BPMNShape&gt;\n      &lt;bpmndi:BPMNShape bpmnElement=&quot;endevent1&quot; id=&quot;BPMNShape_endevent1&quot;&gt;\n        &lt;omgdc:Bounds height=&quot;35.0&quot; width=&quot;35.0&quot; x=&quot;360.0&quot; y=&quot;200.0&quot;&gt;&lt;/omgdc:Bounds&gt;\n      &lt;/bpmndi:BPMNShape&gt;\n      &lt;bpmndi:BPMNEdge bpmnElement=&quot;flow1&quot; id=&quot;BPMNEdge_flow1&quot;&gt;&lt;/bpmndi:BPMNEdge&gt;\n      &lt;bpmndi:BPMNEdge bpmnElement=&quot;flow2&quot; id=&quot;BPMNEdge_flow2&quot;&gt;&lt;/bpmndi:BPMNEdge&gt;\n    &lt;/bpmndi:BPMNPlane&gt;\n  &lt;/bpmndi:BPMNDiagram&gt;\n&lt;/definitions&gt;\n</code></pre><p>重点代码  <strong>activiti:assignee=”crystal”</strong></p>\n<p>启动流程实例</p>\n<pre><code class=\"java\">public void start() {\n    ProcessInstance pi = runtimeService().startProcessInstanceByKey(&quot;task&quot;);\n}</code></pre>\n<p><strong>（2）方式二</strong></p>\n<p>定义流程图时配置任务节点变量，完成任务之前由流程变量指定任务办理人。在开发中，可以在页面中指定下一个任务的办理人，通过流程变量设置下一个任务的办理人。</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904183224.png\" alt></p>\n<p>定义的bpmn文件中定义任务办理人的名称</p>\n<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n&lt;definitions xmlns=&quot;http://www.omg.org/spec/BPMN/20100524/MODEL&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:xsd=&quot;http://www.w3.org/2001/XMLSchema&quot; xmlns:activiti=&quot;http://activiti.org/bpmn&quot; xmlns:bpmndi=&quot;http://www.omg.org/spec/BPMN/20100524/DI&quot; xmlns:omgdc=&quot;http://www.omg.org/spec/DD/20100524/DC&quot; xmlns:omgdi=&quot;http://www.omg.org/spec/DD/20100524/DI&quot; typeLanguage=&quot;http://www.w3.org/2001/XMLSchema&quot; expressionLanguage=&quot;http://www.w3.org/1999/XPath&quot; targetNamespace=&quot;http://www.activiti.org/test&quot;&gt;\n  &lt;process id=&quot;personalTask2&quot; name=&quot;PersonalTask2&quot; isExecutable=&quot;true&quot;&gt;\n    &lt;startEvent id=&quot;startevent1&quot; name=&quot;Start&quot;&gt;&lt;/startEvent&gt;\n    &lt;userTask id=&quot;usertask1&quot; name=&quot;审批&quot; activiti:assignee=&quot;#{userId}&quot;&gt;&lt;/userTask&gt;\n    &lt;sequenceFlow id=&quot;flow1&quot; sourceRef=&quot;startevent1&quot; targetRef=&quot;usertask1&quot;&gt;&lt;/sequenceFlow&gt;\n    &lt;endEvent id=&quot;endevent1&quot; name=&quot;End&quot;&gt;&lt;/endEvent&gt;\n    &lt;sequenceFlow id=&quot;flow2&quot; sourceRef=&quot;usertask1&quot; targetRef=&quot;endevent1&quot;&gt;&lt;/sequenceFlow&gt;\n  &lt;/process&gt;\n  &lt;bpmndi:BPMNDiagram id=&quot;BPMNDiagram_personalTask2&quot;&gt;\n    &lt;bpmndi:BPMNPlane bpmnElement=&quot;personalTask2&quot; id=&quot;BPMNPlane_personalTask2&quot;&gt;\n      &lt;bpmndi:BPMNShape bpmnElement=&quot;startevent1&quot; id=&quot;BPMNShape_startevent1&quot;&gt;\n        &lt;omgdc:Bounds height=&quot;35.0&quot; width=&quot;35.0&quot; x=&quot;380.0&quot; y=&quot;40.0&quot;&gt;&lt;/omgdc:Bounds&gt;\n      &lt;/bpmndi:BPMNShape&gt;\n      &lt;bpmndi:BPMNShape bpmnElement=&quot;usertask1&quot; id=&quot;BPMNShape_usertask1&quot;&gt;\n        &lt;omgdc:Bounds height=&quot;55.0&quot; width=&quot;105.0&quot; x=&quot;345.0&quot; y=&quot;110.0&quot;&gt;&lt;/omgdc:Bounds&gt;\n      &lt;/bpmndi:BPMNShape&gt;\n      &lt;bpmndi:BPMNShape bpmnElement=&quot;endevent1&quot; id=&quot;BPMNShape_endevent1&quot;&gt;\n        &lt;omgdc:Bounds height=&quot;35.0&quot; width=&quot;35.0&quot; x=&quot;380.0&quot; y=&quot;210.0&quot;&gt;&lt;/omgdc:Bounds&gt;\n      &lt;/bpmndi:BPMNShape&gt;\n      &lt;bpmndi:BPMNEdge bpmnElement=&quot;flow1&quot; id=&quot;BPMNEdge_flow1&quot;&gt;&lt;/bpmndi:BPMNEdge&gt;\n      &lt;bpmndi:BPMNEdge bpmnElement=&quot;flow2&quot; id=&quot;BPMNEdge_flow2&quot;&gt;&lt;/bpmndi:BPMNEdge&gt;\n    &lt;/bpmndi:BPMNPlane&gt;\n  &lt;/bpmndi:BPMNDiagram&gt;\n&lt;/definitions&gt;</code></pre><p>重点代码  <strong>activiti:assignee=”#{userId}”</strong></p>\n<p>启动流程实例，需要设置流程变量</p>\n<pre><code class=\"java\">public void start() {\n    Map&lt;String, Object&gt; variables = new HashMap&lt;String, Object&gt;();\n    variables.put(&quot;userId&quot;, &quot;crystal&quot;);\n    ProcessInstance pi = runtimeService().startProcessInstanceByKey(&quot;task&quot;,variables);\n}</code></pre>\n<p><strong>（3）方式三</strong></p>\n<p>流程图中不指定任务办理人，添加监听类，需要实现TaskListener接口</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904183040.png\" alt></p>\n<p>定义的bpmn文件中定义任务办理人的名称</p>\n<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n&lt;definitions xmlns=&quot;http://www.omg.org/spec/BPMN/20100524/MODEL&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:xsd=&quot;http://www.w3.org/2001/XMLSchema&quot; xmlns:activiti=&quot;http://activiti.org/bpmn&quot; xmlns:bpmndi=&quot;http://www.omg.org/spec/BPMN/20100524/DI&quot; xmlns:omgdc=&quot;http://www.omg.org/spec/DD/20100524/DC&quot; xmlns:omgdi=&quot;http://www.omg.org/spec/DD/20100524/DI&quot; typeLanguage=&quot;http://www.w3.org/2001/XMLSchema&quot; expressionLanguage=&quot;http://www.w3.org/1999/XPath&quot; targetNamespace=&quot;http://www.activiti.org/test&quot;&gt;\n  &lt;process id=&quot;personalTask3&quot; name=&quot;PersonalTask3&quot; isExecutable=&quot;true&quot;&gt;\n    &lt;startEvent id=&quot;startevent1&quot; name=&quot;Start&quot;&gt;&lt;/startEvent&gt;\n    &lt;userTask id=&quot;usertask1&quot; name=&quot;审批&quot;&gt;\n      &lt;extensionElements&gt;\n        &lt;activiti:taskListener event=&quot;create&quot; class=&quot;com.activiti.test.TaskListenerImpl&quot;&gt;&lt;/activiti:taskListener&gt;\n      &lt;/extensionElements&gt;\n    &lt;/userTask&gt;\n    &lt;sequenceFlow id=&quot;flow1&quot; sourceRef=&quot;startevent1&quot; targetRef=&quot;usertask1&quot;&gt;&lt;/sequenceFlow&gt;\n    &lt;endEvent id=&quot;endevent1&quot; name=&quot;End&quot;&gt;&lt;/endEvent&gt;\n    &lt;sequenceFlow id=&quot;flow2&quot; sourceRef=&quot;usertask1&quot; targetRef=&quot;endevent1&quot;&gt;&lt;/sequenceFlow&gt;\n  &lt;/process&gt;\n  &lt;bpmndi:BPMNDiagram id=&quot;BPMNDiagram_personalTask3&quot;&gt;\n    &lt;bpmndi:BPMNPlane bpmnElement=&quot;personalTask3&quot; id=&quot;BPMNPlane_personalTask3&quot;&gt;\n      &lt;bpmndi:BPMNShape bpmnElement=&quot;startevent1&quot; id=&quot;BPMNShape_startevent1&quot;&gt;\n        &lt;omgdc:Bounds height=&quot;35.0&quot; width=&quot;35.0&quot; x=&quot;310.0&quot; y=&quot;20.0&quot;&gt;&lt;/omgdc:Bounds&gt;\n      &lt;/bpmndi:BPMNShape&gt;\n      &lt;bpmndi:BPMNShape bpmnElement=&quot;usertask1&quot; id=&quot;BPMNShape_usertask1&quot;&gt;\n        &lt;omgdc:Bounds height=&quot;55.0&quot; width=&quot;105.0&quot; x=&quot;275.0&quot; y=&quot;100.0&quot;&gt;&lt;/omgdc:Bounds&gt;\n      &lt;/bpmndi:BPMNShape&gt;\n      &lt;bpmndi:BPMNShape bpmnElement=&quot;endevent1&quot; id=&quot;BPMNShape_endevent1&quot;&gt;\n        &lt;omgdc:Bounds height=&quot;35.0&quot; width=&quot;35.0&quot; x=&quot;310.0&quot; y=&quot;200.0&quot;&gt;&lt;/omgdc:Bounds&gt;\n      &lt;/bpmndi:BPMNShape&gt;\n      &lt;bpmndi:BPMNEdge bpmnElement=&quot;flow1&quot; id=&quot;BPMNEdge_flow1&quot;&gt;&lt;/bpmndi:BPMNEdge&gt;\n      &lt;bpmndi:BPMNEdge bpmnElement=&quot;flow2&quot; id=&quot;BPMNEdge_flow2&quot;&gt;&lt;/bpmndi:BPMNEdge&gt;\n    &lt;/bpmndi:BPMNPlane&gt;\n  &lt;/bpmndi:BPMNDiagram&gt;\n&lt;/definitions&gt;</code></pre><p>重点代码</p>\n<p><code>&lt;activiti:taskListener event=&quot;create&quot; class=&quot;com.activiti.test.TaskListenerImpl&quot;&gt;&lt;/activiti:taskListener&gt;</code></p>\n<p>监听类 TaskListenerImpl.java</p>\n<pre><code class=\"java\">package com.activiti.test;\nimport org.activiti.engine.delegate.DelegateTask;\nimport org.activiti.engine.delegate.TaskListener;\npublic class TaskListenerImpl implements TaskListener {\n    /**\n     * 指定个人任务和组任务的办理人\n     */\n    @Override\n    public void notify(DelegateTask delegateTask) {\n        delegateTask.setAssignee(&quot;crystal&quot;);// 指派个人任务\n    }\n}</code></pre>\n<p>启动流程实例</p>\n<pre><code class=\"java\">public void start() {\n    ProcessInstance pi = runtimeService().startProcessInstanceByKey(&quot;task&quot;);\n}</code></pre>\n<p>总结：</p>\n<pre><code class=\"java\">个人任务及三种分配方式： \n  1.在taskProcess.bpmn中直接写 assignee=”crystal” \n  2.在taskProcess.bpmn中写 assignee=“#{userID}”，变量的值要是String的（使用流程变量指定办理人）。 \n  3.使用TaskListener接口，要使类实现该接口\n    在类中定义： delegateTask.setAssignee(assignee);// 指定个人任务的办理人 \n  4.使用任务ID和办理人重新指定办理人： taskService.setAssignee(taskId, userId);</code></pre>\n<h3 id=\"4-3-组任务的三种指派方式\"><a href=\"#4-3-组任务的三种指派方式\" class=\"headerlink\" title=\"4.3 组任务的三种指派方式\"></a>4.3 组任务的三种指派方式</h3><p><strong>方式一：直接指定办理人</strong></p>\n<p>（1）.在任务节点设置办理人</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182327.png\" alt></p>\n<p>（2）bpmn中的代码片段</p>\n<pre><code> &lt;userTask activiti:candidateUsers=&quot;小a,小b,小c&quot; activiti:exclusive=&quot;true&quot; id=&quot;usertask1&quot; name=&quot;提交申请&quot;/&gt;</code></pre><p>（3）部署流程和启动流程</p>\n<pre><code class=\"java\">public void test(){\n    repositoryService.createDeployment().addClasspathResource(&quot;test1.bpmn&quot;).deploy();//部署流程\n    ProcessInstance pi = runtimeService.startProcessInstanceByKey(&quot;helloword&quot;);//启动流程\n}</code></pre>\n<p>（4）查询我的个人任务，没有执行结果</p>\n<pre><code class=\"java\"> public void queryTask(String assignee) {\n     List&lt;Task&gt; list = taskService.createTaskQuery().orderByTaskCreateTime()\n             .desc().taskAssignee(assignee).list();\n     if (list != null &amp;&amp; list.size() &gt; 0) {\n         for (Task task : list) {\n             System.out.println(&quot;任务ID：&quot; + task.getId());\n             System.out.println(&quot;任务的办理人：&quot; + task.getAssignee());\n             System.out.println(&quot;任务名称：&quot; + task.getName());\n             System.out.println(&quot;任务的创建时间：&quot; + task.getCreateTime());\n             System.out.println(&quot;流程实例ID：&quot; + task.getProcessInstanceId());\n             System.out.println(&quot;#######################################&quot;);\n         }\n     }\n}</code></pre>\n<p>（5）查询组任务，可以查到查询结果</p>\n<pre><code> public void findGroupTaskList(String candidateUser) {\n        List&lt;Task&gt; list = taskService.createTaskQuery().taskCandidateUser(candidateUser).list();\n        if (list != null &amp;&amp; list.size() &gt; 0) {\n            for (Task task : list) {\n                System.out.println(&quot;任务ID：&quot; + task.getId());\n                System.out.println(&quot;任务的办理人：&quot; + task.getAssignee());\n                System.out.println(&quot;任务名称：&quot; + task.getName());\n                System.out.println(&quot;任务的创建时间：&quot; + task.getCreateTime());\n                System.out.println(&quot;流程实例ID：&quot; + task.getProcessInstanceId());\n                System.out.println(&quot;#######################################&quot;);\n            }\n        }\n    }</code></pre><p>查询结果如下</p>\n<blockquote>\n<p>任务ID：15010<br>任务的办理人：null<br>任务名称：提交申请<br>任务的创建时间：Thu Apr 04 10:50:00 CST 2019<br>流程实例ID：15005</p>\n</blockquote>\n<p>（6）查询正在执行的组任务列表</p>\n<pre><code class=\"java\">public void findGroupCandidate(String taskId) {\n    List&lt;IdentityLink&gt; list = taskService.getIdentityLinksForTask(taskId);\n        if (list != null &amp;&amp; list.size() &gt; 0) {\n        for (IdentityLink identityLink : list) {\n            System.out.println(&quot;任务ID：&quot; + identityLink.getTaskId());\n            System.out.println(&quot;流程实例ID：&quot;+ identityLink.getProcessInstanceId());\n            System.out.println(&quot;用户ID：&quot; + identityLink.getUserId());\n            System.out.println(&quot;工作流角色ID：&quot; + identityLink.getGroupId());\n            System.out.println(&quot;#########################################&quot;);\n        }\n    }\n}</code></pre>\n<p>执行结果</p>\n<blockquote>\n<p>任务ID：15010<br>流程实例ID：null<br>用户ID：小a<br>工作流角色ID：null</p>\n<p>任务ID：15010<br>流程实例ID：null<br>用户ID：小b<br>工作流角色ID：null</p>\n<p>任务ID：15010<br>流程实例ID：null<br>用户ID：小c<br>工作流角色ID：null</p>\n</blockquote>\n<p>（7）查询历史的组任务列表</p>\n<pre><code class=\"java\">public void findHistoryGroupCandidate(String processInstanceId) {\n    String processInstanceId = &quot;3705&quot;;\n    List&lt;HistoricIdentityLink&gt; list = historyService\n            .getHistoricIdentityLinksForProcessInstance(processInstanceId);\n    if (list != null &amp;&amp; list.size() &gt; 0) {\n        for (HistoricIdentityLink identityLink : list) {\n            System.out.println(&quot;任务ID：&quot; + identityLink.getTaskId());\n            System.out.println(&quot;流程实例ID：&quot;+ identityLink.getProcessInstanceId());\n            System.out.println(&quot;用户ID：&quot; + identityLink.getUserId());\n            System.out.println(&quot;工作流角色ID：&quot; + identityLink.getGroupId());\n            System.out.println(&quot;#########################################&quot;);\n        }\n    }\n}</code></pre>\n<p>说明：     </p>\n<ul>\n<li>小A，小B，小C是组任务的办理人     </li>\n<li>但是这样分配组任务的办理人不够灵活，因为项目开发中任务的办理人不要放置XML文件中。     </li>\n<li>act_ru_identitylink表存放组任务的办理人，表示正在执行的任务     </li>\n<li>act_hi_identitylink表存放所有任务的办理人，包括个人任务和组任务<strong>，</strong>表示历史任务</li>\n</ul>\n<p><strong>方式二：使用流程变量</strong></p>\n<p> （1）在任务节点设置变量</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904183359.png\" alt></p>\n<p>（2）bpmn中的代码片段</p>\n<pre><code>&lt;userTask activiti:candidateUsers=&quot;#{userIDs}&quot; activiti:exclusive=&quot;true&quot; id=&quot;usertask1&quot; name=&quot;提交申请&quot;/&gt;</code></pre><p>（3）部署流程和启动流程</p>\n<p>启动流程实例的同时，设置流程变量，使用流程变量的方式设置下一个任务的办理人</p>\n<p> 流程变量的名称，是task.bpmn中定义activiti:candidateUsers=”#{userIDs}”的userIDs  流程变量的值，就是任务的办理人（组任务）</p>\n<pre><code class=\"java\">public void test(){\n    repositoryService.createDeployment().addClasspathResource(&quot;test1.bpmn&quot;).deploy();//部署流程\n    Map&lt;String, Object&gt; variables = new HashMap&lt;String, Object&gt;();\n    variables.put(&quot;userIDs&quot;, &quot;小a,小b,小c&quot;);\n    ProcessInstance pi = runtimeService.startProcessInstanceByKey(&quot;helloword&quot;,variables);//使用流程定义的key的最新版本启动流程\n}</code></pre>\n<p><strong>方式三：使用监听器</strong></p>\n<p>（1）设置监听器变量</p>\n<p><img src=\"https://img-blog.csdn.net/20151227154130920\" alt=\"img\"></p>\n<p>（2）编写监听器类</p>\n<pre><code>public class TaskListenerImpl implements TaskListener {\n    /**\n     * 可以设置任务的办理人（个人组人和组任务）\n     */\n    @Override\n    public void notify(DelegateTask delegateTask) {\n        //指定组任务\n        delegateTask.addCandidateUser(&quot;孙悟空&quot;);\n        delegateTask.addCandidateUser(&quot;猪八戒&quot;);\n    }\n}</code></pre><p>（3）测试代码</p>\n<pre><code class=\"java\">/**将组任务指定个人任务(拾取任务)*/\npublic void claim(){\n    String taskId = &quot;6308&quot;;\n    //个人任务的办理人\n    String userId = &quot;唐僧&quot;;\n    taskService.claim(taskId, userId);\n}\n\n/**将个人任务再回退到组任务（前提：之前这个任务是组任务）*/\npublic void setAssignee(){\n    String taskId = &quot;6308&quot;;\n    taskService.setAssignee(taskId, null);\n}\n\n/**向组任务中添加成员*/\npublic void addGroupUser(){\n    String taskId = &quot;6308&quot;;\n    //新增组任务的成员\n    String userId = &quot;如来&quot;;\n    taskService.addCandidateUser(taskId, userId);\n}\n\n/**向组任务中删除成员*/\npublic void deleteGroupUser(){\n    String taskId = &quot;6308&quot;;\n    //新增组任务的成员\n    String userId = &quot;猪八戒&quot;;\n    taskService.deleteCandidateUser(taskId, userId);\n}</code></pre>\n<p>总结：      以上就是分配组任务的三种方式，和分配个人任务相对应，同样有三种方式，与个人任务的操作相比，组任务操作增加了组任务分配个人任务（认领任务），个人任务分配给组任务，以及向组任务添加人员和向组任务删除人员的操作。</p>\n<h3 id=\"4-4-工作流提供的用户角色\"><a href=\"#4-4-工作流提供的用户角色\" class=\"headerlink\" title=\"4.4 工作流提供的用户角色\"></a>4.4 工作流提供的用户角色</h3><p>（1）设置用户角色</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182357.png\" alt></p>\n<p>这个【部门经理】相当于一个用户角色，一个角色可以对应多个人，比如有三个人：张三、李四是部门经理，王五是总经理，那我们可以把这三个人录入的我们自己的用户表中，那么工作流也给我们提供了至少三张表：用户表，角色表，用户角色关联表那我们就可以把部门经理这个角色与张三、李四关联起来</p>\n<p>（2）具体做法：1、添加用户角色组  2、创建角色3、创建用户4、创建角色用户关联关系测试代码如下：</p>\n<pre><code class=\"java\">public void addUser(){    \n        //创建角色(两个角色)\n        identityService.saveGroup(new GroupEntity(&quot;部门经理&quot;));\n        identityService.saveGroup(new GroupEntity(&quot;总经理&quot;));\n\n        //创建用户（三个用户）\n        identityService.saveUser(new UserEntity(&quot;张三&quot;));\n        identityService.saveUser(new UserEntity(&quot;李四&quot;));\n        identityService.saveUser(new UserEntity(&quot;王五&quot;));\n\n        //创建用户角色关联关系\n        identityService.createMembership(&quot;张三&quot;, &quot;部门经理&quot;);\n        identityService.createMembership(&quot;李四&quot;, &quot;部门经理&quot;);\n        identityService.createMembership(&quot;王五&quot;, &quot;总经理&quot;);\n}</code></pre>\n<p>（3）部署流程定义</p>\n<pre><code>public void deployementAndStart(){\n    Deployment deployment = repositoryService.createDeployment().name(&quot;组任务&quot;)\n                    .addClasspathResource(&quot;diagrams/group.bpmn&quot;)\n                    .addClasspathResource(&quot;diagrams/group.png&quot;).deploy();\n    ProcessInstance pi = runtimeService.startProcessInstanceByKey(&quot;group&quot;);//启动流程  \n}                </code></pre><p>（4）查询张三或者李四的任务</p>\n<pre><code>public void findGroupTask(){\n        String candidateUser = &quot;张三&quot;;\n        List&lt;Task&gt; list =taskService.createTaskQuery().taskCandidateUser(candidateUser).list();\n        if(list!=null &amp;&amp; list.size()&gt;0){  \n            for(Task task:list){  \n                System.out.println(&quot;任务ID：&quot;+task.getId());  \n                System.out.println(&quot;任务的办理人：&quot;+task.getAssignee());  \n                System.out.println(&quot;任务名称：&quot;+task.getName());  \n                System.out.println(&quot;任务的创建时间：&quot;+task.getCreateTime());  \n                System.out.println(&quot;流程实例ID：&quot;+task.getProcessInstanceId());  \n                System.out.println(&quot;#######################################&quot;);  \n            }  \n         }\n}</code></pre><p>执行结果</p>\n<blockquote>\n<p> 任务ID：167504 </p>\n<p> 任务的办理人：null </p>\n<p> 任务名称：审核 </p>\n<p> 任务的创建时间：Thu Jul 07 10:21:27 GMT+08:00 2016 </p>\n<p> 流程实例ID：167501 </p>\n</blockquote>\n<p>（5）候选者不一定真正的参与任务的办理，所以我们需要拾取任务，将组任务分配给个人任务,即指定任务办理人字段</p>\n<pre><code class=\"java\">public void cliam(){\n        //将组任务分配给个人任务\n        String taskId =&quot;167504&quot;;\n        //分配的个人任务（可以是组任务中的成员，也可以是非组任务的成员）\n        String userId =&quot;张三&quot;;\n        taskService.claim(taskId, userId);\n        //当执行完查询正执行的任务表（act_ru_task）可发现ASSIGNEE_字段（指定任务办理人）值为&#39;张三&#39;\n        //此时任务就指定给了张三，再用李四去查个人组任务就查询不出来任何任务【组任务最终也是需要指定一个人办理的，所以需要拾取任务】\n}\n</code></pre>\n<p>（6）张三完成任务</p>\n<pre><code class=\"java\">public void completeTask(){\n    String taskId =&quot;167504&quot;;\n    taskService.complete(taskId);\n}\n</code></pre>\n<p>当我们部署完流程定义，启动流程实例之后，我们可以查看您一下几张数据表：<strong>表act_ru_task</strong></p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904183255.png\" alt></p>\n<p> 可以看见任务办理人的字段值为null,所以可能有两种情况可能没有办理人或者可能这个任务是组任务</p>\n<p><strong>表act_ru_identitylink</strong>   正在执行的任务办理人表</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904183326.png\" alt></p>\n<p>在这个表可以看见Task_ID 的值为167504就是正在执行的任务ID，流程实例字段为空，所以这个任务是组任务，处理这个组任务的角色ID为部门经理而张三和李四都是这个角色的用户，所以张三李四都可以查到这个任务，也可以进行任务的拾取，分配等操作。</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182422.png\" alt></p>\n<p>需要说明的是在我们自己项目开发的时候，我们一般都是不用工作流自带的用户表、角色表，用户角色关联表都是自己来建，因为自带的表提供的字段不全。</p>\n<h3 id=\"4-5-任务签收与反签收\"><a href=\"#4-5-任务签收与反签收\" class=\"headerlink\" title=\"4.5 任务签收与反签收\"></a>4.5 任务签收与反签收</h3><pre><code class=\"java\">//任务签收\npublic void claim(String taskId) {\n   String userId = &quot;1111&quot;;\n   taskService.claim(taskId, userId);\n}\n\n//任务反签收\npublic String unclaim(String taskId) {\n    taskService.unclaim(taskId);\n}</code></pre>\n<h3 id=\"4-6-驳回申请\"><a href=\"#4-6-驳回申请\" class=\"headerlink\" title=\"4.6 驳回申请\"></a>4.6 驳回申请</h3><h3 id=\"4-7-流程变量的设置和获取\"><a href=\"#4-7-流程变量的设置和获取\" class=\"headerlink\" title=\"4.7  流程变量的设置和获取\"></a>4.7  流程变量的设置和获取</h3><p><strong>设置流程变量</strong></p>\n<p>流程变量的设置方式有两种，一是通过基本类型设置，第二种是通过JavaBean类型设置。</p>\n<p><strong>（1）基本类型</strong></p>\n<pre><code>    public void setProcessVariables(){\n        String processInstanceId = &quot;1301&quot;;//流程实例ID\n        String assignee = &quot;张三&quot;;//任务办理人\n        //查询当前办理人的任务ID\n        Task task = taskService.createTaskQuery()\n                .processInstanceId(processInstanceId)//使用流程实例ID\n                .taskAssignee(assignee)//任务办理人\n                .singleResult();\n        //设置流程变量【基本类型】\n        taskService.setVariable(task.getId(), &quot;请假人&quot;, assignee);\n        taskService.setVariableLocal(task.getId(), &quot;请假天数&quot;,3);\n        taskService.setVariable(task.getId(), &quot;请假日期&quot;, new Date());\n    }</code></pre><p>对应数据库表：act_ru_variable</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182451.png\" alt></p>\n<p><strong>（2）JavaBean类型</strong></p>\n<pre><code>public class Person{\n    private Integer id;\n    private String name;\n    private String education;\n}</code></pre><p>然后，通过JavaBean设置流程变量。这里要注意的是，Javabean类型设置获取流程变量，除了需要这个javabean实现了Serializable接口外，还要求流程变量对象的属性不能发生编号，否则抛出异常。 </p>\n<pre><code class=\"java\">public void setProcessVariables(){\n    String processInstanceId = &quot;1301&quot;;//流程实例ID\n    String assignee = &quot;张三&quot;;//任务办理人\n    //查询当前办理人的任务ID\n    Task task = taskService.createTaskQuery()\n        .processInstanceId(processInstanceId).taskAssignee(assignee).singleResult();\n    //设置流程变量【javabean类型】\n    Person p = new Person();\n    p.setId(1);\n    p.setName(&quot;周江霄&quot;);\n    taskService.setVariable(task.getId(), &quot;人员信息&quot;, p);\n}</code></pre>\n<p>数据库对应表：act_ru_variable，细心的你可以看到，通过JavaBean设置的流程变量，在act_ru_variable中存储的类型为serializable，变量真正存储的地方在act_ge_bytearray中</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182524.png\" alt> </p>\n<p> <strong>获取流程变量</strong></p>\n<p><strong>（1）基本类型</strong></p>\n<pre><code class=\"java\">public void getProcessVariables(){\n        String processInstanceId = &quot;1301&quot;;//流程实例ID\n        String assignee = &quot;张三&quot;;//任务办理人\n        TaskService taskService = processEngine.getTaskService();\n        //获取当前办理人的任务ID\n        Task task = taskService.createTaskQuery()\n                .processInstanceId(processInstanceId)\n                .taskAssignee(assignee)\n                .singleResult();\n        String person = (String) taskService.getVariable(task.getId(), &quot;请假人&quot;);\n        Integer day = (Integer) taskService.getVariableLocal(task.getId(), &quot;请假天数&quot;);\n        Date date = (Date) taskService.getVariable(task.getId(), &quot;请假日期&quot;);\n        System.out.println(person+&quot;  &quot;+day+&quot;   &quot;+date);\n}</code></pre>\n<p><strong>（2）JavaBean类型</strong></p>\n<pre><code class=\"java\">/**获取流程变量*/\n    @Test\n    public void getProcessVariables(){\n        String processInstanceId = &quot;1301&quot;;//流程实例ID\n        String assignee = &quot;张三&quot;;//任务办理人\n        //获取当前办理人的任务ID\n        Task task = taskService.createTaskQuery()\n                .processInstanceId(processInstanceId)\n                .taskAssignee(assignee)\n                .singleResult();\n        //获取流程变量【javaBean类型】\n        Person p = (Person) taskService.getVariable(task.getId(), &quot;人员信息&quot;);\n        System.out.println(p.getId()+&quot;  &quot;+p.getName());\n        System.out.println(&quot;获取成功~~&quot;);\n    }</code></pre>\n<p>  <strong>查询历史流程变量</strong> </p>\n<pre><code>/**查询历史的流程变量*/\npublic void getHistoryProcessVariables(){\n    List&lt;HistoricVariableInstance&gt; list = processEngine.getHistoryService()\n                .createHistoricVariableInstanceQuery()//创建一个历史的流程变量查询\n                .variableName(&quot;请假天数&quot;).list();\n    if(list != null &amp;&amp; list.size()&gt;0){\n        for(HistoricVariableInstance hiv : list){\n                System.out.println(\n                hiv.getTaskId()+&quot;  &quot;+hiv.getVariableName()+&quot;\n                &quot;+hiv.getValue()+&quot;        &quot;+hiv.getVariableTypeName());\n        }\n    }                \n}</code></pre><p>对应数据库表：act_ru_execution</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182542.png\" alt></p>\n<h3 id=\"4-8-查询所有的正在执行的任务\"><a href=\"#4-8-查询所有的正在执行的任务\" class=\"headerlink\" title=\"4.8 查询所有的正在执行的任务\"></a>4.8 查询所有的正在执行的任务</h3><pre><code class=\"java\">public void testQueryTask(){\n        ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();\n        List&lt;Task&gt; tasks = processEngine.getTaskService()\n                .createTaskQuery()\n                .list();\n        for (Task task : tasks) {\n            System.out.println(task.getName());\n        }\n}</code></pre>\n<h3 id=\"4-9-完成任务\"><a href=\"#4-9-完成任务\" class=\"headerlink\" title=\"4.9 完成任务\"></a>4.9 完成任务</h3><pre><code>public void complete(){\n        Task task=taskService.createTaskQuery()\n            .processInstanceId(pi.getId()).taskDefinitionKey(&quot;task&quot;).singleResult();\n        taskService.setVariable(task.getId(), &quot;var1&quot;, &quot;var1&quot;);\n         taskService.complete(task.getId());\n }</code></pre><p>以上代码是查询流程本次执行实例下名为task1的任务</p>\n<p>给任务设置全局变量，如果调用的是taskService.setVariableLocal方法，则任务执行完毕后，相关变量数据就会删除，然后再完成任务。</p>\n<p>首先向act_ru_variable表中插入变量信息，包含本次流程执行实例的两个id外键，但不包括任务的id，因为setVariable方法设置的是全局变量，也就是整个流程都会有效的变量</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182930.png\" alt>     </p>\n<p>此时整个流程执行完毕，act_ru_task，act_ru_execution和act_ru_variable表全被清空</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182951.png\" alt></p>\n<h2 id=\"五、历史任务\"><a href=\"#五、历史任务\" class=\"headerlink\" title=\"五、历史任务\"></a>五、历史任务</h2><h3 id=\"5-1-查已完成任务和当前在执行的任务\"><a href=\"#5-1-查已完成任务和当前在执行的任务\" class=\"headerlink\" title=\"5.1 查已完成任务和当前在执行的任务\"></a>5.1 查已完成任务和当前在执行的任务</h3><pre><code class=\"java\">public void findHistoryTask(){\n        ProcessEngine defaultProcessEngine = ProcessEngines.getDefaultProcessEngine();\n        //如果只想获取到已经执行完成的，那么就要加入completed这个过滤条件\n        List&lt;HistoricTaskInstance&gt; historicTaskInstances1 = defaultProcessEngine.getHistoryService()\n                .createHistoricTaskInstanceQuery()\n                .taskDeleteReason(&quot;completed&quot;)\n                .list();\n        //如果只想获取到已经执行完成的，那么就要加入completed这个过滤条件\n        List&lt;HistoricTaskInstance&gt; historicTaskInstances2 = defaultProcessEngine.getHistoryService()\n                .createHistoricTaskInstanceQuery()\n                .list();\n        System.out.println(&quot;执行完成的任务：&quot; + historicTaskInstances1.size());\n        System.out.println(&quot;所有的总任务数（执行完和当前未执行完）：&quot; +historicTaskInstances2.size());\n    }</code></pre>\n<p>Activiti 个人任务（三种指派方式） <a href=\"https://blog.csdn.net/caoyue_new/article/details/52180539\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/caoyue_new/article/details/52180539</a></p>\n<p>六：关于流程实例的相关API</p>\n<p><strong>涉及到的表：</strong>   </p>\n<p>*<em>act_hi_actinst  *</em></p>\n<p>1、说明 *         act:activiti  *         hi:history  *         actinst:activity instance  *            流程图上出现的每一个元素都称为activity  *            流程图上正在执行的元素或者已经执行完成的元素称为activity instance  *      2、字段 *         proc_def_id:pdid  *         proc_inst_id:流程实例ID  *         execution_id_:执行ID  *         act_id_:activity  *         act_name  *         act_type  </p>\n<p>*<em>act_hi_procinst *</em></p>\n<p>**      1、说明 *         procinst:process instance  历史的流程实例 *            正在执行的流程实例也在这张表中 *         如果end_time_为null，说明正在执行，如果有值，说明该流程实例已经结束了 *    _</p>\n<p><strong>act_hi_taskinst</strong></p>\n<pre><code> 1、说明 *          taskinst:task instance  历史任务 *             正在执行的任务也在这张表中 *             如果end_time_为null,说明该任务正在执行 *             如果end_time不为null,说明该任务已经执行完毕了 *    **act_ru_execution**</code></pre><p>_      1、说明 *         ru:runtime  *         代表正在执行的流程实例表 *         如果当期正在执行的流程实例结束以后，该行在这张表中就被删除掉了，所以该表也是一个临时表 *      2、字段 *         proc_inst_id_:piid  流程实例ID，如果不存在并发的情况下，piid和executionID是一样的 *         act_id:当前正在执行的流程实例(如果不考虑并发的情况)的正在执行的activity有一个，所以act_id就是当前正在执行的流程实例的正在执行的 *           节点 *    <strong>act_ru_task</strong>_</p>\n<p>1、代表正在执行的任务表    该表是一个临时表，如果当前任务被完成以后，任务在这张表中就被删除掉了 </p>\n<p>2、字段 </p>\n<p> id_:  主键    任务ID      execution_id_:执行ID    *              根据该ID查询出来的任务肯定是一个 *          proc_inst_id:piid  *              根据该id查询出来的任务 *                 如果没有并发，则是一个 *                 如果有并发，则是多个 *          name_:任务的名称 *          assignee_:任务的执行人**</p>\n<h2 id=\"六、工作流采购流程如何与业务关联\"><a href=\"#六、工作流采购流程如何与业务关联\" class=\"headerlink\" title=\"六、工作流采购流程如何与业务关联\"></a>六、工作流采购流程如何与业务关联</h2><p>实例.采购流程的监控</p>\n<ul>\n<li><p>查询当前获任务和业务关联</p>\n</li>\n<li><p>查询已经结束的流程</p>\n</li>\n<li><p>查询当前采购流程节点的位置图展示（在流程定义的节点上标出当前节点的位置，使用红色的框标出）</p>\n</li>\n<li><p>查询某个流程下的历史任务（从流程开始到运行结束）</p>\n</li>\n<li><p>查询某个用户所办理的历史任</p>\n</li>\n</ul>\n<p>2.流程变量</p>\n<ul>\n<li>全局变量</li>\n<li>局部变量</li>\n</ul>\n<p>3.连线分支</p>\n<p>设置连线的condition条件实现分支</p>\n<h3 id=\"6-1-流程定义图的画法\"><a href=\"#6-1-流程定义图的画法\" class=\"headerlink\" title=\"6.1 流程定义图的画法\"></a>6.1 流程定义图的画法</h3><p>流程图注意的东西</p>\n<p>（1）流程定义key  </p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182636.png\" alt></p>\n<p>（2）流程变量 ：</p>\n<p>分支条件：<strong>$</strong>(price&gt;=1000) 和<strong>$</strong>(price&lt;1000)</p>\n<p><img src=\"C:%5CUsers%5CAdministrator%5CAppData%5CLocal%5CTemp%5C1567592826450.png\" alt=\"1567592826450\"></p>\n<p>（3）人员设置流程变量</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182721.png\" alt></p>\n<p>其他和部门经理的设置方法一样</p>\n<p>部门经理审批的代办人流程变量  <strong>$</strong>{u} </p>\n<p>总经理审批的代办人流程变量  <strong>$</strong>{m} </p>\n<p>财务审批的代办人流程变量  <strong>$</strong>{c} </p>\n<p>（4）order.bpmn文件</p>\n<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;yes&quot;?&gt;\n&lt;definitions xmlns=&quot;http://www.omg.org/spec/BPMN/20100524/MODEL&quot; xmlns:activiti=&quot;http://activiti.org/bpmn&quot; xmlns:bpmndi=&quot;http://www.omg.org/spec/BPMN/20100524/DI&quot; xmlns:dc=&quot;http://www.omg.org/spec/DD/20100524/DC&quot; xmlns:di=&quot;http://www.omg.org/spec/DD/20100524/DI&quot; xmlns:tns=&quot;Examples&quot; xmlns:xsd=&quot;http://www.w3.org/2001/XMLSchema&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; expressionLanguage=&quot;http://www.w3.org/1999/XPath&quot; id=&quot;m1539757531057&quot; name=&quot;&quot; targetNamespace=&quot;Examples&quot; typeLanguage=&quot;http://www.w3.org/2001/XMLSchema&quot;&gt;\n  &lt;process id=&quot;orderKey&quot; isClosed=&quot;false&quot; isExecutable=&quot;true&quot; processType=&quot;None&quot;&gt;\n    &lt;startEvent id=&quot;_2&quot; name=&quot;StartEvent&quot;/&gt;\n    &lt;userTask activiti:assignee=&quot;#{u}&quot; activiti:exclusive=&quot;true&quot; id=&quot;_3&quot; name=&quot;部门经理审批&quot;/&gt;\n    &lt;sequenceFlow id=&quot;_7&quot; sourceRef=&quot;_2&quot; targetRef=&quot;_3&quot;/&gt;\n    &lt;userTask activiti:assignee=&quot;${c}&quot; activiti:exclusive=&quot;true&quot; id=&quot;_4&quot; name=&quot;财务审批&quot;/&gt;\n    &lt;userTask activiti:assignee=&quot;${m}&quot; activiti:exclusive=&quot;true&quot; id=&quot;_5&quot; name=&quot;总经理审批&quot;/&gt;\n    &lt;endEvent id=&quot;_6&quot; name=&quot;EndEvent&quot;/&gt;\n    &lt;sequenceFlow id=&quot;_8&quot; sourceRef=&quot;_4&quot; targetRef=&quot;_6&quot;/&gt;\n    &lt;sequenceFlow id=&quot;_9&quot; sourceRef=&quot;_3&quot; targetRef=&quot;_4&quot;&gt;\n      &lt;conditionExpression xsi:type=&quot;tFormalExpression&quot;&gt;&lt;![CDATA[${price &lt; 1000} ]]&gt;&lt;/conditionExpression&gt;\n    &lt;/sequenceFlow&gt;\n    &lt;sequenceFlow id=&quot;_10&quot; sourceRef=&quot;_3&quot; targetRef=&quot;_5&quot;&gt;\n      &lt;conditionExpression xsi:type=&quot;tFormalExpression&quot;&gt;&lt;![CDATA[${price &gt;= 1000} ]]&gt;&lt;/conditionExpression&gt;\n    &lt;/sequenceFlow&gt;\n    &lt;sequenceFlow id=&quot;_11&quot; sourceRef=&quot;_5&quot; targetRef=&quot;_4&quot;/&gt;\n  &lt;/process&gt;\n  &lt;bpmndi:BPMNDiagram documentation=&quot;background=#32424A;count=1;horizontalcount=1;orientation=0;width=842.4;height=1195.2;imageableWidth=832.4;imageableHeight=1185.2;imageableX=5.0;imageableY=5.0&quot; id=&quot;Diagram-_1&quot; name=&quot;New Diagram&quot;&gt;\n    &lt;bpmndi:BPMNPlane bpmnElement=&quot;orderKey&quot;&gt;\n      &lt;bpmndi:BPMNShape bpmnElement=&quot;_2&quot; id=&quot;Shape-_2&quot;&gt;\n        &lt;dc:Bounds height=&quot;32.0&quot; width=&quot;32.0&quot; x=&quot;100.0&quot; y=&quot;10.0&quot;/&gt;\n        &lt;bpmndi:BPMNLabel&gt;\n          &lt;dc:Bounds height=&quot;32.0&quot; width=&quot;32.0&quot; x=&quot;0.0&quot; y=&quot;0.0&quot;/&gt;\n        &lt;/bpmndi:BPMNLabel&gt;\n      &lt;/bpmndi:BPMNShape&gt;\n      &lt;bpmndi:BPMNShape bpmnElement=&quot;_3&quot; id=&quot;Shape-_3&quot;&gt;\n        &lt;dc:Bounds height=&quot;55.0&quot; width=&quot;85.0&quot; x=&quot;75.0&quot; y=&quot;95.0&quot;/&gt;\n        &lt;bpmndi:BPMNLabel&gt;\n          &lt;dc:Bounds height=&quot;55.0&quot; width=&quot;85.0&quot; x=&quot;0.0&quot; y=&quot;0.0&quot;/&gt;\n        &lt;/bpmndi:BPMNLabel&gt;\n      &lt;/bpmndi:BPMNShape&gt;\n      &lt;bpmndi:BPMNShape bpmnElement=&quot;_4&quot; id=&quot;Shape-_4&quot;&gt;\n        &lt;dc:Bounds height=&quot;55.0&quot; width=&quot;85.0&quot; x=&quot;70.0&quot; y=&quot;220.0&quot;/&gt;\n        &lt;bpmndi:BPMNLabel&gt;\n          &lt;dc:Bounds height=&quot;55.0&quot; width=&quot;85.0&quot; x=&quot;0.0&quot; y=&quot;0.0&quot;/&gt;\n        &lt;/bpmndi:BPMNLabel&gt;\n      &lt;/bpmndi:BPMNShape&gt;\n      &lt;bpmndi:BPMNShape bpmnElement=&quot;_5&quot; id=&quot;Shape-_5&quot;&gt;\n        &lt;dc:Bounds height=&quot;55.0&quot; width=&quot;85.0&quot; x=&quot;295.0&quot; y=&quot;95.0&quot;/&gt;\n        &lt;bpmndi:BPMNLabel&gt;\n          &lt;dc:Bounds height=&quot;55.0&quot; width=&quot;85.0&quot; x=&quot;0.0&quot; y=&quot;0.0&quot;/&gt;\n        &lt;/bpmndi:BPMNLabel&gt;\n      &lt;/bpmndi:BPMNShape&gt;\n      &lt;bpmndi:BPMNShape bpmnElement=&quot;_6&quot; id=&quot;Shape-_6&quot;&gt;\n        &lt;dc:Bounds height=&quot;32.0&quot; width=&quot;32.0&quot; x=&quot;95.0&quot; y=&quot;380.0&quot;/&gt;\n        &lt;bpmndi:BPMNLabel&gt;\n          &lt;dc:Bounds height=&quot;32.0&quot; width=&quot;32.0&quot; x=&quot;0.0&quot; y=&quot;0.0&quot;/&gt;\n        &lt;/bpmndi:BPMNLabel&gt;\n      &lt;/bpmndi:BPMNShape&gt;\n      &lt;bpmndi:BPMNEdge bpmnElement=&quot;_7&quot; id=&quot;BPMNEdge__7&quot; sourceElement=&quot;_2&quot; targetElement=&quot;_3&quot;&gt;\n        &lt;di:waypoint x=&quot;116.0&quot; y=&quot;42.0&quot;/&gt;\n        &lt;di:waypoint x=&quot;116.0&quot; y=&quot;95.0&quot;/&gt;\n        &lt;bpmndi:BPMNLabel&gt;\n          &lt;dc:Bounds height=&quot;0.0&quot; width=&quot;0.0&quot; x=&quot;0.0&quot; y=&quot;0.0&quot;/&gt;\n        &lt;/bpmndi:BPMNLabel&gt;\n      &lt;/bpmndi:BPMNEdge&gt;\n      &lt;bpmndi:BPMNEdge bpmnElement=&quot;_8&quot; id=&quot;BPMNEdge__8&quot; sourceElement=&quot;_4&quot; targetElement=&quot;_6&quot;&gt;\n        &lt;di:waypoint x=&quot;111.0&quot; y=&quot;275.0&quot;/&gt;\n        &lt;di:waypoint x=&quot;111.0&quot; y=&quot;380.0&quot;/&gt;\n        &lt;bpmndi:BPMNLabel&gt;\n          &lt;dc:Bounds height=&quot;0.0&quot; width=&quot;0.0&quot; x=&quot;0.0&quot; y=&quot;0.0&quot;/&gt;\n        &lt;/bpmndi:BPMNLabel&gt;\n      &lt;/bpmndi:BPMNEdge&gt;\n      &lt;bpmndi:BPMNEdge bpmnElement=&quot;_9&quot; id=&quot;BPMNEdge__9&quot; sourceElement=&quot;_3&quot; targetElement=&quot;_4&quot;&gt;\n        &lt;di:waypoint x=&quot;115.0&quot; y=&quot;150.0&quot;/&gt;\n        &lt;di:waypoint x=&quot;115.0&quot; y=&quot;220.0&quot;/&gt;\n        &lt;bpmndi:BPMNLabel&gt;\n          &lt;dc:Bounds height=&quot;0.0&quot; width=&quot;0.0&quot; x=&quot;0.0&quot; y=&quot;0.0&quot;/&gt;\n        &lt;/bpmndi:BPMNLabel&gt;\n      &lt;/bpmndi:BPMNEdge&gt;\n      &lt;bpmndi:BPMNEdge bpmnElement=&quot;_11&quot; id=&quot;BPMNEdge__11&quot; sourceElement=&quot;_5&quot; targetElement=&quot;_4&quot;&gt;\n        &lt;di:waypoint x=&quot;340.0&quot; y=&quot;150.0&quot;/&gt;\n        &lt;di:waypoint x=&quot;340.0&quot; y=&quot;190.0&quot;/&gt;\n        &lt;di:waypoint x=&quot;155.0&quot; y=&quot;247.5&quot;/&gt;\n        &lt;bpmndi:BPMNLabel&gt;\n          &lt;dc:Bounds height=&quot;0.0&quot; width=&quot;0.0&quot; x=&quot;0.0&quot; y=&quot;0.0&quot;/&gt;\n        &lt;/bpmndi:BPMNLabel&gt;\n      &lt;/bpmndi:BPMNEdge&gt;\n      &lt;bpmndi:BPMNEdge bpmnElement=&quot;_10&quot; id=&quot;BPMNEdge__10&quot; sourceElement=&quot;_3&quot; targetElement=&quot;_5&quot;&gt;\n        &lt;di:waypoint x=&quot;160.0&quot; y=&quot;122.5&quot;/&gt;\n        &lt;di:waypoint x=&quot;295.0&quot; y=&quot;122.5&quot;/&gt;\n        &lt;bpmndi:BPMNLabel&gt;\n          &lt;dc:Bounds height=&quot;0.0&quot; width=&quot;0.0&quot; x=&quot;0.0&quot; y=&quot;0.0&quot;/&gt;\n        &lt;/bpmndi:BPMNLabel&gt;\n      &lt;/bpmndi:BPMNEdge&gt;\n    &lt;/bpmndi:BPMNPlane&gt;\n  &lt;/bpmndi:BPMNDiagram&gt;\n&lt;/definitions&gt;\n</code></pre><blockquote>\n<p>关键点  <process id=\"orderKey\" isclosed=\"false\" isexecutable=\"true\" processtype=\"None\"></process></p>\n</blockquote>\n<h3 id=\"6-2流程定义的部署\"><a href=\"#6-2流程定义的部署\" class=\"headerlink\" title=\"6.2流程定义的部署\"></a>6.2流程定义的部署</h3><p>activitiService.java</p>\n<pre><code class=\"java\">public void deployByClassPath(String bpmnName) {\n        Deployment deploy =       repositoryService.createDeployment().addClasspathResource(bpmnName+&quot;.bpmn&quot;).deploy();\n        printDeploy(deploy);\n    }</code></pre>\n<pre><code class=\"java\">@RequestMapping(&quot;/deploy&quot;)\n@ResponseBody\npublic String deploy(String bpmnName) {\n    activitiService.deployByClassPath(bpmnName);\n    activitiService.queryDeployList();\n    return &quot;deploy&quot;;\n}</code></pre>\n<h3 id=\"6-3-流程实例启动时关联业务\"><a href=\"#6-3-流程实例启动时关联业务\" class=\"headerlink\" title=\"6.3 流程实例启动时关联业务\"></a>6.3 流程实例启动时关联业务</h3><p>使用activiti自带表act_ru_execution中的BUSINESS_KEY字段我存在业务的唯一表示 </p>\n<pre><code class=\"java\">/**\n* 流程变量\n* 给&lt;userTask activiti:assignee=&quot;#{u}&quot; activiti:exclusive=&quot;true&quot; name=&quot;部门经理审批&quot;/&gt;的u赋值\n* 给&lt;userTask activiti:assignee=&quot;#{m}&quot; activiti:exclusive=&quot;true&quot; name=&quot;总经理审批&quot;/&gt;的u赋值\n* 给&lt;userTask activiti:assignee=&quot;#{c}&quot; activiti:exclusive=&quot;true&quot; name=&quot;财务审批&quot;/&gt;的u赋值\n* 给&lt;conditionExpression xsi:type=&quot;tFormalExpression&quot;&gt;&lt;![CDATA[${price &lt; 1000}]]&gt;\n* &lt;/conditionExpression&gt;的price赋值\n* 同时设置业务key bussinessKey\n*/\npublic &lt;T&gt; void startProcess(String processDefinitionId,T t){\n    HashMap&lt;String, Object&gt; map = new HashMap&lt;&gt;();\n    map.put(&quot;u&quot;, &quot;u&quot;);\n    map.put(&quot;m&quot;, &quot;m&quot;);\n    map.put(&quot;c&quot;, &quot;c&quot;);\n    map.put(&quot;price&quot;, &quot;1200&quot;);// 分别测试流程走的分支条件 map.put(&quot;price&quot;, &quot;300&quot;);\n    runtimeService.startProcessInstanceByKey(key, map);\n    String bussinessKey= t.getClass().getName()+&quot;:&quot;+t.getId();\n    runtimeService.startProcessInstanceById(processDefinitionId,bussinessKey,map);\n}</code></pre>\n<p>启动流程是第二个参数就是表act_ru_execution中的BUSINESS_KEY字段，我一般喜欢使用业务名+ id来存储当前业务</p>\n<h3 id=\"6-4-查询当前获任务和业务关联\"><a href=\"#6-4-查询当前获任务和业务关联\" class=\"headerlink\" title=\"6.4 查询当前获任务和业务关联\"></a>6.4 查询当前获任务和业务关联</h3><p>通过task获得当前流程，通过当前流程获取当前流程的业务id</p>\n<p>查询属性：流程实例id，当前节点，采购名称，采购金额</p>\n<pre><code class=\"java\">/**\n     * \n     * @param assignee 任务办理人\n     */\npublic void getTaskDetailByAassignee(String assignee){\n    List&lt;Task&gt; tasks = taskService.createTaskQuery().taskAssignee(assignee).list();\n    for (Task task : tasks) {\n        String processInstanceId = task.getProcessInstanceId();\n        ProcessInstance processInstance = runtimeService.createProcessInstanceQuery().processInstanceId(processInstanceId).singleResult();\n        String businessKey = processInstance.getBusinessKey();\n        //当前运行的流程节点\n        String activityId = processInstance.getActivityId();\n        System.out.println(&quot;processInstanceId:&quot;+processInstanceId+&quot; businessKey:&quot;+businessKey+&quot; activityId:&quot;+activityId);\n        //业务主键id\n        Integer id;\n        if(StringUtils.isNotEmpty(businessKey)){\n            id=Integer.parseInt(businessKey.split(&quot;:&quot;)[1]);\n            //根据id查询出业务信息\n        }\n    }\n}</code></pre>\n<h3 id=\"6-5-查询已经结束的流程\"><a href=\"#6-5-查询已经结束的流程\" class=\"headerlink\" title=\"6.5 查询已经结束的流程\"></a>6.5 查询已经结束的流程</h3><p>通过task获得当前流程，通过当前流程获取当前流程的业务id</p>\n<p>查询属性：流程实例id，执行开始时间，执行结束时间，采购名称，采购金额</p>\n<h3 id=\"6-6-包含流程变量条件的流程\"><a href=\"#6-6-包含流程变量条件的流程\" class=\"headerlink\" title=\"6.6 包含流程变量条件的流程\"></a>6.6 包含流程变量条件的流程</h3><h3 id=\"6-6-对采购单的金额进行统计查询-如统计金额的总和\"><a href=\"#6-6-对采购单的金额进行统计查询-如统计金额的总和\" class=\"headerlink\" title=\"6.6 对采购单的金额进行统计查询 如统计金额的总和\"></a>6.6 对采购单的金额进行统计查询 如统计金额的总和</h3><p>（1）先查询已经结束的流程，用关联sql的方式 不好</p>\n<p>（2）最直接的方法，只从业务系统中查询采购单的信息，并统计。因为统计的数据是业务数据，业务系统只负责业务数据。但是面临的一个问题是，并不知道业务系统中的哪些采购单是已经结束了的。</p>\n<p>如果，在采购单业务表中加入一个字段status，则表中有采购单结束的标识。</p>\n<p>实现方法：</p>\n<p><strong>方法1：</strong> taskListener监听器的方法</p>\n<p>在流程定义的最后一个节点定义一个监听器，此监听器在完成任务的时候执行，在监听器中更新采购单业务表中的status字段的值，如：complete完成。</p>\n<p><strong>方法2：</strong>executionListener监听器的方法</p>\n<p>在endevent节点上添加executionListener监听器的方法，监听事件选择end</p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904182803.png\" alt></p>\n<h2 id=\"七、业务开发总结\"><a href=\"#七、业务开发总结\" class=\"headerlink\" title=\"七、业务开发总结\"></a>七、业务开发总结</h2><p>觉得不需要用activitEntity保存那么多的属性id  processInstanceId和 只需要  查询task列表的时候可以返回一个List<hashmap>，其实可以不需要 因为有businessEntity</hashmap></p>\n<p>1.新建一个activitEntity.java包含两个字段id和流程实例Id</p>\n<pre><code>public ActivitEntity{\n    private String id;\n    private String processInstanceId;\n}</code></pre><p>2.业务表单继承ActivitEntity基类</p>\n<p>3.保存业务表单的时候启动一个流程，创建采购单时，在填写新增记录保存时，启动流程实例。</p>\n<p>4.业务service层执行的时候，要确定业务key，uuid以及启动流程之后返回的流程实例id</p>\n<p>5.启动流程的时候，如果用流程定义Id的话，感觉不太好，应为部署的问题，所以建议使用startBykey的方式</p>\n<pre><code>public ActivitService{\n    private void saveOrder(){\n        Order order=new Order();\n        String id=UUid.gen();\n        order.setId(id);\n        //String businessKey=Order.getClass().getName()+&quot;:&quot;+id;//业务key 用类名和id组合 order:id\n        Map&lt;String, Object&gt; variables=new Hash&lt;&gt;();\n        //String processDefinitionId=&quot;11&quot;;\n        String processDefinitionKey=&quot;从部署bpmn文件中获取&quot;  //有工具类可以获取到这key 网络搜素一下\n        //调用服务的方式\n        //ActivitClient.startProcess(processDefinitionId,order,variables)\n        ActivitClient.startProcess(processDefinitionKey,order,variables)\n    }\n}\n\n\npublic &lt;T extends ActivitEntity&gt; void startProcess(String processDefinitionKey,T t,Map&lt;String, Object&gt; variables){\n        String bussinessKey= t.getClass().getName()+&quot;:&quot;+t.getId(); //业务key 用类名和id组合 order:id\n\n         //runtimeService.startProcessInstanceById(processDefinitionId,bussinessKey,variables);\n         runtimeService.startProcessInstanceByKey(processDefinitionKey,bussinessKey,variables);\n}</code></pre><p>6.为防止对采购单的业务数据进行修改，所以，创建采购单的人要提交申请，在提交申请之前，是可以对数据进行修改的，提交申请之后，数据不能修改，同时任务流向下一个节点。</p>\n<p>7.待提交的采购单如何查询</p>\n<p>利用activiti的taskservice查询出当前用户的代办任务</p>\n<p>任务的名称，任务的待办人，任务申请人，任务提交的时间，采购金额，采购类型</p>\n<p>8.提交采购单  当前任务的taskid  taskService.coomplete(taskid);</p>\n<p>9.审核业务（另起数据表–审核表—字段包含 id,采购单,采购申请人,采购类型，审核意见，审核状态0不同意，1通过，审核时间）</p>\n<p>进入审核页面  填写审核信息  提交审核  </p>\n<p>业务逻辑 ：保存审核意见到审核表中，然后再用activit完成任务</p>\n"},{"title":"大数据","date":"2019-08-09T12:32:59.000Z","password":123,"abstract":"欢迎来到test, 请输入密码.","message":"欢迎来到test, 请输入密码.","toc":false,"mathjax":false,"_content":"\n# scala\n\n## 一.scala的maven在IDE中的搭建\n\n1.开始创建项目体系结构\nFile --> Project \n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904175253.png)\n\n\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904175319.png)\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904175417.png)\n\n\n\n\n![输入图片说明](https://static.oschina.net/uploads/img/201802/11153427_h2XW.png \"在这里输入图片标题\")\n\n2.修改pom.xml\n\n```\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\">\n  <modelVersion>4.0.0</modelVersion>\n  <groupId>scala_maven</groupId>\n  <artifactId>com.chen</artifactId>\n  <version>1.0-SNAPSHOT</version>\n  <inceptionYear>2008</inceptionYear>\n  <properties>\n    <scala.version>2.11.7</scala.version>\n  </properties>\n\n  <dependencies>\n    <dependency>\n      <groupId>org.scala-lang</groupId>\n      <artifactId>scala-library</artifactId>\n      <version>${scala.version}</version>\n    </dependency>\n\n    <dependency>\n      <groupId>com.typesafe.akka</groupId>\n      <artifactId>akka-actor_2.11</artifactId>\n      <version>2.5.3</version>\n    </dependency>\n    <dependency>\n      <groupId>org.specs</groupId>\n      <artifactId>specs</artifactId>\n      <version>1.2.5</version>\n      <scope>test</scope>\n    </dependency>\n  </dependencies>\n\n  <build>\n    <sourceDirectory>src/main/scala</sourceDirectory>\n    <testSourceDirectory>src/test/scala</testSourceDirectory>\n    <plugins>\n      <plugin>\n        <groupId>org.scala-tools</groupId>\n        <artifactId>maven-scala-plugin</artifactId>\n        <executions>\n          <execution>\n            <goals>\n              <goal>compile</goal>\n              <goal>testCompile</goal>\n            </goals>\n          </execution>\n        </executions>\n        <configuration>\n          <scalaVersion>${scala.version}</scalaVersion>\n          <args>\n            <arg>-target:jvm-1.5</arg>\n          </args>\n        </configuration>\n      </plugin>\n      <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-eclipse-plugin</artifactId>\n        <configuration>\n          <downloadSources>true</downloadSources>\n          <buildcommands>\n            <buildcommand>ch.epfl.lamp.sdt.core.scalabuilder</buildcommand>\n          </buildcommands>\n          <additionalProjectnatures>\n            <projectnature>ch.epfl.lamp.sdt.core.scalanature</projectnature>\n          </additionalProjectnatures>\n          <classpathContainers>\n            <classpathContainer>org.eclipse.jdt.launching.JRE_CONTAINER</classpathContainer>\n            <classpathContainer>ch.epfl.lamp.sdt.launching.SCALA_CONTAINER</classpathContainer>\n          </classpathContainers>\n        </configuration>\n      </plugin>\n    </plugins>\n  </build>\n  <reporting>\n    <plugins>\n      <plugin>\n        <groupId>org.scala-tools</groupId>\n        <artifactId>maven-scala-plugin</artifactId>\n        <configuration>\n          <scalaVersion>${scala.version}</scalaVersion>\n        </configuration>\n      </plugin>\n    </plugins>\n  </reporting>\n</project>\n\n```\n\n> **注意：如果有akka-actor的话  要和scala的版本相对应**\n>\n\n![](https://static.oschina.net/uploads/space/2018/0211/155017_Suab_3005534.png)\n\n\n\n\n\n## 二.scala的单词拆分\n\n```\nvar word=Array(\"hello tom hello jelly\",\"tom jelly\",\"hello world hello tom\",\"hello jelly\",\"hello tom\")\nvar b=word.flatMap(_.split(\" \")).map((_,1)).groupBy(_._1).map(m=>(m._1,m._2.map(x=>x._2).sum)).toArray\nb.sortWith(_._2 > _._2).toMap\nres33: scala.collection.immutable.Map[String,Int] = Map(hello -> 6, tom -> 4, jelly -> 3, world -> 1)\n```\n\n或者\n```\nscala> b.toSeq.sortWith(_._2>_._2).toMap\nres32: scala.collection.immutable.Map[String,Int] = Map(hello -> 6, tom -> 4, jelly -> 3, world -> 1)\n```\n\n扩展：\n```\na=Map()//数据清空使用再次new\nprintln(a.size)\na.toSeq.sortBy(_._1)//升序排序 key\na.toSeq.sortBy(_._2)//升序排序 value\na.toSeq.sortWith(_._1>_._1) //降序排序 key\na.toSeq.sortWith(_._2>_._2) //降序排序 value\n```\n\n```\nscala> var word=Array(\"hello tom hello jelly\",\"tom jelly\",\"hello world hello tom\",\"hello jelly\",\"hello tom\")\n\nscala> word.flatMap(_.split(\" \"))  //将数组中每个元素，按照空格切分并且扁平化\nres34: Array[String] = Array(hello, tom, hello, jelly, tom, jelly, hello, world, hello, tom, hello, jelly, hello, tom)\n\nscala> word.flatMap(_.split(\" \")).map((_,1))  //将数组中每个单词，转成元组，并标记1\nres35: Array[(String, Int)] = Array((hello,1), (tom,1), (hello,1), (jelly,1), (tom,1), (jelly,1), (hello,1), (world,1), (hello,1), (tom,1), (hello,1), (jelly,1), (hello,1), (tom,1))\n\nscala> word.flatMap(_.split(\" \")).map((_,1)).groupBy(_._1)//将元组的数组中按照元组的第一个元素排序\nres36: scala.collection.immutable.Map[String,Array[(String, Int)]] = Map(world -> Array((world,1)), tom -> Array((tom,1), (tom,1), (tom,1), (tom,1)), hello -> Array((hello,1), (hello,1), (hello,1), (hello,1), (hello,1), (hello,1)), jelly -> Array((jelly,1), (jelly,1), (jelly,1)))\n\nscala> word.flatMap(_.split(\" \")).map((_,1)).groupBy(_._1).map(m=>(m._1,m._2.map(x=>x._2).sum)) //将排序后的元组进行数值求和\nres37: scala.collection.immutable.Map[String,Int] = Map(world -> 1, tom -> 4, hello -> 6, jelly -> 3)\n\nscala> word.flatMap(_.split(\" \")).map((_,1)).groupBy(_._1).map(m=>(m._1,m._2.map(x=>x._2).sum)).toArray\n//将排序求和后的map转化成元组方便排序\nres38: Array[(String, Int)] = Array((world,1), (tom,4), (hello,6), (jelly,3))\n\nscala> word.flatMap(_.split(\" \")).map((_,1)).groupBy(_._1).map(m=>(m._1,m._2.map(x=>x._2).sum)).toArray.sortWith(_._2 > _._2) //将排序求和后的map转化成元组排序\nres39: Array[(String, Int)] = Array((hello,6), (tom,4), (jelly,3), (world,1))\n\nscala> word.flatMap(_.split(\" \")).map((_,1)).groupBy(_._1).map(m=>(m._1,m._2.map(x=>x._2).sum)).toArray.sortWith(_._2 > _._2).toMap //转化回来map\nres40: scala.collection.immutable.Map[String,Int] = Map(hello -> 6, tom -> 4, jelly -> 3, world -> 1)\n\n\n\n```\n\n##  三.数组常见方法汇总\n\n**array学习笔记**\n\n数组要点\n1.若长度固定则使用Array，若长度可能有变化则使用ArrayBuffer\n2.提供初始值时不要使用new\n3.用()来访问元素\n4.用for(elem <- arr) 来遍历元素\n5.用for(elem <- array if ...) ... yield 来将原数组转型为新数组\n6.Scala数组和Java数组可以互操作，用ArrayBuffer，使用scala.collection.JavaConversions中的转换函数。\n定长数组 如果数组长度不变，则可使用scala中的Array，例如：\n\n```\nval nums = new Array[Int](10)    //10个整数的数组，所有元素初始化为0\nval string = new Array[String](10) //10个元素的字符串数组，所有元素被初始化为null\nval s = Array(\"hello\",\"scala\")  //长度为2的Array[String]——类型是推断出来的。已提供初始值，不需要new\n```\n变长数组\n对于那种长度按需要变化的数组，Java有ArrayList，C++有vector。Scalable中有等效的数据结构为：ArrayBuffer\n```\nimport scala.collection.mutable.ArrayBuffer\nval b = ArrayBuffer[Int]()\n//或者new ArrayBuffer[Int]\n//一个空的数组缓冲，准备存放整数\nb += 1   //ArrayBuffer(1),用+=在尾部添加元素\nb += (1,2,3,4)     //在尾部添加多个元素\n \nb ++= Array(8,12,13)   //可以用++=操作符追加任何集合\nb.trimEnd(5)  //移除最后5个元素\n\n//在任意 位置添加元素\nb.insert(2,6)   //在下标2之前插入\nb.insert(2,6,7,8)   //在下标2之前插入6,7,8\n\nb.remove(2)   //移除下标为2的位置开始移除元素\nb.remove(2,3)  //从下标为2开始移除3个元素；第二个参数是表示移除元素的个数\n```\n在使用时，有时不确定数组需要装元素的个数。此时，可以先构建一个数组缓冲，然后调用\n```\nb.toArray   //将缓冲数组转换为定长数组\n```\n定长数组也可以转换为缓冲数组\n```\na.toBuffer\n```\n遍历数组和数组缓冲\n\n使用for循环遍历数组和数组缓冲\n使用下标的方式\n```\nfor (i <- 0 until a.length){\n    println( i + \":\" + a(i))\n}\n```\nuntil用法扩展：这只步长--> 0 until (a.length,2)  从数组尾部开始-->(0 until a.length).reverse\n不使用下标访问数组元素\n```\nfor (elem <- arrName) {println(elem)}\n```\n数组转换\n```\nval a = Array(2,3,4)\nval result = for (elem <- a) yield 2 * elem\nfor (elem <-  a if elem %2==0) yield 2 * elem\n```\n常用算法\n```\nsum: Array(1,2,3).sum\nmax/min : Array(1,2,3).max/min\nsorted : Array(1,2,3).sorted(_ < ) ; Array(1,2,3).sorted( > _) //不能对缓冲数组排序\nquickSort方法排序：scala.util.Sorting.quickSort(a)\n显示数组内容：mkString; a.mkString(\" and \") //可以设置分隔符\n```\n\n1、定长数组定义：\n```\n//定义一个长度为10的数值数组\nscala> val numberArray = new Array[int](10)\nnumberArray:Array[Int] = Array(0,0,0,0,0,0,0,0,0,0)\n//定义一个长度为10的String类数组\nscala> val strArray = new Array[String](10)\nstrArray:Array[String] = Array(null, null, null, null, null, null, null, null, null, null)\n\n//由上可以看出，复杂对象类型在数组定义时被初始化为null，数值型呗初始化为0，并且上面复杂类型定义的时候必须加new，否则会报错\n\n//提供初始值的定义数组\nscala> val strArray2 = Array(\"First\", \"Second\")  //这里说明已提供初始值就不需要new\nstrArray2:Array[String] = Array(First, Second)\n\nscala> strArray2(0) = \"Goodbye\"\nstrArray2:Array[String] = Array(Goodbye, Second)\n\n```\n2、变长数组定义\n\n```\n对于长度需要变化的数组，Java有ArrayList,C++有vector。Scala中的等效数据结构为ArrayBuffer\n\n//导入可变包，Scala中的可变集合都是放在mutable中，使用时要导入\nscala> import scala.collection.mutable.ArrayBuffer\nimport scala.collection.mutable.ArrayBuffer\n\nscala> val arrayBuffer = ArrayBuffer[Int]()\narrayBuffer: scala.collection.mutable.ArrayBuffer[Int] = ArrayBuffer()\n\n//在尾部添加一个值\nscala> arrayBuffer += 1\nres17: arrayBuffer.type = ArrayBuffer(1)\n\n//在尾部添加多个元素\nscala> arrayBuffer += (2, 3, 4, 5)\nres19: arrayBuffer.type = ArrayBuffer(1, 2, 3, 4, 5)\n\n//在尾部添加一个集合\nscala> arrayBuffer ++= Array(6, 7, 8, 9)\nres20: arrayBuffer.type = ArrayBuffer(1, 2, 3, 4, 5, 6, 7, 8, 9)\n\n//移除最后2个元素\nscala> arrayBuffer.trimEnd(2)\n\n//在开头移除1一个元素\nscala> arrayBuffer.trimStart(2)\n\nscala> arrayBuffer\nres23: scala.collection.mutable.ArrayBuffer[Int] = ArrayBuffer(2, 3, 4, 5, 6, 7)\n\n\n//在任意位置插入或者删除元素\nscala> arrayBuffer.insert(2, 6)\n//ArrayBuffer(2, 3, 6, 4, 5, 6, 7)\n\nscala> arrayBuffer.insert(1, 2, 3, 4)\n//ArrayBuffer(2, 1, 2, 3, 4, 3, 6, 4, 5, 6, 7)\n\nscala> arrayBuffer.remove(2)\n//ArrayBuffer(2, 1, 3, 4, 3, 6, 4, 5, 6, 7)\n\nscala> arrayBuffer.remover(1, 8)\n//ArrayBuffer(2, 7)\n\n```\n3、变长数组和定长数组转换\n\n```\n//变长转换长定长\nscala > arrayBuffer.toArray\n//Array(2, 7)\n\n//定长转换成变长\nscala>res7.toBuffer\n//ArrayBuffer(2, 7)\n\n```\n4、遍历定长和变长数组\n\n```\nfor(i <- 0 until.arrayBuffer.length)\n    println(i + \": \" + a(i))\n0 until.arrayBuffer.length实际上是一个方法调用，返回的是一个区间Range： 0.until(arrayBuffer.length)\nfor(i <- 区间)会让变量i遍历该区间的所有值\n如果想要在区间中步长不为1，则：0 until (arrayBuffer.length, 2)\n如果想要数组从尾端开始，则遍历的写法为:(0 until (arrayBuffer.length, 2)).reverse\n\nScala也提供了一个和Java增强for循环类似的for\n\n//增强for\nfor(i <- arrayBuffer)\n    println(i + \": \" + a(i))\n\n```\n5、数组转换\n\n在《Scala入门学习笔记二-基本数据类型、程序控制结构》提到在for循环推导式，可以利用原来的数组产生一个新的数组。\n```\nscala> val a = Array(2, 3, 5, 7, 11)\na: Array[Int] = Array(2, 3, 5, 7, 11)\n//这里产生了一个新的数组，原来的数组也在\nscala> val result = for(elem <- a) yield 2 * elem\nresult: Array[Int] = Array(4, 6, 10, 14, 22)\n如果for中使用的是定长数组，则for(...)...yield之后得到的是定长数组;如果使用的是变长数组，则会得到变长数组\n\nScala也提供了另外一种做法\nscala> a.filter(_ % 2 == 0).map(2 * _)\n\n甚至\nscala>a.filter(_ % 2 == 0).map{2 * _}\n例子：\n给定一个整数的缓冲数组，我们想要移除第一个负数之外的所有负数。有几种做法\n\n//第一种做法：\nvar first = true\nvar n = a.length\nvar i = 0\nwhile(i < n){\n    if(a(i) > 0) i += 1\n    else{\n        if(first) {first = false; i += 1}\n        else {a.remove(i); n-= 1}\n    }\n}\n\n//第二种做法：\n//首先使用一个新数组用于记录满足条件的数组的下标\nval first = true\nval indexes = for(i <- 0 until a.length if first || a(i) > 0) yield {\n    if(a(i) < 0) first = false; i\n}\n//然后将元素移动到该去的位置，截断尾端\nfor(j <- o until indexes.length) a(j) = a(indexes(j))\na.trimEnd(a.length-indexes.length)\n```\n6、常用算法\nScala针对数组提供了一个常用的函数\n```\n//定义一个整型数组\nscala> val intArr=Array(1,2,3,4,5,6,7,8,9,10)\nintArr: Array[Int] = Array(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n\n//求和\nscala> intArr.sum\nres87: Int = 55\n\n//求最大值\nscala> intArr.max\nres88: Int = 10\n\nscala> ArrayBuffer(\"Hello\",\"Hell\",\"Hey\",\"Happy\").max\nres90: String = Hey\n\n//求最小值\nscala> intArr.min\nres89: Int = 1\n\n//排序\n//sorted方法将数组或数组缓冲排序并返回经过排序的数组或数组缓冲，原始数组被保留\nscala>val b = ArrayBuffer(1, 7, 2, 9)\nb:ArrayBuffer[Int] = ArrayBuffer(1, 7, 2, 9)\nscala>val bSorted = b.sorted(_<_) \nbSorted: ArrayBuffer[Int] = ArrayBuffer(1, 2, 7, 9)\n\n//toString()方法\nscala> intArr.toString()\nres94: String = [I@141aba8\n\n//mkString()方法\nscala> intArr.mkString(\",\")\nres96: String = 1,2,3,4,5,6,7,8,9,10\n\nscala> intArr.mkString(\"<\",\",\",\">\")\nres97: String = <1,2,3,4,5,6,7,8,9,10>\n```\n7、ArrayBuffer Scaladoc解析\n```\n初学者在查看sacaladoc时常常会感到困惑，不用担心，随着学习的深入，api文档中的内容将逐渐清晰\n下面给出两个示例：\n++=方法传入的参数类型是TraversableOnce Trait的子类，它返回的是更新好的ArrayBuffer\n\n++=方法解析\n\ndropWhile传入的是一个函数，该函数返回值是布尔类型，dropWhile反回的是操作后的ArrayBuffer\n\ndropWith方法解析\n```\n8、多维数组\n和Java一样，多维数组是通过数组的数组来实现的。\n```\n//第一种构造方式\nval metrix = Array.ofDim[Double](3, 4) //3行 4列\n\n//访问其中的元素\nmetrix(row)(column)  =42\n\n//可以创建不规则的数组，每一行的长度不相同\nval triangle = new Array[Array[Int]](10)\nfor(i <- 0 until triangle.length)\n    trianglr(i) = new Array[Int](i+1)\n\n//在创建的时候赋值\nscala> val metrix = Array(Array(1, 2, 3), Array(2.3, 3.4), Array(\"asdf\", \"asdfas\"))\nmetrix: Array[Array[_ >: String with Double with Int]] = Array(Array(1, 2, 3), Array(2.3, 3.4), Arra\ny(asdf, asdfas))\n\n//打印输出数组\nscala> for(i <- metrix) println(i.mkString(\" \"))\n1 2 3\n2.3 3.4\nasdf asdfas\n\n//输出二维数组的每个值\nscala> for(i <- metrix; from = i; j <- from) println(j)\n1\n2\n3\n2.3\n3.4\nasdf\nasdfas\n```\n\n## 四.数组操作(二)\n\nScala数组操作：\n\n1.定长数组\n 长度不变的数组的声明：\n\n```\n//长度为10的整数数组，所有元素初始化为0\n val numArr = new Array[Int](10)\n\n//长度为10的字符串数组，所有元素初始化为null\nval numArr = new Array[String](10)\n\n//长度为2的数组，数据类型自动推断出来，已经提供初始值就不需要new关键字\nval s = Array(\"cai\",\"yong\")\n\n//通过ArrayName(index)访问数组元素和更改数组元素\nval s = Array(\"cai\",\"yong\")\n println(s(0))\ns(0) = \"haha\"\nprintln(s(0))\n输出：\n cai\n haha\n\n```\n2.变长数组：数组缓冲\n Scala也支持长度变化的数组，支持的数据结构是ArrayBuffer\n```\n//一个空的数组缓冲，准备存放整数\n val ab = ArrayBuffer[Int]()\n val ab2 = new ArrayBuffer[Int]\n\n//用+=在尾部添加元素\nab += 2\n\n//在尾部添加多个元素\nab += (1,2,3,4,5)\n\n//通过++=往数组缓冲后面追加集合\n ab ++= Array(6,7,8,9)\n\n//使用trimEnd(n)移除尾部n个元素\nab.trimEnd(3)\n\n//在下标3之前插入元素\nab.insert(3, 33)\n\n//插入多个元素，第一个值为index，后面所有的值为要插入的值\nab.insert(3,3,4,5,6)\n\n//移除某个位置的元素\nab.remove(3)\n\n//移除从下标为n开始（包括n）的count个元素\nab.remove(n, count)\n```\n 有时候需要构造一个Array，但是不知道具体要存放多少元素，可以先构造ArrayBuffer,再调用toArray方法转化成Array，同样，对Array调用toBuffer方法可以转成ArrayBuffer.\n\n 注：在数组缓冲的尾部进行元素添加移除操作的效率很高，但是在任意位置插入或移除元素的效率并不太高效，因为涉及到数组元素的移动。\n\n3.遍历数组\n```\n//for循环遍历\nfor(i <- 0 until ab.length){\n print(ab(i) + \", \")\n }\n\n//根据特定步长遍历数组\nfor(i <- 0 until (ab.length, 2)){\n print(ab(i) + \", \")\n }\n\n//从数组的尾部开始向前遍历数组\nfor(i <- (0 until ab.length).reverse){\n print(ab(i) + \", \")\n}\n\n//类似于Java中的foreach遍历数组\n for(elem <- ab){\n print(elem + \", \")\n}\n```\n\n4.数组转换\n```\n//进行数组转换会生成一个新的数组，而不会修改原始数组\n val change = for(elem <- ab) yield elem * 2\nfor(elem <- change){\nprint(elem + \", \")\n }\n\n//添加一个守卫的数组转换\nval change = for(elem <- ab if elem%2 == 0) yield elem * 2\n```\n5.数组操作常用算法\n```\n//sum求和(数组与阿奴必须是数值型数据)\nprintln(change.sum)\n\n//min max 输出数组中最小和最大元素\nprintln(change.min)\nprintln(change.max)\n\n//使用sorted方法对数组或数组缓冲进行升序排序，这个过程不会修改原始数组\n val sortArr = ab.sorted \n for(elem <- sortArr)\n print(elem + \", \")\n\n//使用比较函数sortWith进行排序\nval sortArr = ab.sortWith(_>_)\n\n//数组显示\n println(sortArr.mkString(\"|\"))\n println(sortArr.mkString(\"startFlag\",\"|\",\"endFlag\"))\n```\n6.多维数组\n```\n//构造一个2行3列的数组\nval arr = Array.ofDim[Int](2,3)\nprintln(arr.length)\nprintln(arr(0).length)\narr(0)(0) = 20\nprintln(arr(0)(0))\n\n//创建长度不规则的数组\nval arr = new Array[Array[Int]](3)\n      \n for(i <- 0 until arr.length){\narr(i) = new Array[Int](i + 2)\n}\n      \nfor(i <- 0 until arr.length){\nprintln(arr(i).length)\n}\n```\n\n## 五.Tuple常见方法汇总\n\n```\ntuple的定义\n\n对偶是元组(tuple)的最简单形态——元组是不同类型的值的聚集。\n元组的值是通过将单个值包含在圆括号中构成。Example：（1，1.3415，“Fred”)\ntuple的访问\n\n可以通过_1,_2,_3访问元组的元素\nval first = tuple._1 //元组的位置从1开始，而非从0开始\n```\n与列表一样，元组也是不可变的，但与列表不同的是元组可以包含不同类型的元素。\n元组的值是通过将单个的值包含在圆括号中构成的。例如：\n```\nval t = (1, 3.14, \"Fred\")  \n```\n以上实例在元组中定义了三个元素，对应的类型分别为[Int, Double, java.lang.String]。\n此外我们也可以使用以上方式来定义：\n```\nval t = new Tuple3(1, 3.14, \"Fred\")\n```\n元组的实际类型取决于它的元素的类型，比如 (99, \"runoob\") 是 Tuple2[Int, String]。 ('u', 'r', \"the\", 1, 4, \"me\") 为 Tuple6[Char, Char, String, Int, Int, String]。\n目前 Scala 支持的元组最大长度为 22。对于更大长度你可以使用集合，或者扩展元组。\n访问元组的元素可以通过数字索引，如下一个元组：\n```\nval t = (4,3,2,1)\nval sum = t._1 + t._2 + t._3 + t._4\nprintln( \"元素之和为: \"  + sum )//10\n```\n迭代元组\n```\nval t = (4,3,2,1)\nt.productIterator.foreach{ i =>println(\"Value = \" + i )}\nValue = 4\nValue = 3\nValue = 2\nValue = 1\n```\n元组转为字符串\n你可以使用 Tuple.toString() 方法将元组的所有元素组合成一个字符串，实例如下：\n```\nval t = new Tuple3(1, \"hello\", Console)\nprintln(\"连接后的字符串为: \" + t.toString() )\n连接后的字符串为: (1,hello,scala.Console$@4dd8dc3)\n```\n\n\n\n## 六.List常见方法汇总\n\nList的4种操作符的区别和联\n\n(1):+和+: 两者的区别在于:+方法用于在尾部追加元素，+:方法用于在头部追加元素，和::很类似，但是::可以用于pattern match ，而+:则不行. 关于+:和:+,只要记住冒号永远靠近集合类型就OK了。\n```\nscala> a\nres23: List[Int] = List(1, 2, 3, 4)\n\nscala> var b=a:+9\nb: List[Int] = List(1, 2, 3, 4, 9)\n\nscala> var c=9:+a\n<console>:15: error: value :+ is not a member of Int\n       var c=9:+a\n              ^\nscala> var c=9+:a\nc: List[Int] = List(9, 1, 2, 3, 4)\n\nscala> var r1=\"A\"+:\"B\"+:Nil\nr1: List[String] = List(A, B)\n\nscala>var r2=Nil:+\"A\":+\"B\"\nr2: List[String] = List(A, B)\n```\n(2):: 该方法被称为cons，意为构造，向队列的头部追加数据，创造新的列表。用法为 x::list,其中x为加入到头部的元素，无论x是列表与否，它都只将成为新生成列表的第一个元素，也就是说新生成的列表长度为list的长度＋1(btw, x::list等价于list.::(x))\n```\nscala>\"A\"::\"B\"::Nil\nres0: List[String] = List(A, B)\n\nscala>List(\"A\",\"B\")::List(\"C\",\"D\")\nres1: List[java.io.Serializable] = List(List(A, B), C, D)\n```\n(3) ++ 该方法用于连接两个集合，list1++list2\n```\nscala>List(\"A\",\"B\") ++ List(\"C\",\"D\")\nres2: List[String] = List(A, B, C, D)\n```\n(4)::: 该方法只能用于连接两个List类型的集合\n```\nscala>List(\"A\",\"B\") ::: List(\"C\",\"D\")\nres3: List[String] = List(A, B, C, D)\n```\n**List常用用法**\n\n1）List类型定义以及List的特点：\n```\n//字符串类型List\nscala> val fruit=List(\"Apple\",\"Banana\",\"Orange\")\nfruit: List[String] = List(Apple, Banana, Orange)\n\n//前一个语句与下面语句等同\nscala> val fruit=List.apply(\"Apple\",\"Banana\",\"Orange\")\nfruit: List[String] = List(Apple, Banana, Orange)\n\n//数值类型List\nscala> val nums=List(1,2,3,4,5)\nnums: List[Int] = List(1, 2, 3, 4, 5)\n\n//多重List，List的子元素为List\nscala> val list = List(List(1, 2, 3), List(\"adfa\", \"asdfa\", \"asdf\"))\nlist: List[List[Any]] = List(List(1, 2, 3), List(adfa, asdfa, asdf))\n\n//遍历List\nscala> for(i <- list; from=i; j<-from)println(j)\n1\n2\n3\nadfa\nasdfa\nasdf\n```\n（2）List与Array的区别：\n```\n1、List一旦创建，已有元素的值不能改变，可以使用添加元素或删除元素生成一个新的集合返回。\n如前面的nums，改变其值的话，编译器就会报错。而Array就可以成功\n\nscala>nums(3)=4\n<console>:10: error: value update is not a member of List[Int]\n              nums(3)=4\n              ^\n2、List具有递归结构(Recursive Structure),例如链表结构\nList类型和气他类型集合一样，它具有协变性(Covariant),即对于类型S和T，如果S是T的子类型，则List[S]也是List[T]的子类型。\n例如:\n\nscala>var listStr:List[Object] = List(\"This\", \"Is\", \"Covariant\", \"Example\")\nlistStr:List[Object] = List(This, Is, Covariant, Example)\n\n//空的List,其类行为Nothing,Nothing在Scala的继承层次中的最底层\n//,即Nothing是任何Scala其它类型如String,Object等的子类\nscala> var listStr = List()\nlistStr:List[Nothing] = List()\n\nscala>var listStr:List[String] = List()\nlistStr:List[String] = List()\n```\n（3）List常用构造方法\n```\n//1、常用::及Nil进行列表构建\nscala> val nums = 1 :: (2:: (3:: (4 :: Nil)))\nnums: List[Int] = List(1, 2, 3, 4)\n\n\n//由于::操作符的优先级是从右向左的，因此上一条语句等同于下面这条语句\nscala> val nums = 1::2::3::4::Nil\nnums:List[Int] = List(1, 2, 3, 4)\n至于::操作符的使用将在下面介绍\n```\n（4）List常用操作\n```\n//判断是否为空\nscala> nums.isEmpty\nres5: Boolean = false\n\n//取第一个元素\nscala> nums.head\nres6: Int = 1\n\n//取列表第二个元素\nscala>nums.tail.head\nres7: Int = 2\n\n//取第三个元素\nscala>nums.tail.tail.head\nres8: Int = 3\n\n//插入操作\n//在第二个位置插入一个元素\nscala>nums.head::(3::nums.tail)\nres11: List[Int] = List(1, 3, 2, 3, 4)\n\nscala> nums.head::(nums.tail.head::(4::nums.tail.tail))\nres12: List[Int] = List(1, 2, 4, 3, 4)\n\n//插入排序算法实现\ndef isort(xs: List[Int]):List[Int] = {\n    if(xs.isEmpty) Nil\n    else insert(xs.head, issort(xs.tail))\n}\n\ndef insert(x:Int, xs:List[Int]):List[Int] = {\n    if(xs.isEmpty || x <= xs.head) x::xs\n    else xs.head :: insert(x, xs.tail)\n}\n\n//连接操作\nscala>List(1, 2, 3):::List(4, 5, 6)\nres13: List[Int] = List(1, 2, 3, 4, 5, 6)\n\n//去除最后一个元素外的元素，返回的是列表\nscala> nums.init\nres13: List[Int] = List(1, 2, 3)\n\n//取出列表最后一个元素\nscala>nums.last\nres14: Int = 4\n\n//列表元素倒置\nscala> nums.reverse\nres15: List[Int] = List(4, 3, 2, 1)\n\n//一些好玩的方法调用\nscala> nums.reverse.reverse == nums\n\n\n//丢弃前面n个元素\nscala>nums drop 3\nres16: List[Int] = List(4)\n\n//获取前面n个元素\nscala>nums take 1\nres17: List[Int] = List[1]\n\n//将列表进行分割\nscala> nums.splitAt(2)\nres18: (List[Int], List[Int]) = (List(1, 2),List(3, 4))\n\n//前一个操作与下列语句等同\nscala> (nums.take(2),nums.drop(2))\nres19: (List[Int], List[Int]) = (List(1, 2),List(3, 4))\n\n//Zip操作\nscala> val nums=List(1,2,3,4)\nnums: List[Int] = List(1, 2, 3, 4)\n\nscala> val chars=List('1','2','3','4')\nchars: List[Char] = List(1, 2, 3, 4)\n\n//返回的是List类型的元组(Tuple），返回的元素个数与最小的List集合的元素个数一样\nscala> nums zip chars\nres20: List[(Int, Char)] = List((1,1), (2,2), (3,3), (4,4))\n\n//List toString方法\nscala> nums.toString\nres21: String = List(1, 2, 3, 4)\n\n//List mkString方法\nscala> nums.mkString\nres22: String = 1234\n\n//转换成数组\nscala> nums.toArray\nres23: Array[Int] = Array(1, 2, 3, 4)\n```\n（5）List伴生对象方法\n```\n//apply方法\nscala>  List.apply(1, 2, 3)\nres24: List[Int] = List(1, 2, 3)\n\n//range方法，构建某一值范围内的List\nscala>  List.range(2, 6)\nres25: List[Int] = List(2, 3, 4, 5)\n\n//步长为2\nscala>  List.range(2, 6,2)\nres26: List[Int] = List(2, 4)\n\n//步长为-1\nscala>  List.range(2, 6,-1)\nres27: List[Int] = List()\n\nscala>  List.range(6,2 ,-1)\nres28: List[Int] = List(6, 5, 4, 3)\n\n//构建相同元素的List\nscala> List.make(5, \"hey\")\nres29: List[String] = List(hey, hey, hey, hey, hey)\n\n//unzip方法\nscala> List.unzip(res20)\nres30: (List[Int], List[Char]) = (List(1, 2, 3, 4),List(1, 2, 3, 4))\n\n//list.flatten，将列表平滑成第一个无素\nscala> val xss =\n     | List(List('a', 'b'), List('c'), List('d', 'e'))\nxss: List[List[Char]] = List(List(a, b), List(c), List(d, e))\nscala> xss.flatten\nres31: List[Char] = List(a, b, c, d, e)\n\n//列表连接\nscala> List.concat(List('a', 'b'), List('c'))\nres32: List[Char] = List(a\n, b, c)\n```\n（6）::和:::操作符介绍\n```\nList中常用'::',发音为\"cons\"。Cons把一个新元素组合到已有元素的最前端，然后返回结果List。\n\nscala> val twoThree = List(2, 3)\nscala> val oneTwoThree = 1 :: twoThree\nscala> oneTwoThree\noneTwoThree: List[Int] = List(1, 2, 3)\n上面表达式\"1::twoThree\"中，::是右操作数，列表twoThree的方法。可能会有疑惑。表达式怎么是右边参数的方法，这是Scala语言的一个例外的情况:如果一个方法操作符标注，如a * b,那么方法被左操作数调用，就像a.* (b)--除非方法名以冒号结尾。这种情况下，方法被右操作数调用。\nList有个方法叫\":::\"，用于实现叠加两个列表。\n\nscala> val one = List('A', 'B')\nval one = List('A', 'B')\nscala> val two = List('C', 'D')\n\nscala> one:::two\nres1: List[Char] = List(A, B, C, D)\n```\n创建列表\n```\nscala> val days = List(\"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\")\ndays: List[String] = List(Sunday, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday)\n```\n创建空列表\n```\nscala> val l = Nil //scala.collection.immutable.Nil继承了List[Nothing]  这是空列表\nl: scala.collection.immutable.Nil.type = List()\n\nscala> val l = List()\nl: List[Nothing] = List()\n```\n用字符串创建列表\n```\nscala> val l = \"Hello\" :: \"Hi\" :: \"Hah\" :: \"WOW\" :: \"WOOW\" :: Nil\nl: List[String] = List(Hello, Hi, Hah, WOW, WOOW)\n```\n用“:::”叠加创建新列表\n```\nscala> val wow = l ::: List(\"WOOOW\", \"WOOOOW\")\nwow: List[String] = List(Hello, Hi, Hah, WOW, WOOW, WOOOW, WOOOOW)\n```\n通过索引获取列表值\n```\nscala> l(3)\nres0: String = WOW\n```\n获取值长度为3的元素数目\n```\nscala> l.count(s => s.length == 3)\nres1: Int = 2\n```\n返回去掉l头两个元素的新列表\n```\nscala> l.drop(2)\nres2: List[String] = List(Hah, WOW, WOOW)\n\nscala> l\nres3: List[String] = List(Hello, Hi, Hah, WOW, WOOW)\n```\n返回去掉l后两个元素的新列表\n```\nscala> l.dropRight(2)\nres5: List[String] = List(Hello, Hi, Hah)\n\nscala> l\nres6: List[String] = List(Hello, Hi, Hah, WOW, WOOW)\n```\n判断l是否存在某个元素\n```\nscala> l.exists(s => s == \"Hah\")\nres7: Boolean = true\n```\n滤出长度为3的元素\n```\nscala> l.filter(s => s.length == 3)\nres8: List[String] = List(Hah, WOW)\n```\n判断所有元素是否以“H”打头\n```\nscala> l.forall(s => s.startsWith(\"H\"))\nres10: Boolean = false\n```\n判断所有元素是否以“H”结尾\n```\nscala> l.forall(s => s.endsWith(\"W\"))\nres11: Boolean = false\n```\n打印每个元素\n```\nscala> l.foreach(s => print(s + ' '))\nHello Hi Hah WOW WOOW\n```\n取出第一个元素\n```\nscala> l.head\nres17: String = Hello\n```\n取出最后一个元素\n```\nscala> l.last\nres20: String = WOOW\n```\n剔除最后一个元素，生成新列表\n```\nscala> l.init\nres18: List[String] = List(Hello, Hi, Hah, WOW)\n```\n剔除第一个元素，生成新列表\n```\nscala> l.tail\nres49: List[String] = List(Hi, Hah, WOW, WOOW)\n```\n判断列表是否为空\n```\nscala> l.isEmpty\nres19: Boolean = false\n```\n获得列表长度\n```\nscala> l.length\nres21: Int = 5\n```\n修改每个元素，再反转每个元素形成新列表\n```\nscala> l.map(s => {val s1 = s + \" - 01\"; s1.reverse})\nres29: List[String] = List(10 - olleH, 10 - iH, 10 - haH, 10 - WOW, 10 - WOOW)\n```\n生成用逗号隔开的字符串\n```\nscala> l.mkString(\", \")\nres30: String = Hello, Hi, Hah, WOW, WOOW\n```\n反序生成新列表\n```\nscala> l.reverse\nres41: List[String] = List(WOOW, WOW, Hah, Hi, Hello)\n```\n按字母递增排序\n```\nscala> l.sortWith(_.compareTo(_) < 0)\nres48: List[String] = List(Hah, Hello, Hi, WOOW, WOW)\n```\n\n**List定义的方法**\n\n```\ndef  ++[B >: A, That](that: GenTraversableOnce[B])(implicit bf: CanBuildFrom[List[A], B, That]): That\nReturns a new list containing the elements from the left hand operand followed by the elements from the right hand operand.\n```\n```\ndef  ++:[B >: A, That](that: collection.Traversable[B])(implicit bf: CanBuildFrom[List[A], B, That]): That\nAs with ++, returns a new collection containing the elements from the left operand followed by the elements from the right operand.\n```\n```\ndef  ++:[B](that: TraversableOnce[B]): List[B]\n[use case] As with ++, returns a new collection containing the elements from the left operand followed by the elements from the right operand.\n```\n```\ndef  +:(elem: A): List[A]\n[use case]\nA copy of the list with an element prepended.\n\nNote that :-ending operators are right associative (see example). A mnemonic for +: vs. :+ is: the COLon goes on the COLlection side.\n\nAlso, the original list is not modified, so you will want to capture the result.\n\nExample:\n\nscala> val x = List(1)\nx: List[Int] = List(1)\n\nscala> val y = 2 +: x\ny: List[Int] = List(2, 1)\n\nscala> println(x)\nList(1)\nelem\nthe prepended element\nreturns\na new list consisting of elem followed by all elements of this list.\n```\n```\ndef inition Classes\nList → SeqLike → GenSeqLike\n Full Signature\n```\n```\ndef  /:[B](z: B)(op: (B, A) ⇒ B): B\nApplies a binary operator to a start value and all elements of this traversable or iterator, going left to right.\n```\n```\ndef  :+(elem: A): List[A]\n[use case] A copy of this list with an element appended.\n```\n```\ndef  ::(x: A): List[A]\n[use case] Adds an element at the beginning of this list.\n```\n```\ndef  :::(prefix: List[A]): List[A]\n[use case] Adds the elements of a given list in front of this list.\n```\n```\ndef  :\\[B](z: B)(op: (A, B) ⇒ B): B\nApplies a binary operator to all elements of this traversable or iterator and a start value, going right to left.\n```\n```\ndef  addString(b: StringBuilder): StringBuilder\nAppends all elements of this traversable or iterator to a string builder.\n```\n```\ndef  addString(b: StringBuilder, sep: String): StringBuilder\nAppends all elements of this traversable or iterator to a string builder using a separator string.\n```\n```\ndef  addString(b: StringBuilder, start: String, sep: String, end: String): StringBuilder\nAppends all elements of this traversable or iterator to a string builder using start, end, and separator strings.\n```\n```\ndef  aggregate[B](z: ⇒ B)(seqop: (B, A) ⇒ B, combop: (B, B) ⇒ B): B\nAggregates the results of applying an operator to subsequent elements.\n```\n```\ndef  andThen[C](k: (A) ⇒ C): PartialFunction[Int, C]\nComposes this partial function with a transformation function that gets applied to results of this partial function.\n```\n```\ndef  apply(n: Int): A\nSelects an element by its index in the sequence.\n```\n```\ndef  applyOrElse[A1 <: Int, B1 >: A](x: A1, ```\n```\ndef ault: (A1) ⇒ B1): B1\nApplies this partial function to the given argument when it is contained in the function domain.\n```\n\n```\ndef  canEqual(that: Any): Boolean\nMethod called from equality methods, so that user-```\n```\ndef ined subclasses can refuse to be equal to other collections of the same kind.\nfinal ```\n```\ndef  collect[B](pf: PartialFunction[A, B]): List[B]\n[use case] Builds a new collection by applying a partial function to all elements of this list on which the function is ```\n```\ndef ined.\n```\n```\ndef  collectFirst[B](pf: PartialFunction[A, B]): Option[B]\nFinds the first element of the traversable or iterator for which the given partial function is ```\n```\ndef ined, and applies the partial function to it.\n```\n\n```\ndef  combinations(n: Int): Iterator[List[A]]\nIterates over combinations.\n```\n\n```\ndef  companion: GenericCompanion[List]\nThe factory companion object that builds instances of class List.\n```\n\n```\ndef  compose[A](g: (A) ⇒ Int): (A) ⇒ A\nComposes two instances of Function1 in a new Function1, with this function applied last.\n```\n\n```\ndef  contains[A1 >: A](elem: A1): Boolean\nTests whether this sequence contains a given value as an element.\n```\n\n```\ndef  containsSlice[B](that: GenSeq[B]): Boolean\nTests whether this sequence contains a given sequence as a slice.\n```\n\n```\ndef  copyToArray(xs: Array[A], start: Int, len: Int): Unit\n[use case] Copies the elements of this list to an array.\n```\n\n```\ndef  copyToArray(xs: Array[A]): Unit\n[use case] Copies the elements of this list to an array.\n```\n\n```\ndef  copyToArray(xs: Array[A], start: Int): Unit\n[use case] Copies the elements of this list to an array.\n```\n\n```\ndef  copyToBuffer[B >: A](dest: Buffer[B]): Unit\nCopies all elements of this traversable or iterator to a buffer.\nfinal ```\n```\ndef  corresponds[B](that: GenSeq[B])(p: (A, B) ⇒ Boolean): Boolean\nTests whether every element of this sequence relates to the corresponding element of another sequence by satisfying a test predicate.\n```\n```\ndef  count(p: (A) ⇒ Boolean): Int\nCounts the number of elements in the traversable or iterator which satisfy a predicate.\n```\n```\ndef  diff(that: collection.Seq[A]): List[A]\n[use case] Computes the multiset difference between this list and another sequence.\n```\n```\ndef  distinct: List[A]\nBuilds a new sequence from this sequence without any duplicate elements.\n```\n```\ndef  drop(n: Int): List[A]\nSelects all elements except first n ones.\n```\n```\ndef  dropRight(n: Int): List[A]\nSelects all elements except last n ones.\nfinal ```\n```\ndef  dropWhile(p: (A) ⇒ Boolean): List[A]\nDrops longest prefix of elements that satisfy a predicate.\n```\n\n```\ndef  endsWith[B](that: GenSeq[B]): Boolean\nTests whether this sequence ends with the given sequence.\n```\n\n```\ndef  equals(that: Any): Boolean\nThe equals method for arbitrary sequences.\n```\n\n```\ndef  exists(p: (A) ⇒ Boolean): Boolean\nTests whether a predicate holds for at least one element of this sequence.\n```\n\n```\ndef  filter(p: (A) ⇒ Boolean): List[A]\nSelects all elements of this traversable collection which satisfy a predicate.\n```\n\n```\ndef  filterNot(p: (A) ⇒ Boolean): List[A]\nSelects all elements of this traversable collection which do not satisfy a predicate.\n```\n\n```\ndef  find(p: (A) ⇒ Boolean): Option[A]\nFinds the first element of the sequence satisfying a predicate, if any.\nfinal ```\n```\ndef  flatMap[B](f: (A) ⇒ GenTraversableOnce[B]): List[B]\n[use case] Builds a new collection by applying a function to all elements of this list and using the elements of the resulting collections.\n```\n```\ndef  flatten[B]: List[B]\n[use case] Converts this list of traversable collections into a list formed by the elements of these traversable collections.\n```\n```\ndef  fold[A1 >: A](z: A1)(op: (A1, A1) ⇒ A1): A1\nFolds the elements of this traversable or iterator using the specified associative binary operator.\n```\n```\ndef  foldLeft[B](z: B)(op: (B, A) ⇒ B): B\nApplies a binary operator to a start value and all elements of this sequence, going left to right.\n```\n```\ndef  foldRight[B](z: B)(op: (A, B) ⇒ B): B\nApplies a binary operator to all elements of this list and a start value, going right to left.\n```\n```\ndef  forall(p: (A) ⇒ Boolean): Boolean\nTests whether a predicate holds for all elements of this sequence.\nfinal ```\n```\ndef  foreach(f: (A) ⇒ Unit): Unit\n[use case] Applies a function f to all elements of this list.\n```\n\n```\ndef  genericBuilder[B]: Builder[B, List[B]]\nThe generic builder that builds instances of Traversable at arbitrary element types.\n```\n\n```\ndef  groupBy[K](f: (A) ⇒ K): Map[K, List[A]]\nPartitions this traversable collection into a map of traversable collections according to some discriminator function.\n```\n\n```\ndef  grouped(size: Int): Iterator[List[A]]\nPartitions elements in fixed size iterable collections.\n```\n\n```\ndef  has```\n```\ndef initeSize: Boolean\nTests whether this traversable collection is known to have a finite size.\n```\n```\ndef  hashCode(): Int\nHashcodes for Seq produce a value from the hashcodes of all the elements of the sequence.\n```\n```\ndef  head: A\nSelects the first element of this iterable collection.\n```\n```\ndef  headOption: Option[A]\nOptionally selects the first element.\n```\n```\ndef  indexOf(elem: A, from: Int): Int\n[use case] Finds index of first occurrence of some value in this list after or at some start index.\n```\n```\ndef  indexOf(elem: A): Int\n[use case] Finds index of first occurrence of some value in this list.\n```\n```\ndef  indexOfSlice[B >: A](that: GenSeq[B], from: Int): Int\nFinds first index after or at a start index where this sequence contains a given sequence as a slice.\n```\n```\ndef  indexOfSlice[B >: A](that: GenSeq[B]): Int\nFinds first index where this sequence contains a given sequence as a slice.\n```\n```\ndef  indexWhere(p: (A) ⇒ Boolean, from: Int): Int\nFinds index of the first element satisfying some predicate after or at some start index.\n```\n```\ndef  indexWhere(p: (A) ⇒ Boolean): Int\nFinds index of first element satisfying some predicate.\n```\n```\ndef  indices: Range\nProduces the range of all indices of this sequence.\n```\n```\ndef  init: List[A]\nSelects all elements except the last.\n```\n```\ndef  inits: Iterator[List[A]]\nIterates over the inits of this traversable collection.\n```\n```\ndef  intersect(that: collection.Seq[A]): List[A]\n[use case] Computes the multiset intersection between this list and another sequence.\n```\n```\ndef  is```\n```\ndef inedAt(x: Int): Boolean\nTests whether this sequence contains given index.\n```\n\n```\ndef  isEmpty: Boolean\nTests whether this sequence is empty.\nfinal ```\n```\ndef  isTraversableAgain: Boolean\nTests whether this traversable collection can be repeatedly traversed.\n```\n```\ndef  iterator: Iterator[A]\nCreates a new iterator over all elements contained in this iterable object.\n```\n```\ndef  last: A\nSelects the last element.\n```\n```\ndef  lastIndexOf(elem: A, end: Int): Int\n[use case] Finds index of last occurrence of some value in this list before or at a given end index.\n```\n```\ndef  lastIndexOf(elem: A): Int\n[use case] Finds index of last occurrence of some value in this list.\n```\n```\ndef  lastIndexOfSlice[B >: A](that: GenSeq[B], end: Int): Int\nFinds last index before or at a given end index where this sequence contains a given sequence as a slice.\n```\n```\ndef  lastIndexOfSlice[B >: A](that: GenSeq[B]): Int\nFinds last index where this sequence contains a given sequence as a slice.\n```\n```\ndef  lastIndexWhere(p: (A) ⇒ Boolean, end: Int): Int\nFinds index of last element satisfying some predicate before or at given end index.\n```\n```\ndef  lastIndexWhere(p: (A) ⇒ Boolean): Int\nFinds index of last element satisfying some predicate.\n```\n```\ndef  lastOption: Option[A]\nOptionally selects the last element.\n```\n```\ndef  length: Int\nThe length of the sequence.\n```\n```\ndef  lengthCompare(len: Int): Int\nCompares the length of this sequence to a test value.\n```\n```\ndef  lift: (Int) ⇒ Option[A]\nTurns this partial function into a plain function returning an Option result.\nfinal ```\n```\ndef  map[B](f: (A) ⇒ B): List[B]\n[use case] Builds a new collection by applying a function to all elements of this list.\nfinal ```\n```\ndef  mapConserve(f: (A) ⇒ A): List[A]\n[use case] Builds a new list by applying a function to all elements of this list.\n```\n```\ndef  max: A\n[use case] Finds the largest element.\n```\n```\ndef  maxBy[B](f: (A) ⇒ B): A\n[use case] Finds the first element which yields the largest value measured by function f.\n```\n```\ndef  min: A\n[use case] Finds the smallest element.\n```\n```\ndef  minBy[B](f: (A) ⇒ B): A\n[use case] Finds the first element which yields the smallest value measured by function f.\n```\n```\ndef  mkString: String\nDisplays all elements of this traversable or iterator in a string.\n```\n```\ndef  mkString(sep: String): String\nDisplays all elements of this traversable or iterator in a string using a separator string.\n```\n```\ndef  mkString(start: String, sep: String, end: String): String\nDisplays all elements of this traversable or iterator in a string using start, end, and separator strings.\n```\n```\ndef  nonEmpty: Boolean\nTests whether the traversable or iterator is not empty.\n```\n```\ndef  orElse[A1 <: Int, B1 >: A](that: PartialFunction[A1, B1]): PartialFunction[A1, B1]\nComposes this partial function with a fallback partial function which gets applied where this partial function is not ```\n```\ndef ined.\n```\n\n```\ndef  padTo(len: Int, elem: A): List[A]\n[use case] A copy of this list with an element value appended until a given target length is reached.\n```\n\n```\ndef  par: ParSeq[A]\nReturns a parallel implementation of this collection.\n```\n\n```\ndef  partition(p: (A) ⇒ Boolean): (List[A], List[A])\nPartitions this traversable collection in two traversable collections according to a predicate.\n```\n\n```\ndef  patch(from: Int, that: GenSeq[A], replaced: Int): List[A]\n[use case] Produces a new list where a slice of elements in this list is replaced by another sequence.\n```\n\n```\ndef  permutations: Iterator[List[A]]\nIterates over distinct permutations.\n```\n\n```\ndef  prefixLength(p: (A) ⇒ Boolean): Int\nReturns the length of the longest prefix whose elements all satisfy some predicate.\n```\n\n```\ndef  product: A\n[use case] Multiplies up the elements of this collection.\n```\n\n```\ndef  productIterator: scala.Iterator[Any]\nAn iterator over all the elements of this product.\n```\n\n```\ndef  productPrefix: String\nA string used in the toString methods of derived classes.\n```\n\n```\ndef  reduce[A1 >: A](op: (A1, A1) ⇒ A1): A1\nReduces the elements of this traversable or iterator using the specified associative binary operator.\n```\n\n```\ndef  reduceLeft[B >: A](op: (B, A) ⇒ B): B\nApplies a binary operator to all elements of this sequence, going left to right.\n```\n\n```\ndef  reduceLeftOption[B >: A](op: (B, A) ⇒ B): Option[B]\nOptionally applies a binary operator to all elements of this traversable or iterator, going left to right.\n```\n\n```\ndef  reduceOption[A1 >: A](op: (A1, A1) ⇒ A1): Option[A1]\nReduces the elements of this traversable or iterator, if any, using the specified associative binary operator.\n```\n\n```\ndef  reduceRight[B >: A](op: (A, B) ⇒ B): B\nApplies a binary operator to all elements of this sequence, going right to left.\n```\n\n```\ndef  reduceRightOption[B >: A](op: (A, B) ⇒ B): Option[B]\nOptionally applies a binary operator to all elements of this traversable or iterator, going right to left.\n```\n\n```\ndef  repr: List[A]\nThe collection of type traversable collection underlying this TraversableLike object.\n```\n\n```\ndef  reverse: List[A]\nReturns new list with elements in reversed order.\n```\n\n```\ndef  reverseIterator: Iterator[A]\nAn iterator yielding elements in reversed order.\n```\n\n```\ndef  reverseMap[B](f: (A) ⇒ B): List[B]\n[use case] Builds a new collection by applying a function to all elements of this list and collecting the results in reversed order.\n```\n\n```\ndef  reverse_:::(prefix: List[A]): List[A]\n[use case] Adds the elements of a given list in reverse order in front of this list.\n```\n\n```\ndef  runWith[U](action: (A) ⇒ U): (Int) ⇒ Boolean\nComposes this partial function with an action function which gets applied to results of this partial function.\n```\n\n```\ndef  sameElements(that: GenIterable[A]): Boolean\n[use case] Checks if the other iterable collection contains the same elements in the same order as this list.\n```\n\n```\ndef  scan[B >: A, That](z: B)(op: (B, B) ⇒ B)(implicit cbf: CanBuildFrom[List[A], B, That]): That\nComputes a prefix scan of the elements of the collection.\n```\n\n```\ndef  scanLeft[B, That](z: B)(op: (B, A) ⇒ B)(implicit bf: CanBuildFrom[List[A], B, That]): That\nProduces a collection containing cumulative results of applying the operator going left to right.\n```\n\n```\ndef  scanRight[B, That](z: B)(op: (A, B) ⇒ B)(implicit bf: CanBuildFrom[List[A], B, That]): That\nProduces a collection containing cumulative results of applying the operator going right to left.\n```\n\n```\ndef  segmentLength(p: (A) ⇒ Boolean, from: Int): Int\nComputes length of longest segment whose elements all satisfy some predicate.\n```\n\n```\ndef  seq: LinearSeq[A]\nA version of this collection with all of the operations implemented sequentially (i.e., in a single-threaded manner).\n```\n\n```\ndef  size: Int\nThe size of this sequence, equivalent to length.\n```\n\n```\ndef  slice(from: Int, until: Int): List[A]\n```\n\n```\ndef  sliding(size: Int, step: Int): Iterator[List[A]]\nGroups elements in fixed size blocks by passing a \"sliding window\" over them (as opposed to partitioning them, as is done in grouped.)\n```\n\n```\ndef  sliding(size: Int): Iterator[List[A]]\nGroups elements in fixed size blocks by passing a \"sliding window\" over them (as opposed to partitioning them, as is done in grouped.) The \"sliding window\" step is set to one.\n```\n\n```\ndef  sortBy[B](f: (A) ⇒ B)(implicit ord: math.Ordering[B]): List[A]\nSorts this Seq according to the Ordering which results from transforming an implicitly given Ordering with a transformation function.\n```\n\n```\ndef  sortWith(lt: (A, A) ⇒ Boolean): List[A]\nSorts this sequence according to a comparison function.\n```\n\n```\ndef  sorted[B >: A](implicit ord: math.Ordering[B]): List[A]\nSorts this sequence according to an Ordering.\nfinal ```\n```\ndef  span(p: (A) ⇒ Boolean): (List[A], List[A])\nSplits this list into a prefix/suffix pair according to a predicate.\n```\n```\ndef  splitAt(n: Int): (List[A], List[A])\nSplits this list into two at a given position.\n```\n```\ndef  startsWith[B](that: GenSeq[B], offset: Int): Boolean\nTests whether this sequence contains the given sequence at a given index.\n```\n```\ndef  startsWith[B](that: GenSeq[B]): Boolean\nTests whether this general sequence starts with the given sequence.\n```\n```\ndef  stringPrefix: String\n```\n```\ndef ines the prefix of this object's toString representation.\n```\n```\ndef  sum: A\n[use case] Sums up the elements of this collection.\n```\n```\ndef  tail: List[A]\nSelects all elements except the first.\n```\n```\ndef  tails: Iterator[List[A]]\nIterates over the tails of this traversable collection.\n```\n```\ndef  take(n: Int): List[A]\nSelects first n elements.\n```\n```\ndef  takeRight(n: Int): List[A]\nSelects last n elements.\nfinal ```\n```\ndef  takeWhile(p: (A) ⇒ Boolean): List[A]\nTakes longest prefix of elements that satisfy a predicate.\n```\n\n```\ndef  to[Col[_]]: Col[A]\n[use case] Converts this list into another by copying all elements.\n```\n\n```\ndef  toArray: Array[A]\n[use case] Converts this list to an array.\n```\n\n```\ndef  toBuffer[B >: A]: Buffer[B]\nUses the contents of this traversable or iterator to create a new mutable buffer.\n```\n\n```\ndef  toIndexedSeq: IndexedSeq[A]\nConverts this traversable or iterator to an indexed sequence.\n```\n\n```\ndef  toIterable: collection.Iterable[A]\nReturns this iterable collection as an iterable collection.\n```\n\n```\ndef  toIterator: Iterator[A]\nReturns an Iterator over the elements in this iterable collection.\n```\n\n```\ndef  toList: List[A]\nConverts this list to a list.\n```\n\n```\ndef  toMap[T, U]: collection.Map[T, U]\n[use case] Converts this list to a map.\n```\n\n```\ndef  toParArray: ParArray[T]\n```\n\n```\ndef  toSeq: Seq[A]\nConverts this immutable sequence to a sequence.\n```\n\n```\ndef  toSet[B >: A]: Set[B]\nConverts this traversable or iterator to a set.\n```\n\n```\ndef  toStream: Stream[A]\nConverts this list to a stream.\n```\n\n```\ndef  toString(): String\nConverts this sequence to a string.\n```\n\n```\ndef  toTraversable: collection.Traversable[A]\nConverts this traversable collection to an unspecified Traversable.\n```\n\n```\ndef  toVector: scala.Vector[A]\nConverts this traversable or iterator to a Vector.\n```\n\n```\ndef  transpose[B](implicit asTraversable: (A) ⇒ GenTraversableOnce[B]): List[List[B]]\nTransposes this collection of traversable collections into a collection of collections.\n```\n\n```\ndef  union(that: collection.Seq[A]): List[A]\n[use case] Produces a new sequence which contains all elements of this list and also all elements of a given sequence.\n```\n\n```\ndef  unzip[A1, A2](implicit asPair: (A) ⇒ (A1, A2)): (List[A1], List[A2])\nConverts this collection of pairs into two collections of the first and second half of each pair.\n```\n\n```\ndef  unzip3[A1, A2, A3](implicit asTriple: (A) ⇒ (A1, A2, A3)): (List[A1], List[A2], List[A3])\nConverts this collection of triples into three collections of the first, second, and third element of each triple.\n```\n\n```\ndef  updated(index: Int, elem: A): List[A]\n[use case] A copy of this list with one single replaced element.\n```\n\n```\ndef  view(from: Int, until: Int): SeqView[A, List[A]]\nCreates a non-strict view of a slice of this sequence.\n```\n\n```\ndef  view: SeqView[A, List[A]]\nCreates a non-strict view of this sequence.\n```\n\n```\ndef  withFilter(p: (A) ⇒ Boolean): FilterMonadic[A, List[A]]\nCreates a non-strict filter of this traversable collection.\n```\n\n```\ndef  zip[B](that: GenIterable[B]): List[(A, B)]\n[use case] Returns a list formed from this list and another iterable collection by combining corresponding elements in pairs.\n```\n\n```\ndef  zipAll[B](that: collection.Iterable[B], thisElem: A, thatElem: B): List[(A, B)]\n[use case] Returns a list formed from this list and another iterable collection by combining corresponding elements in pairs.\n```\n\n```\ndef  zipWithIndex: List[(A, Int)]\n[use case] Zips this list with its indices.\n```\n\n\n```\n\n## 七.Map的常见方法汇总\n\n（1）不可变Map\n\n```\nvar a:Map[String,Int]=Map(\"k1\"->1,\"k2\"->2)//初始化构造函数\na += (\"k3\"->3)//添加元素\na += (\"k4\"->4)//添加元素\na += (\"k1\"->100)//已经存在添加元素会覆盖\na -= (\"k2\",\"k1\")//删除元素    //a(\"k1\") = \"foo\"//不支持\nprintln(a.contains(\"k6\"))//是否包含某元素\nprintln(a.size)//打印大小\nprintln(a.get(\"k1\").getOrElse(\"default\")) //根据key读取元素，不存在就替换成默认值\na.foreach{case (e,i) => println(e,i)} //遍历打印1\nfor( (k,v)<-a ) println(k,v) //遍历打印2\nprintln(a.isEmpty)//判断是否为空\na.keys.foreach(println)//只打印key\na.values.foreach(println)//只打印value\n\na=Map()//数据清空使用再次new\nprintln(a.size)\na.toSeq.sortBy(_._1)//升序排序 key\na.toSeq.sortBy(_._2)//升序排序 value\na.toSeq.sortWith(_._1>_._1) //降序排序 key\na.toSeq.sortWith(_._2>_._2) //降序排序 value\n    \n//下面自定义按英文字母或数字排序\nimplicit  val KeyOrdering=new Ordering[String] {\n      override def compare(x: String, y: String): Int = {\n        x.compareTo(y)\n      }\n}\nprintln(a.toSeq.sorted)\n```\n\n2）可变Map例子\n```\nvar a:scala.collection.mutable.Map[String,Int]=scala.collection.mutable.Map(\"k1\"->1,\"k2\"->2)//初始化构造函数\n  a += (\"k3\"->3)//添加元素\n  a += (\"k4\"->4)//添加元素\n  a += (\"k1\"->100)//已经存在添加元素会覆盖\n  a += (\"k1\"->100,\"k9\"->9)//添加多个元素\n  a -= (\"k2\",\"k1\")//删除元素\n  a ++= List(\"CA\" -> 23, \"CO\" -> 25)//追加集合\n  a --= List(\"AL\", \"AZ\")//删除集合\n\n  a.retain((k,v)=> k==\"k1\")//只保留等于k1元素，其他的删除\n  a.put(\"put1\",200)//put\n  a.remove(\"k2\")//remove\n  a.clear()//清空\n  a(\"k3\")=100//支持\n\n  println(a.contains(\"k6\"))//是否包含某元素\n  println(a.size)//打印大小\n  println(a.get(\"k1\").getOrElse(\"default\")) //根据key读取元素，不存在就替换成默认值\n  a.foreach{case (e,i) => println(e,i)} //遍历打印1\n  for( (k,v)<-a ) println(k,v) //遍历打印2\n  println(a.isEmpty)//判断是否为空\n  a.keys.foreach(println)//只打印key\n  a.values.foreach(println)//只打印value\n  a=scala.collection.mutable.Map()//引用能变\n  println(a.size)\n  a.toSeq.sortBy(_._1)//排序 key\n  a.toSeq.sortBy(_._2)//排序 value\n  a.toSeq.sortWith(_._1>_._1) //降序排序 key\n  a.toSeq.sortWith(_._2>_._2) //降序排序 value\n  \n//下面自定义按英文字母或数字排序\n  implicit  val KeyOrdering=new Ordering[String] {\n    override def compare(x: String, y: String): Int = {\n      x.compareTo(y)\n    }\n  }\n  println(a.toSeq.sorted)\n}\n```\n\n默认情况下，Scala使用不可变映射(Map)。如果要使用可变集合(Set)，则必须明确导入scala.collection.mutable.Map类。如果想同时使用可变的和不可变映射(Map)，那么可以继续引用不可变映射(Map)，但是可以将mutable集合引用mutable.Map。\n以下是声明不可变映射(Map)的示例声明 \n集合基本操作\n```\nscala> val colors = Map(\"red\" -> \"#FF0000\", \"azure\" -> \"#F0FFFF\", \"peru\" -> \"#CD853F\")\ncolors: scala.collection.immutable.Map[String,String] = Map(red -> #FF0000, azure -> #F0FFFF, peru -> #CD853F)\n\nscala> val nums: Map[Int, Int] = Map()\nnums: Map[Int,Int] = Map()\n\nscala>println( \"Keys in colors : \" + colors.keys )\nKeys in colors : Set(red, azure, peru)\n\nscala>println( \"Values in colors : \" + colors.values )\nValues in colors : MapLike(#FF0000, #F0FFFF, #CD853F)\n\nscala>println( \"Check if colors is empty : \" + colors.isEmpty )\nCheck if colors is empty : false\n\nscala>println( \"Check if nums is empty : \" + nums.isEmpty )\nCheck if nums is empty : true\n```\n\n连接映射\n```\nscala>val colors1 = Map(\"red\" -> \"#FF0000\", \"azure\" -> \"#F0FFFF\", \"peru\" -> \"#CD853F\")\ncolors1: scala.collection.immutable.Map[String,String] = Map(red -> #FF0000, azure -> #F0FFFF, peru -> #CD853F)\n\nscala>val colors2 = Map(\"blue\" -> \"#0033FF\", \"yellow\" -> \"#FFFF00\", \"red\" -> \"#FF0000\")\ncolors2: scala.collection.immutable.Map[String,String] = Map(blue -> #0033FF, yellow -> #FFFF00, red -> #FF0000)\n\nscala>var colors = colors1 ++ colors2\ncolors: scala.collection.immutable.Map[String,String] = Map(blue -> #0033FF, azure -> #F0FFFF, peru -> #CD853F, yellow -> #FFFF00, red -> #FF0000)\n\nscala>println( \"colors1 ++ colors2 : \" + colors )\ncolors1 ++ colors2 : Map(blue -> #0033FF, azure -> #F0FFFF, peru -> #CD853F, yellow -> #FFFF00, red -> #FF0000)\n\nscala>colors = colors1.++(colors2)\ncolors: scala.collection.immutable.Map[String,String] = Map(blue -> #0033FF, azure -> #F0FFFF, peru -> #CD853F, yellow -> #FFFF00, red -> #FF0000)\n\nscala>println( \"colors1.++(colors2)) : \" + colors )\ncolors1.++(colors2)) : Map(blue -> #0033FF, azure -> #F0FFFF, peru -> #CD853F, yellow -> #FFFF00, red -> #FF0000)\n\n```\n\n打印映射的键和值\n```\nval colors = Map(\"red\" -> \"#FF0000\", \"azure\" -> \"#F0FFFF\",\"peru\" -> \"#CD853F\")\ncolors.keys.foreach{ i =>  \n    print( \"Key = \" + i )\n    println(\" Value = \" + colors(i) )}\n}\n\nKey = red Value = #FF0000\nKey = azure Value = #F0FFFF\nKey = peru Value = #CD853F\n```\n查找检查映射中的键\n```\nval colors = Map(\"red\" -> \"#FF0000\", \"azure\" -> \"#F0FFFF\", \"peru\" -> \"#CD853F\")\nif( colors.contains( \"red\" )) {\n    println(\"Red key exists with value :\"  + colors(\"red\"))\n} else {\n    println(\"Red key does not exist\")\n}\nif( colors.contains( \"maroon\" )) {\n    println(\"Maroon key exists with value :\"  + colors(\"maroon\"))\n} else {\n    println(\"Maroon key does not exist\")\n}\n```\n\n\nscala - Map基础\n构造Map:不可变：\n```\nval map = Map(\"sa\" -> 1, \"s\" -> 2)\nmap(\"sa\") = 3 // error\nval emptyMap = new scala.collection.immutable.HashMap[String, Int]\n```\n可变：\n```\nval map2 = scala.collection.mutable.Map(\"sa\" -> 2)\nmap2(\"sa\") = 3\nval emptyMap = new scala.collection.mutable.HashMap[String, Int]\n```\n注：->用来创建元组， \"sa\" -> 1即(\"sa\", 1) 初始化完全可以 val map = Map((\"sa\", 1), (\"s\", 2))\n获取Map中的值：\n```\n如果map中不包含请求中使用的key值，则抛异常。NoSuchElementException\nmap(\"sa\") // 类似于java中的map.get(\"sa\")\n```\n\n要检查map中是否包含某个key，使用contains方法。\n```\nval sa = if (map2.contains(\"sa3\")) map2(\"sa3\") else 0;\n快捷的方式：\nval sa2 = map.getOrElse(\"sa2\", 0)\n一次得到是否包含key，并获取值：\nval sa3 = map.get(\"sa3\"); // Option类型，\nprintln(sa3.isEmpty)\n```\n更新Map中的值：\n```\n添加或更新：map(\"sa\") = 3\n添加或更新多个：map += (\"aa\" -> 4, \"bb\" -> 5)\n```\n移除某个key和对应的值：\n```\nmap -= \"aa\"\n不可变的map也可以使用+和-操作，但是会生成新的map\nvar map = Map(\"aa\" -> 1)\nmap = map + (\"bb\" -> 2)\nmap += (\"cc\" -> 2)\nmap -= \"aa\"\n```\n迭代map：\n```\nfor ((k, v) <- map) {\n\n}\n所有key：map.keySet\n所有值：map.values\n反转：map2 = for((k, v) <- map) yield (v, k)\n```\n已排序Map：\n按key排序：SortedMap\n按添加顺序：LinkedHashMap\nMap与Java互操作：\nJava Properties转为scala.collection.Map：\n```\nimport scala.collection.JavaConversions.propertiesAsScalaMap\nval prop: scala.collection.Map[String, String] = System.getProperties();\n```\nJava Map转为scala.collection.mutable.Map[String, Int]：\n```\nimport scala.collection.JavaConversions.mapAsScalaMap\nval map: scala.collection.mutable.Map[String, Int] = new TreeMap[String, Int]\n```\nScala Map转为Java Map:\n```\nimport scala.collection.JavaConversions.mapAsJavaMap\nimport java.awt.font.TextAttribute._\nvar fs = Map(FAMILY -> \"Serif\", SIZE -> 12)\nvar fonts = new Font(fs)\n```\n\n**Map的操作方法**\n\n```\ndef ++(xs: Map[(A, B)]): Map[A, B]\n返回一个新的 Map，新的 Map xs 组成\n```\n```\t\ndef -(elem1: A, elem2: A, elems: A*): Map[A, B]\n返回一个新的 Map, 移除 key 为 elem1, elem2 或其他 elems。\n```\n```\t\ndef --(xs: GTO[A]): Map[A, B]\n返回一个新的 Map, 移除 xs 对象中对应的 key\n```\n```\t\ndef get(key: A): Option[B]\n返回指定 key 的值\n```\n```\t\ndef iterator: Iterator[(A, B)]\n创建新的迭代器，并输出 key/value 对\n```\n```\t\ndef addString(b: StringBuilder): StringBuilder\n将 Map 中的所有元素附加到StringBuilder，可加入分隔符\n```\n```\t\ndef addString(b: StringBuilder, sep: String): StringBuilder\n将 Map 中的所有元素附加到StringBuilder，可加入分隔符\n```\n```\t\ndef apply(key: A): B\n返回指定键的值，如果不存在返回 Map 的默认方法\n```\n```\t\ndef clear(): Unit\n清空 Map\n```\n```\t\ndef clone(): Map[A, B]\n从一个 Map 复制到另一个 Map\n```\n```\t\ndef contains(key: A): Boolean\n如果 Map 中存在指定 key，返回 true，否则返回 false。\n```\n```\t\ndef copyToArray(xs: Array[(A, B)]): Unit\n复制集合到数组\n```\n```\t\ndef count(p: ((A, B)) => Boolean): Int\n计算满足指定条件的集合元素数量\n```\n```\t\ndef default(key: A): B\n定义 Map 的默认值，在 key 不存在时返回。\n```\n```\t\ndef drop(n: Int): Map[A, B]\n返回丢弃前n个元素新集合\n```\n```\t\ndef dropRight(n: Int): Map[A, B]\n返回丢弃最后n个元素新集合\n```\n```\t\ndef dropWhile(p: ((A, B)) => Boolean): Map[A, B]\n从左向右丢弃元素，直到条件p不成立\n```\n```\t\ndef empty: Map[A, B]\n返回相同类型的空 Map\n```\n```\t\ndef equals(that: Any): Boolean\n如果两个 Map 相等(key/value 均相等)，返回true，否则返回false\n```\n```\t\ndef exists(p: ((A, B)) => Boolean): Boolean\n判断集合中指定条件的元素是否存在\n```\n```\ndef filter(p: ((A, B))=> Boolean): Map[A, B]\n返回满足指定条件的所有集合\n```\n```\t\ndef filterKeys(p: (A) => Boolean): Map[A, B]\n返回符合指定条件的的不可变 Map\n```\n```\t\ndef find(p: ((A, B)) => Boolean): Option[(A, B)]\n查找集合中满足指定条件的第一个元素\n```\n```\t\ndef foreach(f: ((A, B)) => Unit): Unit\n将函数应用到集合的所有元素\n```\n```\t\ndef init: Map[A, B]\n返回所有元素，除了最后一个\n```\n```\t\ndef isEmpty: Boolean\n检测 Map 是否为空\n```\n```\t\ndef keys: Iterable[A]\n返回所有的key/p>\n```\n```\t\ndef last: (A, B)\n返回最后一个元素\n```\n```\t\ndef max: (A, B)\n查找最大元素\n```\n```\t\ndef min: (A, B)\n查找最小元素\n```\n```\t\ndef mkString: String\n集合所有元素作为字符串显示\n```\n```\t\ndef product: (A, B)\n返回集合中数字元素的积。\n```\n```\t\ndef remove(key: A): Option[B]\n移除指定 key\n```\n```\t\ndef retain(p: (A, B) => Boolean): Map.this.type\n如果符合满足条件的返回 true\n```\n```\t\ndef size: Int\n返回 Map 元素的个数\n```\n```\t\ndef sum: (A, B)\n返回集合中所有数字元素之和\n```\n```\t\ndef tail: Map[A, B]\n返回一个集合中除了第一元素之外的其他元素\n```\n```\ndef take(n: Int): Map[A, B]\n返回前 n 个元素\n```\n```\t\ndef takeRight(n: Int): Map[A, B]\n返回后 n 个元素\n```\n```\t\ndef takeWhile(p: ((A, B)) => Boolean): Map[A, B]\n返回满足指定条件的元素\n```\n```\ndef toArray: Array[(A, B)]\n集合转数组\n```\n```\ndef toBuffer[B >: A]: Buffer[B]\n返回缓冲区，包含了 Map 的所有元素\n```\n```\ndef toList: List[A]\n返回 List，包含了 Map 的所有元素\n```\n```\t\ndef toSeq: Seq[A]\n返回 Seq，包含了 Map 的所有元素\n```\n```\t\ndef toSet: Set[A]\n返回 Set，包含了 Map 的所有元素\n```\n```\ndef toString(): String\n返回字符串对象\n```\n\n## 八.类的定义及构造器\n\n**类和对象之基础**\n\n**定义**\n\nScala 中以 class 来作为类的声明，在类中可以定义成员和方法，成员和方法可以有不同的可见性（这个会在后文详述）\n```\nscala> class Company {\n     |   private var employeeCount = 0\n     |   def getEmployeeCount(): Int = employeeCount\n     |   def setEmployeeCount( count: Int)= {\n     |     employeeCount = count\n     |   }\n     |\n     |   def m( i: Int ) {}\n     |   def m( str: String ) {}\n     | }\ndefined class Company\n```\n**构造器**\n\nScala 中，类有一个主构造器，主构造器必须包含所需的所有参数。除了一个主构造器，还可以有0个或多个辅助构造器，辅助构造器又称次构造器。辅助构造器命名为 this，其第一条语句必须调用主构造器或其他辅助构造器，来看下面的例子：\n```\nscala> class T ( x1: Int, y1: String, z1: Double ) {\n     |   private val xx1 = x1\n     |   private val yy1 = y1\n     |   private val zz1 = z1\n     |\n     |   def this ( x1: Int, y1: String ) {\n     |     this( x1, y1, 1.0 )\n     |   }\n     |\n     |   def this ( x1: Int ) {\n     |     this( x1, \"\" )\n     |   }\n     | }\ndefined class T\n```\n还有一点需要注意的是，被调用的辅助构造函数的定义必须放在主动调用的辅助构造函数前面，不然会报错：\n```\nscala> class T ( x1: Int, y1: String, z1: Double ) {\n     |   private val xx1 = x1\n     |   private val yy1 = y1\n     |   private val zz1 = z1\n     |\n     |   def this ( x1: Int ) {\n     |     this( x1, \"\" )\n     |   }\n     |\n     |   def this ( x1: Int, y1: String ) {\n     |     this( x1, y1, 1.0 )\n     |   }\n     | }\n<console>:13: error: called constructor's definition must precede calling constructor's definition\n           this( x1, \"\" )\n           ^\n```\n不管辅助函数调来调去，最终都还是要调用到主构造函数，这确保了新实例的初始化逻辑一致。\n\n如果在主构造函数的参数前加 var 或 val，该参数就成为实例的一个成员，这部分知识在Scala case class那些你不知道的知识有更详细的介绍\n\n**重载**\n\nScala 类方法允许重载，如类 Company 中的 m 方法。重载要求参数列表和返回类型不完全相同，但参数名可相同，这是因为编译后是通过方法名、参数列表、返回类型综合来区分各个方法的。\n\n在方法重载时，有一点需要注意：对于『高级类型』，存在类型擦除机制，所谓的高级类型就是包含类型参数的类型，比如 List[A]，下面这个例子可以展示了类型擦除：\n\n```\nscala> class Tmp {\n     |   def m( data: List[Int] ) {}\n     |   def m( data: List[String] ) {}\n     | }\n<console>:9: error: double definition:\nmethod m:(data: List[String])Unit and\nmethod m:(data: List[Int])Unit at line 8\nhave same type after erasure: (data: List)Unit\n         def m( data: List[String] ) {}\n             ^\n```\n报了有相同类型的参数的错误。\n\n**类型成员**\n\nScala 允许你在类内部定义类型成员，在构造类实例的时候指定该类型成员对应的具体类型。类型成员可用于类内部的成员或函数，提供了更好的泛华能力，从下面这个简单的例子可以看出：\n```\nscala> class T {\n     |   type X\n     |\n     |   def getClassName( x: X): String = {\n     |     x.getClass.getTypeName\n     |   }\n     | }\ndefined class T\n\nscala> val x1 = new T{ type X = Int }\nx1: T{type X = Int} = $anon$1@515f550a\n\nscala> x1.getClassName(10)\nres0: String = java.lang.Integer\n\nscala> val x2 = new T{ type X = String }\nx2: T{type X = String} = $anon$1@61a52fbd\n\nscala> x2.getClassName(\"string\")\nres1: String = java.lang.String\n```\n当然，也可以在类外部定义类型变量，如：\n```\nscala> type L = List[Int]\ndefined type alias L\n```\n**方法与成员同名**\n\n与 JAVA 不同，如果方法参数列表不为空，该方法可以与成员同名，如：\n```\nscala> class T {\n     |   private val m = 0\n     |\n     |   def m( i: Int ): Int = m + i\n     | }\ndefined class T\n\n```\n\n##  九.类和对象之进阶（一）\n\n 1、Scala中的类是公有可见性的，且多个类可以包含在同一个源文件中；\n\n```\nclass Counter{\n    private var value = 0　　//类成员变量必须初始化，否则报错\n    def increment(){    //类中的方法默认是公有可见性\n        value += 1\n    }\n    def current() = value //对于类中的“取值方法”，在定义时可省略掉括号，直接 def current = value\n}\n```\n\n继承\n\n只能有一个父类\n\n与其他支持面向对象的语言一样，Scala 也支持继承，并且子类只能有一个父类，不能继承于多个父类，如果希望实现类似继承多个父类的功能，应该考虑引入 trait。虽然只支持一个父类，但是父类还可以有父类，也就是爷爷类，对于类继承的层数是没有具体要求的，这几点在下面这个例子中都有体现：\n```\nscala> class A {\n     | }\ndefined class A\n\nscala> class B {\n     | }\ndefined class B\n\nscala> class AA extends A {\n     | }\ndefined class AA\n\nscala> class AB extends A with B {\n     | }\n<console>:9: error: class B needs to be a trait to be mixed in\n       class AB extends A with B {\n                               ^\n\nscala> class AAA extends AA {\n     | }\ndefined class AAA\n\nscala> class AAAA extends AAA {\n     | }\ndefined class AAAA\n```\n都继承了什么\n\n子类继承父类时都会继承些什么呢，这里结合可见性（可见性的详细内容会在下文介绍）进行分析，先定义这样一组父子类：\n```\nscala> class Parent ( x: Int, y: String, z: Double ) {\n     |   val xx = x\n     |   protected val yy = y\n     |   private val zz = z\n     |\n     |   def getXX = xx\n     |   protected def getYY = yy\n     |   private def getZZ = zz\n     |\n     |   def testYY = yy\n     |   def testZZ = zz\n     |   def testGetYY = getYY\n     |   def testGetZZ = getZZ\n     | }\ndefined class Parent\n```\n在 Scala 类继承中，允许在子类内部直接访问父类的 public 及 protected 成员及方法，但不允许子类直接访问父类的 private 成员及方法，如下例：\n```\nscala> class Child1 ( x: Int, y: String, z: Double ) extends Parent(x, y, z ) {\n     |   println( xx )\n     |   println( yy )\n     |   println( getXX )\n     |   println( getYY )\n     | }\ndefined class Child1\n\nscala> class Child2 ( x: Int, y: String, z: Double ) extends Parent(x, y, z ) {\n     |   println( zz )\n     |   println( getZZ )\n     | }\n<console>:9: error: value zz in class Parent cannot be accessed in Child2\n         println( zz )\n                  ^\n<console>:10: error: method getZZ in class Parent cannot be accessed in Child2\n         println( getZZ )\n                  ^\n```\n在类外部，只有 public 的方法和成员能被直接访问，protected 及 private 均不予许：\n```\nscala> class Child3 ( x: Int, y: String, z: Double ) extends Parent(x, y, z ) {\n     | }\ndefined class Child3\n\nscala> val child = new Child3( 1, \"hello\", 3.1415926 )\nchild: Child3 = Child3@39529185\n\nscala> child.xx\nres6: Int = 1\n\nscala> child.yy\n<console>:11: error: value yy in class Parent cannot be accessed in Child3\n Access to protected value yy not permitted because\n enclosing object $iw is not a subclass of\n class Parent where target is defined\n              child.yy\n                    ^\n\nscala> child.zz\n<console>:11: error: value zz in class Parent cannot be accessed in Child3\n              child.zz\n                    ^\n\nscala>\n\nscala> child.getXX\nres9: Int = 1\n\nscala> child.getYY\n<console>:11: error: method getYY in class Parent cannot be accessed in Child3\n Access to protected method getYY not permitted because\n enclosing object $iw is not a subclass of\n class Parent where target is defined\n              child.getYY\n                    ^\n\nscala> child.getZZ\n<console>:11: error: method getZZ in class Parent cannot be accessed in Child3\n              child.getZZ\n                    ^\n```\n但我们可以通过父类提供的方法来间接访问 protected 和 private 的成员和方法：\n```\nscala> child.testYY\nres20: String = hello\n\nscala> child.testZZ\nres21: Double = 3.1415926\n\nscala> child.testGetYY\nres22: String = hello\n\nscala> child.testGetZZ\nres23: Double = 3.1415926\n```\n单例对象\n\n在 Scala 中，使用关键字 object 来定义单例对象：\n```\nscala> object T {}\ndefined module T\n```\n单例对象将在其首次被调用时初始化，且没有参数。单例对象一旦定义完毕，它的名字就代表了该单例对象的唯一实例。\n\n当单例对象与某个类的名字相同且两者定义在同一文件中，就形成了特殊的单例对象-伴生对象，对应的类称为伴生类，若单例没有相同名字的类的话成为孤立对象（好惨）。我们经常使用在伴生对象中对应 apply 方法来创建新的伴生类实例并且将半身列的可见性设置为 private，以便能方便的创建伴生类实例，更重要的是可以在伴生类对象中管理所有伴生类实例，例子如下：\n```\nclass Q ( qParam: String ) {\n  private val q = qParam\n}\n\nobject Q {\n  private val qList = ListBuffer[ Q ]()\n\n  def apply( qParam: String ) {\n    val qInstance = new Q( qParam )\n    qList.append( qInstance )\n    qInstance\n  }\n\n  def qListSize = qList.size\n}\n\nobject Test {\n  def main (args: Array[String]) {\n    val qIns1 = Q( \"q1\" )\n    val qIns2 = Q( \"q2\" )\n    println( Q.qListSize )\n  }\n}\n```\n输出：\n```\n2\n```\n另外伴生对象与伴生类可以互相访问 private 成员和方法，object 也可以继承父类或混入特质\n## 十.类和对象之进阶（二）\n\nScala 中的可见性非常灵活且复杂，这篇文章希望通过大量的示例来说清楚各种情况下的可见性是怎么样的。\n默认可见性\nScala 中的默认可见性为 public，所谓默认即你没有在类或者成员前显示加 private 或 protected 可见性关键字。虽然默认可见性为 public，但这是逻辑上的，实际上 Scala 中并没有 public 这个关键字，如果你用 public 来声明一个类或成员，编译器会报错。\n可见性作用域\n在 Scala 中，可以在类型的 class 或 trait 关键字之前、字段的 val 或 var 之前，方法定义的 def 关键字之前指定可见性。\n公有可见性\n对于公有可见性，任何作用域内都可以访问公有成员或公有类型。\nProtected 可见性\n对于受保护可见性，用 protected 声明，受保护成员对本类型、继承类型可见。而受保护的类型则只对包含该类的包内可见。\n下面例子是关于 protected 成员的：\n```\npackage P1 {\n  class C1 {\n    protected val c = 0\n\n    //< 受保护可见性中,嵌套类可访问 protected 成员\n    class C11 {\n      println( c )\n    }\n  }\n\n  package P11 {\n    //< 继承类客房为父类 protected 成员\n    class C1Child extends C1 {\n      println( c )\n    }\n  }\n\n}\n\npackage P2 {\n  //< 继承类客房为父类 protected 成员\n  class C2Child extends P1.C1 {\n    println( c )\n  }\n}\n```\n接下来是 protected 类型的：\n```\npackage P1 {\n  protected class C1 {\n  }\n\n  //< 对于 protected 类型,相同包内可见\n  class C1Child extends C1 {\n  }\n\n  package P11 {\n    //< 对于 protected 类型,子包内可见\n    class C11Child extends C1 {\n    }\n  }\n}\n\npackage P2 {\n//< 对于 protected 类型,外部包不可见\n  class C2Child extends P1.C1 {\n  }\n}\n```\n编译报错如下，这是因为 protected 类型只在包含该类的包内可见\n```\nError:(22, 28) class C1 in package P1 cannot be accessed in package P1\n Access to protected class C1 not permitted because\n enclosing package P2 is not a subclass of \n package P1 where target is defined\n  class C2Child extends P1.C1 {\n```\n私有可见性\n\n私有可见性将实现细节完全隐藏起来，即便是继承类也无法访问这些细节。声明中包含了 private 关键字的所有成员只对该类可见，该类型的其他实例也能访问这些成员。如果类型被声明为私有可见性类型，那么该类型的可见性将仅限于包含该类型的包内\n```\npackage P1 {\n  class C1 {\n    private val c = 0\n  }\n\n  //< 对于 private 类型,相同包内的子类都不可见\n  class C1Child extends C1 {\n    println( c )\n  }\n}\n\npackage P2 {\n  //< 对于 private 类型,外部包内的子类也不可见\n  class C2Child extends P1.C1 {\n    println( c )\n  }\n}\n```\n编译报错：\n```\nError:(12, 14) value c in class C1 cannot be accessed in P1.C1Child\n    println( c )\n             ^\n\nError:(19, 14) value c in class C1 cannot be accessed in P2.C2Child\n    println( c )\n             ^\n```\n另外，嵌套类中的私有成员也是无法访问的。在私有可见性中，私有类型只在包含该类型的包中可见，在子包或外部包中均不可见。我们用下面的例子进一步说明，具体说明见代码中的注释：\n```\npackage P1 {\n  private class C1\n\n  class C11 extends C1            //< 错误,这样相当于变相改变了C1的可见性,子包和外部包都能访问C11,也就间接能访问C1\n  protected class C12 extends C1  //< 错误这样相当于变相改变了C1的可见性,子包能访问C11,也就间接能访问C1\n  private class C13 extends C1    //< 正确,由于C13也为 private,是的C1的 private 可见性不会\n\n  class C14 {\n    val c14_1 = new C1            //< 正确,私有类型在其所在包内可见\n  }\n}\n\npackage P2 {\n\n  //< 对于私有类型,外部包内不可见\n  class C2 {\n    val c1 = new P1.C1\n  }\n}\n```\n编译报错：\n```\nError:(8, 21) private class C1 escapes its defining scope as part of type P1.C1\n  class C11 extends C1            //< 错误\n                    ^\n\nError:(9, 31) private class C1 escapes its defining scope as part of type P1.C1\n  protected class C12 extends C1  //< 错误\n                              ^\n\nError:(22, 21) class C1 in package P1 cannot be accessed in package P1\n    val c1 = new P1.C1\n                    ^\n```\n作用域内私有和作用域内受保护可见性\n\n所谓作用域内私有/受保护可见性，就是你可以更细粒度指定某个类或某个成员在某个作用域（可以是包或类）私有或受保护可见性\n\n成员在类和包中的 private/protected 可见性\n该可见性可以有16种组合，下面的例子列举除了这些组合\n```\npackage P1 {\n  class C1 {\n    private[C1] val m1 = 1\n    private[this] val m2 = 2\n    private[P1] val m3 = 3\n    private[P2] val m4 = 4\n\n    protected[C1] val n1 = 1\n    protected[this] val n2 = 2\n    protected[P1] val n3 = 3\n    protected[P2] val n4 = 4\n\n    //< 不管什么样的作用域内 private 或 protected,在自身类中都是可见的\n    println( m1 )\n    println( m2 )\n    println( m3 )\n    println( m4 )\n\n    println( n1 )\n    println( n2 )\n    println( n3 )\n    println( n4 )\n  }\n\n  class C11 extends C1 {\n    println( m1 )   //< 1, 错误\n    println( m2 )   //< 2, 错误\n    println( m3 )   //< 3, 正确\n    println( m4 )   //< 4, 正确\n\n    println( n1 )   //< 5, 正确\n    println( n2 )   //< 6, 正确\n    println( n3 )   //< 7, 正确\n    println( n4 )   //< 8, 正确\n  }\n}\n\npackage P2 {\n  class C21 extends P1.C1 {\n    println( m1 )   //< 9, 错误\n    println( m2 )   //< 10, 错误\n    println( m3 )   //< 11, 错误\n    println( m4 )   //< 12, 正确\n\n    println( n1 )   //< 13, 正确\n    println( n2 )   //< 14, 正确\n    println( n3 )   //< 15, 正确\n    println( n4 )   //< 16, 正确\n  }\n}\n```\n\n下面我们对每一项进行解释，并穿插介绍一些规则：\n\nprivate[C1]指定成员在自身类作用域 private，在该类所在的包内和包外均不可见（9也是这个道理）\nprivate[this]比 private[C1]更加严格，前者只对相同实例可见，相同类的不同实例都不可见；而后者对相同类的不同实例也可见\nprivate[P1]指定在包 P1 内 private，则在 P1 包中的类中均可见，而在 P1外的包均不可见\nprivate[P2]指定在包 P2 内 private，则在包 P2 及该类所在包内均可见\nprotected[C1]指定在 C1 中 protected，则在 C1 所在包内的继承类及外部包内所在的继承类均可见\n\n类型在类和包中的 private/protected 可见性\n类型的情况就会少一点：\n```\npackage P1 {\n\n  private[P1] class C1\n  protected[P1] class C2\n\n  package P11 {\n    private[P1] class C3\n    protected[P1] class C4\n    private[P11] class C5\n    protected[P11] class C6\n  }\n\n\n  class C11 extends C1  //< 1, 正确\n  class C12 extends C2  //< 2, 正确\n\n  import P11._\n  class C13 extends C3  //< 3, 正确\n  class C14 extends C4  //< 4, 正确\n  class C15 extends C5  //< 5, 错误\n  class C16 extends C6  //< 6, 正确\n}\n\npackage P2 {\n  import P1._\n  import P1.P11._\n\n\n  class C21 extends C1  //< 7, 错误\n  class C22 extends C2  //< 8, 正确\n\n  class C23 extends C3  //< 9, 错误\n  class C24 extends C4  //< 10, 正确\n  class C25 extends C5  //< 11, 错误\n  class C26 extends C6  //< 12, 正确\n}\n```\n从上面的例子我们可以得出以下结论：\n\n对于 private[package] 声明的类型，在 package 包内及 package 子包内可见；在外部包内不可见\n对于 protected[package] 声明的类型，在 package 包内、package 子包内及外部包均可见\n有包 package 的子包为 package1，对于 private[package1]，在 package1 包内、package1 子包及其父包即 package 内可见，在外部包不可见\n有包 package 的子包为 package1，对于 protected[package1]，在 package1包内、package1子包、package1父包及外部包可见\n\n## 十一.trait\n\n这是我以前在知乎上看到关于类继承作用的回答，虽不完全正确，却十分明确的表达出了好的代码应避免类继承而尽量使用类组合。Scala 显然也非常赞同这一点，以至于有了 trait，又叫做特质。当我们定义特质时，应该要遵循这样的原则：一个 trait 只干一件事，如果要干多件事，就定义多个 trait，然后使用一个类来 extends 这些 traits\n\n**定义 trait**\n\ntrait 的定义与 class 类似:\n```\nscala> trait T {\n     | }\ndefined trait T\n```\n当然，trait 可以包含成员和方法，并且：\n\ntrait 中的成员可以仅声明，也可以声明并指定值\ntrait 中的方法可以有实现，也可以只有声明而没有实现\n```\nscala> trait T {\n     |   val a: Int\n     |   val b: Int = 1\n     |\n     |   def getA(): Int\n     |   def getB() = b\n     | }\ndefined trait T\n```\n对比而言，类一旦包含未定义的方法就必须声明为 abstract；而 Java 的接口中的方法是不能实现的，必须是抽象方法。如果 trait 既为实现它所声明的方法，也没有定义或声明其他成员，那么在字节码级别，该 trait 其实是接口是相同的\n\n另一个与类不同的是，trait 主构造函数不允许有参数列表，并且不允许为 trait 定义辅助构造函数\n\n混入多个 trait\n\nScala 类只能有一个父类，但可以混入多个 trait，当要混入多个 traits 或已经继承了某个父类时，需要使用关键字 with，如下例：\n```\nscala> trait T {\n     |   val a: Int\n     |   val b: Int = 1\n     |\n     |   def getA(): Int\n     |   def getB() = b\n     | }\ndefined trait T\n\nscala>\n\nscala> trait Q {\n     |   def currentTime: String = System.currentTimeMillis().toString\n     | }\ndefined trait Q\n\nscala>\n\nscala> class X extends T with Q {\n     |   override val a = 1\n     |   override def getA(): Int = a\n     | }\ndefined class X\n```\n当类混入 trait 时，需要实现 trait 中为实现的成员和方法。要混入多个 trait 是为了保证『高内聚』，通俗说就是一个 trait 只干一件事，如果要干多件事，就定义多个 trait 然后混入它们\n\n当你继承的父类和混入的特质或混入的不同特质之间有同名方法时可能会有冲突，分为以下几种情况：\n\ntrait 中的方法未实现：不会冲突\n```\nscala> class C {\n     |   def a: String = \"a\"\n     | }\ndefined class C\n\nscala>\n\nscala> trait T {\n     |   def a: String\n     | }\ndefined trait T\n\nscala>\n\nscala> trait Q extends C with T {}\ndefined trait Q\n```\ntrait 中的方法实现了且与父类中的方法参数列表及返回类型相同：会冲突\n```\nscala> class C {\n     |   def a: String = \"a\"\n     | }\ndefined class C\n\nscala>\n\nscala> trait T {\n     |   def a: String = \"\"\n     | }\ndefined trait T\n\nscala>\n\nscala> trait Q extends C with T {}\n<console>:9: error: trait Q inherits conflicting members:\n  method a in class C of type => String  and\n  method a in trait T of type => String\n(Note: this can be resolved by declaring an override in trait Q.)\n       trait Q extends C with T {}\n             ^\n```\ntrait 中的方法实现了且与父类中的参数列表相同，返回类型不同：会冲突\n```\nscala> class C {\n     |   def a: String = \"a\"\n     | }\ndefined class C\n\nscala>\n\nscala> trait T {\n     |   def a: Int = 1\n     | }\ndefined trait T\n\nscala>\n\nscala> trait Q extends C with T {}\n<console>:9: error: trait Q inherits conflicting members:\n  method a in class C of type => String  and\n  method a in trait T of type => Int\n(Note: this can be resolved by declaring an override in trait Q.)\n       trait Q extends C with T {}\n             ^\n```\ntrait 中的方法实现了且与父类的参数列表不同，返回类型相同：不会冲突\n```\nscala> class C {\n     |   def a: String = \"a\"\n     | }\ndefined class C\n\nscala>\n\nscala> trait T {\n     |   def a( i: Int ): String = i.toString\n     | }\ndefined trait T\n\nscala>\n\nscala> trait Q extends C with T {}\ndefined trait Q\n```\n**trait 的继承**\n\n一个 trait 同样可以混入其他 trait 或继承类：\n```\nscala> class C {\n     |   def currentTime: String = System.currentTimeMillis().toString\n     | }\ndefined class C\n\nscala>\n\nscala> trait T {\n     |   def random: Int\n     | }\ndefined trait T\n\nscala>\n\nscala> trait Q extends C with T {}\ndefined trait Q\n```\n\n## 十二.case class样例类\n\n当你声明了一个 case class，Scala 编译器为你做了这些：\n创建 case class 和它的伴生 object\n实现了 apply 方法让你不需要通过 new 来创建类实例\n```\nscala> case class Person(lastname: String, firstname: String, birthYear: Int)\ndefined class Person\n\nscala> val p = Person(\"Lacava\", \"Alessandro\", 1976)\np: Person = Person(Lacava,Alessandro,1976)\n```\n默认为主构造函数参数列表的所有参数前加 val\n```\nscala> println( p.lastname )\nLacava\n\nscala> p.lastname = \"jhon\"\n<console>:10: error: reassignment to val\n   p.lastname = \"jhon\"\n              ^\n```\n添加天然的 hashCode、equals 和 toString 方法。由于 == 在 Scala 中总是代表 equals，所以 case class 实例总是可比较的\n```\nscala> val p_1 = new Person( \"Brown\", \"John\", 1969 )\np_1: Person = Person(Brown,John,1969)\n\nscala>val p_2 = new Person( \"Lacave\", \"Alessandro\", 1976)\np_2: Person = Person(Lacave,Alessandro,1976)\n\nscala> p_1.hashCode\nres1: Int = -1362628729\n\nscala> p_1.toString\nres2: String = Person(Brown,John,1969)\n\nscala> p_1.equals(p_2)\nres3: Boolean = false\n\nscala> p_1 == p_2\nres4: Boolean = false\n```\n\n生成一个 copy 方法以支持从实例 a 生成另一个实例 b，实例 b 可以指定构造函数参数与 a 一致或不一致\n```\n//< 保留 lastname 一致，修改 firstname 和 birthYear\nscala> val p_3 = p.copy(firstname = \"Michele\", birthYear = 1972)\np_3: Person = Person(Lacava,Michele,1972)\n```\n由于编译器实现了 unapply 方法，一个 case class 支持模式匹配\n```\nscala> case class A( a: Int )\ndefined class A\n\nscala> case class B( b: String )\ndefined class B\n\nscala> def classMath( x: AnyRef ): Unit = {\n     |   x match {\n     |     case A(a) => println( \"A:\" + a )\n     |     case B(b) => println( \"B:\" + b )\n     |     case A => println( A.apply(100) )\n     |   }\n     | }\nclassMath: (x: AnyRef)Unit\n\nscala> val a = A( 1 )\na: A = A(1)\n\nscala> val b = B( \"b\" )\nb: B = B(b)\n\nscala> classMath( a )\nA:1\n\nscala> classMath( b )\nB:b\n```\n\n也许你已经知道，在模式匹配中，当你的 case class 没有参数的时候，你是在使用 case object 而不是一个空参数列表的 case class\n```\nscala> classMath( A )\nA(100)\n```\n除了在模式匹配中使用之外，unapply 方法可以让你结构 case class 来提取它的字段，如：\n```\nscala> val Person(lastname, _, _) = p\nlastname: String = Lacava\n```\n\ncase class 接收一个 tuple 作为参数，该 tuple 的元素类型与个数与某 case class 相同，那么可以将该tuple 作为 case class 的 tuple 方法参数来构造 case class 实例\n```\nscala> val meAsTuple: (String, String, Int) = (\"Lacava\", \"Alessandro\", 1976)\nmeAsTuple: (String, String, Int) = (Lacava,Alessandro,1976)\n\nscala> Person.tupled( meAsTuple )\nres2: Person = Person(Lacava,Alessandro,1976)\n```\n相对用 tuple 来创建 case class 实例，还可以从 case class 实例中解构并提取出 tuple 对象\n```\nscala> val transform: Person => Option[ (String, String, Int) ] = {\n |   Person.unapply _\n | }\ntransform: Person => Option[(String, String, Int)] = <function1>\n\nscala> transform( p )\nres0: Option[(String, String, Int)] = Some((Lacava,Alessandro,1976))\n\n```\n\n**另一种定义 case class 的方式**\n\n还有另一种很少人知道的定义 case class 的方式，如：\n```\ncase class Person( lastname: String )( firstname: String, birthYear: Int )\n```\n这种方式有点像偏函数，有两个参数列表，要注意的是，对这两个参数列表是区别对待的。上文提到的所有 case class 的特性在这种定义方式下只作用于第一个参数列表中的参数（比如在参数前自动加 val，模式匹配，copy 支持等等），第二个及之后的参数列表中的参数和普通的 class 参数列表参数无异。\n\nfirstname和birthYear前不再自动添加 val，不再是类的成员\n```\nscala> val p = Person(\"Lacava\")(\"Alessandro\", 1976)\np: Person = Person(Lacava)\n\nscala> p.lastname\nres0: String = Lacava\n\nscala> p.firstname\n<console>:11: error: value firstname is not a member of Person\n              p.firstname\n                ^\n\nscala> p.birthYear\n<console>:11: error: value birthYear is not a member of Person\n              p.birthYear\n                ^\n```\ncopy 时，当不指定birthYear的值时，不会使用 p 中的birthYear，因为根本没这个值，会报错\n```\nscala> p.copy()(firstname = \"Jhon\")\n<console>:11: error: not enough arguments for method copy: (firstname: String, birthYear: Int)Person.\nUnspecified value parameter birthYear.\n              p.copy()(firstname = \"Jhon\")\n```\nequals 和 toString 方法也发生了改变：\n```\nscala> val p_1 = Person(\"Lacava\")(\"Jhon\", 2001)\np_1: Person = Person(Lacava)\n\nscala> p.equals(p_1)\nres9: Boolean = true\n\nscala> p == p_1\nres10: Boolean = true\n\nscala> println ( p.toString )\nPerson(Lacava)\n```\n\n## 十三.对象\n\n 1、Scala中没有静态方法和静态字段，但是可以用object语法来实现类似的功能。对象定义了某个类的单个实例。\n\nScala的object中可以用来实现类似的功能，用来存放工具函数或常量等。如\n\n```\nobject Sequence{\n    private var next_num = 0\n    val threshold = 100\n\n    def getSequence() = {\n        next_num += 1\n        next_num\n    }\n}\n```\n\n## 十四.常用操作符\n\n一、常用操作符（操作符其实也是函数）\n\n++ ++[B](that: GenTraversableOnce[B]): List[B] 从列表的尾部添加另外一个列表\n++: ++:[B >: A, That](that: collection.Traversable[B])(implicit bf: CanBuildFrom[List[A], B, That]): That 在列表的头部添加一个列表\n+: +:(elem: A): List[A] 在列表的头部添加一个元素\n:+ :+(elem: A): List[A] 在列表的尾部添加一个元素\n:: ::(x: A): List[A] 在列表的头部添加一个元素\n::: :::(prefix: List[A]): List[A] 在列表的头部添加另外一个列表\n:\\ :[B](z: B)(op: (A, B) ⇒ B): B 与foldRight等价\n\nval left = List(1,2,3)\nval right = List(4,5,6)\n\n//以下操作等价\nleft ++ right   // List(1,2,3,4,5,6)\nleft ++: right  // List(1,2,3,4,5,6)\nright.++:(left)    // Listval left = List(1,2,3)(1,2,3,4,5,6)\nright.:::(left)  // List(1,2,3,4,5,6)\n\n//以下操作等价\n0 +: left    //List(0,1,2,3)\nleft.+:(0)   //List(0,1,2,3)\n\n//以下操作等价\nleft :+ 4    //List(1,2,3,4)\nleft.:+(4)   //List(1,2,3,4)\n\n//以下操作等价\n0 :: left      //List(0,1,2,3)\nleft.::(0)     //List(0,1,2,3)\n\n\n看到这里大家应该跟我一样有一点晕吧，怎么这么多奇怪的操作符，这里给大家一个提示，任何以冒号结果的操作符，都是右绑定的，即 0 :: List(1,2,3) = List(1,2,3).::(0) = List(0,1,2,3) 从这里可以看出操作::其实是右边List的操作符，而非左边Int类型的操作符\n\n二、常用变换操作\n1.map\nmap[B](f: (A) ⇒ B): List[B]\n定义一个变换,把该变换应用到列表的每个元素中,原列表不变，返回一个新的列表数据\nExample1 平方变换\n```\nval nums = List(1,2,3)\nval square = (x: Int) => x*x   \nval squareNums1 = nums.map(num => num*num)    //List(1,4,9)\nval squareNums2 = nums.map(math.pow(_,2))    //List(1,4,9)\nval squareNums3 = nums.map(square)            //List(1,4,9)1\n```\nExample2 保存文本数据中的某几列\n```\nval text = List(\"Homeway,25,Male\",\"XSDYM,23,Female\")\nval usersList = text.map(_.split(\",\")(0))    \nval usersWithAgeList = text.map(line => {\n    val fields = line.split(\",\")\n    val user = fields(0)\n    val age = fields(1).toInt\n    (user,age)\n})\n```\n2.flatMap, flatten\nflatten: flatten[B]: List[B] 对列表的列表进行平坦化操作 flatMap: flatMap[B](f: (A) ⇒ GenTraversableOnce[B]): List[B] map之后对结果进行flatten\n\n定义一个变换f, 把f应用列表的每个元素中，每个f返回一个列表，最终把所有列表连结起来。\n```\nval text = List(\"A,B,C\",\"D,E,F\")\nval textMapped = text.map(_.split(\",\").toList) // List(List(\"A\",\"B\",\"C\"),List(\"D\",\"E\",\"F\"))\nval textFlattened = textMapped.flatten          // List(\"A\",\"B\",\"C\",\"D\",\"E\",\"F\")\nval textFlatMapped = text.flatMap(_.split(\",\").toList) // List(\"A\",\"B\",\"C\",\"D\",\"E\",\"F\")\n```\n\n3.reduce\nreduce[A1 >: A](op: (A1, A1) ⇒ A1): A1\n定义一个变换f, f把两个列表的元素合成一个，遍历列表，最终把列表合并成单一元素\nExample 列表求和\n```\nval nums = List(1,2,3)\nval sum1 = nums.reduce((a,b) => a+b)   //6\nval sum2 = nums.reduce(_+_)            //6\nval sum3 = nums.sum                 //6\n```\n4.reduceLeft,reduceRight\nreduceLeft: reduceLeft[B >: A](f: (B, A) ⇒ B): B\nreduceRight: reduceRight[B >: A](op: (A, B) ⇒ B): B\nreduceLeft从列表的左边往右边应用reduce函数，reduceRight从列表的右边往左边应用reduce函数\nExample\n```\nval nums = List(2.0,2.0,3.0)\nval resultLeftReduce = nums.reduceLeft(math.pow)  // = pow( pow(2.0,2.0) , 3.0) = 64.0\nval resultRightReduce = nums.reduceRight(math.pow) // = pow(2.0, pow(2.0,3.0)) = 256.0\n```\n5.fold,foldLeft,foldRight\nfold: fold[A1 >: A](z: A1)(op: (A1, A1) ⇒ A1): A1 带有初始值的reduce,从一个初始值开始，从左向右将两个元素合并成一个，最终把列表合并成单一元素。\nfoldLeft: foldLeft[B](z: B)(f: (B, A) ⇒ B): B 带有初始值的reduceLeft\nfoldRight: foldRight[B](z: B)(op: (A, B) ⇒ B): B 带有初始值的reduceRight\n```\nval nums = List(2,3,4)\nval sum = nums.fold(1)(_+_)  // = 1+2+3+4 = 9\n\nval nums = List(2.0,3.0)\nval result1 = nums.foldLeft(4.0)(math.pow) // = pow(pow(4.0,2.0),3.0) = 4096\nval result2 = nums.foldRight(1.0)(math.pow) // = pow(1.0,pow(2.0,3.0)) = 8.0\n```\n6.sortBy,sortWith,sorted\nsortBy: sortBy[B](f: (A) ⇒ B)(implicit ord: math.Ordering[B]): List[A] 按照应用函数f之后产生的元素进行排序\nsorted： sorted[B >: A](implicit ord: math.Ordering[B]): List[A] 按照元素自身进行排序\nsortWith： sortWith(lt: (A, A) ⇒ Boolean): List[A] 使用自定义的比较函数进行排序\n```\nval nums = List(1,3,2,4)\nval sorted = nums.sorted  //List(1,2,3,4)\n\nval users = List((\"HomeWay\",25),(\"XSDYM\",23))\nval sortedByAge = users.sortBy{case(user,age) => age}  //List((\"XSDYM\",23),(\"HomeWay\",25))\nval sortedWith = users.sortWith{case(user1,user2) => user1._2 < user2._2} //List((\"XSDYM\",23),(\"HomeWay\",25))\n```\n7.filter, filterNot\nfilter: filter(p: (A) ⇒ Boolean): List[A]\nfilterNot: filterNot(p: (A) ⇒ Boolean): List[A]\nfilter 保留列表中符合条件p的列表元素 ， filterNot，保留列表中不符合条件p的列表元素\n```\nval nums = List(1,2,3,4)\nval odd = nums.filter( _ % 2 != 0) // List(1,3)\nval even = nums.filterNot( _ % 2 != 0) // List(2,4)\n```\n\n8.count\ncount(p: (A) ⇒ Boolean): Int\n计算列表中所有满足条件p的元素的个数，等价于 filter(p).length\n```\nval nums = List(-1,-2,0,1,2) \nval plusCnt1 = nums.count(_> 0) \nval plusCnt2 = nums.filter(_> 0).length \n```\n9. diff, union, intersect\n  diff:diff(that: collection.Seq[A]): List[A] 保存列表中那些不在另外一个列表中的元素，即从集合中减去与另外一个集合的交集\n  union : union(that: collection.Seq[A]): List[A] 与另外一个列表进行连结\n  intersect: intersect(that: collection.Seq[A]): List[A] 与另外一个集合的交集\n```\nval nums1 = List(1,2,3)\nval nums2 = List(2,3,4)\nval diff1 = nums1 diff nums2   // List(1)\nval diff2 = nums2.diff(num1)   // List(4)\nval union1 = nums1 union nums2  // List(1,2,3,2,3,4)\nval union2 = nums2 ++ nums1        // List(2,3,4,1,2,3)\nval intersection = nums1 intersect nums2  //List(2,3)\n```\n10.distinct\n\ndistinct: List[A] 保留列表中非重复的元素，相同的元素只会被保留一次\n```\nval list = List(\"A\",\"B\",\"C\",\"A\",\"B\") val distincted = list.distinct // List(\"A\",\"B\",\"C\")1\n```\n11.groupBy, grouped\ngroupBy : groupBy[K](f: (A) ⇒ K): Map[K, List[A]] 将列表进行分组，分组的依据是应用f在元素上后产生的新元素 \ngrouped: grouped(size: Int): Iterator[List[A]] 按列表按照固定的大小进行分组\n```\nval data = List((\"HomeWay\",\"Male\"),(\"XSDYM\",\"Femail\"),(\"Mr.Wang\",\"Male\"))\nval group1 = data.groupBy(_._2) // = Map(\"Male\" -> List((\"HomeWay\",\"Male\"),(\"Mr.Wang\",\"Male\")),\"Female\" -> List((\"XSDYM\",\"Femail\")))\nval group2 = data.groupBy{case (name,sex) => sex} // = Map(\"Male\" -> List((\"HomeWay\",\"Male\"),(\"Mr.Wang\",\"Male\")),\"Female\" -> List((\"XSDYM\",\"Femail\")))\nval fixSizeGroup = data.grouped(2).toList // = Map(\"Male\" -> List((\"HomeWay\",\"Male\"),(\"XSDYM\",\"Femail\")),\"Female\" -> List((\"Mr.Wang\",\"Male\")))\n```\n12.scan\nscan[B >: A, That](z: B)(op: (B, B) ⇒ B)(implicit cbf: CanBuildFrom[List[A], B, That]): That\n由一个初始值开始，从左向右，进行积累的op操作，这个比较难解释，具体的看例子吧。\n```\nval nums = List(1,2,3)\nval result = nums.scan(10)(_+_)   // List(10,10+1,10+1+2,10+1+2+3) = List(10,11,13,16)\n```\n13.scanLeft,scanRight\nscanLeft: scanLeft[B, That](z: B)(op: (B, A) ⇒ B)(implicit bf: CanBuildFrom[List[A], B, That]): That\nscanRight: scanRight[B, That](z: B)(op: (A, B) ⇒ B)(implicit bf: CanBuildFrom[List[A], B, That]): That\nscanLeft: 从左向右进行scan函数的操作，scanRight：从右向左进行scan函数的操作\n```\nval nums = List(1.0,2.0,3.0)\nval result = nums.scanLeft(2.0)(math.pow)   // List(2.0,pow(2.0,1.0), pow(pow(2.0,1.0),2.0),pow(pow(pow(2.0,1.0),2.0),3.0) = List(2.0,2.0,4.0,64.0)\nval result = nums.scanRight(2.0)(math.pow)  // List(2.0,pow(3.0,2.0), pow(2.0,pow(3.0,2.0)), pow(1.0,pow(2.0,pow(3.0,2.0))) = List(1.0,512.0,9.0,2.0)\n```\n\n14.take,takeRight,takeWhile\ntake : takeRight(n: Int): List[A] 提取列表的前n个元素 takeRight: takeRight(n: Int): List[A] 提取列表的最后n个元素 takeWhile: takeWhile(p: (A) ⇒ Boolean): List[A] 从左向右提取列表的元素，直到条件p不成立\n```\nval nums = List(1,1,1,1,4,4,4,4)\nval left = nums.take(4)   // List(1,1,1,1)\nval right = nums.takeRight(4) // List(4,4,4,4)\nval headNums = nums.takeWhile( _ == nums.head)  // List(1,1,1,1)\n```\n\n15.drop,dropRight,dropWhile\ndrop: drop(n: Int): List[A] 丢弃前n个元素，返回剩下的元素 dropRight: dropRight(n: Int): List[A] 丢弃最后n个元素，返回剩下的元素 dropWhile: dropWhile(p: (A) ⇒ Boolean): List[A] 从左向右丢弃元素，直到条件p不成立\n```\nval nums = List(1,1,1,1,4,4,4,4)\nval left = nums.drop(4)   // List(4,4,4,4)\nval right = nums.dropRight(4) // List(1,1,1,1)\nval tailNums = nums.dropWhile( _ == nums.head)  // List(4,4,4,4)\n```\n\n16.span, splitAt, partition\nspan : span(p: (A) ⇒ Boolean): (List[A], List[A]) 从左向右应用条件p进行判断，直到条件p不成立，此时将列表分为两个列表\nsplitAt: splitAt(n: Int): (List[A], List[A]) 将列表分为前n个，与，剩下的部分\npartition: partition(p: (A) ⇒ Boolean): (List[A], List[A]) 将列表分为两部分，第一部分为满足条件p的元素，第二部分为不满足条件p的元素\n```\nval nums = List(1,1,1,2,3,2,1)\nval (prefix,suffix) = nums.span( _ == 1) // prefix = List(1,1,1), suffix = List(2,3,2,1)\nval (prefix,suffix) = nums.splitAt(3)  // prefix = List(1,1,1), suffix = List(2,3,2,1)\nval (prefix,suffix) = nums.partition( _ == 1) // prefix = List(1,1,1,1), suffix = List(2,3,2)\n```\n\n17.padTo\n```\npadTo(len: Int, elem: A): List[A]\n将列表扩展到指定长度，长度不够的时候，使用elem进行填充，否则不做任何操作。\n val nums = List(1,1,1)\n val padded = nums.padTo(6,2)   // List(1,1,1,2,2,2)\n```\n\n18.combinations,permutations\n```\ncombinations: combinations(n: Int): Iterator[List[A]] 取列表中的n个元素进行组合，返回不重复的组合列表，结果一个迭代器\npermutations: permutations: Iterator[List[A]] 对列表中的元素进行排列，返回不重得的排列列表，结果是一个迭代器\nval nums = List(1,1,3)\nval combinations = nums.combinations(2).toList //List(List(1,1),List(1,3))\nval permutations = nums.permutations.toList        // List(List(1,1,3),List(1,3,1),List(3,1,1))\n```\n19.zip, zipAll, zipWithIndex, unzip,unzip3\nzip: zip[B](that: GenIterable[B]): List[(A, B)] 与另外一个列表进行拉链操作，将对应位置的元素组成一个pair，返回的列表长度为两个列表中短的那个\nzipAll: zipAll[B](that: collection.Iterable[B], thisElem: A, thatElem: B): List[(A, B)] 与另外一个列表进行拉链操作，将对应位置的元素组成一个pair，若列表长度不一致，自身列表比较短的话使用thisElem进行填充，对方列表较短的话使用thatElem进行填充\nzipWithIndex：zipWithIndex: List[(A, Int)] 将列表元素与其索引进行拉链操作，组成一个pair\nunzip: unzip[A1, A2](implicit asPair: (A) ⇒ (A1, A2)): (List[A1], List[A2]) 解开拉链操作\nunzip3: unzip3[A1, A2, A3](implicit asTriple: (A) ⇒ (A1, A2, A3)): (List[A1], List[A2], List[A3]) 3个元素的解拉链操作\n```\nval alphabet = List(\"A\",B\",\"C\")\nval nums = List(1,2)\nval zipped = alphabet zip nums   // List((\"A\",1),(\"B\",2))\nval zippedAll = alphabet.zipAll(nums,\"*\",-1)   // List((\"A\",1),(\"B\",2),(\"C\",-1))\nval zippedIndex = alphabet.zipWithIndex  // List((\"A\",0),(\"B\",1),(\"C\",3))\nval (list1,list2) = zipped.unzip        // list1 = List(\"A\",\"B\"), list2 = List(1,2)\nval (l1,l2,l3) = List((1, \"one\", '1'),(2, \"two\", '2'),(3, \"three\", '3')).unzip3   // l1=List(1,2,3),l2=List(\"one\",\"two\",\"three\"),l3=List('1','2','3')\n```\n20.slice\nslice(from: Int, until: Int): List[A] 提取列表中从位置from到位置until(不含该位置)的元素列表\n```\nval nums = List(1,2,3,4,5)\nval sliced = nums.slice(2,4)  //List(3,4)\n```\n21.sliding\nsliding(size: Int, step: Int): Iterator[List[A]] 将列表按照固定大小size进行分组，步进为step，step默认为1,返回结果为迭代器\n```\nval nums = List(1,1,2,2,3,3,4,4)\nval groupStep2 = nums.sliding(2,2).toList  //List(List(1,1),List(2,2),List(3,3),List(4,4))\nval groupStep1 = nums.sliding(2).toList //List(List(1,1),List(1,2),List(2,2),List(2,3),List(3,3),List(3,4),List(4,4)) \n```\n\n22.updated\nupdated(index: Int, elem: A): List[A] 对列表中的某个元素进行更新操作\n```\nval nums = List(1,2,3,3)\nval fixed = nums.updated(3,4)  // List(1,2,3,4)\n```\n\n## 十五.快学scala练习题\n\n练习：\n\n1.设置一个映射,其中包含你想要的一些装备，以及它们的价格。然后构建另一个映射，采用同一组键，但是价格上打9折\n\n```\nscala> val price = Map(\"ipad\" -> 4000,\"iPhone\" -> 6000, \"iWatch\" -> 3000)\nprice: scala.collection.immutable.Map[String,Int] = Map(ipad -> 4000, iPhone ->\n6000, iWatch -> 3000)\n\nscala> val newprice = for((k,v) <- price) yield (k, v * 0.9)\nnewprice: scala.collection.immutable.Map[String,Double] = Map(ipad -> 3600.0, iP\nhone -> 5400.0, iWatch -> 2700.0)\n```\n2.编写一段程序，从文件中读取单词。用一个可变映射来清点每个单词出现的频率。读取这些单词的操作可以使用java.util.Scanner:\nval in = new java.util.Scanner(new java.io.File(\"myfile.txt\")) while(in.hasNext()) 处理 in.next()最后，打印出所有单词和它们出现的次数。\n```\nimport scala.io.Source\nimport scala.collection.mutable.HashMap\nobject Pract {\n   def main(args: Array[String])  = {\n      val source = Source.fromFile(\"file.txt\").mkString\n      val tokens = source.split(\"\\s+\")\n      val map = new HashMap[String,Int]\n  for(key <- tokens){\n    map(key) = map.getOrElse(key, 0) + 1\n  }\n  println(map.mkString(\",\"))      \n   }\n}\n```\n3.重复前一个练习，这次用不可变的映射\n不可变映射与可变映射的区别就是每次添加新的元素时都会返回一个新的映射。\n\n```\nimport scala.io.Source\nobject Pract {\n   def main(args: Array[String])  = {\n      val source = Source.fromFile(\"file.txt\").mkString\n      val tokens = source.split(\"\\s+\")\n      var map = MapString,Int //注意这里用的 var 了\n\n  for(key <- tokens){\n      map += (key -> (map.getOrElse(key, 0) + 1))\n  }\n  println(map.mkString(\",\"))      \n   }\n}\n```\n4.重复前一个练习，这次使用已排序的映射，以便单词可以按顺序打印出来\n```\nimport scala.io.Source\nimport scala.collection.SortedMap\n\nobject Pract {\n   def main(args: Array[String])  = {\n      val source = Source.fromFile(\"file.txt\").mkString\n      val tokens = source.split(\"\\s+\")\n      var sortedmap = SortedMapString,Int //注意这里用的 var 了\n\n  for(key <- tokens){\n      sortedmap += (key -> (sortedmap.getOrElse(key, 0) + 1))\n  }\n  println(sortedmap.mkString(\",\"))      \n   }\n}\n```\n5.重复前一个练习，这次使用java.util.TreeMap并使之适用于Scala API\n```\nimport scala.io.Source\nimport scala.collection.mutable.Map\nimport scala.collection.JavaConversions.mapAsScalaMap\nimport java.util.TreeMap\n\nobject Pract {\n   def main(args: Array[String])  = {\n      val source = Source.fromFile(\"file.txt\").mkString\n      val tokens = source.split(\"\\s+\")\n      val map:Map[String,Int] = new TreeMap[String,Int]\n\n  for(key <- tokens){\n     map(key) = map.getOrElse(key, 0) + 1\n  }\n  println(map.mkString(\",\"))   \n   }\n}\n```\n6.定义一个链式哈希映射,将\"Monday\"映射到java.util.Calendar.MONDAY,依次类推加入其他日期。展示元素是以插入的顺序被访问的\n```\nimport scala.collection.mutable.LinkedHashMap\nimport java.util.Calendar\n\nobject Pract {\n   def main(args: Array[String])  = {\n      val map = new LinkedHashMap[String, Int]\n      map += (\"MONDAY\" -> Calendar.MONDAY)\n      map += (\"TUESDAY\" -> Calendar.TUESDAY)\n      map += (\"WENDSDAY\" -> Calendar.WEDNESDAY)\n      map += (\"THURSDAY\" -> Calendar.THURSDAY)\n      map += (\"FRIDAY\" -> Calendar.FRIDAY)\n      map += (\"SATURDAY\" -> Calendar.SATURDAY)\n      map += (\"SUNDAY\" -> Calendar.SUNDAY)\n      println(map.mkString(\",\"))\n   }\n}\n```\n\n7.打印出所有Java系统属性的表格\n\nJAVA系统属性转scala map的使用\n\n```\nimport scala.collection.JavaConversions.propertiesAsScalaMap\nimport scala.collection.Map\n\nobject Pract {\n   def main(args: Array[String])  = {\n      val props: Map[String,String] = System.getProperties\n      val keys = props.keySet\n      val keylength = for( key <- keys) yield key.length\n      val maxlength = keylength.max\n      for( key <- keys) {\n        print(key)\n        print(\" \" * (maxlength - key.length))\n        print(\"| \")\n        println(props(key))\n      }\n\n   }\n}\n```\n8.编写一个函数minmax(values:Array[Int]),返回数组中最小值和最大值的对偶\n```\ndef minmax(values:Array[Int])  = {\n     (values.max,values.min)\n   }\n```\n9.编写一个函数Iteqgt(values:Array[int],v:Int),返回数组中小于v,等于v和大于v的数量，要求三个值一起返回\n\n```\ndef Iteqgt(values:Array[Int],v:Int) = {\n     var a,b,c=0\n     for(value <- values){\n       if(value > v) a += 1\n       else if(value == v) b += 1\n       else c += 1\n     }\n     (a,b,c)\n   }\n\n   def Iteqgt1(values:Array[Int],v:Int) = {\n     (values.count( > v),values.count( == v), values.count(_ < v))\n   }\n```\n10.当你将两个字符串拉链在一起，比如\"Hello\".zip(\"World\")，会是什么结果？想出一个讲得通的用例\n```\nscala> \"Hello\".zip(\"world\")\nres0: scala.collection.immutable.IndexedSeq[(Char, Char)] = Vector((H,w), (e,o),\n (l,r), (l,l), (o,d))\n\n```\n\n## 十六.构造器\n\nScala的类可以有一个主构造器和多个辅助构造器。每个辅助构造器的名称为this，每一个辅助构造器都必须以调用已经定义的辅助构造器或主构造器开始定义\n\n- 主构造器\n\n\n> 如果一个类没有显示定义主构造器，则有一个默认的无参主构造器     如定义一个Student类\n\n```\nclass Student(val name:String, var age:Int = 0, address:String = \"\", private var school:String = \"\"){\n    var grade:Int = if( age>7 ) age -7 else 0\n    println(\" I'm in main constructor. \")\n    def info() = \" name is \"+name+\", age is \"+age+\", address is \"+address\n}\n```\n　　对于Scala类，主构造器的参数放置在类名后，由括号括起来。且对于主构造器中var、val、private 等标注的参数，都会成为类的对应字段，并生成对应的默认getter、setter方法。如Student类中的name、age、school等。对于主构造器中的未用var、val标注的参数，如果在类的任何一个方法用用到该参数，该参数将会转换为类的字段，否则不会，如Student类的address属性。\n\n　　由于在Student类中的info方法中用到了参数address，所以Student共有name、age、address、school、grade等5个属性，且Scala根据对应属性的特点生成了默认的getter和setter方法。\n\n　　对于主构造器的参数，也可以提供参数默认值。通过为主构造器提供默认值可减少辅助构造器的个数\n　　主构造器的函数体，是类中除了方法定义以外的其他语句，如在Student类的主构造器中，包含grade属性的初始化和prinln这两行语句。\n\n![](https://static.oschina.net/uploads/space/2018/1116/110347_10HB_3005534.png)\n\n- 辅助构造器\n>  辅助构造器通过this来定义，且必须首先调用主构造器或者其他已经定义的辅助构造器。\n\n```\nclass Person(val name:String){\n    var age = 0\n    var sex:Char = 'f'\n    println(\"main constructor...\")\n\n    def this(name:String,  age:Int){\n        this(name)        //调用主构造器\n        this.age = age     //使用this关键字\n        println(\" auxiliary constructor1 \")\n    }\n\n    def this(name:String, age:Int, sex:Char){\n        this(name, age)\n        this.sex = sex\n        println(\" auxiliary constructor2 \")\n    }\n}\n```\n\n> 【注：辅助构造器的参数前不能添加val、var标志，否则会报错。】\n\n![](https://static.oschina.net/uploads/space/2018/1116/110550_hUV6_3005534.png)\n\n- 私有主构造器\n\n\n```\nclass Person private(val name:String){\n    var age:Int = 1\n    def this(name: String, age:Int){\n        this(name)\n        this.age = age\n    }\n}\n```\n\n\n\n\n\n# hadoop\n\n## 一.Nodepad远程linux插件NppFTP\n\n**1.在该github上下载自己notepad++对应版本位数的插件**\n[NppFTP下载地址](https://github.com/ashkulz/NppFTP/releases/tag/v0.27.6 )：https://github.com/ashkulz/NppFTP/releases/tag/v0.27.6\n\n> 下载时可以因为被墙的原因下载不了，如果有跨网服务器，直接wget 实际下载地址\n> ![输入图片说明](https://static.oschina.net/uploads/img/201901/11105326_7IeQ.png \"在这里输入图片标题\")\n\n> 软件如果下载不了 可以到百度网盘qq939598604/我的软件/NppFTP目录下下载\n\n**2.下载之后进行解压，然后将bin目录下的dll文件拷贝到notepad++的安装目录下的插件目录**\nnotepad++的安装目录可以右键notepad++的快捷方式，找到安装目录\n![输入图片说明](https://static.oschina.net/uploads/img/201901/11105635_bvCw.png \"在这里输入图片标题\")\n![输入图片说明](https://static.oschina.net/uploads/img/201901/11105728_rL2U.png \"在这里输入图片标题\") \n\n**3.重启notepad++**\n\n**4.重启后，在插件菜单中会显示该插件**\n![输入图片说明](https://static.oschina.net/uploads/img/201901/11105829_SBf5.png \"在这里输入图片标题\")\n\n**5.NppFTP使用**\n![输入图片说明](https://static.oschina.net/uploads/img/201901/11110929_I4h9.png \"在这里输入图片标题\")\n![输入图片说明](https://static.oschina.net/uploads/img/201901/11110936_ZoEY.png \"在这里输入图片标题\")\n![输入图片说明](https://static.oschina.net/uploads/img/201901/11110948_7ATB.png \"在这里输入图片标题\")\n![输入图片说明](https://static.oschina.net/uploads/img/201901/11110955_AfYH.png \"在这里输入图片标题\")\n\n![输入图片说明](https://static.oschina.net/uploads/img/201901/11112540_Mc1p.png \"在这里输入图片标题\")\n\n\n\n##  二.实现linux集群所有机器免密钥登录\n\n**1.先安装expect** \n```\nyum install expect\n```\n**2.生成密钥 **\n```\nssh-keygen(注,一路回车,不用管)\n```\n**3.修改host文件 /etc/hosts**\n```\n192.168.197.21 master\n192.168.197.25 slave1\n192.168.197.27 slave2 \n```\n**4.编写shell脚本 vim.ssh_copy_id_to_all.sh**\n```\n#!/bin/bash\nSERVERS=\"master slave1 slave2\"\nPASSWORD=root\nauto_ssh_copy_id() {\n    expect -c \"set timeout -1;\n        spawn ssh-copy-id $1;\n        expect {\n            *(yes/no)* {send -- yes\\r;exp_continue;}\n            *assword:* {send -- $2\\r;exp_continue;}\n            eof        {exit 0;}\n        }\";\n}\n\nssh_copy_id_to_all() {\n    for SERVER in $SERVERS\n    do\n        auto_ssh_copy_id $SERVER $PASSWORD\n    done\n}\n\nssh_copy_id_to_all\n```\n**5.chomd +x ssh_copy_id_to_all.sh**\n**6.执行脚本**\n./ssh_copy_id_to_all.sh\n\n## 三.Windows安装部署hadoop-2.7.5\n\n**(1).编辑“M:\\soft\\hadoop-2.7.5\\etc\\hadoop”下的core-site.xml文件，将下列文本粘贴进去，并保存；**\n\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n<configuration>\n    <property>\n        <name>hadoop.tmp.dir</name>\n        <value>/M:/soft/hadoop-2.7.5/tmp</value>\n    </property>\n    <property>\n        <name>dfs.name.dir</name>\n        <value>/M:/soft/hadoop-2.7.5/name</value>\n    </property>\n    <property>\n        <name>fs.default.name</name>\n        <value>hdfs://localhost:9000</value>\n    </property>\n</configuration>\n```\n\n**(2).编辑“M:\\soft\\hadoop-2.7.5\\etc\\hadoop”目录下的mapred-site.xml(没有就将mapred-site.xml.template重命名为mapred-site.xml)文件，粘贴一下内容并保存:**\n\n```\n<?xml version=\"1.0\"?>\n<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n<configuration>\n    <property>\n       <name>mapreduce.framework.name</name>\n       <value>yarn</value>\n    </property>\n    <property>\n       <name>mapred.job.tracker</name>\n       <value>hdfs://localhost:9001</value>\n    </property>\n</configuration>\n```\n\n**(3).编辑“M:\\soft\\hadoop-2.7.5\\etc\\hadoop”目录下的hdfs-site.xml文件，粘贴以下内容并保存。请自行创建data目录，在这里我是在HADOOP_HOME目录下创建了data目录:**\n\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n<configuration>\n    <!-- 这个参数设置为1，因为是单机版hadoop -->\n    <property>\n        <name>dfs.replication</name>\n        <value>1</value>\n    </property>\n    <property>\n        <name>dfs.data.dir</name>\n        <value>/M:/soft/hadoop-2.7.5/data</value>\n    </property>\n</configuration>\n```\n\n**(4).编辑“M:\\soft\\hadoop-2.7.5\\etc\\hadoop”目录下的yarn-site.xml文件，粘贴以下内容并保存；**\n\n```\n<?xml version=\"1.0\"?>\n<configuration>\n    <property>\n       <name>yarn.nodemanager.aux-services</name>\n       <value>mapreduce_shuffle</value>\n    </property>\n    <property>\n       <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>\n       <value>org.apache.hadoop.mapred.ShuffleHandler</value>\n    </property>\n</configuration>\n```\n\n**(5).编辑“M:\\soft\\hadoop-2.7.5\\etc\\hadoop”目录下的hadoop-env.cmd文件，将JAVA_HOME用 @rem注释掉，编辑为JAVA_HOME的路径，然后保存:**\n\n```\n@rem set JAVA_HOME=%JAVA_HOME%\nset JAVA_HOME=M:\\soft\\Java\\jdk1.8.0_101\n```\n\n**替换文件** 将下载好的hadooponwindows-master.zip（笔记第一步有下载地址，不知道可以去笔记开头的需求栏目查看）解压，将解压后的**\\*bin目录下的所有文件直接覆盖Hadoop的bin目录***。\n\n## 四.hadoop集群安装\n\n**（一）.安装环境 ：所有的软件安装在根目录下的/soft目录**\n\njava---/soft/jdk1.0.8\nhadoop--/soft/hadoop2.7.4\n固定hadoop配置变量(JAVA_HOME,主机名称,hadoop的固定目录)可以不用安装那么多\nhadoop-env.sh 文件:\n```\nexport JAVA_HOME=/soft/jdk1.0.8\n```\ncore-site.xml文件: \n```\n<name>fs.defaultFS</name>\n<value>hdfs://node1:9000</value>\n```\nhdfs-site.xml文件：\n```\n<name>dfs.namenode.name.dir</name>\n<value>file:/soft/hadoop-2.7.4/tmp/dfs/name</value>\n```\nslaves文件\n```\nslave1   slave2 \n```\n\n集群规划\n主机名           ip          安装的软件         进程\nmaster   192.168.197.255  jdk、hadoop  namenode ressourcemanager\nslave1   192.168.197.256  jdk、hadoop  datanode secondnamenode\nslave2   192.168.197.257  jdk、hadoop  datanade\n\n**（二）.安装JDK** \n\n1.下载jdk1.8.0_161\n2.在/etc/profile中添加如下配置\nsudo vim /etc/profile\n```\nexport JAVA_HOME=/soft/jdk1.8.0_161\nexport JRE_HOME=${JAVA_HOME}/jre\nexport CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib\nexport PATH=${JAVA_HOME}/bin:$PATH\n```\n3.使环境变量生效，source /etc/profile\n4.安装验证# java -version \n\n\n**（三）.准备host文件和修改主机名称**\n1.vim /etc/hosts\n```\n192.168.197.225 master\n192.168.197.226 slave1\n192.168.197.227 slave2\n```\n2.拷贝/etc/hosts到其它主机\n   scp /etc/hosts slave1:/etc/\n   scp /etc/hosts slave2:/etc/\n\n3.修改主机名\n   vim /etc/hosts  \n   master slave1 slave2 \n\n**（四）.免登录**\n1.注意将防火墙关掉\nCentOS7 \n\n```\n (1)关闭防火墙：sudo systemctl stop firewalld.service\n (2)关闭开机启动：sudo systemctl disable firewalld.service\n (3)安装iptables防火墙：sudo yum install iptables-services\n (4)设置iptables防火墙开机启动：sudo systemctl enable iptables\n```\n\nubuntu\n\n```\n(1)关闭ubuntu的防火墙 ufw disable\n(2)开启防火墙 ufw enable\n(3)卸载了iptables apt-get remove iptables \n(4)关闭ubuntu中的防火墙的其余命令\n    iptables -P INPUT ACCEPT\n    iptables -P FORWARD ACCEPT\n    iptables -P OUTPUT ACCEPT\n    iptables -F\n```\n\n2.ssh无密登录,\n(1)在集群/etc/ssh/sshd_config 文件去掉以下选项的注释\nsudo vim /etc/ssh/sshd_config\n```\nPort 22\nProtocol 2\nRSAAuthentication yes      #开启私钥验证\nPubkeyAuthentication yes   #开启公钥验证\n```\n3.生成秘钥\n(1)在主从节点(集群的每一个节点节点)输入命令 ，生成 key，一律回车\n   ssh-keygen -t rsa -P ''\n(2)将从节点(集群的每一个节点节点)公钥收集到一个文件中authorized_keys，并发送到各个节点\n从节点配置：\n      在slave1的机器：scp /home/chen/.ssh/id_rsa.pub master:/home/chen/.ssh/id_rsa.pub.s1\n      在slave2的机器：scp /home/chen/.ssh/id_rsa.pub master:/home/chen/.ssh/id_rsa.pub.s2\n主节点配置：\n(3)将所有机器的id_rsa.pub文件收集到authorized_keys，并发送到各个节点\n   sudo cat /home/chen/.ssh/id_rsa.pub >> /home/chen/.ssh/authorized_keys\n   sudo cat /home/chen/.ssh/id_rsa.pub.s1 >> /home/chen/.ssh/authorized_keys\n   sudo cat /home/chen/.ssh/id_rsa.pub.s2 >> /home/chen/.ssh/authorized_keys\n(4)最后将生成的包含三个节点的秘钥的authorized_keys 复制到s1和s2的.ssh目录下（ \n   scp /home/chen/.ssh/authorized_keys slave1:/home/chen/.ssh/\n   scp /home/chen/.ssh/authorized_keys slave2:/home/chen/.ssh/\n\n验证ssh免密码登录\n1.输入命令ssh  localhost(主机名) 根据提示输入“yes” \n2.输入命令exit注销（Logout）\n3.再次输入命令ssh localhost即可直接登录\n\n\n**（五）hadoop的配置**\n(1)编辑 hadoop-env.sh 文件,找到 JAVA_HOME 改为 JDK 的安装目录\n   sudo vim /soft/hadoop-2.7.4/etc/hadoop/hadoop-env.sh\n   export JAVA_HOME=/soft/jdk1.8.0_161\n(2)修改 core-site.xml\n   sudo vim core-site.xml\n   ```\n<configuration>\n       <property>\n           <name>fs.defaultFS</name>\n           <value>hdfs://master:9000</value>\n       </property>\n       <property>\n           <name>hadoop.tmp.dir</name>\n           <value>file:/soft/hadoop-2.7.4/tmp</value>\n       </property>\n   </configuration>\n   ```\n(2)修改 hdfs-site.xml\n   sudo vim hdfs-site.xml\n```\n<configuration>\n    <property>\n        <name>dfs.namenode.secondary.http-address</name>\n        <value>master:50090</value>\n    </property>\n    <property>\n        <name>dfs.replication</name>\n        <value>2</value>\n    </property>\n    <property>\n        <name>dfs.namenode.name.dir</name>\n        <value>file:/soft/hadoop-2.7.4/tmp/dfs/name</value>\n    </property>\n    <property>\n        <name>dfs.datanode.data.dir</name>\n        <value>file:/soft/hadoop-2.7.4/tmp/dfs/data</value>\n    </property>\n</configuration>\n```\n(3)修改 mapred-site.xml\n目录下么没有这个文件,这有一个模板,我们需要先拷贝一份\n cp mapred-site.xml.template mapred-site.xml\n vim  mapred-site.xml\n```\n<configuration>\n    <property>\n        <name>mapreduce.framework.name</name>\n        <value>yarn</value>\n    </property>\n    <property>\n        <name>mapreduce.jobhistory.address</name>\n        <value>master:10020</value>\n    </property>\n    <property>\n        <name>mapreduce.jobhistory.webapp.address</name>\n        <value>master:19888</value>\n    </property>\n</configuration>\n```\n(4)修改 yarn-site.xml\nvi yarn-site.xml\n```\n<configuration>\n    <property>\n        <name>yarn.resourcemanager.hostname</name>\n        <value>master</value>\n    </property>\n    <property>\n        <name>yarn.nodemanager.aux-services</name>\n        <value>mapreduce_shuffle</value>\n    </property>\n</configuration>\n```\n\n**（六）配置集群**\n(1)复制节点,将hadoop-2.7.4 文件夹重打包后复制到其他子节点\n```\nscp /soft/hadoop-2.7.4/ chen@slave1:/soft\nscp /soft/hadoop-2.7.4/ chen@slave2:/soft\n```\n(2)配置slaves文件\n修改（Master主机）/soft/hadoop-2.7.4/etc/hadoop/slaves该文件指定哪些服务器节点是datanode节点。删除locahost，添加所有datanode节点的主机名\nsudo vim /soft/hadoop-2.7.4/etc/hadoop/slaves\n```\nslave1\nslave2\n```\n(3)格式化namenode和datanode并启动，（在master上执行就可以了 不需要在slave上执行）\n```\ncd /soft/hadoop-2.7.4/bin\n./hadoop namenode -format\n./hadoop datanode -format\n```\n\n**（七）启动 hadoop**\n\ncd /soft/hadoop-2.7.4/sbin\n./start-dfs.sh\n./start-yarn.sh\n./mr-jobhistory-daemon.sh start historyserver\n或者\n./start-all.sh\n./mr-jobhistory-daemon.sh start historyserver\n\n**（八）查看进程服务**\n查看启动进程,缺少以下任一进程都表示出错\n$ jps\n2528 NameNode\n2720 SecondaryNameNode\n2872 ResourceManager\n3151 JobHistoryServer\n查看端口占用情况\nnetstat -tnlp | grep java\n访问master\nhttp://192.168.197.255:50070\nhttp://192.168.197.255:8088\n\n**（九）停止 hadoop**\ncd /soft/hadoop-2.7.4/sbin\n./stop-all.sh\n\n#  \n\n#  hbase\n\n## 一.hbase在linux系统本地模式\n\n1.安装好jdk\n2.下载hbase hbase 下载地址：http://hbase.apache.org/\n\n```\nhbase-2.0.2-bin.tar.gz\n```\n3.上传到linux服务的/soft目录下\n4.tar 开hbase压缩包\n```\ntar -zxvf /soft/hbase-2.0.2-bin.tar.gz -C /soft/\n```\n5.修改conf/hbase-env.sh \nvim /soft/hbase-2.0.2/conf/hbase-env.sh\n```\nexport JAVA_HOME=/soft/jdk1.8.0_161\n```\n6.编辑hbase-site.xml \n```\n<configuration>\n    <property>\n        <name>hbase.rootdir</name>\n        <value>file:///soft/hbase-2.0.2/data</value>\n    </property>\n</configuration>\n\n```\n7.新建hbase数据存放目录\n```\nmkdir /soft/hbase-2.0.2/data\n```\n8.启动hbase\n```\ncd /soft/hbase-2.0.2/bin\n./bin/start-hbase.sh\n```\n9.jps 查看后 出现Hmaster就是启动成功 然后就可以进入shell进行对hbase的操作\n```\n[root@master hbase-2.0.2]# jps\n4359 Main\n5532 Jps\n4829 HMaster\n```\n10.进入hbase shell\n```\n./bin/hbase shell\n```\n11.访问web\n```\nhttp://192.168.197.21:16010/master-status\n```\n\n\n**shell环境测试**\n创建表\n```\nhbase(main):016:0> create 't1', {NAME => 'f1', VERSIONS => 1}\n```\n查看表\n```\nhbase(main):017:0> list\nTABLE\nt1\n1 row(s)\nTook 0.0053 seconds                                                                   \n=> [\"t1\"]\n```\n插入一条数据\n```\nhbase(main):019:0> put 't1', 'r1', 'f1', 'v1'\n```\n扫描t1表的全数据\n```\nhbase(main):018:0>  scan 't1'\nROW                       COLUMN+CELL                                                 \nr1                       column=f1:, timestamp=1540885480142, value=v1                \n1 row(s)\n```\n\n## 二.Hbase在linux集群搭建\n\n软件放置路径为初级配置的路径/soft/hbase-1.3.1\n1.解压已经安装整理过的压缩包hbase-1.3.1-install.tar.gz\n```\ntar -zxvf /soft/hbase-1.3.1-install.tar.gz -C /soft/\n```\n2.修改hbase-env环境变量\nvim /soft/hbase-1.3.1/conf/hbase-env.sh\n```\nexport JAVA_HOME=/soft/jdk1.8.0_161\nexport HBASE_CLASSPATH=/soft/hadoop-2.7.4\nexport HBASE_MANAGES_ZK=false          # 不使用自带的zk，使用独立的zookeeper\n```\n3.修改hbase-site.xml\nvim /soft/hbase-1.3.1/conf/hbase-site.xml    # 配置站点信息\n```\n<configuration>\n    <property>\n        <name>hbase.rootdir</name>\n        <value>hdfs://master:9000/hbase</value>\n    </property>\n    <property>\n        <name>hbase.master</name>\n        <value>master</value>\n    </property>\n    <property>\n        <name>hbase.cluster.distributed</name>\n        <value>true</value>\n    </property>\n    <property>\n        <name>hbase.zookeeper.property.clientPort</name>\n        <value>2181</value>                                     # 这里指的是zook的端口\n    </property>\n    <property>\n        <name>hbase.zookeeper.quorum</name>                     # 主机名一定要对应上\n        <value>master,slave1,slave2</value>\n    </property>\n    <property>\n        <name>zookeeper.session.timeout</name>                  # zook的session超时时长\n        <value>60000000</value>\n    </property>\n    <property>\n        <name>dfs.support.append</name>\n        <value>true</value>\n    </property>\n</configuration>\n```\n4.指定添加regionservers\nvim /soft/hbase-1.3.1/conf/regionservers# 配置从节点 一定要对应上\n```\nmaster\nslave1\nslave2\n```\n5.复制/soft/hbase-1.3.1到各个从的机器\n```\nscp /soft/hbase-1.3.1 root@slave1:/soft/\nscp /soft/hbase-1.3.1 root@slave2:/soft/\n```\n6.在各个节点添加hbase的环境变量\nvim /etc/profile\n```\nexport HBASE_HOME=/soft/hbase-1.3.1\nexport PATH=$HBASE_HOME/bin:$PATH\n```\n7.在master启动hbase\n```\n/soft/hbase-1.3.1/bin/start-hbase.sh\n```\n8.浏览器检查打开master机器的端口16010\nhttp://192.168.197.231:16010/master-status\n\n## 三.hbase在window环境下安装\n\n1.安装jdk\n```\n默认JDK已安装并配置好环境变量，本处用的jdk1.8.0_101 \n```\n2、下载hbase-2.0.2-bin.tar.gz\n```\n解压到C:\\hbase-2.0.2\\目录下\n```\n\n3、下载hadoop-common-2.2.0-bin-master\n```\nhadoop-common-2.2.0-bin-master(包含windows端开发Hadoop2.2需要的winutils.exe)，HBase在Windows下部署需要使用到。    \n地址：https://github.com/srccodes/hadoop-common-2.2.0-bin，下载hadoop-common-2.2.0-bin-master.zip，解压缩到D:\\hadoop\\hadoop-common-2.2.0-bin-master。\n```\n\n4、修改HBase下的conf/hbase-env.cmd\n```\nset JAVA_HOME=M:\\soft\\Java\\jdk1.8.0_101\nset HBASE_MANAGES_ZK=true\n```\n\n5.修改HBase下的hbase-site.xml\n```\n<?xml version=\"1.0\"?>\n<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n<configuration>\n\t<property>  \n\t\t<name>hbase.rootdir</name>  \n\t\t<value>file:///C:/hbase-2.0.2/data</value>  \n\t</property>  \n\t<property>  \n\t\t<name>hbase.tmp.dir</name>  \n\t\t<value>C:/hbase-2.0.2/tmp</value>  \n\t</property>  \n\t<property>  \n\t\t<name>hbase.zookeeper.quorum</name>  \n\t\t<value>127.0.0.1</value>  \n\t</property>  \n\t<property>  \n\t\t<name>hbase.zookeeper.property.dataDir</name>  \n\t\t<value>C:/hbase-2.0.2/tmp/zoo</value>  \n\t</property>  \n\t<property>  \n\t\t<name>hbase.cluster.distributed</name>  \n\t\t<value>false</value>  \n\t</property>\n</configuration>\n\n```\n\n6.配置用户变量HADOOP_HOME\n```\n新建环境变量HADOOP_HOME，值为C:\\hadoop-common-2.2.0-bin-master\n在path后添加：%HADOOP_HOME%\\bin\n\n```\n\n7.启动HBase\n```\n在C:\\hbase-2.0.2\\bin下打开命令行，输入start-hbase.cmd，启动HBase。\n```\n8.测试Shell\n```\n HBase启动后，在命令行输入hbase shell，打卡HBase的shell命令行\n```\n9.打开HBase主页，网址：http://127.0.0.1:16010/master-status\n10.可以通过测试命令建表测试等等\n\n##  四.hbase的filter操作\n\n**1.创建表**\n```\ncreate 'test1', 'lf', 'sf'\n```\n\n**2.导入数据**\n```\nput 'test1', 'user1|ts1', 'sf:c1', 'sku1'\nput 'test1', 'user1|ts2', 'sf:c1', 'sku188'\nput 'test1', 'user1|ts3', 'sf:s1', 'sku123'\nput 'test1', 'user2|ts4', 'sf:c1', 'sku2'\nput 'test1', 'user2|ts5', 'sf:c2', 'sku288'\nput 'test1', 'user2|ts6', 'sf:s1', 'sku222'\n```\n\n**3.查询案例：谁的值=sku188**\n```\nscan 'test1', FILTER=>\"ValueFilter(=,'binary:sku188')\"\n```\n**#查询结果\n```\nROW                         COLUMN+CELL                    \nuser1|ts2                   column=sf:c1, timestamp=1409122354918, value=sku188\n```\n\n**4.查询案例：谁的值包含88**\n```\nscan 'test1', FILTER=>\"ValueFilter(=,'substring:88')\"\n```\n**#查询结果\n```\n ROW                         COLUMN+CELL    \n user1|ts2                   column=sf:c1, timestamp=1409122354918, value=sku188\n user2|ts5                   column=sf:c2, timestamp=1409122355030, value=sku288\n```\n\n**5.查询案例：谁的值包含88**\n```\nscan 'test1', FILTER=>\"ValueFilter(=,'substring:88')\"\n```\n**#查询结果\n```\n ROW                         COLUMN+CELL    \n user1|ts2                   column=sf:c1, timestamp=1409122354918, value=sku188\n user2|ts5                   column=sf:c2, timestamp=1409122355030, value=sku288\n```\n\n**6.通过广告点击进来的(column为c2)值包含88的用户**\n```\nscan 'test1', FILTER=>\"ColumnPrefixFilter('c2') AND ValueFilter(=,'substring:88')\"\n```\n**#查询结果\n```\n ROW                         COLUMN+CELL\n user2|ts5                   column=sf:c2, timestamp=1409122355030, value=sku288\n```\n\n**7.通过搜索进来的(column为s)值包含123或者222的用户**\n```\nscan 'test1', FILTER=>\"ColumnPrefixFilter('s') AND ( ValueFilter(=,'substring:123') OR ValueFilter(=,'substring:222') )\"\n```\n**#查询结果\n```\n ROW                         COLUMN+CELL\n user1|ts3                   column=sf:s1, timestamp=1409122354954, value=sku123\n user2|ts6                   column=sf:s1, timestamp=1409122355970, value=sku222\n```\n\n**8.rowkey为user1开头的**\n```\nscan 'test1', FILTER => \"PrefixFilter ('user1')\"\n```\n**#查询结果\n```\n ROW                        COLUMN+CELL\n user1|ts1                   column=sf:c1, timestamp=1409122354868, value=sku1\n user1|ts2                   column=sf:c1, timestamp=1409122354918, value=sku188\n user1|ts3                   column=sf:s1, timestamp=1409122354954, value=sku123\n```\n**9.从user1|ts2开始,找到所有的rowkey以user1开头的**\n```\nscan 'test1', {STARTROW=>'user1|ts2', FILTER => \"PrefixFilter ('user1')\"}\n```\n**#查询结果\n```\n ROW                         COLUMN+CELL\n user1|ts2                   column=sf:c1, timestamp=1409122354918, value=sku188\n user1|ts3                   column=sf:s1, timestamp=1409122354954, value=sku123 \n```\n**10.从user1|ts2开始,找到所有的到rowkey以user2开头**\n```\nscan 'test1', {STARTROW=>'user1|ts2', STOPROW=>'user2'}\n```\n**#查询结果\n```\n ROW                          COLUMN+CELL\n user1|ts2                   column=sf:c1, timestamp=1409122354918, value=sku188\n user1|ts3                   column=sf:s1, timestamp=1409122354954, value=sku123\n```\n**11.查询rowkey里面包含ts3的**\n```\nimport org.apache.hadoop.hbase.filter.CompareFilter\nimport org.apache.hadoop.hbase.filter.SubstringComparator\nimport org.apache.hadoop.hbase.filter.RowFilter\nscan 'test1', {FILTER => RowFilter.new(CompareFilter::CompareOp.valueOf('EQUAL'), SubstringComparator.new('ts3'))}\n```\n**#查询结果\n```\n ROW                          COLUMN+CELL\n user1|ts3                   column=sf:s1, timestamp=1409122354954, value=sku123 \n```\n**12.查询rowkey里面包含ts的**\n```\nimport org.apache.hadoop.hbase.filter.CompareFilter\nimport org.apache.hadoop.hbase.filter.SubstringComparator\nimport org.apache.hadoop.hbase.filter.RowFilter\nscan 'test1', {FILTER => RowFilter.new(CompareFilter::CompareOp.valueOf('EQUAL'), SubstringComparator.new('ts'))}\n```\n**#查询结果\n```\n ROW                         COLUMN+CELL\n user1|ts1                   column=sf:c1, timestamp=1409122354868, value=sku1\n user1|ts2                   column=sf:c1, timestamp=1409122354918, value=sku188\n user1|ts3                   column=sf:s1, timestamp=1409122354954, value=sku123\n user2|ts4                   column=sf:c1, timestamp=1409122354998, value=sku2\n user2|ts5                   column=sf:c2, timestamp=1409122355030, value=sku288\n user2|ts6                   column=sf:s1, timestamp=1409122355970, value=sku222\n```\n**13.加入一条测试数据**\n```\nput 'test1', 'user2|err', 'sf:s1', 'sku999'\n```\n\n\n**14.查询rowkey里面以user开头的，新加入的测试数据并不符合正则表达式的规则，故查询不出来**\n```\nimport org.apache.hadoop.hbase.filter.RegexStringComparator\nimport org.apache.hadoop.hbase.filter.CompareFilter\nimport org.apache.hadoop.hbase.filter.SubstringComparator\nimport org.apache.hadoop.hbase.filter.RowFilter\nscan 'test1', {FILTER => RowFilter.new(CompareFilter::CompareOp.valueOf('EQUAL'),RegexStringComparator.new('^user\\d+\\|ts\\d+$'))}\n```\n**#查询结果\n```\n ROW                         COLUMN+CELL\n user1|ts1                   column=sf:c1, timestamp=1409122354868, value=sku1\n user1|ts2                   column=sf:c1, timestamp=1409122354918, value=sku188\n user1|ts3                   column=sf:s1, timestamp=1409122354954, value=sku123\n user2|ts4                   column=sf:c1, timestamp=1409122354998, value=sku2\n user2|ts5                   column=sf:c2, timestamp=1409122355030, value=sku288\n user2|ts6                   column=sf:s1, timestamp=1409122355970, value=sku222\n```\n**15.加入测试数据**\n```\nput 'test1', 'user1|ts9', 'sf:b1', 'sku1'\n```\n**16.b1开头的列中并且值为sku1的**\n```\nscan 'test1', FILTER=>\"ColumnPrefixFilter('b1') AND ValueFilter(=,'binary:sku1')\"\n```\n**#查询结果\n```\n ROW                          COLUMN+CELL                                                   user1|ts9                   column=sf:b1, timestamp=1409124908668, value=sku1\n```\n\n**17.SingleColumnValueFilter的使用，b1开头的列中并且值为sku1的**\n```\nimport org.apache.hadoop.hbase.filter.CompareFilter\nimport org.apache.hadoop.hbase.filter.SingleColumnValueFilter\nimport org.apache.hadoop.hbase.filter.SubstringComparator\nscan 'test1', {COLUMNS => 'sf:b1', FILTER => SingleColumnValueFilter.new(Bytes.toBytes('sf'), Bytes.toBytes('b1'), CompareFilter::CompareOp.valueOf('EQUAL'), Bytes.toBytes('sku1'))}\n```\n**#查询结果\n```\n ROW                         COLUMN+CELL\n user1|ts9                   column=sf:b1, timestamp=1409124908668, value=sku1\n```\n**18.KeyOnlyFilter: 只要key,不要value**\n```\nscan 'test1', FILTER=>\"FirstKeyOnlyFilter() AND ValueFilter(=,'binary:sku188') AND KeyOnlyFilter()\"\n```\n**#查询结果\n```\n ROW                         COLUMN+CELL\n user1|ts2                   column=sf:c1, timestamp=1409122354918, value=\n```\nFirstKeyOnlyFilter: 一个rowkey可以有多个version,同一个rowkey的同一个column也会有多个的值, 只拿出key中的第一个column的第一个version\n\n##  五.hbase的java操作 maven构建\n\n**1.pom.xml文件添加hbase依赖**\n```\n<properties>\n    <hbase.version>2.0.2</hbase.version>\n</properties>\n\n<dependencies>\n    <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-server</artifactId>\n        <version>${hbase.version}</version>\n    </dependency>\n    <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-client</artifactId>\n        <version>${hbase.version}</version>\n    </dependency>\n    <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-common</artifactId>\n        <version>${hbase.version}</version>\n    </dependency>\n</dependencies>\n```\n\n**2.初始化静态方法**\n```\nstatic {\n    Configuration configuration = HBaseConfiguration.create();\n    try {\n        connection = ConnectionFactory.createConnection(configuration);\n        admin = connection.getAdmin();\n    } catch (Exception e) {\n        e.printStackTrace();\n    }\n}\n```\n**3.判断表是否存在**\n```\npublic static boolean isExist(String tableName) throws Exception {\n    return admin.tableExists(TableName.valueOf(tableName));\n}\n```\n**4.创建表**\n```\npublic static void createTable(String tableName,String ... column) throws Exception {\n    if(isExist(tableName)){\n        System.out.println(tableName+\"已经存在\");\n        return;\n    }\n    HTableDescriptor tableDescriptor = new HTableDescriptor(TableName.valueOf(tableName));\n    for (String c : column) {\n        HColumnDescriptor hColumnDescriptor = new HColumnDescriptor(c);\n        tableDescriptor.addFamily(hColumnDescriptor);\n    }\n    admin.createTable(tableDescriptor);\n    System.out.println(tableName+\"创建成功\");\n    getAllTable();\n}\n```\n**5.删除表**\n```\npublic static void deleteTable(String tableName) throws Exception {\n    if(isExist(tableName)){\n        admin.disableTable(TableName.valueOf(tableName));\n        admin.deleteTable(TableName.valueOf(tableName));\n    }\n    System.out.println(tableName+\"已被删除\");\n    getAllTable();\n }\n```\n\n**6.获取所有表**\n```\npublic static void getAllTable() throws Exception {\n    TableName[] tableNames = admin.listTableNames();\n    for (TableName tableName : tableNames) {\n        System.out.println(Bytes.toString(tableName.getName()));\n    }\n}\n```\n**7.添加一行数据**\n```\npublic static void add1Row(String tableName,String rowkey,String cf,String column,String val) throws Exception {\n    Table table = connection.getTable(TableName.valueOf(tableName));\n    Put put = new Put(Bytes.toBytes(rowkey));\n    put.addColumn(Bytes.toBytes(cf),Bytes.toBytes(column),Bytes.toBytes(val));\n    table.put(put);\n}\n```\n**8.删除一行数据**\n```\npublic static void del1Row(String tableName,String rowkey) throws Exception {\n    Table table = connection.getTable(TableName.valueOf(tableName));\n    Delete delete = new Delete(Bytes.toBytes(rowkey));\n    table.delete(delete);\n}\n```\n**9.删除多行数据**\n```\npublic static void delMulRow(String tableName,String... rowkeys) throws Exception {\n    Table table = connection.getTable(TableName.valueOf(tableName));\n    List<Delete> deletes = new ArrayList<Delete>();\n    for (String rowkey : rowkeys) {\n        Delete delete = new Delete(Bytes.toBytes(rowkey));\n        deletes.add(delete);\n    }\n    table.delete(deletes);\n}\n```\n**10.获取多行数据**\n```\npublic static void getAllrows(String tableName) throws Exception {\n    Table table = connection.getTable(TableName.valueOf(tableName));\n    Scan scan = new Scan();\n    scan.setMaxVersions();\n    ResultScanner resultScanner = table.getScanner(scan);\n    for (Result result : resultScanner) {\n        Cell[] cells = result.rawCells();\n        for (Cell cell : cells) {\n            System.out.print(Bytes.toString(CellUtil.cloneFamily(cell))+\" \");\n            System.out.print(Bytes.toString(CellUtil.cloneQualifier(cell))+\" \");\n            System.out.print(Bytes.toString(CellUtil.cloneRow(cell))+\" \");\n            System.out.println(Bytes.toString(CellUtil.cloneValue(cell)));\n        }\n    }\n}\n```\n\n**11.获取一行数据**\n```\npublic static void getrow(String tableName,String rowkey) throws Exception {\n    Table table = connection.getTable(TableName.valueOf(tableName));\n    Get get = new Get(Bytes.toBytes(rowkey));\n    Result result = table.get(get);\n    Cell[] cells = result.rawCells();\n    for (Cell cell : cells) {\n        System.out.print(Bytes.toString(CellUtil.cloneFamily(cell))+\" \");\n        System.out.print(Bytes.toString(CellUtil.cloneQualifier(cell))+\" \");\n        System.out.print(Bytes.toString(CellUtil.cloneRow(cell))+\" \");\n        System.out.println(Bytes.toString(CellUtil.cloneValue(cell)));\n    }\n}\n```\n\n**hbase的demo**\n\n```\npackage com.chen;\n\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.hbase.*;\nimport org.apache.hadoop.hbase.client.*;\nimport org.apache.hadoop.hbase.util.Bytes;\n\nimport java.io.IOException;\nimport java.util.ArrayList;\nimport java.util.List;\n\npublic class App {\n    static Admin admin = null;\n    static Connection connection = null;\n\n    /**\n     * 静态初始化\n     */\n    static {\n        Configuration configuration = HBaseConfiguration.create();\n        try {\n            connection = ConnectionFactory.createConnection(configuration);\n            admin = connection.getAdmin();\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n\n    /**\n     * 判断表是否存在\n     * @param tableName\n     * @return\n     * @throws Exception\n     */\n    public static boolean isExist(String tableName) throws Exception {\n        return admin.tableExists(TableName.valueOf(tableName));\n    }\n\n    /**\n     * 创建表\n     * @param tableName\n     * @param column\n     * @throws Exception\n     */\n    public static void createTable(String tableName,String ... column) throws Exception {\n        if(isExist(tableName)){\n            System.out.println(tableName+\"已经存在\");\n            return;\n        }\n        HTableDescriptor tableDescriptor = new HTableDescriptor(TableName.valueOf(tableName));\n        for (String c : column) {\n            HColumnDescriptor hColumnDescriptor = new HColumnDescriptor(c);\n            tableDescriptor.addFamily(hColumnDescriptor);\n        }\n        admin.createTable(tableDescriptor);\n        System.out.println(tableName+\"创建成功\");\n        getAllTable();\n    }\n\n    /**\n     * 删除表\n     * @param tableName\n     * @throws Exception\n     */\n    public static void deleteTable(String tableName) throws Exception {\n        if(isExist(tableName)){\n            admin.disableTable(TableName.valueOf(tableName));\n            admin.deleteTable(TableName.valueOf(tableName));\n        }\n        System.out.println(tableName+\"已被删除\");\n        getAllTable();\n    }\n\n    /**\n     * 获取所有表\n     * @throws Exception\n     */\n    public static void getAllTable() throws Exception {\n        TableName[] tableNames = admin.listTableNames();\n        for (TableName tableName : tableNames) {\n            System.out.println(Bytes.toString(tableName.getName()));\n        }\n    }\n\n\n    /**\n     * 添加一行数据\n     * @param tableName\n     * @param rowkey\n     * @param cf\n     * @param column\n     * @param val\n     * @throws Exception\n     */\n    public static void add1Row(String tableName,String rowkey,String cf,String column,String val) throws Exception {\n        Table table = connection.getTable(TableName.valueOf(tableName));\n        Put put = new Put(Bytes.toBytes(rowkey));\n        put.addColumn(Bytes.toBytes(cf),Bytes.toBytes(column),Bytes.toBytes(val));\n        table.put(put);\n    }\n\n\n    /**\n     * 删除一行数据\n     * @param tableName\n     * @param rowkey\n     * @throws Exception\n     */\n    public static void del1Row(String tableName,String rowkey) throws Exception {\n        Table table = connection.getTable(TableName.valueOf(tableName));\n        Delete delete = new Delete(Bytes.toBytes(rowkey));\n        table.delete(delete);\n    }\n\n    /**\n     * 删除多行数据\n     * @param tableName\n     * @param rowkeys\n     * @throws Exception\n     */\n    public static void delMulRow(String tableName,String... rowkeys) throws Exception {\n        Table table = connection.getTable(TableName.valueOf(tableName));\n        List&lt;Delete&gt; deletes = new ArrayList&lt;Delete&gt;();\n        for (String rowkey : rowkeys) {\n            Delete delete = new Delete(Bytes.toBytes(rowkey));\n            deletes.add(delete);\n        }\n        table.delete(deletes);\n    }\n\n    /**\n     * 获取多行数据\n     * @param tableName\n     * @throws Exception\n     */\n    public static void getAllrows(String tableName) throws Exception {\n        Table table = connection.getTable(TableName.valueOf(tableName));\n        Scan scan = new Scan();\n        scan.setMaxVersions();\n        ResultScanner resultScanner = table.getScanner(scan);\n        for (Result result : resultScanner) {\n            Cell[] cells = result.rawCells();\n            for (Cell cell : cells) {\n                System.out.print(Bytes.toString(CellUtil.cloneFamily(cell))+\" \");\n                System.out.print(Bytes.toString(CellUtil.cloneQualifier(cell))+\" \");\n                System.out.print(Bytes.toString(CellUtil.cloneRow(cell))+\" \");\n                System.out.println(Bytes.toString(CellUtil.cloneValue(cell)));\n            }\n        }\n    }\n\n    public static void main(String[] args) throws Exception {\n        /*String table=\"t3\";\n        System.out.println(isExist(table));*/\n        //createTable(\"test1\",\"info\",\"extra\");\n        //deleteTable(\"test1\");\n        add1Row(\"test1\",\"r2\",\"extra\",\"age\",\"11\");\n        //del1Row(\"test1\",\"r1\");\n        getAllrows(\"test1\");\n    }\n}\n\n```\n\n# flume\n\n## 一.flume的搭建\n\n1.将在qq939598604的百度网盘中的路径，我的软件/apache-flume-1.8.0-bin.tar.gz下载并上传到/soft/elk目录下\n2.解压\n```\ncd /soft/elk\ntar –zxvf apache-flume-1.8.0-bin.tar.gz\n```\n3.配置java_home\ncp flume-env.sh.template flume-env.sh\nvim flume-env.sh\n```\nexport JAVA_HOME=/soft/jdk1.8.0_161\n```\n4.编辑配置文件\nvim  spool1.conf \n```\na1.sources = r1\na1.sinks = k1\na1.channels = c1\n\n# Describe/configure the source\na1.sources.r1.type = netcat\na1.sources.r1.bind = localhost\na1.sources.r1.port = 44444\n\n# Describe the sink\na1.sinks.k1.type = logger\n\n# Use a channel which buffers events in memory\na1.channels.c1.type = memory\na1.channels.c1.capacity = 1000\na1.channels.c1.transactionCapacity = 100\n\n# Bind the source and sink to the channel\na1.sources.r1.channels = c1\na1.sinks.k1.channel = c1\n```\n5.启动flume\n```\n/soft/elk/apache-flume-1.8.0-bin/bin/flume-ng agent -c /soft/elk/apache-flume-1.8.0-bin/conf -f /soft/elk/apache-flume-1.8.0-bin/conf/spool1.conf --name a1 -Dflume.root.logger=INFO,console\n```\n6.安装telnet工具\n```\nyum install telnet -y\ntelnet localhost 4444\n```\n7.在telnet终端发送数据到flume中并查看是否有接收到\n\n\n\n# zookpeer\n\n##  一.Zookeeper集群搭建\n\n（一）先把Java环境配好，三台机器，配置Zookeeper \n（二）下载zookeeper-3.4.10.tar.gz，并且上传到/soft/目录下，直接解压zookeeper-3.4.10.tar.gz\n tar -zxvf zookeeper-3.4.10.tar.gz\n（三）修改配置文件名称\n\n```\nmv /soft/zookeeper-3.4.10/conf/zoo_simple.cfg /soft/zookeeper-3.4.10/conf/zoo.cfg\n```\n\n（四）编辑配置文件\n\n```\nvim /soft/zookeeper-3.4.10/conf/zoo.cfg\n```\n\n修改**dataDir=/soft/zookeeper-3.4.10/data**\n同时增加\n\n```\nserver.1=192.168.197.231:2888:3888\nserver.2=192.168.197.232:2888:3888\nserver.3=192.168.197.233:2888:3888\n```\n\n**server.X=A:B:C**  X-代表服务器编号 A-代表ip  B和C-代表端口，这个端口用来系统之间通信\n\n（五）编辑配置myid文件\n\nvim /soft/zookeeper-3.4.10/data/myid\n之后会产生一个新文件，直接在里面写X即可，比如我配置的三个server，当前服务器的ip是多少，myid里面写的X就是server.X=ip:2888:3888 中ip所对应的X\n\n```\nserver.1=192.168.197.231:2888:3888【192.168.197.231服务器上面的myid填写1】\nserver.2=192.168.197.232:2888:3888【192.168.197.232服务器上面的myid填写2】\nserver.3=192.168.197.233:2888:3888【192.168.197.233服务器上面的myid填写3】\n```\n\n（六）修改环境\n\n​\tvim /etc/profile\n　　在export PATH语句前添加两行：\n\n```\nZOOKEEPER=/soft/zookeeper-3.4.10\nPATH=PATH:ZOOKEEPER/bin\n```\n\n（六）并执行 source /etc/profile\n（七）启动zookeeper\n分别在3台机器启动 zookeeper\n\n\n\n# kafka\n\n##  一.认识\n\n**首先几个概念：**\n\n1. **kafka作为一个集群运**行在一个或多个服务器上。\n2. kafka集群存储的消息是以topic为类别记录的。\n3. 每个消息（也叫记录record，我习惯叫消息）是由一个key，一个value和时间戳构成。\n4. kafka是基于点对点的拉取（pull）模式（看到尚硅谷视频讲到，便记下来）\n\n**kafka有四个核心API：**\n\n- 应用程序使用 `Producer API` 发布消息到1个或多个topic（主题）。\n\n- 应用程序使用 `Consumer API` 来订阅一个或多个topic，并处理产生的消息。\n\n- 应用程序使用 `Streams API` 充当一个流处理器，从1个或多个topic消费输入流，并生产一个输出流到1个或多个输出topic，有效地将输入流转换到输出流。\n\n- `Connector API`允许构建或运行可重复使用的生产者或消费者，将topic连接到现有的应用程序或数据系统。例如，一个关系数据库的连接器可捕获每一个变化。\n\n  ![1565660315040](C:\\Users\\Administrator\\Desktop\\Md笔记\\pic\\product.png)\n\n \n\n**基本术语：**\n\n**Topic**\n\nKafka将消息种子(Feed)分门别类，每一类的消息称之为一个主题(Topic).\n\n- Topic是Kafka数据写入操作的基本单元，可以指定副本\n- 一个Topic包含一个或多个Partition，建Topic时可手动指定Partition个数，个数必须少于服务器个数\n- 每条消息属于且仅属于一个Topic\n- Producer发布数据时，必须指定将该消息发布到哪个Topic\n- Consumer订阅消息时，也必须指定订阅哪个Topic的信息\n\n **Partition**\n\n- 每个Partition只会在一个Broker上，物理上每个Partition对应的是一个文件夹\n- Kafka默认使用的是hash进行分区，所以会出现不同的分区数据不一样的情况，但是partitioner是可以override的\n- Partition包含多个Segment，每个Segment对应一个文件，Segment可以手动指定大小，当Segment达到阈值时，将不再写数据，每个Segment都是大小相同的\n- Segment由多个不可变的记录组成，记录只会被append到Segment中，不会被单独删除或者修改，每个Segment中的Message数量不一定相等\n\n **Producer**\n\n发布消息的对象称之为主题生产者(Kafka topic producer)，写数据只会找leader\n\n**Consumer**\n\n订阅消息并处理发布的消息的对象称之为主题消费者(consumers)\n\n **Broker**\n\n已发布的消息保存在一组服务器中，称之为Kafka集群。集群中的每一个服务器都是一个代理(Broker). 消费者可以订阅一个或多个主题（topic），并从Broker拉数据，从而消费这些已发布的消息。\n\n **主题**\n\n Topic是发布的消息的类别或者种子Feed名。对于每一个Topic，Kafka集群维护这一个分区的log，就像下图中的示例： \n\n![1565660685648](C:\\Users\\Administrator\\Desktop\\Md笔记\\pic\\1565660685648.png)\n\n 每一个分区都是一个顺序的、不可变的消息队列， 并且可以持续的添加。分区中的消息都被分了一个序列号，称之为偏移量(offset)，在每个分区中此偏移量都是唯一的。 \n\nKafka集群保持所有的消息，直到它们过期， 无论消息是否被消费了。 实际上消费者所持有的仅有的元数据就是这个偏移量，也就是消费者在这个log中的位置。 这个偏移量由消费者控制：正常情况当消费者消费消息的时候，偏移量也线性的的增加。但是实际偏移量由消费者控制，消费者可以将偏移量重置为更老的一个偏移量，重新读取消息。 可以看到这种设计对消费者来说操作自如， 一个消费者的操作不会影响其它消费者对此log的处理。 再说说分区。Kafka中采用分区的设计有几个目的。一是可以处理更多的消息，不受单台服务器的限制。Topic拥有多个分区意味着它可以不受限的处理更多的数据。第二，分区可以作为并行处理的单元，稍后会谈到这一点。\n\nkafka存储数据有2个地方：broker里面的patition下的log文件，broker的存储策略是文件的大小和存储时间，zookpeer里面的元数据\n\n\n\n##  二.window安装kafka\n\n**（一）zookeeper在Windows下的安装**\n\n1.把下载的zookeeper的文件解压到指定目录：D:\\zookeeper-3.4.14\n\n2.复制conf目录下的zoo_sample.cfg文件为zoo.cfg\n\n3.修改内容如下：\n\n```\ndataDir=D:\\data\\zookeeper\n```\n\n4.进入到bin目录，双击启动zkServer.cmd\n\n5.启动后jps可以看到QuorumPeerMain的进程\n\n```\nD:\\zookeeper-3.4.14\\bin >jps\n```\n\n6.启动客户端运行查看一下\n\n```\nD:\\zookeeper-3.4.14\\bin>zkCli.cmd -server 127.0.0.1:2181\n```\n\n**（二）kafka在Windows下的安装**\n\n1.下载kafka\n\n下载kafka，必须scala的版本对应kafka_2.11-2.3.0，其中前面的是2.12是scala的 版本号\n\nhttps://www.apache.org/dyn/closer.cgi?path=/kafka/2.3.0/kafka_2.11-2.3.0.tgz\n\n2.解压文件（我的目录是D:\\kafka_2.11-2.3.0  【这里不要在Program Files等文件名之间有空格的目录下，不然一会执行会不识别路径】）\n\n3.修改D:\\kafka_2.11-2.3.0\\config下server.properties文件\n\n```\nlog.dirs=D:\\kafka_2.11-2.3.0\\kafka-logs\nbroker.id=0\nport=9092\nzookeeper.connect=localhost:2181\n```\n\n4.进入kafka文件目录D:\\kafka_2.11-2.3.0，执行以下命令，启动kafka通讯的服务器broker\n\n```\n.\\bin\\windows\\kafka-server-start.bat .\\config\\server.properties\n```\n\n5.进入kafka文件目录D:\\kafka_2.11-2.3.0\\bin\\windows，创建kafka的消息topics\n\n```\nkafka-topics.bat --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test\n```\n\n 6.分别打开两个cmd窗口，进入目录D:\\kafka_2.11-2.3.0\\bin\\windows，创建Producer和Consumer\n\n（1）Producer\n\n进入目录D:\\kafka_2.11-2.3.0\\bin\\windows输入如下命令\n\n```\nkafka-console-producer.bat --broker-list localhost:9092 --topic test\n```\n\n（2）Consumer\n\n进入目录D:\\kafka_2.11-2.3.0\\bin\\windows输入如下命令\n\n```\nkafka-console-consumer.bat --zookeeper localhost:2181 --topic testDemo\n```\n\n然后就可以在Producer中发信息，在Consumer中收信息了\n\n**（三）kafka集群在Windows下的安装**\n\n1.复制上面的kafka单机版文件夹\n\n修改文件名为：kafka_2.11-2.3.0--1和 kafka_2.11-2.3.0--2\n\n![1565773682533](C:\\Users\\Administrator\\Desktop\\Md笔记\\pic\\1565773682533.png)\n\n2.修改D:\\kafka_2.11-2.3.0--1\\config下server.properties文件\n\n```\nlog.dirs=D:\\kafka_2.11-2.3.0--1\\kafka-logs\nbroker.id=1\nport=9093\nzookeeper.connect=localhost:2181\n```\n\n3.修改D:\\kafka_2.11-2.3.0--2\\config下server.properties文件\n\n```\nlog.dirs=D:\\kafka_2.11-2.3.0--2\\kafka-logs\nbroker.id=2\nport=9094\nzookeeper.connect=localhost:2181\n```\n\n4.分别进入kafka文件目录D:\\kafka_2.11-2.3.0和kafka_2.11-2.3.0--1和 kafka_2.11-2.3.0--2三个文件夹，执行以下命令，启动kafka通讯的服务器broker\n\n```\n.\\bin\\windows\\kafka-server-start.bat .\\config\\server.properties\n```\n\n  5.查看kafka集群中所有broker节点\n\nbroker的配置文件中有zookeeper的地址,也有自己的broker ID \n\n当broker启动后,会在zookeeper中新建一个znode,访问zk并执行ls /brokers/ids 就可以看到zk中存的所有的broker id list，然后确认你增加的broker的ID是否在list里面 \n\n```\nD:\\zookeeper-3.4.14\\bin>zkCli.cmd -server 127.0.0.1:2181\n[zk: 127.0.0.1:2181(CONNECTED) 2] ls /\n[cluster, controller_epoch, controller, brokers, zookeeper, admin, isr_change_no\ntification, consumers, log_dir_event_notification, latest_producer_id_block, config]\n[zk: 127.0.0.1:2181(CONNECTED) 3] ls /brokers\n[ids, topics, seqid]\n[zk: 127.0.0.1:2181(CONNECTED) 4] ls /brokers/ids\n[0, 1, 2]\n```\n\n上面可以看到/brokers/ids有[0, 1, 2]，说明是一个集群了\n\n6.windows下kafka集群的批处理启动脚本\n\n```\nstart d:\\windows_install\\zookeeper-3.4.14\\bin\\zkServer.cmd\nstart d:\\windows_install\\kafka_2.11-2.3.0\\bin\\windows\\kafka-server-start.bat d:\\windows_install\\kafka_2.11-2.3.0\\config\\server.properties\nstart d:\\windows_install\\kafka_2.11-2.3.0--1\\bin\\windows\\kafka-server-start.bat d:\\windows_install\\kafka_2.11-2.3.0--1\\config\\server.properties\nstart d:\\windows_install\\kafka_2.11-2.3.0--2\\bin\\windows\\kafka-server-start.bat d:\\windows_install\\kafka_2.11-2.3.0--2\\config\\server.properties\n```\n\n##  三.**消费者组案例测试**\n\n**案例一**\n\n生产者：如果topicA只有一个patition，即patition0，启动一个生产者实例\n\n消费者组中有A和B，其中消费者A先启动，A会绑定topicA中的patition0，然后再启动消费者B，启动的时候会提示，没有patition被绑定，则topicA中的生产数据的时候只有消费者A消费。\n\n**案例二**\n\n在前面的kafka集群3台机器中，连接测试192.168.197.30测试，以下测试是在windows的D:\\windows_install\\kafka_2.11-2.3.0\\bin\\windows>目录下进行\n\n1.新建一个topic，指定复制因子为3，分区为3\n\n```\nkafka-topics.bat --create --zookeeper 192.168.197.30:2181 --replication-factor 3 --partitions 3 --topic test\nCreated topic test.\n```\n\n2.启动一个生产者\n\n```\nkafka-console-producer.bat --broker-list 192.168.197.30:9092 --topic test\n```\n\n3.启动消费者A，并指定组id为t\n\n```\nkafka-console-consumer.bat --bootstrap-server 192.168.197.30:9092 --topic test --group t\n```\n\n4.启动消费者B，并指定组id为t\n\n```\nkafka-console-consumer.bat --bootstrap-server 192.168.197.30:9092 --topic test --group t\n```\n\n5.在生产者端输入消息\n\n```\nD:\\windows_install\\kafka_2.11-2.3.0\\bin\\windows>kafka-console-producer.bat --broker-list 192.168.197.30:9092 --topic test\n>dafads\n>sdfa\n>fadsads\n>dfads\n```\n\n6.可以观察到，同个消费者组的消费者，消费消息只能由一个完成，并且只有一次\n\n消费者A获取到的消息如下：\n\n```\nD:\\windows_install\\kafka_2.11-2.3.0\\bin\\windows>kafka-console-consumer.bat --botstrap-server 192.168.197.30:9092 --topic test --group t\ndafads\nfadsads\n```\n\n消费者B获取到的消息如下：\n\n```\nD:\\windows_install\\kafka_2.11-2.3.0\\bin\\windows>kafka-console-consumer.bat --bootstrap-server 192.168.197.30:9092 --topic test --group t\nsdfa\ndfads\n```\n\n**同个消费者组的消费者，消费消息只能由一个完成，并且只有一次**\n\n\n\n##  四.消费者连接集群只需一个broker\n\n在前面的kafka集群3台机器中，连接测试192.168.197.30测试，以下测试是在windows的D:\\windows_install\\kafka_2.11-2.3.0\\bin\\windows>目录下进行\n\n1.新建一个topic，指定复制因子为3，分区为3\n\n```\nkafka-topics.bat --create --zookeeper 192.168.197.30:2181 --replication-factor 3 --partitions 3 --topic test\nCreated topic test.\n```\n\n2.启动一个生产者\n\n```\nkafka-console-producer.bat --broker-list 192.168.197.30:9092 --topic test\n```\n\n3.启动消费者A，连接的bootstrap-server,参数指定为 `--bootstrap-server 192.168.197.30:9092`并指定组id为t\n\n```\nkafka-console-consumer.bat --bootstrap-server 192.168.197.30:9092 --topic test --group t\n```\n\n4.启动消费者B，连接的bootstrap-server和消费者A不一样,参数指定为 `--bootstrap-server 192.168.197.30:9093`并指定组id为t\n\n```\nkafka-console-consumer.bat --bootstrap-server 192.168.197.30:9092 --topic test --group t\n```\n\n5.在生产者端输入消息\n\n```\nD:\\windows_install\\kafka_2.11-2.3.0\\bin\\windows>kafka-console-producer.bat --broker-list 192.168.197.30:9092 --topic test\n>ghjhh67\n>ljgty\n>tyetw\n>uioqw\n```\n\n6.可以观察到，消费者连接集群只需一个broker，即可获取到整个集群的消息\n\n消费者A获取到的消息如下：\n\n```\nD:\\windows_install\\kafka_2.11-2.3.0\\bin\\windows>kafka-console-consumer.bat --botstrap-server 192.168.197.30:9092 --topic test --group t\nghjhh67\ntyetw\n```\n\n消费者B获取到的消息如下：\n\n```\nD:\\windows_install\\kafka_2.11-2.3.0\\bin\\windows>kafka-console-consumer.bat --bootstrap-server 192.168.197.30:9093 --topic test --group t\nljgty\nuioqw\n```\n\n**消费者连接集群只需一个broker，即可获取到整个集群的消息**\n\n##  五.生产者的java版本代码编写\n\n**(一)最简单的调用方式**\n\n1.新建一个MyProduce.java，发送消息到test的topic\n\n```java\npublic class MyProduce {\n    public static void main(String[] args) {\n        Properties props = new Properties();\n        props.put(\"bootstrap.servers\",\"192.168.197.30:9092\");\n        props.put(\"acks\",\"all\");\n        props.put(\"retries\",0);\n        props.put(\"batch.size\",16384);\n        props.put(\"linger.ms\",1);\n        props.put(\"buffer.memory\",33554432);\n        props.put(\"key.serializer\",\"org.apache.kafka.common.serialization.StringSerializer\");\n        props.put(\"value.serializer\",\"org.apache.kafka.common.serialization.StringSerializer\");\n        Producer<String, String> producer = new KafkaProducer<>(props);\n        for(int i=0;i<10;i++){\n          producer.send(new ProducerRecord<>(\"test\", Integer.toString(i), Integer.toString(i)));\n        }\n        producer.close();\n    }\n}\n```\n\n**(二)有回调的生产者**\n\n```\npackage com.gzstrong.TestKafka;\n\nimport org.apache.kafka.clients.producer.*;\n\nimport java.util.Properties;\n\n/**\n * @author 陈锦华\n * @version V1.0\n * @Title:\n * @Description: create by Intellij Idea\n * @date 2019/8/15 0015 上午 9:08\n **/\npublic class MyProduce {\n    public static void main(String[] args) {\n        Properties props = new Properties();\n        props.put(\"bootstrap.servers\",\"192.168.197.30:9092\");\n        props.put(\"acks\",\"all\");\n        props.put(\"retries\",0);\n        props.put(\"batch.size\",16384);\n        props.put(\"linger.ms\",1);\n        props.put(\"buffer.memory\",33554432);\n        props.put(\"key.serializer\",\"org.apache.kafka.common.serialization.StringSerializer\");\n        props.put(\"value.serializer\",\"org.apache.kafka.common.serialization.StringSerializer\");\n        Producer<String, String> producer = new KafkaProducer<>(props);\n        for(int i=0;i<10;i++){\n            producer.send(new ProducerRecord<>(\"test\", Integer.toString(i), Integer.toString(i)), new Callback() {\n                @Override\n                public void onCompletion(RecordMetadata metadata, Exception exception) {\n                    System.out.println(metadata.partition()+\"---\"+metadata.offset());\n                }\n            });\n\n        }\n        producer.close();\n    }\n}\n```\n\n**(二)指定分区发送，且有回调的生产者**\n\n1.新建ProducePatition.java实现Partitioner接口\n\n```\npublic class ProducePatition implements Partitioner {\n\n    @Override\n    public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {\n        return 0;\n    }\n\n    @Override\n    public void close() {\n\n    }\n\n    @Override\n    public void configure(Map<String, ?> configs) {\n\n    }\n}\n```\n\n2.在生产者里面设置参数`props.put(\"partitioner.class\",\"com.gzstrong.TestKafka.ProducePatition\");`\n\n```\npublic class MyProduce {\n    public static void main(String[] args) {\n        Properties props = new Properties();\n        props.put(\"bootstrap.servers\",\"192.168.197.30:9092\");\n        props.put(\"acks\",\"all\");\n        props.put(\"retries\",0);\n        props.put(\"batch.size\",16384);\n        props.put(\"linger.ms\",1);\n        props.put(\"buffer.memory\",33554432);\n        props.put(\"partitioner.class\",\"com.gzstrong.TestKafka.ProducePatition\");\n        props.put(\"key.serializer\",\"org.apache.kafka.common.serialization.StringSerializer\");\n        props.put(\"value.serializer\",\"org.apache.kafka.common.serialization.StringSerializer\");\n        Producer<String, String> producer = new KafkaProducer<>(props);\n        for(int i=0;i<10;i++){\n            producer.send(new ProducerRecord<>(\"test\", Integer.toString(i), Integer.toString(i)), (metadata, exception) -> System.out.println(metadata.partition()+\"---\"+metadata.offset()));\n        }\n        producer.close();\n    }\n}\n```\n\n##  六.消费者java编码\n\n（一）高级消费者\n\n```\npublic class MyComSumer {\n    public static void main(String[] args){\n        Properties props = new Properties();\n        props.put(\"bootstrap.servers\", \"192.168.197.30:9092\");\n        props.put(\"group.id\", \"test\");\n        props.put(\"enable.auto.commit\", \"false\");\n        props.put(\"auto.commit.interval.ms\", \"1000\");\n        props.put(\"session.timeout.ms\", \"30000\");\n        props.put(\"key.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");\n        props.put(\"value.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");\n        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n        consumer.subscribe(Arrays.asList(\"test\", \"bar\"));\n        final int minBatchSize = 200;\n        List<ConsumerRecord<String, String>> buffer = new ArrayList<>();\n        while (true) {\n            ConsumerRecords<String, String> records = consumer.poll(100);\n            for (ConsumerRecord<String, String> record : records) {\n                System.out.println(\"offset:\"+record.offset()+\" partition: \"+record.partition()+\" record: \"+ record);\n            }\n        }\n    }\n}\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#  spark\n\n##  一.spark集群搭建\n\n**（一）.安装基础环境（JAVA和SCALA环境）**\n\n**1.安装JDK**\n\n(1)下载jdk1.8.0_161\n(2)在/etc/profile中添加如下配置\n vim /etc/profile\n```\n    export JAVA_HOME=/soft/jdk1.8.0_161\n    export JRE_HOME=${JAVA_HOME}/jre\n    export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib\n    export PATH=${JAVA_HOME}/bin:$PATH\n```\n(3)使环境变量生效，source /etc/profile\n(4)安装验证# java -version \n\n**2.安装SCALA**\n\n(1)到http://www.scala-lang.org/download/2.11.8.html下载scala2.11.8.tar.gz\n将下载的文件上传到/soft目录下\n```\ntar -zxvf /soft/scala-2.11.8.tgz -C /soft/\n```\n(2)在/etc/profile中添加如下配置\n  vim /etc/profile\n```\n  export SCALA_HOME=/soft/scala-2.11.8\n  export PATH=$SCALA_HOME/bin:$PATH\n```\n(3)使环境变量生效，source /etc/profile\n(4)安装验证# java -version \n\n**（二）Hadoop2.7.4完全分布式搭建**\n\n**（三）Spark2.1.0完全分布式环境搭建 **\n\n以下操作都在Master节点进行。\n1.下载二进制包spark-2.1.0-bin-hadoop2.7.tgz\n2.解压并移动到相应目录，命令如下：\n```\ntar -zxvf spark-2.2.1-bin-hadoop2.7.tgz -C /soft/\n```\n3.修改相应的配置文件。\n　　在/etc/profile中添加如下配置\n      \tvim /etc/profile\n```　　\n  export SPARK_HOME=/soft/spark-2.2.1-bin-hadoop2.7/\n  export PATH=$PATH:$SPARK_HOME/bin\n```\n    使环境变量生效，source /etc/profile\n4.复制spark-env.sh.template成spark-env.sh\n　  　cp /soft/spark-2.2.1-bin-hadoop2.7/conf/spark-env.sh.template /soft/spark-2.2.1-bin-\t\thadoop2.7/conf/spark-env.sh\n5.修改$SPARK_HOME/conf/spark-env.sh，添加如下内容：\n```　\nexport JAVA_HOME=/soft/jdk1.8.0_161/\nexport SCALA_HOME=/soft/scala-2.11.8\nexport HADOOP_HOME=/soft/hadoop-2.7.4\nexport HADOOP_CONF_DIR=/soft/hadoop-2.7.4/etc/hadoop\nexport SPARK_MASTER_IP=master\nexport SPARK_MASTER_HOST=master\nexport SPARK_WORKER_MEMORY=512m\nexport SPARK_HOME=/soft/spark-2.2.1-bin-hadoop2.7\nexport SPARK_DIST_CLASSPATH=$(/soft/hadoop-2.7.4/bin/hadoop classpath)\n```\n6.复制slaves.template成slaves\n7.cp /soft/spark-2.2.1-bin-hadoop2.7/conf/slaves.template /soft/spark-2.2.1-bin-hadoop2.7/conf/slaves\n8.修改$SPARK_HOME/conf/slaves，添加如下内容：\n```　\nmaster\nslave1\nslave2\n```\n9.将配置好的spark文件复制到Slave1和Slave2节点。\n\tscp /opt/spark-2.1.0-bin-hadoop2.7 root@Slave1:/opt\n      \tscp /opt/spark-2.1.0-bin-hadoop2.7 root@Slave2:/opt\n10.修改Slave1和Slave2配置。\n　　在slave1和slave2上分别修改/etc/profile，增加Spark的配置，过程同Master一样。\n　　在slave1和slave2修改$SPARK_HOME/conf/spark-env.sh，将export SPARK_LOCAL_IP=114.55.246.88改成slave1和slave2对应节点的IP。\n11.在master节点启动集群。\n　　/opt/spark-2.1.0-bin-hadoop2.7/sbin/start-all.sh\n12.查看集群是否启动成功：\n　　jps\n　　master在Hadoop的基础上新增了：\n　　master\n　　slave在Hadoop的基础上新增了：\n　　Worker\n\n## 二.spark的maven项目构建（基于idea 和maven）\n\n首先idea安装scala插件\n![输入图片说明](https://images.gitee.com/uploads/images/2019/0521/154430_f3a9b447_429848.png \"QQ截图20190521154225.png\")\n\n新建一个maven项目\n开始创建项目体系结构\nFile --> Project \n![输入图片说明](https://static.oschina.net/uploads/img/201802/11153035_Ac2b.png \"在这里输入图片标题\")\n![输入图片说明](https://static.oschina.net/uploads/img/201802/11153132_Ijqk.png \"在这里输入图片标题\")\n![输入图片说明](https://static.oschina.net/uploads/img/201802/11153403_6Rrj.png \"在这里输入图片标题\")\n![输入图片说明](https://static.oschina.net/uploads/img/201802/11153427_h2XW.png \"在这里输入图片标题\")\n\npom.xml\n\n```\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n    <groupId>com.chen</groupId>\n    <artifactId>Spark_Test</artifactId>\n    <version>1.0-SNAPSHOT</version>\n    <inceptionYear>2008</inceptionYear>\n    <properties>\n        <scala.version>2.11.0</scala.version>\n        <spark.version>2.0.2</spark.version>\n        <scala>2.11</scala>\n    </properties>\n\n    <repositories>\n        <repository>\n            <id>scala-tools.org</id>\n            <name>Scala-Tools Maven2 Repository</name>\n            <url>http://scala-tools.org/repo-releases</url>\n        </repository>\n    </repositories>\n\n    <pluginRepositories>\n        <pluginRepository>\n            <id>scala-tools.org</id>\n            <name>Scala-Tools Maven2 Repository</name>\n            <url>http://scala-tools.org/repo-releases</url>\n        </pluginRepository>\n    </pluginRepositories>\n\n    <dependencies>\n        <dependency>\n            <groupId>org.scala-lang</groupId>\n            <artifactId>scala-library</artifactId>\n            <version>${scala.version}</version>\n        </dependency>\n        <dependency>\n            <groupId>junit</groupId>\n            <artifactId>junit</artifactId>\n            <version>4.4</version>\n            <scope>test</scope>\n        </dependency>\n        <dependency>\n            <groupId>org.specs</groupId>\n            <artifactId>specs</artifactId>\n            <version>1.2.5</version>\n            <scope>test</scope>\n        </dependency>\n\n        <dependency>\n            <groupId>org.apache.spark</groupId>\n            <artifactId>spark-core_${scala}</artifactId>\n            <version>${spark.version}</version>\n        </dependency>\n        <dependency>\n            <groupId>org.apache.spark</groupId>\n            <artifactId>spark-streaming_${scala}</artifactId>\n            <version>${spark.version}</version>\n        </dependency>\n        <dependency>\n            <groupId>org.apache.spark</groupId>\n            <artifactId>spark-sql_${scala}</artifactId>\n            <version>${spark.version}</version>\n        </dependency>\n        <dependency>\n            <groupId>org.apache.spark</groupId>\n            <artifactId>spark-hive_${scala}</artifactId>\n            <version>${spark.version}</version>\n        </dependency>\n        <dependency>\n            <groupId>org.apache.spark</groupId>\n            <artifactId>spark-mllib_${scala}</artifactId>\n            <version>${spark.version}</version>\n        </dependency>\n    </dependencies>\n\n    <build>\n        <sourceDirectory>src/main/scala</sourceDirectory>\n        <testSourceDirectory>src/test/scala</testSourceDirectory>\n        <plugins>\n            <plugin>\n                <groupId>org.scala-tools</groupId>\n                <artifactId>maven-scala-plugin</artifactId>\n                <executions>\n                    <execution>\n                        <goals>\n                            <goal>compile</goal>\n                            <goal>testCompile</goal>\n                        </goals>\n                    </execution>\n                </executions>\n                <configuration>\n                    <scalaVersion>2.11</scalaVersion>\n                    <args>\n                        <arg>-target:jvm-1.5</arg>\n                    </args>\n                </configuration>\n            </plugin>\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-surefire-plugin</artifactId>\n                <version>2.19</version>\n                <configuration>\n                    <skip>true</skip>\n                </configuration>\n            </plugin>\n\n            <plugin>\n                <artifactId>maven-compiler-plugin</artifactId>\n                <version>3.6.0</version>\n                <configuration>\n                    <source>1.8</source>\n                    <target>1.8</target>\n                    <excludes>\n                        <exclude>**/*.java</exclude>\n                    </excludes>\n                </configuration>\n            </plugin>\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-eclipse-plugin</artifactId>\n                <configuration>\n                    <downloadSources>true</downloadSources>\n                    <buildcommands>\n                        <buildcommand>ch.epfl.lamp.sdt.core.scalabuilder</buildcommand>\n                    </buildcommands>\n                    <additionalProjectnatures>\n                        <projectnature>ch.epfl.lamp.sdt.core.scalanature</projectnature>\n                    </additionalProjectnatures>\n                    <classpathContainers>\n                        <classpathContainer>org.eclipse.jdt.launching.JRE_CONTAINER</classpathContainer>\n                        <classpathContainer>ch.epfl.lamp.sdt.launching.SCALA_CONTAINER</classpathContainer>\n                    </classpathContainers>\n                </configuration>\n            </plugin>\n        </plugins>\n    </build>\n    <reporting>\n        <plugins>\n            <plugin>\n                <groupId>org.scala-tools</groupId>\n                <artifactId>maven-scala-plugin</artifactId>\n                <configuration>\n                    <scalaVersion>${scala.version}</scalaVersion>\n                </configuration>\n            </plugin>\n        </plugins>\n    </reporting>\n</project>\n\n```\n\n目录结构如下:\n![输入图片说明](https://static.oschina.net/uploads/img/201803/29141709_MjWs.png \"在这里输入图片标题\")\n在src的main目录下新建java和scala文件夹\n![输入图片说明](https://static.oschina.net/uploads/img/201803/29142045_fhmF.png \"在这里输入图片标题\")\n同时修改java和scala文件夹为源码文件夹\n![输入图片说明](https://static.oschina.net/uploads/img/201803/29142301_rELw.png \"在这里输入图片标题\")\n![输入图片说明](https://static.oschina.net/uploads/img/201803/29142317_bdXa.png \"在这里输入图片标题\")\n在src的test目录下新建java和scala文件夹\n![输入图片说明](https://static.oschina.net/uploads/img/201803/29142115_RNRo.png \"在这里输入图片标题\")\n同时修改java和scala文件夹为测试文件夹\n![输入图片说明](https://static.oschina.net/uploads/img/201803/29142409_KwUu.png \"在这里输入图片标题\")\n\n然后设置scal为项目的sdk\n\n## 三.spark的java7代码编写\n\n新建package名称为\n![输入图片说明](https://static.oschina.net/uploads/img/201803/29142627_StWH.png \"在这里输入图片标题\")\n新建Java7WordCount.java的文件\n\nJava7WordCount.java\n\n    package com.chen;\n    \n    import org.apache.spark.SparkConf;\n    import org.apache.spark.api.java.JavaPairRDD;\n    import org.apache.spark.api.java.JavaRDD;\n    import org.apache.spark.api.java.JavaSparkContext;\n    import org.apache.spark.api.java.function.FlatMapFunction;\n    import org.apache.spark.api.java.function.Function2;\n    import org.apache.spark.api.java.function.PairFunction;\n    import org.apache.spark.api.java.function.VoidFunction;\n    import scala.Tuple2;\n    \n    import java.util.Arrays;\n    import java.util.Iterator;\n    \n    /**\n     * @author 陈锦华\n     * @version V1.0\n     * @Title:\n     * @Description: create by Intellij Idea\n     * @date 2018/3/29 0029 上午 10:57\n     **/\n    public class Java7WordCount {\n    \n        /**\n         * 使用Java的方式开发进行本地测试Spark的WordCount程序\n         *\n         */\n            public static void main(String[] args) {\n                /**\n                 * * setAppName：设置应用名字，此名字会在Spark web UI显示\n                 * setMaster：设置主节点URL，本例使用“local”是指本机单线程，另外还有以下选项：\n                 * local[K]：本机K线程\n                 * local[*]：本机多线程，线程数与服务器核数相同\n                 * spark://HOST:PORT：Spark集群地址和端口，默认端口为7077\n                 * mesos://HOST:PORT：Mesos集群地址和端口，默认端口为5050\n                 * yarn：YARN集群\n                 * 第1步：创建Spark的配置对象SparkConf，设置Spark程序的运行时的配置信息，\n                 * 例如说通过setMaster来设置程序要链接的Spark集群的Master的URL,如果设置\n                 * 为local，则代表Spark程序在本地运行，特别适合于机器配置条件非常差（例如 只有1G的内存）的初学者 *\n                 */\n                SparkConf conf = new SparkConf().setAppName(\"Spark WordCount written by Java\").setMaster(\"local\");\n                /**\n                 * 第2步：创建SparkContext对象\n                 * SparkContext是Spark程序所有功能的唯一入口，无论是采用Scala、Java、Python\n                 * 、R等都必须有一个SparkContext(不同的语言具体的类名称不同，如果是Java的话则为JavaSparkContext)\n                 * SparkContext核心作用：初始化Spark应用程序运行所需要的核心组件，包括DAGScheduler、TaskScheduler、\n                 * SchedulerBackend 同时还会负责Spark程序往Master注册程序等\n                 * SparkContext是整个Spark应用程序中最为至关重要的一个对象\n                 */\n                JavaSparkContext sc = new JavaSparkContext(conf); // 其底层实际上就是Scala的SparkContext\n                /**\n                 * 第3步：根据具体的数据来源（HDFS、HBase、Local FS、DB、S3等）通过JavaSparkContext来创建JavaRDD\n                 * JavaRDD的创建基本有三种方式：根据外部的数据来源（例如HDFS）、根据Scala集合、由其它的RDD操作\n                 * 数据会被RDD划分成为一系列的Partitions，分配到每个Partition的数据属于一个Task的处理范畴\n                 * 注意：文件路径不能直接用Windows路径中的反斜扛\\，要改成Linux下的斜扛/\n                 */\n                JavaRDD<String> lines = sc.textFile(\"C:\\\\offline_FtnInfo.txt\");\n                /**\n                 * 第4步：对初始的JavaRDD进行Transformation级别的处理，例如map、filter等高阶函数等的编程，来进行具体的数据计算\n                 * 第4.1步：讲每一行的字符串拆分成单个的单词\n                 */\n                JavaRDD<String> words = lines.flatMap(new FlatMapFunction<String, String>() {\n                            @Override\n                            public Iterator<String> call(String line) throws Exception {\n                                return Arrays.asList(line.split(\" \")).iterator();\n                            }\n                        });\n                /**\n                 * 第4步：对初始的JavaRDD进行Transformation级别的处理，例如map、filter等高阶函数等的编程，来进行具体的数据计算\n                 * 第4.2步：在单词拆分的基础上对每个单词实例计数为1，也就是word => (word, 1)\n                 */\n                JavaPairRDD<String, Integer> pairs = words.mapToPair(new PairFunction<String, String, Integer>() {\n                            public Tuple2<String, Integer> call(String word) throws Exception {\n                                return new Tuple2<String, Integer>(word, 1);\n                            }\n                        });\n                /**\n                 * 第4步：对初始的RDD进行Transformation级别的处理，例如map、filter等高阶函数等的编程，来进行具体的数据计算\n                 * 第4.3步：在每个单词实例计数为1基础之上统计每个单词在文件中出现的总次数\n                 */\n                JavaPairRDD<String, Integer> wordsCount = pairs.reduceByKey(new Function2<Integer, Integer, Integer>() { // 对相同的Key，进行Value的累计（包括Local和Reducer级别同时Reduce）\n                            public Integer call(Integer v1, Integer v2) throws Exception {\n                                return v1 + v2;\n                            }\n                        });\n                wordsCount.foreach(new VoidFunction<Tuple2<String, Integer>>() {\n                    public void call(Tuple2<String, Integer> pairs) throws Exception {\n                        System.out.println(pairs._1 + \" : \" + pairs._2);\n                    }\n                });\n                sc.close();\n            }\n        }\n\n## 四.spark的java8代码编写\n\n新建package名称为com.chen\n\n新建Java8WordCount.java的文件\n\nJava8WordCount.java\n\n    package com.chen;\n    \n    import org.apache.spark.SparkConf;\n    import org.apache.spark.api.java.JavaPairRDD;\n    import org.apache.spark.api.java.JavaRDD;\n    import org.apache.spark.api.java.JavaSparkContext;\n    import scala.Tuple2;\n    \n    import java.util.Arrays;\n    import java.util.List;\n    \n    /**\n     * @author 陈锦华\n     * @version V1.0\n     * @Title:\n     * @Description: create by Intellij Idea\n     * @date 2018/3/29 0029 上午 10:57\n     **/\n    public class Java8WordCount {\n        /**\n         * 使用Java的方式开发进行本地测试Spark的WordCount程序\n         */\n        public static void main(String[] args) {\n            WordCount2();\n        }\n    \n        public static void WordCount1(){\n            /**\n             * 第4步：对初始的JavaRDD进行Transformation级别的处理，例如map、filter等高阶函数等的编程，来进行具体的数据计算\n             * 第4.2步：在单词拆分的基础上对每个单词实例计数为1，也就是word => (word, 1)\n             * 第4步：对初始的RDD进行Transformation级别的处理，例如map、filter等高阶函数等的编程，来进行具体的数据计算\n             * 第4.3步：在每个单词实例计数为1基础之上统计每个单词在文件中出现的总次数\n             */\n            SparkConf conf = new SparkConf().setAppName(\"Spark WordCount written by Java\").setMaster(\"local\");\n            JavaSparkContext sc = new JavaSparkContext(conf); // 其底层实际上就是Scala的SparkContext\n            JavaRDD<String> lines = sc.textFile(\"C:\\\\offline_FtnInfo.txt\");\n            JavaRDD<String> words = lines.flatMap((line) ->Arrays.asList(line.split(\" \")).iterator());\n            JavaPairRDD<String, Integer> pairs = words.mapToPair((word)->new Tuple2<>(word, 1));\n            JavaPairRDD<String, Integer> wordsCount = pairs.reduceByKey((Integer v1, Integer v2) ->v1 + v2);\n            wordsCount.foreach((Tuple2<String, Integer> pair)->System.out.println(pair._1 + \" : \" + pair._2));\n            sc.close();\n        }\n    \n        public static void WordCount2(){\n            SparkConf conf = new SparkConf().setAppName(\"Spark WordCount written by Java\").setMaster(\"local\");\n            JavaSparkContext sc = new JavaSparkContext(conf); // 其底层实际上就是Scala的SparkContext\n            JavaRDD<String> lines = sc.textFile(\"C:\\\\offline_FtnInfo.txt\");\n            JavaRDD<String> words = lines.flatMap(line -> Arrays.asList(line.split(\" \")).iterator());\n            JavaPairRDD<String, Integer> counts = words.mapToPair(w -> new Tuple2<String, Integer>(w, 1))\n                .reduceByKey((x, y) -> x + y);\n            List<Tuple2<String, Integer>> output = counts.collect();\n                for (Tuple2<?, ?> tuple : output) {\n                    System.out.println(tuple._1() + \":== \" + tuple._2());\n                }\n            sc.close();\n        }\n    }    \n\n## 五.spark的scalar代码编写\n\n1.新建package名称为\n\ncom.chen\n\n2.新建scalaWordCount.scala的文件\n\nscalaWordCount.scala\n\n    package com.chen\n    \n    import org.apache.spark.{SparkConf, SparkContext}\n    \n        object scalaWordCount{\n            def main(args: Array[String]) {\n                //setMaster(\"local\") 本机的spark就用local，远端的就写ip\n                //如果是打成jar包运行则需要去掉 setMaster(\"local\")因为在参数中会指定。\n                val conf = new SparkConf().setAppName(\"local Application\").setMaster(\"local\")\n                val sc = new SparkContext(conf)\n                val rdd = sc.textFile(\"C:\\\\offline_FtnInfo.txt\")\n                val wordcount = rdd\n                        .flatMap(_.split(\" \"))\n                        .map((_,1))\n                        .reduceByKey(_ + _)\n                        .map(x => (x._2,x._1))\n                        .sortByKey(false)\n                        .map(x => (x._2,x._1)\n                    )\n                wordcount.foreach(x=>println(x._1+\"的数量是:\"+x._2))\n                sc.stop()\n            }\n        }\n\n##  六.RDD\n\n###  （一）rdd的创建方式\n\n**1.parallelize从集合创建**\n\n```\nvar rdd = sc.parallelize(1 to 10)\n```\n\n**2.makeRdd创建**\n\n```\nval seq = List((1, List(\"iteblog.com\", \"sparkhost1.com\", \"sparkhost2.com\")),(2, List(\"iteblog.com\", \"sparkhost2.com\")))\nval rdd = sc.makeRDD(seq)\n```\n\n**3.从外部存储创建RDD**\n\n```\nvar rdd = sc.textFile(\"hdfs:///tmp/lxw1234/1.txt\")\n```\n\n**4.从其他HDFS文件格式创建**\n\nhadoopFile\n\nsequenceFile\n\nobjectFile\n\nnewAPIHadoopFile\n\n从Hadoop接口API创建\n\nhadoopRDD\n\nnewAPIHadoopRDD\n\n**5.从HBase创建RDD** \n\n```scala\nimport org.apache.hadoop.hbase.{HBaseConfiguration, HTableDescriptor, TableName}\nimport org.apache.hadoop.hbase.{HBaseConfiguration, HTableDescriptor, TableName}\nimport org.apache.hadoop.hbase.mapreduce.TableInputFormat\nimport org.apache.hadoop.hbase.mapreduce.TableInputFormat\nimport org.apache.hadoop.hbase.client.HBaseAdmin\nimport org.apache.hadoop.hbase.client.HBaseAdmin\nval conf = HBaseConfiguration.create()\nconf.set(TableInputFormat.INPUT_TABLE,\"lxw1234\")\nvar hbaseRDD = sc.newAPIHadoopRDD(conf,classOf[org.apache.hadoop.hbase.mapreduce.TableInputFormat],classOf[org.apache.hadoop.hbase.io.ImmutableBytesWritable],classOf[org.apache.hadoop.hbase.client.Result])\n```\n\n\n\n## 七.spark Sql\n\n### （一）.spark sql的join\n\n1.spark直接传入List列表用createDataset方法进行创建dataset，然后转DataFrame\n\n```\npackage com.chen\nimport org.apache.spark.sql.{DataFrame, Dataset, SparkSession}\n\nobject TestSpark{\n    def main(args: Array[String]): Unit = {\n        val spark: SparkSession = SparkSession.builder().master(\"local[*]\").appName(\"sparkTest\").getOrCreate()\n        import spark.implicits._\n        val lines: Dataset[(String)] = spark.createDataset(List(\"1,chenjinhua,cn\",\"2,Lisi,usa\",\"3,jony,usa\"))\n        val empDataset: Dataset[(String, String, String)] = lines.map(line => {\n            val field: Array[String] = line.split(\",\")\n            var id = field(0)\n            var empName = field(1)\n            var code = field(2)\n            (id, empName, code)\n        })\n        val empDataFrame: DataFrame = empDataset.toDF(\"id\", \"empName\", \"code\")\n        empDataFrame.createTempView(\"emp\")\n\n        val nations: Dataset[(String)] = spark.createDataset(List(\"cn,中国\",\"usa,美国\"))\n        val nationDataset: Dataset[(String, String)] = nations.map(line => {\n            val field: Array[String] = line.split(\",\")\n            val code = field(0)\n            val name = field(1)\n            (code, name)\n        })\n        val nationDataFrame: DataFrame = nationDataset.toDF(\"code\",\"name\")\n        nationDataFrame.createTempView(\"nation\")\n        val dframe: DataFrame = spark.sql(\"select * from emp left join nation on emp.code=nation.code\")\n        dframe.show()\n        spark.stop()\n    }\n}\n```\n\n执行之后展示结果如下\n\n```\n+---+----------+----+----+----+\n| id|   empName|code|code|name|\n+---+----------+----+----+----+\n|  1|chenjinhua|  cn|  cn|  中国|\n|  2|      Lisi| usa| usa|  美国|\n|  3|      jony| usa| usa|  美国|\n+---+----------+----+----+----+\n```\n\n###  （二）spark Sql计算nginx的日志\n\n1.access.log\n\n```\n192.168.197.50 - - [20/Dec/2018:15:46:15 +0800] \"GET /api/rep/scRepairBusHouse/datagrid?pageNum=1&pageRow=10&busHouseCode=&orgId= HTTP/1.1\" 200 1745 \"http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg\" \"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36\"\n192.168.197.50 - - [20/Dec/2018:15:46:15 +0800] \"GET /api/sys/coreDepart/showCompsTreeByUser HTTP/1.1\" 200 809 \"http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg\" \"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36\"\n192.168.197.50 - - [20/Dec/2018:15:46:15 +0800] \"GET /api/sys/coreDepart/showCompsTreeByUser HTTP/1.1\" 200 809 \"http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg\" \"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36\"\n192.168.197.50 - - [20/Dec/2018:15:46:26 +0800] \"GET /api/rep/scRepairBusHouse/datagrid?pageNum=1&pageRow=10&busHouseCode=&orgId=1 HTTP/1.1\" 200 1745 \"http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg\" \"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36\"\n192.168.197.50 - - [20/Dec/2018:15:46:28 +0800] \"GET /api/rep/scRepairBusHouse/datagrid?pageNum=1&pageRow=10&busHouseCode=&orgId=6 HTTP/1.1\" 200 1340 \"http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg\" \"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36\"\n192.168.197.50 - - [20/Dec/2018:15:46:29 +0800] \"GET /api/rep/scRepairBusHouse/datagrid?pageNum=1&pageRow=10&busHouseCode=&orgId=7 HTTP/1.1\" 200 483 \"http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg\" \"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36\"\n192.168.197.50 - - [20/Dec/2018:15:46:30 +0800] \"GET /api/rep/scRepairBusHouse/datagrid?pageNum=1&pageRow=10&busHouseCode=&orgId=6 HTTP/1.1\" 200 1340 \"http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg\" \"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36\"\n192.168.197.50 - - [20/Dec/2018:15:46:30 +0800] \"GET /api/rep/scRepairBusHouse/datagrid?pageNum=1&pageRow=10&busHouseCode=&orgId=1 HTTP/1.1\" 200 1745 \"http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg\" \"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36\"\n192.168.197.145 - - [20/Dec/2018:15:46:30 +0800] \"GET /static/js/13.c5de91a3a5351c406417.js HTTP/1.1\" 304 0 \"http://192.168.197.28:9090/\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299\"\n192.168.197.145 - - [20/Dec/2018:15:46:31 +0800] \"GET /api/rep/scRepairFixPlace/datagrid?pageNum=1&pageRow=10&positionCode=&orgId= HTTP/1.1\" 200 1559 \"http://192.168.197.28:9090/\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299\"\n192.168.197.145 - - [20/Dec/2018:15:46:31 +0800] \"GET /api/sys/coreDepart/showCompsTreeByUser HTTP/1.1\" 200 809 \"http://192.168.197.28:9090/\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299\"\n192.168.197.145 - - [20/Dec/2018:15:46:31 +0800] \"GET /api/sys/coreDepart/showCompsTreeByUser HTTP/1.1\" 200 809 \"http://192.168.197.28:9090/\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299\"\n192.168.197.50 - - [20/Dec/2018:15:46:31 +0800] \"GET /api/rep/scRepairBusHouse/datagrid?pageNum=1&pageRow=10&busHouseCode=&orgId=1 HTTP/1.1\" 200 1745 \"http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg\" \"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36\"\n192.168.197.145 - - [20/Dec/2018:15:46:33 +0800] \"GET /api/rep/scRepairFixitemInfo/datagrid?pageNum=1&pageRow=10&lineCode=&fixItemTypeId= HTTP/1.1\" 200 906 \"http://192.168.197.28:9090/\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299\"\n192.168.197.145 - - [20/Dec/2018:15:46:33 +0800] \"GET /api/rep/scRepairFixitemType/datagrid?fixItemTypeCode= HTTP/1.1\" 200 861 \"http://192.168.197.28:9090/\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299\"\n192.168.197.145 - - [20/Dec/2018:15:46:33 +0800] \"GET /api/rep/scRepairFixitemType/selectTreeData HTTP/1.1\" 200 861 \"http://192.168.197.28:9090/\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299\"\n192.168.197.145 - - [20/Dec/2018:15:46:34 +0800] \"GET /api/rep/scRepairFaultInfo/datagrid?pageNum=1&pageRow=10&lineCode=&faultTypeId= HTTP/1.1\" 200 816 \"http://192.168.197.28:9090/\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299\"\n192.168.197.145 - - [20/Dec/2018:15:46:34 +0800] \"GET /api/rep/scRepairFaultType/selectTreeData HTTP/1.1\" 200 992 \"http://192.168.197.28:9090/\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299\"\n192.168.197.145 - - [20/Dec/2018:15:46:34 +0800] \"GET /api/rep/scRepairFaultType/datagrid?faultTypeCode= HTTP/1.1\" 200 992 \"http://192.168.197.28:9090/\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299\"\n192.168.197.50 - - [20/Dec/2018:15:46:37 +0800] \"GET /static/js/45.f9d68fececdbd4771c9f.js HTTP/1.1\" 200 14268 \"http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg\" \"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36\"\n192.168.197.50 - - [20/Dec/2018:15:46:37 +0800] \"GET /api/mat/scClRelationClient/datagrid?pageNum=1&pageRow=10&clientName= HTTP/1.1\" 200 1815 \"http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg\" \"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36\"\n```\n\n2.计算每个ip访问的次数，并保存到mysql数据库中\n\n```\nimport org.apache.spark.sql.{DataFrame, Dataset, SparkSession}\nobject SparkSqlTest2{\n    def main(args: Array[String]): Unit = {\n        val spark: SparkSession = SparkSession.builder().master(\"local[*]\").appName(\"sparkTest\").getOrCreate()\n        import spark.implicits._\n        val lines: Dataset[String] = spark.read.textFile(\"file:///C:/Users/Administrator/Desktop/access.log\")\n        val data = lines.map(line => {\n            val fields: Array[String] = line.split(\" \")\n            var ip = fields(0)\n            var method = fields(5)\n            var path = fields(6)\n            var HTTPmethod = fields(7)\n            var status = fields(8)\n            var server = fields(10)\n            (ip, method, path, HTTPmethod,status,server)\n        }).toDF(\"ip\", \"method\", \"path\", \"HTTPmethod\",\"status\", \"server\")\n        data.createTempView(\"logs\")\n        val frame: DataFrame = spark.sql(\"select ip,count(ip) from  logs group by ip\")\n\n        val url=\"jdbc:mysql://localhost:3306/anfu\"\n        val table=\"logs\"\n        val prop=new java.util.Properties()\n        prop.put(\"driver\",\"com.mysql.jdbc.Driver\")\n        prop.put(\"user\",\"root\")\n        prop.put(\"password\",\"root\")\n\n        //表自动创建\n        frame.write.jdbc(url,table,prop)\n        spark.stop()\n    }\n}\n```\n\n###  （三）dataset创建方式\n\n**1.spark读取text文件**\n\n```\nval lines=spark.read.textFile(\"file:///c:/text\")\n```\n\n**2.spark传入list创建**\n\n```scala\nval lines = spark.createDataset(List(\"1,chenjinhua,cn\",\"2,Lisi,usa\",\"3,jony,usa\"))\n```\n\n**3.spark传入Seq创建**\n\n```\nval dataset = Seq(\n  (1, \"zhangyuhang\", java.sql.Date.valueOf(\"2018-05-15\")),\n  (2, \"zhangqiuyue\", java.sql.Date.valueOf(\"2018-05-15\"))\n)\n```\n\n**4.spark传入Rdd创建**\n\n```\nval dataset = spark.createDataset(spark.sparkContext.parallelize(1 to 10))\n```\n\n###  （四）dataFrame创建方式\n\n**1.使用toDF函数创建DataFrame** \n\n```\nimport spark.implicits._\nval df = Seq(\n  (1, \"zhangyuhang\", java.sql.Date.valueOf(\"2018-05-15\")),\n  (2, \"zhangqiuyue\", java.sql.Date.valueOf(\"2018-05-15\"))\n).toDF(\"id\", \"name\", \"created_time\")\n```\n\n**2.使用createDataFrame函数创建DataFrame** ，**通过schema + row 来创建** \n\n可以理解为schema为表的表头，row为表的数据记录 \n\n```\nimport org.apache.spark.sql.types._\n//定义dataframe的结构的schema\nval schema = StructType(List(\n    StructField(\"id\", IntegerType, nullable = false),\n    StructField(\"name\", StringType, nullable = true),\n    StructField(\"create_time\", DateType, nullable = true)\n))\n\n//定义dataframe内容的rdd\nval rdd = sc.parallelize(Seq(\n  Row(1, \"zhangyuhang\", java.sql.Date.valueOf(\"2018-05-15\")),\n  Row(2, \"zhangqiuyue\", java.sql.Date.valueOf(\"2018-05-15\"))\n))\n//创建dataframe\nval df = spark.createDataFrame(rdd, schema)\n```\n\n或者\n\n```\nimport org.apache.spark.sql.types._\n//传入属性参数\nval schemaString = \" id name create_time\"\n//解析参数变成StructField\nval fields = schemaString.split(\" \").map(fieldName => StructField(fieldname, StringType, nullable = true))\n//定义dataframe的结构的schema\nval schema = StructType(fields)\n//定义dataframe内容的rdd\nval lines = sc.textFile(\"file:///people.txt\")\nval rdd = lines.spilt(_.split(\",\")).map(field=>ROW(field(0),field(1).trim) )\n//创建dataframe\nval df = spark.createDataFrame(rdd, schema) \n```\n\n**3.通过反射机制创建DataFrame**\n\n 首先要定义一个case class，因为只有case class才能被Spark隐式转化为DataFrame\n\n```\nimport org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\nimport org.apache.spark.sql.Encoder\nimport spark.implicits._\n//创建匹配类\ncase class Person(id:Int,name:String,age:Long)\n//读取文件生成rdd\nval rdd = sc.textFile(\"file:///\")\n//通过匹配类把rdd转化成dataframe\nval df = rdd.map(_.split(\",\")).map(attributes => Person(attributes(0),attributes(1),attributes(2).trim.toInt)).toDF()　\n```\n\n\n\n### （五）spark sql设置分区数量\n\n保存文件时可以设置分区为一个，文件数量就会是一个\n\n```\nspark.sqlContext.setConf(\"spark.sql.shuffle.partitions\",\"1\")\n```\n\n### （六）spark sql数据读取数据\n\n**1.读取parquet文件** \n\n```\nval df = spark.read.parquet(\"hdfs:/path/to/file\")\n```\n\n**2.读取json文件 **\n\n```\nval df = spark.read.json(\"examples/src/main/resources/people.json\")\n```\n\n**3.读取csv**\n\n```\nval df = spark.read.format(\"com.databricks.spark.csv\")\n        .option(\"header\", \"true\") //reading the headers\n        .option(\"mode\", \"DROPMALFORMED\")\n        .load(\"csv/file/path\")\n```\n\n**4.读取Hive表**\n\n```\nspark.table(\"test.person\") // 库名.表名 的格式\n     .registerTempTable(\"person\")  // 注册成临时表\nspark.sql(\n      \"\"\"\n        | select *\n        | from person\n        | limit 10\n      \"\"\".stripMargin).show()\n```\n\n \n\n###  （七）spark sql数据保存\n\n**1.通过df.write.format().save(\"file:///\")保存** \n\nwrite.format()支持输出的格式有parquet、 JSON、csv、JDBC、text等文件格式,save()定义保存的位置\n\n当我们保存成功后可以在保存位置的目录下看到文件，但是这个文件并不是一个文件而是一个目录。\n\n**（1）parquet格式**\n\n```\ndf.write.mode(SaveMode.Append).format(\"parquet\").save(\"file:///C:/Users/Administrator/Desktop/parquet\")\ndf.write.mode(SaveMode.Append).parquet(\"file:///C:/Users/Administrator/Desktop/parquet2\")\n```\n\n**（2）json格式**\n\n```\ndf.write.format(\"json\").save(\"file:///C:/Users/Administrator/Desktop/myjson\")\n```\n\n**（3）csv格式**\n\n```\ndf.write.format(\"csv\").save(\"file:///C:/Users/Administrator/Desktop/mycsv\")\n```\n\n**（4）jdbc格式，保存到mysql数据库**\n\n```scala\nval url=\"jdbc:mysql://localhost:3306/anfu\"\nval table=\"logs\"\nval prop=new java.util.Properties()\nprop.put(\"driver\",\"com.mysql.jdbc.Driver\")\nprop.put(\"user\",\"root\")\nprop.put(\"password\",\"root\")\n//表自动创建\nframe.write.jdbc(url,table,prop)\n```\n\n**（5）text格式，保存的时候必须是一列，否则报错**\n\n```\ndf.write.format(\"text\").save(\"file:///C:/Users/Administrator/Desktop/mytext\")\n```\n\n**2.通过df.rdd.saveAsTextFile(\"file:///\")转化成rdd再保存**\n\n\n\n**我们对于不同格式的文件读写来说，我们一般使用两套对应方式**\n\n## 八.spark Stream\n\n### （一）netcat运用\n\n**1.netcat在windows下使用**\n\nWindows间传输：\n\n1、安装NetCat\n\n2、开启服务端：nc -l -p 9999\n\n3、开启客户端：nc localhost 9999\n\n4、客户端和服务端间通信\n\n**2.netcat在linux下使用**\n\n**（1）netcat的安装**\n\n```\nyum install nc -y\n```\n\n**（2）netcat使用**\n\n```\nnc -lk 9000\n```\n\n### （二）spark Stream的socketTextStream\n\n**（1）代码编写**\n\n```\nimport org.apache.spark.SparkContext\nimport org.apache.spark.sql.{DataFrame, Dataset, SparkSession}\nimport org.apache.spark.streaming.dstream.{DStream, ReceiverInputDStream}\nimport org.apache.spark.streaming.{Duration, StreamingContext}\n\nobject SparkStreamTest1{\n    def main(args: Array[String]): Unit = {\n        val spark: SparkSession = SparkSession.builder().master(\"local[*]\").appName(\"sparkTest\").getOrCreate()\n        val sc= spark.sparkContext\n        val ssc = new StreamingContext(sc,Duration(5000))\n        val line: ReceiverInputDStream[String] = ssc.socketTextStream(\"192.168.232.140\",9000)\n        val ds: DStream[(String, Int)] = line.flatMap(_.split(\" \")).map((_,1)).reduceByKey(_+_)\n        ds.print()\n        ssc.start()\n        ssc.awaitTermination()\n    }\n}\n```\n\n**（2）在192.168.232.140的netcat下输入数据**\n\n```\n[root@master ~]# nc -lk 9000\ndsfadsfad\nl1l\nkj\nhjhj\n```\n\n**（3）输出结果**\n\n```\n(dsfadsfad,1)\n(hjhj,1)\n(l1l,1)\n(kj,1)\n```\n\n###  （三）spark Stream的结果集保存到数据库\n\n**（1）获取socketTextStream中的数据进行计算之后保存mysql**\n\n```\npackage com.chen\nimport java.sql.{Connection, DriverManager, Statement}\nimport org.apache.log4j.{Level, Logger}\nimport org.apache.spark.sql.SparkSession\nimport org.apache.spark.streaming.dstream.{DStream, ReceiverInputDStream}\nimport org.apache.spark.streaming.{Duration, StreamingContext}\n\nobject SparkStream2MysqlTest1{\n    def main(args: Array[String]): Unit = {\n        Logger.getLogger(\"com.chen\").setLevel(Level.OFF)\n        val spark: SparkSession = SparkSession.builder().master(\"local[*]\").appName(\"sparkTest\").getOrCreate()\n        val sc= spark.sparkContext\n        val ssc = new StreamingContext(sc,Duration(5000))\n        val line: ReceiverInputDStream[String] = ssc.socketTextStream(\"192.168.232.140\",9000)\n        val ds: DStream[(String, Int)] = line.flatMap(_.split(\" \")).map((_,1)).reduceByKey(_+_)\n\n        ds.foreachRDD(rdd=>rdd.foreachPartition(line=>{\n                Class.forName(\"com.mysql.jdbc.Driver\")\n                val connection: Connection = DriverManager.getConnection(\"jdbc:mysql://192.168.197.28:3306/sys\",\"dev\",\"dev@gzstrong\")\n                try{\n                    for (row<-line){\n                        val statement: Statement = connection.createStatement()\n                        val sql=\"INSERT INTO `sys`.`test` (`value`, `valueCount`) VALUES ('\"+row._1+\"','\"+row._2+\"');\"\n                        statement.execute(sql)\n                    }\n                }finally {\n                    connection.close()\n                }\n            })\n        )\n        ssc.start()\n        ssc.awaitTermination()\n    }\n}\n```\n\n**（2）在192.168.232.140的netcat下输入数据**\n\n```\n[root@master ~]# nc -lk 9000\ntest\nsichuang\ngzstrong\n```\n\n**（3）查看数据库中的结果**\n\n|  value   | valuecount |\n| :------: | :--------: |\n|   test   |     1      |\n| sichuang |     1      |\n| gzstrong |     1      |\n\n\n\n###  （四）spark Stream与kafka的集成\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## 九.Structured Streaming\n\n\n\n\n\n## 十.spark案例分析与编程实现\n\n案例一\n\na. 案例描述\n\n提起 Word Count(词频数统计)，相信大家都不陌生，就是统计一个或者多个文件中单词出现的次数。本文将此作为一个入门级案例，由浅入深的开启使用 Scala 编写 Spark 大数据处理程序的大门。\n\nb．案例分析\n\n对于词频数统计，用 Spark 提供的算子来实现，我们首先需要将文本文件中的每一行转化成一个个的单词, 其次是对每一个出现的单词进行记一次数，最后就是把所有相同单词的计数相加得到最终的结果。\n\n对于第一步我们自然的想到使用 flatMap 算子把一行文本 split 成多个单词，然后对于第二步我们需要使用 map 算子把单个的单词转化成一个有计数的 Key-Value 对，即 word -> (word,1). 对于最后一步统计相同单词的出现次数，我们需要使用 reduceByKey 算子把相同单词的计数相加得到最终结果。\n\nc. 编程实现\n\n清单 1.SparkWordCount 类源码\n\nSparkWordCount.scala\n\n    import org.apache.spark.SparkConf\n    import org.apache.spark.SparkContext\n    import org.apache.spark.SparkContext._\n     \n    object SparkWordCount {\n     def FILE_NAME:String = \"word_count_results_\";\n     def main(args:Array[String]) {\n     if (args.length < 1) {\n     println(\"Usage:SparkWordCount FileName\");\n     System.exit(1);\n     }\n     val conf = new SparkConf().setAppName(\"Spark Exercise: Spark Version Word Count Program\");\n     val sc = new SparkContext(conf);\n     val textFile = sc.textFile(args(0));\n     val wordCounts = textFile.flatMap(line => line.split(\" \")).map(\n                                            word => (word, 1)).reduceByKey((a, b) => a + b)\n     //print the results,for debug use.\n     //println(\"Word Count program running results:\");\n     //wordCounts.collect().foreach(e => {\n     //val (k,v) = e\n     //println(k+\"=\"+v)\n     //});\n     wordCounts.saveAsTextFile(FILE_NAME+System.currentTimeMillis());\n     println(\"Word Count program running results are successfully saved.\");\n     }\n    }\n\n\nd. 提交到集群执行\n\n本实例中, 我们将统计 HDFS 文件系统中/user/fams 目录下所有 txt 文件中词频数。其中 spark-exercise.jar 是 Spark 工程打包后的 jar 包，这个 jar 包执行时会被上传到目标服务器的/home/fams 目录下。运行此实例的具体命令如下：\n\n    ./spark-submit \\\n    --class com.ibm.spark.exercise.basic.SparkWordCount \\\n    --master spark://hadoop036166:7077 \\\n    --num-executors 3 \\\n    --driver-memory 6g --executor-memory 2g \\\n    --executor-cores 2 \\\n    /home/fams/sparkexercise.jar \\\n    hdfs://hadoop036166:9000/user/fams/*.txt\n\n\n**案例二**\n\na. 案例描述\n\n该案例中，我们将假设我们需要统计一个 1000 万人口的所有人的平均年龄，当然如果您想测试 Spark 对于大数据的处理能力，您可以把人口数放的更大，比如 1 亿人口，当然这个取决于测试所用集群的存储容量。假设这些年龄信息都存储在一个文件里，并且该文件的格式如下，第一列是 ID，第二列是年龄。\n\n案例二age.txt测试数据格式预览\n\n![è¾å¥å¾çè¯´æ](https://static.oschina.net/uploads/img/201803/29143845_eRx4.jpg) \n\n现在我们需要用 Scala 写一个生成 1000 万人口年龄数据的文件，源程序如下：\n\n清单 3. 年龄信息文件生成类源码\n\n    import java.io.FileWriter\n    import java.io.File\n    import scala.util.Random\n     \n    object SampleDataFileGenerator {\n     \n    def main(args:Array[String]) {\n    val writer = new FileWriter(new File(\"C: \\\\sample_age_data.txt\"),false)\n    val rand = new Random()\n    for ( i <- 1 to 10000000) {\n    writer.write( i + \" \" + rand.nextInt(100))\n    writer.write(System.getProperty(\"line.separator\"))\n    }\n    writer.flush()\n    writer.close()\n    }\n    }\n\n\nb. 案例分析\n\n要计算平均年龄，那么首先需要对源文件对应的 RDD 进行处理，也就是将它转化成一个只包含年龄信息的 RDD，其次是计算元素个数即为总人数，然后是把所有年龄数加起来，最后平均年龄=总年龄/人数。\n\n对于第一步我们需要使用 map 算子把源文件对应的 RDD 映射成一个新的只包含年龄数据的 RDD，很显然需要对在 map 算子的传入函数中使用 split 方法，得到数组后只取第二个元素即为年龄信息；第二步计算数据元素总数需要对于第一步映射的结果 RDD 使用 count 算子；第三步则是使用 reduce 算子对只包含年龄信息的 RDD 的所有元素用加法求和；最后使用除法计算平均年龄即可。\n\n由于本例输出结果很简单，所以只打印在控制台即可。\n\nc. 编程实现\n\n清单 4.AvgAgeCalculator 类源码\n\n    import org.apache.spark.SparkConf\n    import org.apache.spark.SparkContext\n    object AvgAgeCalculator {\n     def main(args:Array[String]) {\n     if (args.length < 1){\n     println(\"Usage:AvgAgeCalculator datafile\")\n     System.exit(1)\n     }\n     val conf = new SparkConf().setAppName(\"Spark Exercise:Average Age Calculator\")\n     val sc = new SparkContext(conf)\n     val dataFile = sc.textFile(args(0), 5);\n     val count = dataFile.count()\n     val ageData = dataFile.map(line => line.split(\" \")(1))\n     val totalAge = ageData.map(age => Integer.parseInt(\n                                    String.valueOf(age))).collect().reduce((a,b) => a+b)\n     println(\"Total Age:\" + totalAge + \";Number of People:\" + count )\n     val avgAge : Double = totalAge.toDouble / count.toDouble\n     println(\"Average Age is \" + avgAge)\n     }\n    }\n\n\n案例三\n\na. 案例描述\n\n本案例假设我们需要对某个省的人口 (1 亿) 性别还有身高进行统计，需要计算出男女人数，男性中的最高和最低身高，以及女性中的最高和最低身高。本案例中用到的源文件有以下格式, 三列分别是 ID，性别，身高 (cm)。\n\n案例三测试数据格式预览\n\n\n\n我们将用以下 Scala 程序生成这个文件，源码如下：\n\n清单 7. 人口信息生成类源码\n\n    import java.io.FileWriter\n    import java.io.File\n    import scala.util.Random\n     \n    object PeopleInfoFileGenerator {\n     def main(args:Array[String]) {\n     val writer = new FileWriter(new File(\"C:\\\\LOCAL_DISK_D\\\\sample_people_info.txt\"),false)\n     val rand = new Random()\n     for ( i <- 1 to 100000000) {\n     var height = rand.nextInt(220)\n     if (height < 50) {\n     height = height + 50\n     }\n     var gender = getRandomGender\n     if (height < 100 && gender == \"M\")\n     height = height + 100\n     if (height < 100 && gender == \"F\")\n     height = height + 50\n     writer.write( i + \" \" + getRandomGender + \" \" + height)\n     writer.write(System.getProperty(\"line.separator\"))\n     }\n     writer.flush()\n     writer.close()\n     println(\"People Information File generated successfully.\")\n     }\n      \n     def getRandomGender() :String = {\n     val rand = new Random()\n     val randNum = rand.nextInt(2) + 1\n     if (randNum % 2 == 0) {\n     \"M\"\n     } else {\n     \"F\"\n     }\n     }\n    }\n\n\nb. 案例分析\n\n对于这个案例，我们要分别统计男女的信息，那么很自然的想到首先需要对于男女信息从源文件的对应的 RDD 中进行分离，这样会产生两个新的 RDD，分别包含男女信息；其次是分别对男女信息对应的 RDD 的数据进行进一步映射，使其只包含身高数据，这样我们又得到两个 RDD，分别对应男性身高和女性身高；最后需要对这两个 RDD 进行排序，进而得到最高和最低的男性或女性身高。\n\n对于第一步，也就是分离男女信息，我们需要使用 filter 算子，过滤条件就是包含”M” 的行是男性，包含”F”的行是女性；第二步我们需要使用 map 算子把男女各自的身高数据从 RDD 中分离出来；第三步我们需要使用 sortBy 算子对男女身高数据进行排序。\n\nc. 编程实现\n\n在实现上，有一个需要注意的点是在 RDD 转化的过程中需要把身高数据转换成整数，否则 sortBy 算子会把它视为字符串，那么排序结果就会受到影响，例如 身高数据如果是：123,110,84,72,100，那么升序排序结果将会是 100,110,123,72,84，显然这是不对的。\n\n清单 8.PeopleInfoCalculator 类源码\n\n    object PeopleInfoCalculator {\n     def main(args:Array[String]) {\n     if (args.length < 1){\n     println(\"Usage:PeopleInfoCalculator datafile\")\n     System.exit(1)\n     }\n     val conf = new SparkConf().setAppName(\"Spark Exercise:People Info(Gender & Height) Calculator\")\n     val sc = new SparkContext(conf)\n     val dataFile = sc.textFile(args(0), 5);\n     val maleData = dataFile.filter(line => line.contains(\"M\")).map(\n                                  line => (line.split(\" \")(1) + \" \" + line.split(\" \")(2)))\n     val femaleData = dataFile.filter(line => line.contains(\"F\")).map(\n                                  line => (line.split(\" \")(1) + \" \" + line.split(\" \")(2)))\n     //for debug use\n     //maleData.collect().foreach { x => println(x)}\n     //femaleData.collect().foreach { x => println(x)}\n     val maleHeightData = maleData.map(line => line.split(\" \")(1).toInt)\n     val femaleHeightData = femaleData.map(line => line.split(\" \")(1).toInt)\n     //for debug use\n     //maleHeightData.collect().foreach { x => println(x)}\n     //femaleHeightData.collect().foreach { x => println(x)}\n     val lowestMale = maleHeightData.sortBy(x => x,true).first()\n     val lowestFemale = femaleHeightData.sortBy(x => x,true).first()\n     //for debug use\n     //maleHeightData.collect().sortBy(x => x).foreach { x => println(x)}\n     //femaleHeightData.collect().sortBy(x => x).foreach { x => println(x)}\n     val highestMale = maleHeightData.sortBy(x => x, false).first()\n     val highestFemale = femaleHeightData.sortBy(x => x, false).first()\n     println(\"Number of Male Peole:\" + maleData.count())\n     println(\"Number of Female Peole:\" + femaleData.count())\n     println(\"Lowest Male:\" + lowestMale)\n     println(\"Lowest Female:\" + lowestFemale)\n     println(\"Highest Male:\" + highestMale)\n     println(\"Highest Female:\" + highestFemale)\n     }\n    }\n\n\n案例四\n\na. 案例描述\n\n该案例中我们假设某搜索引擎公司要统计过去一年搜索频率最高的 K 个科技关键词或词组，为了简化问题，我们假设关键词组已经被整理到一个或者多个文本文件中，并且文档具有以下格式。\n\n图 13. 案例四测试数据格式预览\n\n\n\n我们可以看到一个关键词或者词组可能出现多次，并且大小写格式可能不一致。\n\nb. 案例分析\n\n要解决这个问题，首先我们需要对每个关键词出现的次数进行计算，在这个过程中需要识别不同大小写的相同单词或者词组，如”Spark”和“spark” 需要被认定为一个单词。对于出现次数统计的过程和 word count 案例类似；其次我们需要对关键词或者词组按照出现的次数进行降序排序，在排序前需要把 RDD 数据元素从 (k,v) 转化成 (v,k)；最后取排在最前面的 K 个单词或者词组。\n\n对于第一步，我们需要使用 map 算子对源数据对应的 RDD 数据进行全小写转化并且给词组记一次数，然后调用 reduceByKey 算子计算相同词组的出现次数；第二步我们需要对第一步产生的 RDD 的数据元素用 sortByKey 算子进行降序排序；第三步再对排好序的 RDD 数据使用 take 算子获取前 K 个数据元素。\n\nc. 编程实现\n\n清单 10.TopKSearchKeyWords 类源码\n\n    import org.apache.spark.SparkConf\n    import org.apache.spark.SparkContext\n     \n    object TopKSearchKeyWords {\n     def main(args:Array[String]){\n     if (args.length < 2) {\n     println(\"Usage:TopKSearchKeyWords KeyWordsFile K\");\n     System.exit(1)\n     }\n     val conf = new SparkConf().setAppName(\"Spark Exercise:Top K Searching Key Words\")\n     val sc = new SparkContext(conf)\n     val srcData = sc.textFile(args(0))\n     val countedData = srcData.map(line => (line.toLowerCase(),1)).reduceByKey((a,b) => a+b)\n     //for debug use\n     //countedData.foreach(x => println(x))\n     val sortedData = countedData.map{ case (k,v) => (v,k) }.sortByKey(false)\n     val topKData = sortedData.take(args(1).toInt).map{ case (v,k) => (k,v) }\n     topKData.foreach(println)\n     }\n    }\n\n**案例二的age.txt文件**\n\n1 16\n\n2 73\n\n3 74\n\n4 76 \n\n5 75\n\n6 78\n\n7 66\n\n8 55\n\n9 85\n\n11 25\n\n12 43\n\n13 45\n\n14 61\n\n15 35\n\n16 38\n\n17 69\n\n18 45\n\n19 55\n\n20 45\n\n21 16\n\n22 73\n\n23 74\n\n24 76 \n\n25 75\n\n26 78\n\n27 66\n\n28 55\n\n29 85\n\n30 85\n\n31 25\n\n32 43\n\n33 45\n\n34 61\n\n35 35\n\n36 38\n\n37 69\n\n38 45\n\n39 55\n\n40 45\n\n七.算子reduceByKey和groupByKey，sortByKey和sortBy区别\n\n1. Spark算子reduceByKey深度解析\n   那么这就基本奠定了reduceByKey的作用域是key-value类型的键值对，并且是只对每个key的value进行处理，如果含有多个key的话，那么就对多个values进行处理。这里的函数是我们自己传入的，也就是说是可人为控制的【其实这是废话，人为控制不了这算子一点用没有】。那么举个例子：\n\n    scala> val x = sc.parallelize(Array((\"a\", 1), (\"b\", 1), (\"a\", 1),\n         | (\"a\", 1), (\"b\", 1), (\"b\", 1),\n         | (\"b\", 1), (\"b\", 1)), 3)\n\n\n我们创建了一个Array的字符串，并把其存入spark的集群上，设置了三个分区【这里我们不关注分区，只关注操作】。那么我们调用reduceByKey并且传入函数进行相应操作【本处我们对相同key的value进行相加操作，类似于统计单词出现次数】：\n\n    scala> val y = x.reduceByKey((pre, after) => (pre + after))\n\n\n这里两个参数我们逻辑上让他分别代表同一个key的两个不同values，那么结果想必大家应该猜到了： \n\n    scala> y.collect\n    res0: Array[(String, Int)] = Array((a,3), (b,5))\n\n\n1. reduceByKey和groupByKey区别与用法\n   首先，看一看spark官网[1]是怎么解释的：\n   reduceByKey(func, numPartitions=None)\n   reduceByKey用于对每个key对应的多个value进行merge操作，最重要的是它能够在本地先进行merge操作，并且merge操作可以通过函数自定义。\n\ngroupByKey(numPartitions=None)\n\n也就是，groupByKey也是对每个key进行操作，但只生成一个sequence。需要特别注意“Note”中的话，它告诉我们：如果需要对sequence进行aggregation操作（注意，groupByKey本身不能自定义操作函数），那么，选择reduceByKey/aggregateByKey更好。这是因为groupByKey不能自定义函数，我们需要先用groupByKey生成RDD，然后才能对此RDD通过map进行自定义函数操作。 \n\n    val words = Array(\"one\", \"two\", \"two\", \"three\", \"three\", \"three\")\n    val wordPairsRDD = sc.parallelize(words).map(word => (word, 1))\n    val wordCountsWithReduce = wordPairsRDD.reduceByKey(_ + _)\n    val wordCountsWithGroup = wordPairsRDD.groupByKey().map(t => (t._1, t._2.sum))\n\n\n上面得到的wordCountsWithReduce和wordCountsWithGroup是完全一样的，但是，它们的内部运算过程是不同的。 \n\n（1）当采用reduceByKeyt时，Spark可以在每个分区移动数据之前将待输出数据与一个共用的key结合。借助下图可以理解在reduceByKey里究竟发生了什么。 注意在数据对被搬移前同一机器上同样的key是怎样被组合的(reduceByKey中的lamdba函数)。然后lamdba函数在每个区上被再次调用来将所有值reduce成一个最终结果。整个过程如下：\n\n\n\n（2）当采用groupByKey时，由于它不接收函数，spark只能先将所有的键值对(key-value pair)都移动，这样的后果是集群节点之间的开销很大，导致传输延时。整个过程如下：\n\n\n\n因此，在对大数据进行复杂计算时，reduceByKey优于groupByKey。\n\n另外，如果仅仅是group处理，那么以下函数应该优先于 groupByKey ：\n\n 　　（1）、combineByKey 组合数据，但是组合之后的数据类型与输入时值的类型不一样。\n\n 　　（2）、foldByKey合并每一个 key 的所有值，在级联函数和“零值”中使用。\n\n1. sortByKey和sortBy区别\n   SortByKey()函数\n\nsortBy函数是在org.apache.spark.rdd.RDD类中实现的，它的实现如下：\n\n    def sortBy[K](f: (T) => K,ascending: Boolean = true,\n        numPartitions: Int = this.partitions.size)\n        (implicit ord: Ordering[K], ctag: ClassTag[K]): RDD[T] =\n        this.keyBy[K](f).sortByKey(ascending, numPartitions).values\n\n\n　该函数最多可以传三个参数：\n\n　　第一个参数是一个函数，该函数的也有一个带T泛型的参数，返回类型和RDD中元素的类型是一致的；\n\n　　第二个参数是ascending，从字面的意思大家应该可以猜到，是的，这参数决定排序后RDD中的元素是升序还是降序，默认是true，也就是升序；\n\n　　第三个参数是numPartitions，该参数决定排序后的RDD的分区个数，默认排序后的分区个数和排序之前的个数相等，即为this.partitions.size。\n\n　　从sortBy函数的实现可以看出，第一个参数是必须传入的，而后面的两个参数可以不传入。而且sortBy函数函数的实现依赖于sortByKey函数，关于sortByKey函数后面会进行说明。\n\n   那么，如何使用sortBy函数呢？\n\n    scala> val data = List(3,1,90,3,5,12)\n    data: List[Int] = List(3, 1, 90, 3, 5, 12)\n     \n    scala> val rdd = sc.parallelize(data)\n    rdd: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[0] at parallelize at <console>:14\n     \n    scala> rdd.collect\n    res0: Array[Int] = Array(3, 1, 90, 3, 5, 12)\n     \n    scala> rdd.sortBy(x => x).collect\n    res1: Array[Int] = Array(1, 3, 3, 5, 12, 90)\n     \n    scala> rdd.sortBy(x => x, false).collect\n    res3: Array[Int] = Array(90, 12, 5, 3, 3, 1)\n     \n    scala> val result = rdd.sortBy(x => x, false)\n    result: org.apache.spark.rdd.RDD[Int] = MappedRDD[23] at sortBy at <console>:16\n     \n    scala> result.partitions.size\n    res9: Int = 2\n     \n    scala> val result = rdd.sortBy(x => x, false, 1)\n    result: org.apache.spark.rdd.RDD[Int] = MappedRDD[26] at sortBy at <console>:16\n     \n    scala> result.partitions.size\n    res10: Int = 1\n\n\n上面的实例对rdd中的元素进行升序排序。并对排序后的RDD的分区个数进行了修改，上面的result就是排序后的RDD，默认的分区个数是2，而我们对它进行了修改，所以最后变成了1。\n\n    val data = sc.parallelize(Array((\"cc\",12),(\"bb\",32),(\"cc\",22),(\"aa\",18),(\"bb\",16),(\"dd\",16),(\"ee\",54),(\"cc\",1),(\"ff\",13),(\"gg\",68),(\"bb\",4)))\n    var sortbykey=data.sortByKey(false).collect\n    sortbykey.foreach(x=>(println(x._1+\" \"+x._2)))\n\n\n结果如下\n\n\n\n测到的测试结果如上图所示，显然是根据Key进行了排序。\n\nSortBy()函数\n\nsortByKey函数作用于Key-Value形式的RDD，并对Key进行排序。它是在org.apache.spark.rdd.OrderedRDDFunctions中实现的，实现如下\n\n    def sortByKey(ascending: Boolean = true, numPartitions: Int = self.partitions.size)\n        : RDD[(K, V)] =\n    {\n      val part = new RangePartitioner(numPartitions, self, ascending)\n      new ShuffledRDD[K, V, V](self, part)\n        .setKeyOrdering(if (ascending) ordering else ordering.reverse)\n    }\n\n\n从函数的实现可以看出，它主要接受两个函数，含义和sortBy一样，这里就不进行解释了。该函数返回的RDD一定是ShuffledRDD类型的，因为对源RDD进行排序，必须进行Shuffle操作，而Shuffle操作的结果RDD就是ShuffledRDD。其实这个函数的实现很优雅，里面用到了RangePartitioner，它可以使得相应的范围Key数据分到同一个partition中，然后内部用到了mapPartitions对每个partition中的数据进行排序，而每个partition中数据的排序用到了标准的sort机制，避免了大量数据的shuffle。下面对sortByKey的使用进行说明：\n\n    scala> val a = sc.parallelize(List(\"wyp\", \"iteblog\", \"com\", \"397090770\", \"test\"), 2)\n    a: org.apache.spark.rdd.RDD[String] =ParallelCollectionRDD[30] at parallelize at <console>:12\n     \n    scala> val b = sc. parallelize (1 to a.count.toInt , 2)\n    b: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[31] at parallelize at <console>:14\n     \n    scala> val c = a.zip(b)\n    c: org.apache.spark.rdd.RDD[(String, Int)] = ZippedPartitionsRDD2[32] at zip at <console>:16\n     \n    scala> c.sortByKey().collect\n    res11: Array[(String, Int)] = Array((397090770,4), (com,3), (iteblog,2), (test,5), (wyp,1))\n\n\n    val data = sc.parallelize(Array((\"cc\",12),(\"bb\",32),(\"cc\",22),(\"aa\",18),(\"bb\",16),(\"dd\",16),(\"ee\",54),(\"cc\",1),(\"ff\",13),(\"gg\",68),(\"bb\",4)))\n    var sort=data.reduceByKey(_+_).sortBy(_._2,false).collect()\n    sort.foreach(x=>(println(x._1+\" \"+x._2)))\n\n\n结果如下\n\n\n\n 显然，上图显示的结果是根据Value中的数据进行的排序。\n\n\n\n\n\n# 海量数据算法\n\n**数据倾斜的算子**\n\n数据倾斜只会发生在shuffle过程中。这里给大家罗列一些常用的并且可能会触发shuffle操作的算子：distinct、groupByKey、reduceByKey、aggregateByKey、join、cogroup、repartition等。出现数据倾斜时，可能就是你的代码中使用了这些算子中的某一个所导致的。\n\n## （一）mapjoin解析\n\n利用hive进行join连接操作，相较于MR有两种执行方案，一种为common join，另一种为map join ，map join是相对于common join的一种优化，省去shullfe和reduce的过程，大大的降低的作业运行的时间。 \n\nselect f.a,f.b from A t join B f  on ( f.a=t.a and f.ftime=20110802)  \n\n该语句中B表有30亿行记录，A表只有100行记录，而且B表中数据倾斜特别严重，有一个key上有15亿行记录，在运行过程中特别的慢，而且在reduece的过程中遇有内存不够而报错。\n\n为了解决用户的这个问题，考虑使用mapjoin,mapjoin的原理： \n\n> **MAPJION会把小表全部读入内存中，在map阶段直接拿另外一个表的数据和内存中表数据做匹配，由于在map是进行了join操作，省去了reduce运行的效率也会高很多** \n\n这样就不会由于数据倾斜导致某个reduce上落数据太多而失败。于是原来的sql可以通过使用hint的方式指定join时使用mapjoin。 \n\n> select /*+ mapjoin(A)*/ f.a,f.b from A t join B f  on ( f.a=t.a and f.ftime=20110802)  \n\n再运行发现执行的效率比以前的写法高了好多。 \n\nmapjoin还有一个很大的好处是能够进行不等连接的join操作，如果将不等条件写在where中，那么mapreduce过程中会进行笛卡尔积，运行效率特别低，如果使用mapjoin操作，在map的过程中就完成了不等值的join操作，效率会高很多。 \n\n例子： \n\nselect A.a ,A.b from A join B where A.a>B.a \n\n**简单总结一下，mapjoin的使用场景：**\n\n1.关联操作中有一张表非常小\n\n 2.不等值的链接操作\n\n **MapJoin原理**\n\n![1565833762509](C:\\Users\\Administrator\\Desktop\\Md笔记\\pic\\1565833762509.png)\n\n\n\nMapJoin简单说就是在Map阶段将小表读入内存，顺序扫描大表完成Join。\n\n上图是Hive MapJoin的原理图，出自Facebook工程师Liyin Tang的一篇介绍Join优化的slice，从图中可以看出MapJoin分为两个阶段：\n\n1. 通过MapReduce Local Task，将小表读入内存，生成HashTableFiles上传至Distributed Cache中，这里会对HashTableFiles进行压缩。\n2. MapReduce Job在Map阶段，每个Mapper从Distributed Cache读取HashTableFiles到内存中，顺序扫描大表，在Map阶段直接进行Join，将数据传递给下一个MapReduce任务。\n\n##  （二）美团网的spark调优\n\n基础版  https://tech.meituan.com/2016/04/29/spark-tuning-basic.html\n\n高级版  https://tech.meituan.com/2016/05/12/spark-tuning-pro.html\n\n##  （三） 两阶段聚合（局部聚合+全局聚合）\n\n**方案适用场景：**对RDD执行reduceByKey等聚合类shuffle算子或者在Spark SQL中使用group by语句进行分组聚合时，比较适用这种方案。\n\n**方案实现思路：**这个方案的核心实现思路就是进行两阶段聚合。第一次是局部聚合，先给每个key都打上一个随机数，比如10以内的随机数，此时原先一样的key就变成不一样的了，比如(hello, 1) (hello, 1) (hello, 1) (hello, 1)，就会变成(1_hello, 1) (1_hello, 1) (2_hello, 1) (2_hello, 1)。接着对打上随机数后的数据，执行reduceByKey等聚合操作，进行局部聚合，那么局部聚合结果，就会变成了(1_hello, 2) (2_hello, 2)。然后将各个key的前缀给去掉，就会变成(hello,2)(hello,2)，再次进行全局聚合操作，就可以得到最终结果了，比如(hello, 4)。\n\n**方案实现原理：**将原本相同的key通过附加随机前缀的方式，变成多个不同的key，就可以让原本被一个task处理的数据分散到多个task上去做局部聚合，进而解决单个task处理数据量过多的问题。接着去除掉随机前缀，再次进行全局聚合，就可以得到最终的结果。具体原理见下图。\n\n**方案优点：**对于聚合类的shuffle操作导致的数据倾斜，效果是非常不错的。通常都可以解决掉数据倾斜，或者至少是大幅度缓解数据倾斜，将Spark作业的性能提升数倍以上。\n\n**方案缺点：**仅仅适用于聚合类的shuffle操作，适用范围相对较窄。如果是join类的shuffle操作，还得用其他的解决方案。","source":"_posts/总-大数据.md","raw":"---\ntitle: 大数据\ndate: 2019-08-09 20:32:59\npassword: 123\nabstract: 欢迎来到test, 请输入密码.\nmessage: 欢迎来到test, 请输入密码.\ntoc: false\nmathjax: false\ntags:  [汇总] \ncategory: 汇总\n---\n\n# scala\n\n## 一.scala的maven在IDE中的搭建\n\n1.开始创建项目体系结构\nFile --> Project \n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904175253.png)\n\n\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904175319.png)\n\n![](https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904175417.png)\n\n\n\n\n![输入图片说明](https://static.oschina.net/uploads/img/201802/11153427_h2XW.png \"在这里输入图片标题\")\n\n2.修改pom.xml\n\n```\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\">\n  <modelVersion>4.0.0</modelVersion>\n  <groupId>scala_maven</groupId>\n  <artifactId>com.chen</artifactId>\n  <version>1.0-SNAPSHOT</version>\n  <inceptionYear>2008</inceptionYear>\n  <properties>\n    <scala.version>2.11.7</scala.version>\n  </properties>\n\n  <dependencies>\n    <dependency>\n      <groupId>org.scala-lang</groupId>\n      <artifactId>scala-library</artifactId>\n      <version>${scala.version}</version>\n    </dependency>\n\n    <dependency>\n      <groupId>com.typesafe.akka</groupId>\n      <artifactId>akka-actor_2.11</artifactId>\n      <version>2.5.3</version>\n    </dependency>\n    <dependency>\n      <groupId>org.specs</groupId>\n      <artifactId>specs</artifactId>\n      <version>1.2.5</version>\n      <scope>test</scope>\n    </dependency>\n  </dependencies>\n\n  <build>\n    <sourceDirectory>src/main/scala</sourceDirectory>\n    <testSourceDirectory>src/test/scala</testSourceDirectory>\n    <plugins>\n      <plugin>\n        <groupId>org.scala-tools</groupId>\n        <artifactId>maven-scala-plugin</artifactId>\n        <executions>\n          <execution>\n            <goals>\n              <goal>compile</goal>\n              <goal>testCompile</goal>\n            </goals>\n          </execution>\n        </executions>\n        <configuration>\n          <scalaVersion>${scala.version}</scalaVersion>\n          <args>\n            <arg>-target:jvm-1.5</arg>\n          </args>\n        </configuration>\n      </plugin>\n      <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-eclipse-plugin</artifactId>\n        <configuration>\n          <downloadSources>true</downloadSources>\n          <buildcommands>\n            <buildcommand>ch.epfl.lamp.sdt.core.scalabuilder</buildcommand>\n          </buildcommands>\n          <additionalProjectnatures>\n            <projectnature>ch.epfl.lamp.sdt.core.scalanature</projectnature>\n          </additionalProjectnatures>\n          <classpathContainers>\n            <classpathContainer>org.eclipse.jdt.launching.JRE_CONTAINER</classpathContainer>\n            <classpathContainer>ch.epfl.lamp.sdt.launching.SCALA_CONTAINER</classpathContainer>\n          </classpathContainers>\n        </configuration>\n      </plugin>\n    </plugins>\n  </build>\n  <reporting>\n    <plugins>\n      <plugin>\n        <groupId>org.scala-tools</groupId>\n        <artifactId>maven-scala-plugin</artifactId>\n        <configuration>\n          <scalaVersion>${scala.version}</scalaVersion>\n        </configuration>\n      </plugin>\n    </plugins>\n  </reporting>\n</project>\n\n```\n\n> **注意：如果有akka-actor的话  要和scala的版本相对应**\n>\n\n![](https://static.oschina.net/uploads/space/2018/0211/155017_Suab_3005534.png)\n\n\n\n\n\n## 二.scala的单词拆分\n\n```\nvar word=Array(\"hello tom hello jelly\",\"tom jelly\",\"hello world hello tom\",\"hello jelly\",\"hello tom\")\nvar b=word.flatMap(_.split(\" \")).map((_,1)).groupBy(_._1).map(m=>(m._1,m._2.map(x=>x._2).sum)).toArray\nb.sortWith(_._2 > _._2).toMap\nres33: scala.collection.immutable.Map[String,Int] = Map(hello -> 6, tom -> 4, jelly -> 3, world -> 1)\n```\n\n或者\n```\nscala> b.toSeq.sortWith(_._2>_._2).toMap\nres32: scala.collection.immutable.Map[String,Int] = Map(hello -> 6, tom -> 4, jelly -> 3, world -> 1)\n```\n\n扩展：\n```\na=Map()//数据清空使用再次new\nprintln(a.size)\na.toSeq.sortBy(_._1)//升序排序 key\na.toSeq.sortBy(_._2)//升序排序 value\na.toSeq.sortWith(_._1>_._1) //降序排序 key\na.toSeq.sortWith(_._2>_._2) //降序排序 value\n```\n\n```\nscala> var word=Array(\"hello tom hello jelly\",\"tom jelly\",\"hello world hello tom\",\"hello jelly\",\"hello tom\")\n\nscala> word.flatMap(_.split(\" \"))  //将数组中每个元素，按照空格切分并且扁平化\nres34: Array[String] = Array(hello, tom, hello, jelly, tom, jelly, hello, world, hello, tom, hello, jelly, hello, tom)\n\nscala> word.flatMap(_.split(\" \")).map((_,1))  //将数组中每个单词，转成元组，并标记1\nres35: Array[(String, Int)] = Array((hello,1), (tom,1), (hello,1), (jelly,1), (tom,1), (jelly,1), (hello,1), (world,1), (hello,1), (tom,1), (hello,1), (jelly,1), (hello,1), (tom,1))\n\nscala> word.flatMap(_.split(\" \")).map((_,1)).groupBy(_._1)//将元组的数组中按照元组的第一个元素排序\nres36: scala.collection.immutable.Map[String,Array[(String, Int)]] = Map(world -> Array((world,1)), tom -> Array((tom,1), (tom,1), (tom,1), (tom,1)), hello -> Array((hello,1), (hello,1), (hello,1), (hello,1), (hello,1), (hello,1)), jelly -> Array((jelly,1), (jelly,1), (jelly,1)))\n\nscala> word.flatMap(_.split(\" \")).map((_,1)).groupBy(_._1).map(m=>(m._1,m._2.map(x=>x._2).sum)) //将排序后的元组进行数值求和\nres37: scala.collection.immutable.Map[String,Int] = Map(world -> 1, tom -> 4, hello -> 6, jelly -> 3)\n\nscala> word.flatMap(_.split(\" \")).map((_,1)).groupBy(_._1).map(m=>(m._1,m._2.map(x=>x._2).sum)).toArray\n//将排序求和后的map转化成元组方便排序\nres38: Array[(String, Int)] = Array((world,1), (tom,4), (hello,6), (jelly,3))\n\nscala> word.flatMap(_.split(\" \")).map((_,1)).groupBy(_._1).map(m=>(m._1,m._2.map(x=>x._2).sum)).toArray.sortWith(_._2 > _._2) //将排序求和后的map转化成元组排序\nres39: Array[(String, Int)] = Array((hello,6), (tom,4), (jelly,3), (world,1))\n\nscala> word.flatMap(_.split(\" \")).map((_,1)).groupBy(_._1).map(m=>(m._1,m._2.map(x=>x._2).sum)).toArray.sortWith(_._2 > _._2).toMap //转化回来map\nres40: scala.collection.immutable.Map[String,Int] = Map(hello -> 6, tom -> 4, jelly -> 3, world -> 1)\n\n\n\n```\n\n##  三.数组常见方法汇总\n\n**array学习笔记**\n\n数组要点\n1.若长度固定则使用Array，若长度可能有变化则使用ArrayBuffer\n2.提供初始值时不要使用new\n3.用()来访问元素\n4.用for(elem <- arr) 来遍历元素\n5.用for(elem <- array if ...) ... yield 来将原数组转型为新数组\n6.Scala数组和Java数组可以互操作，用ArrayBuffer，使用scala.collection.JavaConversions中的转换函数。\n定长数组 如果数组长度不变，则可使用scala中的Array，例如：\n\n```\nval nums = new Array[Int](10)    //10个整数的数组，所有元素初始化为0\nval string = new Array[String](10) //10个元素的字符串数组，所有元素被初始化为null\nval s = Array(\"hello\",\"scala\")  //长度为2的Array[String]——类型是推断出来的。已提供初始值，不需要new\n```\n变长数组\n对于那种长度按需要变化的数组，Java有ArrayList，C++有vector。Scalable中有等效的数据结构为：ArrayBuffer\n```\nimport scala.collection.mutable.ArrayBuffer\nval b = ArrayBuffer[Int]()\n//或者new ArrayBuffer[Int]\n//一个空的数组缓冲，准备存放整数\nb += 1   //ArrayBuffer(1),用+=在尾部添加元素\nb += (1,2,3,4)     //在尾部添加多个元素\n \nb ++= Array(8,12,13)   //可以用++=操作符追加任何集合\nb.trimEnd(5)  //移除最后5个元素\n\n//在任意 位置添加元素\nb.insert(2,6)   //在下标2之前插入\nb.insert(2,6,7,8)   //在下标2之前插入6,7,8\n\nb.remove(2)   //移除下标为2的位置开始移除元素\nb.remove(2,3)  //从下标为2开始移除3个元素；第二个参数是表示移除元素的个数\n```\n在使用时，有时不确定数组需要装元素的个数。此时，可以先构建一个数组缓冲，然后调用\n```\nb.toArray   //将缓冲数组转换为定长数组\n```\n定长数组也可以转换为缓冲数组\n```\na.toBuffer\n```\n遍历数组和数组缓冲\n\n使用for循环遍历数组和数组缓冲\n使用下标的方式\n```\nfor (i <- 0 until a.length){\n    println( i + \":\" + a(i))\n}\n```\nuntil用法扩展：这只步长--> 0 until (a.length,2)  从数组尾部开始-->(0 until a.length).reverse\n不使用下标访问数组元素\n```\nfor (elem <- arrName) {println(elem)}\n```\n数组转换\n```\nval a = Array(2,3,4)\nval result = for (elem <- a) yield 2 * elem\nfor (elem <-  a if elem %2==0) yield 2 * elem\n```\n常用算法\n```\nsum: Array(1,2,3).sum\nmax/min : Array(1,2,3).max/min\nsorted : Array(1,2,3).sorted(_ < ) ; Array(1,2,3).sorted( > _) //不能对缓冲数组排序\nquickSort方法排序：scala.util.Sorting.quickSort(a)\n显示数组内容：mkString; a.mkString(\" and \") //可以设置分隔符\n```\n\n1、定长数组定义：\n```\n//定义一个长度为10的数值数组\nscala> val numberArray = new Array[int](10)\nnumberArray:Array[Int] = Array(0,0,0,0,0,0,0,0,0,0)\n//定义一个长度为10的String类数组\nscala> val strArray = new Array[String](10)\nstrArray:Array[String] = Array(null, null, null, null, null, null, null, null, null, null)\n\n//由上可以看出，复杂对象类型在数组定义时被初始化为null，数值型呗初始化为0，并且上面复杂类型定义的时候必须加new，否则会报错\n\n//提供初始值的定义数组\nscala> val strArray2 = Array(\"First\", \"Second\")  //这里说明已提供初始值就不需要new\nstrArray2:Array[String] = Array(First, Second)\n\nscala> strArray2(0) = \"Goodbye\"\nstrArray2:Array[String] = Array(Goodbye, Second)\n\n```\n2、变长数组定义\n\n```\n对于长度需要变化的数组，Java有ArrayList,C++有vector。Scala中的等效数据结构为ArrayBuffer\n\n//导入可变包，Scala中的可变集合都是放在mutable中，使用时要导入\nscala> import scala.collection.mutable.ArrayBuffer\nimport scala.collection.mutable.ArrayBuffer\n\nscala> val arrayBuffer = ArrayBuffer[Int]()\narrayBuffer: scala.collection.mutable.ArrayBuffer[Int] = ArrayBuffer()\n\n//在尾部添加一个值\nscala> arrayBuffer += 1\nres17: arrayBuffer.type = ArrayBuffer(1)\n\n//在尾部添加多个元素\nscala> arrayBuffer += (2, 3, 4, 5)\nres19: arrayBuffer.type = ArrayBuffer(1, 2, 3, 4, 5)\n\n//在尾部添加一个集合\nscala> arrayBuffer ++= Array(6, 7, 8, 9)\nres20: arrayBuffer.type = ArrayBuffer(1, 2, 3, 4, 5, 6, 7, 8, 9)\n\n//移除最后2个元素\nscala> arrayBuffer.trimEnd(2)\n\n//在开头移除1一个元素\nscala> arrayBuffer.trimStart(2)\n\nscala> arrayBuffer\nres23: scala.collection.mutable.ArrayBuffer[Int] = ArrayBuffer(2, 3, 4, 5, 6, 7)\n\n\n//在任意位置插入或者删除元素\nscala> arrayBuffer.insert(2, 6)\n//ArrayBuffer(2, 3, 6, 4, 5, 6, 7)\n\nscala> arrayBuffer.insert(1, 2, 3, 4)\n//ArrayBuffer(2, 1, 2, 3, 4, 3, 6, 4, 5, 6, 7)\n\nscala> arrayBuffer.remove(2)\n//ArrayBuffer(2, 1, 3, 4, 3, 6, 4, 5, 6, 7)\n\nscala> arrayBuffer.remover(1, 8)\n//ArrayBuffer(2, 7)\n\n```\n3、变长数组和定长数组转换\n\n```\n//变长转换长定长\nscala > arrayBuffer.toArray\n//Array(2, 7)\n\n//定长转换成变长\nscala>res7.toBuffer\n//ArrayBuffer(2, 7)\n\n```\n4、遍历定长和变长数组\n\n```\nfor(i <- 0 until.arrayBuffer.length)\n    println(i + \": \" + a(i))\n0 until.arrayBuffer.length实际上是一个方法调用，返回的是一个区间Range： 0.until(arrayBuffer.length)\nfor(i <- 区间)会让变量i遍历该区间的所有值\n如果想要在区间中步长不为1，则：0 until (arrayBuffer.length, 2)\n如果想要数组从尾端开始，则遍历的写法为:(0 until (arrayBuffer.length, 2)).reverse\n\nScala也提供了一个和Java增强for循环类似的for\n\n//增强for\nfor(i <- arrayBuffer)\n    println(i + \": \" + a(i))\n\n```\n5、数组转换\n\n在《Scala入门学习笔记二-基本数据类型、程序控制结构》提到在for循环推导式，可以利用原来的数组产生一个新的数组。\n```\nscala> val a = Array(2, 3, 5, 7, 11)\na: Array[Int] = Array(2, 3, 5, 7, 11)\n//这里产生了一个新的数组，原来的数组也在\nscala> val result = for(elem <- a) yield 2 * elem\nresult: Array[Int] = Array(4, 6, 10, 14, 22)\n如果for中使用的是定长数组，则for(...)...yield之后得到的是定长数组;如果使用的是变长数组，则会得到变长数组\n\nScala也提供了另外一种做法\nscala> a.filter(_ % 2 == 0).map(2 * _)\n\n甚至\nscala>a.filter(_ % 2 == 0).map{2 * _}\n例子：\n给定一个整数的缓冲数组，我们想要移除第一个负数之外的所有负数。有几种做法\n\n//第一种做法：\nvar first = true\nvar n = a.length\nvar i = 0\nwhile(i < n){\n    if(a(i) > 0) i += 1\n    else{\n        if(first) {first = false; i += 1}\n        else {a.remove(i); n-= 1}\n    }\n}\n\n//第二种做法：\n//首先使用一个新数组用于记录满足条件的数组的下标\nval first = true\nval indexes = for(i <- 0 until a.length if first || a(i) > 0) yield {\n    if(a(i) < 0) first = false; i\n}\n//然后将元素移动到该去的位置，截断尾端\nfor(j <- o until indexes.length) a(j) = a(indexes(j))\na.trimEnd(a.length-indexes.length)\n```\n6、常用算法\nScala针对数组提供了一个常用的函数\n```\n//定义一个整型数组\nscala> val intArr=Array(1,2,3,4,5,6,7,8,9,10)\nintArr: Array[Int] = Array(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n\n//求和\nscala> intArr.sum\nres87: Int = 55\n\n//求最大值\nscala> intArr.max\nres88: Int = 10\n\nscala> ArrayBuffer(\"Hello\",\"Hell\",\"Hey\",\"Happy\").max\nres90: String = Hey\n\n//求最小值\nscala> intArr.min\nres89: Int = 1\n\n//排序\n//sorted方法将数组或数组缓冲排序并返回经过排序的数组或数组缓冲，原始数组被保留\nscala>val b = ArrayBuffer(1, 7, 2, 9)\nb:ArrayBuffer[Int] = ArrayBuffer(1, 7, 2, 9)\nscala>val bSorted = b.sorted(_<_) \nbSorted: ArrayBuffer[Int] = ArrayBuffer(1, 2, 7, 9)\n\n//toString()方法\nscala> intArr.toString()\nres94: String = [I@141aba8\n\n//mkString()方法\nscala> intArr.mkString(\",\")\nres96: String = 1,2,3,4,5,6,7,8,9,10\n\nscala> intArr.mkString(\"<\",\",\",\">\")\nres97: String = <1,2,3,4,5,6,7,8,9,10>\n```\n7、ArrayBuffer Scaladoc解析\n```\n初学者在查看sacaladoc时常常会感到困惑，不用担心，随着学习的深入，api文档中的内容将逐渐清晰\n下面给出两个示例：\n++=方法传入的参数类型是TraversableOnce Trait的子类，它返回的是更新好的ArrayBuffer\n\n++=方法解析\n\ndropWhile传入的是一个函数，该函数返回值是布尔类型，dropWhile反回的是操作后的ArrayBuffer\n\ndropWith方法解析\n```\n8、多维数组\n和Java一样，多维数组是通过数组的数组来实现的。\n```\n//第一种构造方式\nval metrix = Array.ofDim[Double](3, 4) //3行 4列\n\n//访问其中的元素\nmetrix(row)(column)  =42\n\n//可以创建不规则的数组，每一行的长度不相同\nval triangle = new Array[Array[Int]](10)\nfor(i <- 0 until triangle.length)\n    trianglr(i) = new Array[Int](i+1)\n\n//在创建的时候赋值\nscala> val metrix = Array(Array(1, 2, 3), Array(2.3, 3.4), Array(\"asdf\", \"asdfas\"))\nmetrix: Array[Array[_ >: String with Double with Int]] = Array(Array(1, 2, 3), Array(2.3, 3.4), Arra\ny(asdf, asdfas))\n\n//打印输出数组\nscala> for(i <- metrix) println(i.mkString(\" \"))\n1 2 3\n2.3 3.4\nasdf asdfas\n\n//输出二维数组的每个值\nscala> for(i <- metrix; from = i; j <- from) println(j)\n1\n2\n3\n2.3\n3.4\nasdf\nasdfas\n```\n\n## 四.数组操作(二)\n\nScala数组操作：\n\n1.定长数组\n 长度不变的数组的声明：\n\n```\n//长度为10的整数数组，所有元素初始化为0\n val numArr = new Array[Int](10)\n\n//长度为10的字符串数组，所有元素初始化为null\nval numArr = new Array[String](10)\n\n//长度为2的数组，数据类型自动推断出来，已经提供初始值就不需要new关键字\nval s = Array(\"cai\",\"yong\")\n\n//通过ArrayName(index)访问数组元素和更改数组元素\nval s = Array(\"cai\",\"yong\")\n println(s(0))\ns(0) = \"haha\"\nprintln(s(0))\n输出：\n cai\n haha\n\n```\n2.变长数组：数组缓冲\n Scala也支持长度变化的数组，支持的数据结构是ArrayBuffer\n```\n//一个空的数组缓冲，准备存放整数\n val ab = ArrayBuffer[Int]()\n val ab2 = new ArrayBuffer[Int]\n\n//用+=在尾部添加元素\nab += 2\n\n//在尾部添加多个元素\nab += (1,2,3,4,5)\n\n//通过++=往数组缓冲后面追加集合\n ab ++= Array(6,7,8,9)\n\n//使用trimEnd(n)移除尾部n个元素\nab.trimEnd(3)\n\n//在下标3之前插入元素\nab.insert(3, 33)\n\n//插入多个元素，第一个值为index，后面所有的值为要插入的值\nab.insert(3,3,4,5,6)\n\n//移除某个位置的元素\nab.remove(3)\n\n//移除从下标为n开始（包括n）的count个元素\nab.remove(n, count)\n```\n 有时候需要构造一个Array，但是不知道具体要存放多少元素，可以先构造ArrayBuffer,再调用toArray方法转化成Array，同样，对Array调用toBuffer方法可以转成ArrayBuffer.\n\n 注：在数组缓冲的尾部进行元素添加移除操作的效率很高，但是在任意位置插入或移除元素的效率并不太高效，因为涉及到数组元素的移动。\n\n3.遍历数组\n```\n//for循环遍历\nfor(i <- 0 until ab.length){\n print(ab(i) + \", \")\n }\n\n//根据特定步长遍历数组\nfor(i <- 0 until (ab.length, 2)){\n print(ab(i) + \", \")\n }\n\n//从数组的尾部开始向前遍历数组\nfor(i <- (0 until ab.length).reverse){\n print(ab(i) + \", \")\n}\n\n//类似于Java中的foreach遍历数组\n for(elem <- ab){\n print(elem + \", \")\n}\n```\n\n4.数组转换\n```\n//进行数组转换会生成一个新的数组，而不会修改原始数组\n val change = for(elem <- ab) yield elem * 2\nfor(elem <- change){\nprint(elem + \", \")\n }\n\n//添加一个守卫的数组转换\nval change = for(elem <- ab if elem%2 == 0) yield elem * 2\n```\n5.数组操作常用算法\n```\n//sum求和(数组与阿奴必须是数值型数据)\nprintln(change.sum)\n\n//min max 输出数组中最小和最大元素\nprintln(change.min)\nprintln(change.max)\n\n//使用sorted方法对数组或数组缓冲进行升序排序，这个过程不会修改原始数组\n val sortArr = ab.sorted \n for(elem <- sortArr)\n print(elem + \", \")\n\n//使用比较函数sortWith进行排序\nval sortArr = ab.sortWith(_>_)\n\n//数组显示\n println(sortArr.mkString(\"|\"))\n println(sortArr.mkString(\"startFlag\",\"|\",\"endFlag\"))\n```\n6.多维数组\n```\n//构造一个2行3列的数组\nval arr = Array.ofDim[Int](2,3)\nprintln(arr.length)\nprintln(arr(0).length)\narr(0)(0) = 20\nprintln(arr(0)(0))\n\n//创建长度不规则的数组\nval arr = new Array[Array[Int]](3)\n      \n for(i <- 0 until arr.length){\narr(i) = new Array[Int](i + 2)\n}\n      \nfor(i <- 0 until arr.length){\nprintln(arr(i).length)\n}\n```\n\n## 五.Tuple常见方法汇总\n\n```\ntuple的定义\n\n对偶是元组(tuple)的最简单形态——元组是不同类型的值的聚集。\n元组的值是通过将单个值包含在圆括号中构成。Example：（1，1.3415，“Fred”)\ntuple的访问\n\n可以通过_1,_2,_3访问元组的元素\nval first = tuple._1 //元组的位置从1开始，而非从0开始\n```\n与列表一样，元组也是不可变的，但与列表不同的是元组可以包含不同类型的元素。\n元组的值是通过将单个的值包含在圆括号中构成的。例如：\n```\nval t = (1, 3.14, \"Fred\")  \n```\n以上实例在元组中定义了三个元素，对应的类型分别为[Int, Double, java.lang.String]。\n此外我们也可以使用以上方式来定义：\n```\nval t = new Tuple3(1, 3.14, \"Fred\")\n```\n元组的实际类型取决于它的元素的类型，比如 (99, \"runoob\") 是 Tuple2[Int, String]。 ('u', 'r', \"the\", 1, 4, \"me\") 为 Tuple6[Char, Char, String, Int, Int, String]。\n目前 Scala 支持的元组最大长度为 22。对于更大长度你可以使用集合，或者扩展元组。\n访问元组的元素可以通过数字索引，如下一个元组：\n```\nval t = (4,3,2,1)\nval sum = t._1 + t._2 + t._3 + t._4\nprintln( \"元素之和为: \"  + sum )//10\n```\n迭代元组\n```\nval t = (4,3,2,1)\nt.productIterator.foreach{ i =>println(\"Value = \" + i )}\nValue = 4\nValue = 3\nValue = 2\nValue = 1\n```\n元组转为字符串\n你可以使用 Tuple.toString() 方法将元组的所有元素组合成一个字符串，实例如下：\n```\nval t = new Tuple3(1, \"hello\", Console)\nprintln(\"连接后的字符串为: \" + t.toString() )\n连接后的字符串为: (1,hello,scala.Console$@4dd8dc3)\n```\n\n\n\n## 六.List常见方法汇总\n\nList的4种操作符的区别和联\n\n(1):+和+: 两者的区别在于:+方法用于在尾部追加元素，+:方法用于在头部追加元素，和::很类似，但是::可以用于pattern match ，而+:则不行. 关于+:和:+,只要记住冒号永远靠近集合类型就OK了。\n```\nscala> a\nres23: List[Int] = List(1, 2, 3, 4)\n\nscala> var b=a:+9\nb: List[Int] = List(1, 2, 3, 4, 9)\n\nscala> var c=9:+a\n<console>:15: error: value :+ is not a member of Int\n       var c=9:+a\n              ^\nscala> var c=9+:a\nc: List[Int] = List(9, 1, 2, 3, 4)\n\nscala> var r1=\"A\"+:\"B\"+:Nil\nr1: List[String] = List(A, B)\n\nscala>var r2=Nil:+\"A\":+\"B\"\nr2: List[String] = List(A, B)\n```\n(2):: 该方法被称为cons，意为构造，向队列的头部追加数据，创造新的列表。用法为 x::list,其中x为加入到头部的元素，无论x是列表与否，它都只将成为新生成列表的第一个元素，也就是说新生成的列表长度为list的长度＋1(btw, x::list等价于list.::(x))\n```\nscala>\"A\"::\"B\"::Nil\nres0: List[String] = List(A, B)\n\nscala>List(\"A\",\"B\")::List(\"C\",\"D\")\nres1: List[java.io.Serializable] = List(List(A, B), C, D)\n```\n(3) ++ 该方法用于连接两个集合，list1++list2\n```\nscala>List(\"A\",\"B\") ++ List(\"C\",\"D\")\nres2: List[String] = List(A, B, C, D)\n```\n(4)::: 该方法只能用于连接两个List类型的集合\n```\nscala>List(\"A\",\"B\") ::: List(\"C\",\"D\")\nres3: List[String] = List(A, B, C, D)\n```\n**List常用用法**\n\n1）List类型定义以及List的特点：\n```\n//字符串类型List\nscala> val fruit=List(\"Apple\",\"Banana\",\"Orange\")\nfruit: List[String] = List(Apple, Banana, Orange)\n\n//前一个语句与下面语句等同\nscala> val fruit=List.apply(\"Apple\",\"Banana\",\"Orange\")\nfruit: List[String] = List(Apple, Banana, Orange)\n\n//数值类型List\nscala> val nums=List(1,2,3,4,5)\nnums: List[Int] = List(1, 2, 3, 4, 5)\n\n//多重List，List的子元素为List\nscala> val list = List(List(1, 2, 3), List(\"adfa\", \"asdfa\", \"asdf\"))\nlist: List[List[Any]] = List(List(1, 2, 3), List(adfa, asdfa, asdf))\n\n//遍历List\nscala> for(i <- list; from=i; j<-from)println(j)\n1\n2\n3\nadfa\nasdfa\nasdf\n```\n（2）List与Array的区别：\n```\n1、List一旦创建，已有元素的值不能改变，可以使用添加元素或删除元素生成一个新的集合返回。\n如前面的nums，改变其值的话，编译器就会报错。而Array就可以成功\n\nscala>nums(3)=4\n<console>:10: error: value update is not a member of List[Int]\n              nums(3)=4\n              ^\n2、List具有递归结构(Recursive Structure),例如链表结构\nList类型和气他类型集合一样，它具有协变性(Covariant),即对于类型S和T，如果S是T的子类型，则List[S]也是List[T]的子类型。\n例如:\n\nscala>var listStr:List[Object] = List(\"This\", \"Is\", \"Covariant\", \"Example\")\nlistStr:List[Object] = List(This, Is, Covariant, Example)\n\n//空的List,其类行为Nothing,Nothing在Scala的继承层次中的最底层\n//,即Nothing是任何Scala其它类型如String,Object等的子类\nscala> var listStr = List()\nlistStr:List[Nothing] = List()\n\nscala>var listStr:List[String] = List()\nlistStr:List[String] = List()\n```\n（3）List常用构造方法\n```\n//1、常用::及Nil进行列表构建\nscala> val nums = 1 :: (2:: (3:: (4 :: Nil)))\nnums: List[Int] = List(1, 2, 3, 4)\n\n\n//由于::操作符的优先级是从右向左的，因此上一条语句等同于下面这条语句\nscala> val nums = 1::2::3::4::Nil\nnums:List[Int] = List(1, 2, 3, 4)\n至于::操作符的使用将在下面介绍\n```\n（4）List常用操作\n```\n//判断是否为空\nscala> nums.isEmpty\nres5: Boolean = false\n\n//取第一个元素\nscala> nums.head\nres6: Int = 1\n\n//取列表第二个元素\nscala>nums.tail.head\nres7: Int = 2\n\n//取第三个元素\nscala>nums.tail.tail.head\nres8: Int = 3\n\n//插入操作\n//在第二个位置插入一个元素\nscala>nums.head::(3::nums.tail)\nres11: List[Int] = List(1, 3, 2, 3, 4)\n\nscala> nums.head::(nums.tail.head::(4::nums.tail.tail))\nres12: List[Int] = List(1, 2, 4, 3, 4)\n\n//插入排序算法实现\ndef isort(xs: List[Int]):List[Int] = {\n    if(xs.isEmpty) Nil\n    else insert(xs.head, issort(xs.tail))\n}\n\ndef insert(x:Int, xs:List[Int]):List[Int] = {\n    if(xs.isEmpty || x <= xs.head) x::xs\n    else xs.head :: insert(x, xs.tail)\n}\n\n//连接操作\nscala>List(1, 2, 3):::List(4, 5, 6)\nres13: List[Int] = List(1, 2, 3, 4, 5, 6)\n\n//去除最后一个元素外的元素，返回的是列表\nscala> nums.init\nres13: List[Int] = List(1, 2, 3)\n\n//取出列表最后一个元素\nscala>nums.last\nres14: Int = 4\n\n//列表元素倒置\nscala> nums.reverse\nres15: List[Int] = List(4, 3, 2, 1)\n\n//一些好玩的方法调用\nscala> nums.reverse.reverse == nums\n\n\n//丢弃前面n个元素\nscala>nums drop 3\nres16: List[Int] = List(4)\n\n//获取前面n个元素\nscala>nums take 1\nres17: List[Int] = List[1]\n\n//将列表进行分割\nscala> nums.splitAt(2)\nres18: (List[Int], List[Int]) = (List(1, 2),List(3, 4))\n\n//前一个操作与下列语句等同\nscala> (nums.take(2),nums.drop(2))\nres19: (List[Int], List[Int]) = (List(1, 2),List(3, 4))\n\n//Zip操作\nscala> val nums=List(1,2,3,4)\nnums: List[Int] = List(1, 2, 3, 4)\n\nscala> val chars=List('1','2','3','4')\nchars: List[Char] = List(1, 2, 3, 4)\n\n//返回的是List类型的元组(Tuple），返回的元素个数与最小的List集合的元素个数一样\nscala> nums zip chars\nres20: List[(Int, Char)] = List((1,1), (2,2), (3,3), (4,4))\n\n//List toString方法\nscala> nums.toString\nres21: String = List(1, 2, 3, 4)\n\n//List mkString方法\nscala> nums.mkString\nres22: String = 1234\n\n//转换成数组\nscala> nums.toArray\nres23: Array[Int] = Array(1, 2, 3, 4)\n```\n（5）List伴生对象方法\n```\n//apply方法\nscala>  List.apply(1, 2, 3)\nres24: List[Int] = List(1, 2, 3)\n\n//range方法，构建某一值范围内的List\nscala>  List.range(2, 6)\nres25: List[Int] = List(2, 3, 4, 5)\n\n//步长为2\nscala>  List.range(2, 6,2)\nres26: List[Int] = List(2, 4)\n\n//步长为-1\nscala>  List.range(2, 6,-1)\nres27: List[Int] = List()\n\nscala>  List.range(6,2 ,-1)\nres28: List[Int] = List(6, 5, 4, 3)\n\n//构建相同元素的List\nscala> List.make(5, \"hey\")\nres29: List[String] = List(hey, hey, hey, hey, hey)\n\n//unzip方法\nscala> List.unzip(res20)\nres30: (List[Int], List[Char]) = (List(1, 2, 3, 4),List(1, 2, 3, 4))\n\n//list.flatten，将列表平滑成第一个无素\nscala> val xss =\n     | List(List('a', 'b'), List('c'), List('d', 'e'))\nxss: List[List[Char]] = List(List(a, b), List(c), List(d, e))\nscala> xss.flatten\nres31: List[Char] = List(a, b, c, d, e)\n\n//列表连接\nscala> List.concat(List('a', 'b'), List('c'))\nres32: List[Char] = List(a\n, b, c)\n```\n（6）::和:::操作符介绍\n```\nList中常用'::',发音为\"cons\"。Cons把一个新元素组合到已有元素的最前端，然后返回结果List。\n\nscala> val twoThree = List(2, 3)\nscala> val oneTwoThree = 1 :: twoThree\nscala> oneTwoThree\noneTwoThree: List[Int] = List(1, 2, 3)\n上面表达式\"1::twoThree\"中，::是右操作数，列表twoThree的方法。可能会有疑惑。表达式怎么是右边参数的方法，这是Scala语言的一个例外的情况:如果一个方法操作符标注，如a * b,那么方法被左操作数调用，就像a.* (b)--除非方法名以冒号结尾。这种情况下，方法被右操作数调用。\nList有个方法叫\":::\"，用于实现叠加两个列表。\n\nscala> val one = List('A', 'B')\nval one = List('A', 'B')\nscala> val two = List('C', 'D')\n\nscala> one:::two\nres1: List[Char] = List(A, B, C, D)\n```\n创建列表\n```\nscala> val days = List(\"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\")\ndays: List[String] = List(Sunday, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday)\n```\n创建空列表\n```\nscala> val l = Nil //scala.collection.immutable.Nil继承了List[Nothing]  这是空列表\nl: scala.collection.immutable.Nil.type = List()\n\nscala> val l = List()\nl: List[Nothing] = List()\n```\n用字符串创建列表\n```\nscala> val l = \"Hello\" :: \"Hi\" :: \"Hah\" :: \"WOW\" :: \"WOOW\" :: Nil\nl: List[String] = List(Hello, Hi, Hah, WOW, WOOW)\n```\n用“:::”叠加创建新列表\n```\nscala> val wow = l ::: List(\"WOOOW\", \"WOOOOW\")\nwow: List[String] = List(Hello, Hi, Hah, WOW, WOOW, WOOOW, WOOOOW)\n```\n通过索引获取列表值\n```\nscala> l(3)\nres0: String = WOW\n```\n获取值长度为3的元素数目\n```\nscala> l.count(s => s.length == 3)\nres1: Int = 2\n```\n返回去掉l头两个元素的新列表\n```\nscala> l.drop(2)\nres2: List[String] = List(Hah, WOW, WOOW)\n\nscala> l\nres3: List[String] = List(Hello, Hi, Hah, WOW, WOOW)\n```\n返回去掉l后两个元素的新列表\n```\nscala> l.dropRight(2)\nres5: List[String] = List(Hello, Hi, Hah)\n\nscala> l\nres6: List[String] = List(Hello, Hi, Hah, WOW, WOOW)\n```\n判断l是否存在某个元素\n```\nscala> l.exists(s => s == \"Hah\")\nres7: Boolean = true\n```\n滤出长度为3的元素\n```\nscala> l.filter(s => s.length == 3)\nres8: List[String] = List(Hah, WOW)\n```\n判断所有元素是否以“H”打头\n```\nscala> l.forall(s => s.startsWith(\"H\"))\nres10: Boolean = false\n```\n判断所有元素是否以“H”结尾\n```\nscala> l.forall(s => s.endsWith(\"W\"))\nres11: Boolean = false\n```\n打印每个元素\n```\nscala> l.foreach(s => print(s + ' '))\nHello Hi Hah WOW WOOW\n```\n取出第一个元素\n```\nscala> l.head\nres17: String = Hello\n```\n取出最后一个元素\n```\nscala> l.last\nres20: String = WOOW\n```\n剔除最后一个元素，生成新列表\n```\nscala> l.init\nres18: List[String] = List(Hello, Hi, Hah, WOW)\n```\n剔除第一个元素，生成新列表\n```\nscala> l.tail\nres49: List[String] = List(Hi, Hah, WOW, WOOW)\n```\n判断列表是否为空\n```\nscala> l.isEmpty\nres19: Boolean = false\n```\n获得列表长度\n```\nscala> l.length\nres21: Int = 5\n```\n修改每个元素，再反转每个元素形成新列表\n```\nscala> l.map(s => {val s1 = s + \" - 01\"; s1.reverse})\nres29: List[String] = List(10 - olleH, 10 - iH, 10 - haH, 10 - WOW, 10 - WOOW)\n```\n生成用逗号隔开的字符串\n```\nscala> l.mkString(\", \")\nres30: String = Hello, Hi, Hah, WOW, WOOW\n```\n反序生成新列表\n```\nscala> l.reverse\nres41: List[String] = List(WOOW, WOW, Hah, Hi, Hello)\n```\n按字母递增排序\n```\nscala> l.sortWith(_.compareTo(_) < 0)\nres48: List[String] = List(Hah, Hello, Hi, WOOW, WOW)\n```\n\n**List定义的方法**\n\n```\ndef  ++[B >: A, That](that: GenTraversableOnce[B])(implicit bf: CanBuildFrom[List[A], B, That]): That\nReturns a new list containing the elements from the left hand operand followed by the elements from the right hand operand.\n```\n```\ndef  ++:[B >: A, That](that: collection.Traversable[B])(implicit bf: CanBuildFrom[List[A], B, That]): That\nAs with ++, returns a new collection containing the elements from the left operand followed by the elements from the right operand.\n```\n```\ndef  ++:[B](that: TraversableOnce[B]): List[B]\n[use case] As with ++, returns a new collection containing the elements from the left operand followed by the elements from the right operand.\n```\n```\ndef  +:(elem: A): List[A]\n[use case]\nA copy of the list with an element prepended.\n\nNote that :-ending operators are right associative (see example). A mnemonic for +: vs. :+ is: the COLon goes on the COLlection side.\n\nAlso, the original list is not modified, so you will want to capture the result.\n\nExample:\n\nscala> val x = List(1)\nx: List[Int] = List(1)\n\nscala> val y = 2 +: x\ny: List[Int] = List(2, 1)\n\nscala> println(x)\nList(1)\nelem\nthe prepended element\nreturns\na new list consisting of elem followed by all elements of this list.\n```\n```\ndef inition Classes\nList → SeqLike → GenSeqLike\n Full Signature\n```\n```\ndef  /:[B](z: B)(op: (B, A) ⇒ B): B\nApplies a binary operator to a start value and all elements of this traversable or iterator, going left to right.\n```\n```\ndef  :+(elem: A): List[A]\n[use case] A copy of this list with an element appended.\n```\n```\ndef  ::(x: A): List[A]\n[use case] Adds an element at the beginning of this list.\n```\n```\ndef  :::(prefix: List[A]): List[A]\n[use case] Adds the elements of a given list in front of this list.\n```\n```\ndef  :\\[B](z: B)(op: (A, B) ⇒ B): B\nApplies a binary operator to all elements of this traversable or iterator and a start value, going right to left.\n```\n```\ndef  addString(b: StringBuilder): StringBuilder\nAppends all elements of this traversable or iterator to a string builder.\n```\n```\ndef  addString(b: StringBuilder, sep: String): StringBuilder\nAppends all elements of this traversable or iterator to a string builder using a separator string.\n```\n```\ndef  addString(b: StringBuilder, start: String, sep: String, end: String): StringBuilder\nAppends all elements of this traversable or iterator to a string builder using start, end, and separator strings.\n```\n```\ndef  aggregate[B](z: ⇒ B)(seqop: (B, A) ⇒ B, combop: (B, B) ⇒ B): B\nAggregates the results of applying an operator to subsequent elements.\n```\n```\ndef  andThen[C](k: (A) ⇒ C): PartialFunction[Int, C]\nComposes this partial function with a transformation function that gets applied to results of this partial function.\n```\n```\ndef  apply(n: Int): A\nSelects an element by its index in the sequence.\n```\n```\ndef  applyOrElse[A1 <: Int, B1 >: A](x: A1, ```\n```\ndef ault: (A1) ⇒ B1): B1\nApplies this partial function to the given argument when it is contained in the function domain.\n```\n\n```\ndef  canEqual(that: Any): Boolean\nMethod called from equality methods, so that user-```\n```\ndef ined subclasses can refuse to be equal to other collections of the same kind.\nfinal ```\n```\ndef  collect[B](pf: PartialFunction[A, B]): List[B]\n[use case] Builds a new collection by applying a partial function to all elements of this list on which the function is ```\n```\ndef ined.\n```\n```\ndef  collectFirst[B](pf: PartialFunction[A, B]): Option[B]\nFinds the first element of the traversable or iterator for which the given partial function is ```\n```\ndef ined, and applies the partial function to it.\n```\n\n```\ndef  combinations(n: Int): Iterator[List[A]]\nIterates over combinations.\n```\n\n```\ndef  companion: GenericCompanion[List]\nThe factory companion object that builds instances of class List.\n```\n\n```\ndef  compose[A](g: (A) ⇒ Int): (A) ⇒ A\nComposes two instances of Function1 in a new Function1, with this function applied last.\n```\n\n```\ndef  contains[A1 >: A](elem: A1): Boolean\nTests whether this sequence contains a given value as an element.\n```\n\n```\ndef  containsSlice[B](that: GenSeq[B]): Boolean\nTests whether this sequence contains a given sequence as a slice.\n```\n\n```\ndef  copyToArray(xs: Array[A], start: Int, len: Int): Unit\n[use case] Copies the elements of this list to an array.\n```\n\n```\ndef  copyToArray(xs: Array[A]): Unit\n[use case] Copies the elements of this list to an array.\n```\n\n```\ndef  copyToArray(xs: Array[A], start: Int): Unit\n[use case] Copies the elements of this list to an array.\n```\n\n```\ndef  copyToBuffer[B >: A](dest: Buffer[B]): Unit\nCopies all elements of this traversable or iterator to a buffer.\nfinal ```\n```\ndef  corresponds[B](that: GenSeq[B])(p: (A, B) ⇒ Boolean): Boolean\nTests whether every element of this sequence relates to the corresponding element of another sequence by satisfying a test predicate.\n```\n```\ndef  count(p: (A) ⇒ Boolean): Int\nCounts the number of elements in the traversable or iterator which satisfy a predicate.\n```\n```\ndef  diff(that: collection.Seq[A]): List[A]\n[use case] Computes the multiset difference between this list and another sequence.\n```\n```\ndef  distinct: List[A]\nBuilds a new sequence from this sequence without any duplicate elements.\n```\n```\ndef  drop(n: Int): List[A]\nSelects all elements except first n ones.\n```\n```\ndef  dropRight(n: Int): List[A]\nSelects all elements except last n ones.\nfinal ```\n```\ndef  dropWhile(p: (A) ⇒ Boolean): List[A]\nDrops longest prefix of elements that satisfy a predicate.\n```\n\n```\ndef  endsWith[B](that: GenSeq[B]): Boolean\nTests whether this sequence ends with the given sequence.\n```\n\n```\ndef  equals(that: Any): Boolean\nThe equals method for arbitrary sequences.\n```\n\n```\ndef  exists(p: (A) ⇒ Boolean): Boolean\nTests whether a predicate holds for at least one element of this sequence.\n```\n\n```\ndef  filter(p: (A) ⇒ Boolean): List[A]\nSelects all elements of this traversable collection which satisfy a predicate.\n```\n\n```\ndef  filterNot(p: (A) ⇒ Boolean): List[A]\nSelects all elements of this traversable collection which do not satisfy a predicate.\n```\n\n```\ndef  find(p: (A) ⇒ Boolean): Option[A]\nFinds the first element of the sequence satisfying a predicate, if any.\nfinal ```\n```\ndef  flatMap[B](f: (A) ⇒ GenTraversableOnce[B]): List[B]\n[use case] Builds a new collection by applying a function to all elements of this list and using the elements of the resulting collections.\n```\n```\ndef  flatten[B]: List[B]\n[use case] Converts this list of traversable collections into a list formed by the elements of these traversable collections.\n```\n```\ndef  fold[A1 >: A](z: A1)(op: (A1, A1) ⇒ A1): A1\nFolds the elements of this traversable or iterator using the specified associative binary operator.\n```\n```\ndef  foldLeft[B](z: B)(op: (B, A) ⇒ B): B\nApplies a binary operator to a start value and all elements of this sequence, going left to right.\n```\n```\ndef  foldRight[B](z: B)(op: (A, B) ⇒ B): B\nApplies a binary operator to all elements of this list and a start value, going right to left.\n```\n```\ndef  forall(p: (A) ⇒ Boolean): Boolean\nTests whether a predicate holds for all elements of this sequence.\nfinal ```\n```\ndef  foreach(f: (A) ⇒ Unit): Unit\n[use case] Applies a function f to all elements of this list.\n```\n\n```\ndef  genericBuilder[B]: Builder[B, List[B]]\nThe generic builder that builds instances of Traversable at arbitrary element types.\n```\n\n```\ndef  groupBy[K](f: (A) ⇒ K): Map[K, List[A]]\nPartitions this traversable collection into a map of traversable collections according to some discriminator function.\n```\n\n```\ndef  grouped(size: Int): Iterator[List[A]]\nPartitions elements in fixed size iterable collections.\n```\n\n```\ndef  has```\n```\ndef initeSize: Boolean\nTests whether this traversable collection is known to have a finite size.\n```\n```\ndef  hashCode(): Int\nHashcodes for Seq produce a value from the hashcodes of all the elements of the sequence.\n```\n```\ndef  head: A\nSelects the first element of this iterable collection.\n```\n```\ndef  headOption: Option[A]\nOptionally selects the first element.\n```\n```\ndef  indexOf(elem: A, from: Int): Int\n[use case] Finds index of first occurrence of some value in this list after or at some start index.\n```\n```\ndef  indexOf(elem: A): Int\n[use case] Finds index of first occurrence of some value in this list.\n```\n```\ndef  indexOfSlice[B >: A](that: GenSeq[B], from: Int): Int\nFinds first index after or at a start index where this sequence contains a given sequence as a slice.\n```\n```\ndef  indexOfSlice[B >: A](that: GenSeq[B]): Int\nFinds first index where this sequence contains a given sequence as a slice.\n```\n```\ndef  indexWhere(p: (A) ⇒ Boolean, from: Int): Int\nFinds index of the first element satisfying some predicate after or at some start index.\n```\n```\ndef  indexWhere(p: (A) ⇒ Boolean): Int\nFinds index of first element satisfying some predicate.\n```\n```\ndef  indices: Range\nProduces the range of all indices of this sequence.\n```\n```\ndef  init: List[A]\nSelects all elements except the last.\n```\n```\ndef  inits: Iterator[List[A]]\nIterates over the inits of this traversable collection.\n```\n```\ndef  intersect(that: collection.Seq[A]): List[A]\n[use case] Computes the multiset intersection between this list and another sequence.\n```\n```\ndef  is```\n```\ndef inedAt(x: Int): Boolean\nTests whether this sequence contains given index.\n```\n\n```\ndef  isEmpty: Boolean\nTests whether this sequence is empty.\nfinal ```\n```\ndef  isTraversableAgain: Boolean\nTests whether this traversable collection can be repeatedly traversed.\n```\n```\ndef  iterator: Iterator[A]\nCreates a new iterator over all elements contained in this iterable object.\n```\n```\ndef  last: A\nSelects the last element.\n```\n```\ndef  lastIndexOf(elem: A, end: Int): Int\n[use case] Finds index of last occurrence of some value in this list before or at a given end index.\n```\n```\ndef  lastIndexOf(elem: A): Int\n[use case] Finds index of last occurrence of some value in this list.\n```\n```\ndef  lastIndexOfSlice[B >: A](that: GenSeq[B], end: Int): Int\nFinds last index before or at a given end index where this sequence contains a given sequence as a slice.\n```\n```\ndef  lastIndexOfSlice[B >: A](that: GenSeq[B]): Int\nFinds last index where this sequence contains a given sequence as a slice.\n```\n```\ndef  lastIndexWhere(p: (A) ⇒ Boolean, end: Int): Int\nFinds index of last element satisfying some predicate before or at given end index.\n```\n```\ndef  lastIndexWhere(p: (A) ⇒ Boolean): Int\nFinds index of last element satisfying some predicate.\n```\n```\ndef  lastOption: Option[A]\nOptionally selects the last element.\n```\n```\ndef  length: Int\nThe length of the sequence.\n```\n```\ndef  lengthCompare(len: Int): Int\nCompares the length of this sequence to a test value.\n```\n```\ndef  lift: (Int) ⇒ Option[A]\nTurns this partial function into a plain function returning an Option result.\nfinal ```\n```\ndef  map[B](f: (A) ⇒ B): List[B]\n[use case] Builds a new collection by applying a function to all elements of this list.\nfinal ```\n```\ndef  mapConserve(f: (A) ⇒ A): List[A]\n[use case] Builds a new list by applying a function to all elements of this list.\n```\n```\ndef  max: A\n[use case] Finds the largest element.\n```\n```\ndef  maxBy[B](f: (A) ⇒ B): A\n[use case] Finds the first element which yields the largest value measured by function f.\n```\n```\ndef  min: A\n[use case] Finds the smallest element.\n```\n```\ndef  minBy[B](f: (A) ⇒ B): A\n[use case] Finds the first element which yields the smallest value measured by function f.\n```\n```\ndef  mkString: String\nDisplays all elements of this traversable or iterator in a string.\n```\n```\ndef  mkString(sep: String): String\nDisplays all elements of this traversable or iterator in a string using a separator string.\n```\n```\ndef  mkString(start: String, sep: String, end: String): String\nDisplays all elements of this traversable or iterator in a string using start, end, and separator strings.\n```\n```\ndef  nonEmpty: Boolean\nTests whether the traversable or iterator is not empty.\n```\n```\ndef  orElse[A1 <: Int, B1 >: A](that: PartialFunction[A1, B1]): PartialFunction[A1, B1]\nComposes this partial function with a fallback partial function which gets applied where this partial function is not ```\n```\ndef ined.\n```\n\n```\ndef  padTo(len: Int, elem: A): List[A]\n[use case] A copy of this list with an element value appended until a given target length is reached.\n```\n\n```\ndef  par: ParSeq[A]\nReturns a parallel implementation of this collection.\n```\n\n```\ndef  partition(p: (A) ⇒ Boolean): (List[A], List[A])\nPartitions this traversable collection in two traversable collections according to a predicate.\n```\n\n```\ndef  patch(from: Int, that: GenSeq[A], replaced: Int): List[A]\n[use case] Produces a new list where a slice of elements in this list is replaced by another sequence.\n```\n\n```\ndef  permutations: Iterator[List[A]]\nIterates over distinct permutations.\n```\n\n```\ndef  prefixLength(p: (A) ⇒ Boolean): Int\nReturns the length of the longest prefix whose elements all satisfy some predicate.\n```\n\n```\ndef  product: A\n[use case] Multiplies up the elements of this collection.\n```\n\n```\ndef  productIterator: scala.Iterator[Any]\nAn iterator over all the elements of this product.\n```\n\n```\ndef  productPrefix: String\nA string used in the toString methods of derived classes.\n```\n\n```\ndef  reduce[A1 >: A](op: (A1, A1) ⇒ A1): A1\nReduces the elements of this traversable or iterator using the specified associative binary operator.\n```\n\n```\ndef  reduceLeft[B >: A](op: (B, A) ⇒ B): B\nApplies a binary operator to all elements of this sequence, going left to right.\n```\n\n```\ndef  reduceLeftOption[B >: A](op: (B, A) ⇒ B): Option[B]\nOptionally applies a binary operator to all elements of this traversable or iterator, going left to right.\n```\n\n```\ndef  reduceOption[A1 >: A](op: (A1, A1) ⇒ A1): Option[A1]\nReduces the elements of this traversable or iterator, if any, using the specified associative binary operator.\n```\n\n```\ndef  reduceRight[B >: A](op: (A, B) ⇒ B): B\nApplies a binary operator to all elements of this sequence, going right to left.\n```\n\n```\ndef  reduceRightOption[B >: A](op: (A, B) ⇒ B): Option[B]\nOptionally applies a binary operator to all elements of this traversable or iterator, going right to left.\n```\n\n```\ndef  repr: List[A]\nThe collection of type traversable collection underlying this TraversableLike object.\n```\n\n```\ndef  reverse: List[A]\nReturns new list with elements in reversed order.\n```\n\n```\ndef  reverseIterator: Iterator[A]\nAn iterator yielding elements in reversed order.\n```\n\n```\ndef  reverseMap[B](f: (A) ⇒ B): List[B]\n[use case] Builds a new collection by applying a function to all elements of this list and collecting the results in reversed order.\n```\n\n```\ndef  reverse_:::(prefix: List[A]): List[A]\n[use case] Adds the elements of a given list in reverse order in front of this list.\n```\n\n```\ndef  runWith[U](action: (A) ⇒ U): (Int) ⇒ Boolean\nComposes this partial function with an action function which gets applied to results of this partial function.\n```\n\n```\ndef  sameElements(that: GenIterable[A]): Boolean\n[use case] Checks if the other iterable collection contains the same elements in the same order as this list.\n```\n\n```\ndef  scan[B >: A, That](z: B)(op: (B, B) ⇒ B)(implicit cbf: CanBuildFrom[List[A], B, That]): That\nComputes a prefix scan of the elements of the collection.\n```\n\n```\ndef  scanLeft[B, That](z: B)(op: (B, A) ⇒ B)(implicit bf: CanBuildFrom[List[A], B, That]): That\nProduces a collection containing cumulative results of applying the operator going left to right.\n```\n\n```\ndef  scanRight[B, That](z: B)(op: (A, B) ⇒ B)(implicit bf: CanBuildFrom[List[A], B, That]): That\nProduces a collection containing cumulative results of applying the operator going right to left.\n```\n\n```\ndef  segmentLength(p: (A) ⇒ Boolean, from: Int): Int\nComputes length of longest segment whose elements all satisfy some predicate.\n```\n\n```\ndef  seq: LinearSeq[A]\nA version of this collection with all of the operations implemented sequentially (i.e., in a single-threaded manner).\n```\n\n```\ndef  size: Int\nThe size of this sequence, equivalent to length.\n```\n\n```\ndef  slice(from: Int, until: Int): List[A]\n```\n\n```\ndef  sliding(size: Int, step: Int): Iterator[List[A]]\nGroups elements in fixed size blocks by passing a \"sliding window\" over them (as opposed to partitioning them, as is done in grouped.)\n```\n\n```\ndef  sliding(size: Int): Iterator[List[A]]\nGroups elements in fixed size blocks by passing a \"sliding window\" over them (as opposed to partitioning them, as is done in grouped.) The \"sliding window\" step is set to one.\n```\n\n```\ndef  sortBy[B](f: (A) ⇒ B)(implicit ord: math.Ordering[B]): List[A]\nSorts this Seq according to the Ordering which results from transforming an implicitly given Ordering with a transformation function.\n```\n\n```\ndef  sortWith(lt: (A, A) ⇒ Boolean): List[A]\nSorts this sequence according to a comparison function.\n```\n\n```\ndef  sorted[B >: A](implicit ord: math.Ordering[B]): List[A]\nSorts this sequence according to an Ordering.\nfinal ```\n```\ndef  span(p: (A) ⇒ Boolean): (List[A], List[A])\nSplits this list into a prefix/suffix pair according to a predicate.\n```\n```\ndef  splitAt(n: Int): (List[A], List[A])\nSplits this list into two at a given position.\n```\n```\ndef  startsWith[B](that: GenSeq[B], offset: Int): Boolean\nTests whether this sequence contains the given sequence at a given index.\n```\n```\ndef  startsWith[B](that: GenSeq[B]): Boolean\nTests whether this general sequence starts with the given sequence.\n```\n```\ndef  stringPrefix: String\n```\n```\ndef ines the prefix of this object's toString representation.\n```\n```\ndef  sum: A\n[use case] Sums up the elements of this collection.\n```\n```\ndef  tail: List[A]\nSelects all elements except the first.\n```\n```\ndef  tails: Iterator[List[A]]\nIterates over the tails of this traversable collection.\n```\n```\ndef  take(n: Int): List[A]\nSelects first n elements.\n```\n```\ndef  takeRight(n: Int): List[A]\nSelects last n elements.\nfinal ```\n```\ndef  takeWhile(p: (A) ⇒ Boolean): List[A]\nTakes longest prefix of elements that satisfy a predicate.\n```\n\n```\ndef  to[Col[_]]: Col[A]\n[use case] Converts this list into another by copying all elements.\n```\n\n```\ndef  toArray: Array[A]\n[use case] Converts this list to an array.\n```\n\n```\ndef  toBuffer[B >: A]: Buffer[B]\nUses the contents of this traversable or iterator to create a new mutable buffer.\n```\n\n```\ndef  toIndexedSeq: IndexedSeq[A]\nConverts this traversable or iterator to an indexed sequence.\n```\n\n```\ndef  toIterable: collection.Iterable[A]\nReturns this iterable collection as an iterable collection.\n```\n\n```\ndef  toIterator: Iterator[A]\nReturns an Iterator over the elements in this iterable collection.\n```\n\n```\ndef  toList: List[A]\nConverts this list to a list.\n```\n\n```\ndef  toMap[T, U]: collection.Map[T, U]\n[use case] Converts this list to a map.\n```\n\n```\ndef  toParArray: ParArray[T]\n```\n\n```\ndef  toSeq: Seq[A]\nConverts this immutable sequence to a sequence.\n```\n\n```\ndef  toSet[B >: A]: Set[B]\nConverts this traversable or iterator to a set.\n```\n\n```\ndef  toStream: Stream[A]\nConverts this list to a stream.\n```\n\n```\ndef  toString(): String\nConverts this sequence to a string.\n```\n\n```\ndef  toTraversable: collection.Traversable[A]\nConverts this traversable collection to an unspecified Traversable.\n```\n\n```\ndef  toVector: scala.Vector[A]\nConverts this traversable or iterator to a Vector.\n```\n\n```\ndef  transpose[B](implicit asTraversable: (A) ⇒ GenTraversableOnce[B]): List[List[B]]\nTransposes this collection of traversable collections into a collection of collections.\n```\n\n```\ndef  union(that: collection.Seq[A]): List[A]\n[use case] Produces a new sequence which contains all elements of this list and also all elements of a given sequence.\n```\n\n```\ndef  unzip[A1, A2](implicit asPair: (A) ⇒ (A1, A2)): (List[A1], List[A2])\nConverts this collection of pairs into two collections of the first and second half of each pair.\n```\n\n```\ndef  unzip3[A1, A2, A3](implicit asTriple: (A) ⇒ (A1, A2, A3)): (List[A1], List[A2], List[A3])\nConverts this collection of triples into three collections of the first, second, and third element of each triple.\n```\n\n```\ndef  updated(index: Int, elem: A): List[A]\n[use case] A copy of this list with one single replaced element.\n```\n\n```\ndef  view(from: Int, until: Int): SeqView[A, List[A]]\nCreates a non-strict view of a slice of this sequence.\n```\n\n```\ndef  view: SeqView[A, List[A]]\nCreates a non-strict view of this sequence.\n```\n\n```\ndef  withFilter(p: (A) ⇒ Boolean): FilterMonadic[A, List[A]]\nCreates a non-strict filter of this traversable collection.\n```\n\n```\ndef  zip[B](that: GenIterable[B]): List[(A, B)]\n[use case] Returns a list formed from this list and another iterable collection by combining corresponding elements in pairs.\n```\n\n```\ndef  zipAll[B](that: collection.Iterable[B], thisElem: A, thatElem: B): List[(A, B)]\n[use case] Returns a list formed from this list and another iterable collection by combining corresponding elements in pairs.\n```\n\n```\ndef  zipWithIndex: List[(A, Int)]\n[use case] Zips this list with its indices.\n```\n\n\n```\n\n## 七.Map的常见方法汇总\n\n（1）不可变Map\n\n```\nvar a:Map[String,Int]=Map(\"k1\"->1,\"k2\"->2)//初始化构造函数\na += (\"k3\"->3)//添加元素\na += (\"k4\"->4)//添加元素\na += (\"k1\"->100)//已经存在添加元素会覆盖\na -= (\"k2\",\"k1\")//删除元素    //a(\"k1\") = \"foo\"//不支持\nprintln(a.contains(\"k6\"))//是否包含某元素\nprintln(a.size)//打印大小\nprintln(a.get(\"k1\").getOrElse(\"default\")) //根据key读取元素，不存在就替换成默认值\na.foreach{case (e,i) => println(e,i)} //遍历打印1\nfor( (k,v)<-a ) println(k,v) //遍历打印2\nprintln(a.isEmpty)//判断是否为空\na.keys.foreach(println)//只打印key\na.values.foreach(println)//只打印value\n\na=Map()//数据清空使用再次new\nprintln(a.size)\na.toSeq.sortBy(_._1)//升序排序 key\na.toSeq.sortBy(_._2)//升序排序 value\na.toSeq.sortWith(_._1>_._1) //降序排序 key\na.toSeq.sortWith(_._2>_._2) //降序排序 value\n    \n//下面自定义按英文字母或数字排序\nimplicit  val KeyOrdering=new Ordering[String] {\n      override def compare(x: String, y: String): Int = {\n        x.compareTo(y)\n      }\n}\nprintln(a.toSeq.sorted)\n```\n\n2）可变Map例子\n```\nvar a:scala.collection.mutable.Map[String,Int]=scala.collection.mutable.Map(\"k1\"->1,\"k2\"->2)//初始化构造函数\n  a += (\"k3\"->3)//添加元素\n  a += (\"k4\"->4)//添加元素\n  a += (\"k1\"->100)//已经存在添加元素会覆盖\n  a += (\"k1\"->100,\"k9\"->9)//添加多个元素\n  a -= (\"k2\",\"k1\")//删除元素\n  a ++= List(\"CA\" -> 23, \"CO\" -> 25)//追加集合\n  a --= List(\"AL\", \"AZ\")//删除集合\n\n  a.retain((k,v)=> k==\"k1\")//只保留等于k1元素，其他的删除\n  a.put(\"put1\",200)//put\n  a.remove(\"k2\")//remove\n  a.clear()//清空\n  a(\"k3\")=100//支持\n\n  println(a.contains(\"k6\"))//是否包含某元素\n  println(a.size)//打印大小\n  println(a.get(\"k1\").getOrElse(\"default\")) //根据key读取元素，不存在就替换成默认值\n  a.foreach{case (e,i) => println(e,i)} //遍历打印1\n  for( (k,v)<-a ) println(k,v) //遍历打印2\n  println(a.isEmpty)//判断是否为空\n  a.keys.foreach(println)//只打印key\n  a.values.foreach(println)//只打印value\n  a=scala.collection.mutable.Map()//引用能变\n  println(a.size)\n  a.toSeq.sortBy(_._1)//排序 key\n  a.toSeq.sortBy(_._2)//排序 value\n  a.toSeq.sortWith(_._1>_._1) //降序排序 key\n  a.toSeq.sortWith(_._2>_._2) //降序排序 value\n  \n//下面自定义按英文字母或数字排序\n  implicit  val KeyOrdering=new Ordering[String] {\n    override def compare(x: String, y: String): Int = {\n      x.compareTo(y)\n    }\n  }\n  println(a.toSeq.sorted)\n}\n```\n\n默认情况下，Scala使用不可变映射(Map)。如果要使用可变集合(Set)，则必须明确导入scala.collection.mutable.Map类。如果想同时使用可变的和不可变映射(Map)，那么可以继续引用不可变映射(Map)，但是可以将mutable集合引用mutable.Map。\n以下是声明不可变映射(Map)的示例声明 \n集合基本操作\n```\nscala> val colors = Map(\"red\" -> \"#FF0000\", \"azure\" -> \"#F0FFFF\", \"peru\" -> \"#CD853F\")\ncolors: scala.collection.immutable.Map[String,String] = Map(red -> #FF0000, azure -> #F0FFFF, peru -> #CD853F)\n\nscala> val nums: Map[Int, Int] = Map()\nnums: Map[Int,Int] = Map()\n\nscala>println( \"Keys in colors : \" + colors.keys )\nKeys in colors : Set(red, azure, peru)\n\nscala>println( \"Values in colors : \" + colors.values )\nValues in colors : MapLike(#FF0000, #F0FFFF, #CD853F)\n\nscala>println( \"Check if colors is empty : \" + colors.isEmpty )\nCheck if colors is empty : false\n\nscala>println( \"Check if nums is empty : \" + nums.isEmpty )\nCheck if nums is empty : true\n```\n\n连接映射\n```\nscala>val colors1 = Map(\"red\" -> \"#FF0000\", \"azure\" -> \"#F0FFFF\", \"peru\" -> \"#CD853F\")\ncolors1: scala.collection.immutable.Map[String,String] = Map(red -> #FF0000, azure -> #F0FFFF, peru -> #CD853F)\n\nscala>val colors2 = Map(\"blue\" -> \"#0033FF\", \"yellow\" -> \"#FFFF00\", \"red\" -> \"#FF0000\")\ncolors2: scala.collection.immutable.Map[String,String] = Map(blue -> #0033FF, yellow -> #FFFF00, red -> #FF0000)\n\nscala>var colors = colors1 ++ colors2\ncolors: scala.collection.immutable.Map[String,String] = Map(blue -> #0033FF, azure -> #F0FFFF, peru -> #CD853F, yellow -> #FFFF00, red -> #FF0000)\n\nscala>println( \"colors1 ++ colors2 : \" + colors )\ncolors1 ++ colors2 : Map(blue -> #0033FF, azure -> #F0FFFF, peru -> #CD853F, yellow -> #FFFF00, red -> #FF0000)\n\nscala>colors = colors1.++(colors2)\ncolors: scala.collection.immutable.Map[String,String] = Map(blue -> #0033FF, azure -> #F0FFFF, peru -> #CD853F, yellow -> #FFFF00, red -> #FF0000)\n\nscala>println( \"colors1.++(colors2)) : \" + colors )\ncolors1.++(colors2)) : Map(blue -> #0033FF, azure -> #F0FFFF, peru -> #CD853F, yellow -> #FFFF00, red -> #FF0000)\n\n```\n\n打印映射的键和值\n```\nval colors = Map(\"red\" -> \"#FF0000\", \"azure\" -> \"#F0FFFF\",\"peru\" -> \"#CD853F\")\ncolors.keys.foreach{ i =>  \n    print( \"Key = \" + i )\n    println(\" Value = \" + colors(i) )}\n}\n\nKey = red Value = #FF0000\nKey = azure Value = #F0FFFF\nKey = peru Value = #CD853F\n```\n查找检查映射中的键\n```\nval colors = Map(\"red\" -> \"#FF0000\", \"azure\" -> \"#F0FFFF\", \"peru\" -> \"#CD853F\")\nif( colors.contains( \"red\" )) {\n    println(\"Red key exists with value :\"  + colors(\"red\"))\n} else {\n    println(\"Red key does not exist\")\n}\nif( colors.contains( \"maroon\" )) {\n    println(\"Maroon key exists with value :\"  + colors(\"maroon\"))\n} else {\n    println(\"Maroon key does not exist\")\n}\n```\n\n\nscala - Map基础\n构造Map:不可变：\n```\nval map = Map(\"sa\" -> 1, \"s\" -> 2)\nmap(\"sa\") = 3 // error\nval emptyMap = new scala.collection.immutable.HashMap[String, Int]\n```\n可变：\n```\nval map2 = scala.collection.mutable.Map(\"sa\" -> 2)\nmap2(\"sa\") = 3\nval emptyMap = new scala.collection.mutable.HashMap[String, Int]\n```\n注：->用来创建元组， \"sa\" -> 1即(\"sa\", 1) 初始化完全可以 val map = Map((\"sa\", 1), (\"s\", 2))\n获取Map中的值：\n```\n如果map中不包含请求中使用的key值，则抛异常。NoSuchElementException\nmap(\"sa\") // 类似于java中的map.get(\"sa\")\n```\n\n要检查map中是否包含某个key，使用contains方法。\n```\nval sa = if (map2.contains(\"sa3\")) map2(\"sa3\") else 0;\n快捷的方式：\nval sa2 = map.getOrElse(\"sa2\", 0)\n一次得到是否包含key，并获取值：\nval sa3 = map.get(\"sa3\"); // Option类型，\nprintln(sa3.isEmpty)\n```\n更新Map中的值：\n```\n添加或更新：map(\"sa\") = 3\n添加或更新多个：map += (\"aa\" -> 4, \"bb\" -> 5)\n```\n移除某个key和对应的值：\n```\nmap -= \"aa\"\n不可变的map也可以使用+和-操作，但是会生成新的map\nvar map = Map(\"aa\" -> 1)\nmap = map + (\"bb\" -> 2)\nmap += (\"cc\" -> 2)\nmap -= \"aa\"\n```\n迭代map：\n```\nfor ((k, v) <- map) {\n\n}\n所有key：map.keySet\n所有值：map.values\n反转：map2 = for((k, v) <- map) yield (v, k)\n```\n已排序Map：\n按key排序：SortedMap\n按添加顺序：LinkedHashMap\nMap与Java互操作：\nJava Properties转为scala.collection.Map：\n```\nimport scala.collection.JavaConversions.propertiesAsScalaMap\nval prop: scala.collection.Map[String, String] = System.getProperties();\n```\nJava Map转为scala.collection.mutable.Map[String, Int]：\n```\nimport scala.collection.JavaConversions.mapAsScalaMap\nval map: scala.collection.mutable.Map[String, Int] = new TreeMap[String, Int]\n```\nScala Map转为Java Map:\n```\nimport scala.collection.JavaConversions.mapAsJavaMap\nimport java.awt.font.TextAttribute._\nvar fs = Map(FAMILY -> \"Serif\", SIZE -> 12)\nvar fonts = new Font(fs)\n```\n\n**Map的操作方法**\n\n```\ndef ++(xs: Map[(A, B)]): Map[A, B]\n返回一个新的 Map，新的 Map xs 组成\n```\n```\t\ndef -(elem1: A, elem2: A, elems: A*): Map[A, B]\n返回一个新的 Map, 移除 key 为 elem1, elem2 或其他 elems。\n```\n```\t\ndef --(xs: GTO[A]): Map[A, B]\n返回一个新的 Map, 移除 xs 对象中对应的 key\n```\n```\t\ndef get(key: A): Option[B]\n返回指定 key 的值\n```\n```\t\ndef iterator: Iterator[(A, B)]\n创建新的迭代器，并输出 key/value 对\n```\n```\t\ndef addString(b: StringBuilder): StringBuilder\n将 Map 中的所有元素附加到StringBuilder，可加入分隔符\n```\n```\t\ndef addString(b: StringBuilder, sep: String): StringBuilder\n将 Map 中的所有元素附加到StringBuilder，可加入分隔符\n```\n```\t\ndef apply(key: A): B\n返回指定键的值，如果不存在返回 Map 的默认方法\n```\n```\t\ndef clear(): Unit\n清空 Map\n```\n```\t\ndef clone(): Map[A, B]\n从一个 Map 复制到另一个 Map\n```\n```\t\ndef contains(key: A): Boolean\n如果 Map 中存在指定 key，返回 true，否则返回 false。\n```\n```\t\ndef copyToArray(xs: Array[(A, B)]): Unit\n复制集合到数组\n```\n```\t\ndef count(p: ((A, B)) => Boolean): Int\n计算满足指定条件的集合元素数量\n```\n```\t\ndef default(key: A): B\n定义 Map 的默认值，在 key 不存在时返回。\n```\n```\t\ndef drop(n: Int): Map[A, B]\n返回丢弃前n个元素新集合\n```\n```\t\ndef dropRight(n: Int): Map[A, B]\n返回丢弃最后n个元素新集合\n```\n```\t\ndef dropWhile(p: ((A, B)) => Boolean): Map[A, B]\n从左向右丢弃元素，直到条件p不成立\n```\n```\t\ndef empty: Map[A, B]\n返回相同类型的空 Map\n```\n```\t\ndef equals(that: Any): Boolean\n如果两个 Map 相等(key/value 均相等)，返回true，否则返回false\n```\n```\t\ndef exists(p: ((A, B)) => Boolean): Boolean\n判断集合中指定条件的元素是否存在\n```\n```\ndef filter(p: ((A, B))=> Boolean): Map[A, B]\n返回满足指定条件的所有集合\n```\n```\t\ndef filterKeys(p: (A) => Boolean): Map[A, B]\n返回符合指定条件的的不可变 Map\n```\n```\t\ndef find(p: ((A, B)) => Boolean): Option[(A, B)]\n查找集合中满足指定条件的第一个元素\n```\n```\t\ndef foreach(f: ((A, B)) => Unit): Unit\n将函数应用到集合的所有元素\n```\n```\t\ndef init: Map[A, B]\n返回所有元素，除了最后一个\n```\n```\t\ndef isEmpty: Boolean\n检测 Map 是否为空\n```\n```\t\ndef keys: Iterable[A]\n返回所有的key/p>\n```\n```\t\ndef last: (A, B)\n返回最后一个元素\n```\n```\t\ndef max: (A, B)\n查找最大元素\n```\n```\t\ndef min: (A, B)\n查找最小元素\n```\n```\t\ndef mkString: String\n集合所有元素作为字符串显示\n```\n```\t\ndef product: (A, B)\n返回集合中数字元素的积。\n```\n```\t\ndef remove(key: A): Option[B]\n移除指定 key\n```\n```\t\ndef retain(p: (A, B) => Boolean): Map.this.type\n如果符合满足条件的返回 true\n```\n```\t\ndef size: Int\n返回 Map 元素的个数\n```\n```\t\ndef sum: (A, B)\n返回集合中所有数字元素之和\n```\n```\t\ndef tail: Map[A, B]\n返回一个集合中除了第一元素之外的其他元素\n```\n```\ndef take(n: Int): Map[A, B]\n返回前 n 个元素\n```\n```\t\ndef takeRight(n: Int): Map[A, B]\n返回后 n 个元素\n```\n```\t\ndef takeWhile(p: ((A, B)) => Boolean): Map[A, B]\n返回满足指定条件的元素\n```\n```\ndef toArray: Array[(A, B)]\n集合转数组\n```\n```\ndef toBuffer[B >: A]: Buffer[B]\n返回缓冲区，包含了 Map 的所有元素\n```\n```\ndef toList: List[A]\n返回 List，包含了 Map 的所有元素\n```\n```\t\ndef toSeq: Seq[A]\n返回 Seq，包含了 Map 的所有元素\n```\n```\t\ndef toSet: Set[A]\n返回 Set，包含了 Map 的所有元素\n```\n```\ndef toString(): String\n返回字符串对象\n```\n\n## 八.类的定义及构造器\n\n**类和对象之基础**\n\n**定义**\n\nScala 中以 class 来作为类的声明，在类中可以定义成员和方法，成员和方法可以有不同的可见性（这个会在后文详述）\n```\nscala> class Company {\n     |   private var employeeCount = 0\n     |   def getEmployeeCount(): Int = employeeCount\n     |   def setEmployeeCount( count: Int)= {\n     |     employeeCount = count\n     |   }\n     |\n     |   def m( i: Int ) {}\n     |   def m( str: String ) {}\n     | }\ndefined class Company\n```\n**构造器**\n\nScala 中，类有一个主构造器，主构造器必须包含所需的所有参数。除了一个主构造器，还可以有0个或多个辅助构造器，辅助构造器又称次构造器。辅助构造器命名为 this，其第一条语句必须调用主构造器或其他辅助构造器，来看下面的例子：\n```\nscala> class T ( x1: Int, y1: String, z1: Double ) {\n     |   private val xx1 = x1\n     |   private val yy1 = y1\n     |   private val zz1 = z1\n     |\n     |   def this ( x1: Int, y1: String ) {\n     |     this( x1, y1, 1.0 )\n     |   }\n     |\n     |   def this ( x1: Int ) {\n     |     this( x1, \"\" )\n     |   }\n     | }\ndefined class T\n```\n还有一点需要注意的是，被调用的辅助构造函数的定义必须放在主动调用的辅助构造函数前面，不然会报错：\n```\nscala> class T ( x1: Int, y1: String, z1: Double ) {\n     |   private val xx1 = x1\n     |   private val yy1 = y1\n     |   private val zz1 = z1\n     |\n     |   def this ( x1: Int ) {\n     |     this( x1, \"\" )\n     |   }\n     |\n     |   def this ( x1: Int, y1: String ) {\n     |     this( x1, y1, 1.0 )\n     |   }\n     | }\n<console>:13: error: called constructor's definition must precede calling constructor's definition\n           this( x1, \"\" )\n           ^\n```\n不管辅助函数调来调去，最终都还是要调用到主构造函数，这确保了新实例的初始化逻辑一致。\n\n如果在主构造函数的参数前加 var 或 val，该参数就成为实例的一个成员，这部分知识在Scala case class那些你不知道的知识有更详细的介绍\n\n**重载**\n\nScala 类方法允许重载，如类 Company 中的 m 方法。重载要求参数列表和返回类型不完全相同，但参数名可相同，这是因为编译后是通过方法名、参数列表、返回类型综合来区分各个方法的。\n\n在方法重载时，有一点需要注意：对于『高级类型』，存在类型擦除机制，所谓的高级类型就是包含类型参数的类型，比如 List[A]，下面这个例子可以展示了类型擦除：\n\n```\nscala> class Tmp {\n     |   def m( data: List[Int] ) {}\n     |   def m( data: List[String] ) {}\n     | }\n<console>:9: error: double definition:\nmethod m:(data: List[String])Unit and\nmethod m:(data: List[Int])Unit at line 8\nhave same type after erasure: (data: List)Unit\n         def m( data: List[String] ) {}\n             ^\n```\n报了有相同类型的参数的错误。\n\n**类型成员**\n\nScala 允许你在类内部定义类型成员，在构造类实例的时候指定该类型成员对应的具体类型。类型成员可用于类内部的成员或函数，提供了更好的泛华能力，从下面这个简单的例子可以看出：\n```\nscala> class T {\n     |   type X\n     |\n     |   def getClassName( x: X): String = {\n     |     x.getClass.getTypeName\n     |   }\n     | }\ndefined class T\n\nscala> val x1 = new T{ type X = Int }\nx1: T{type X = Int} = $anon$1@515f550a\n\nscala> x1.getClassName(10)\nres0: String = java.lang.Integer\n\nscala> val x2 = new T{ type X = String }\nx2: T{type X = String} = $anon$1@61a52fbd\n\nscala> x2.getClassName(\"string\")\nres1: String = java.lang.String\n```\n当然，也可以在类外部定义类型变量，如：\n```\nscala> type L = List[Int]\ndefined type alias L\n```\n**方法与成员同名**\n\n与 JAVA 不同，如果方法参数列表不为空，该方法可以与成员同名，如：\n```\nscala> class T {\n     |   private val m = 0\n     |\n     |   def m( i: Int ): Int = m + i\n     | }\ndefined class T\n\n```\n\n##  九.类和对象之进阶（一）\n\n 1、Scala中的类是公有可见性的，且多个类可以包含在同一个源文件中；\n\n```\nclass Counter{\n    private var value = 0　　//类成员变量必须初始化，否则报错\n    def increment(){    //类中的方法默认是公有可见性\n        value += 1\n    }\n    def current() = value //对于类中的“取值方法”，在定义时可省略掉括号，直接 def current = value\n}\n```\n\n继承\n\n只能有一个父类\n\n与其他支持面向对象的语言一样，Scala 也支持继承，并且子类只能有一个父类，不能继承于多个父类，如果希望实现类似继承多个父类的功能，应该考虑引入 trait。虽然只支持一个父类，但是父类还可以有父类，也就是爷爷类，对于类继承的层数是没有具体要求的，这几点在下面这个例子中都有体现：\n```\nscala> class A {\n     | }\ndefined class A\n\nscala> class B {\n     | }\ndefined class B\n\nscala> class AA extends A {\n     | }\ndefined class AA\n\nscala> class AB extends A with B {\n     | }\n<console>:9: error: class B needs to be a trait to be mixed in\n       class AB extends A with B {\n                               ^\n\nscala> class AAA extends AA {\n     | }\ndefined class AAA\n\nscala> class AAAA extends AAA {\n     | }\ndefined class AAAA\n```\n都继承了什么\n\n子类继承父类时都会继承些什么呢，这里结合可见性（可见性的详细内容会在下文介绍）进行分析，先定义这样一组父子类：\n```\nscala> class Parent ( x: Int, y: String, z: Double ) {\n     |   val xx = x\n     |   protected val yy = y\n     |   private val zz = z\n     |\n     |   def getXX = xx\n     |   protected def getYY = yy\n     |   private def getZZ = zz\n     |\n     |   def testYY = yy\n     |   def testZZ = zz\n     |   def testGetYY = getYY\n     |   def testGetZZ = getZZ\n     | }\ndefined class Parent\n```\n在 Scala 类继承中，允许在子类内部直接访问父类的 public 及 protected 成员及方法，但不允许子类直接访问父类的 private 成员及方法，如下例：\n```\nscala> class Child1 ( x: Int, y: String, z: Double ) extends Parent(x, y, z ) {\n     |   println( xx )\n     |   println( yy )\n     |   println( getXX )\n     |   println( getYY )\n     | }\ndefined class Child1\n\nscala> class Child2 ( x: Int, y: String, z: Double ) extends Parent(x, y, z ) {\n     |   println( zz )\n     |   println( getZZ )\n     | }\n<console>:9: error: value zz in class Parent cannot be accessed in Child2\n         println( zz )\n                  ^\n<console>:10: error: method getZZ in class Parent cannot be accessed in Child2\n         println( getZZ )\n                  ^\n```\n在类外部，只有 public 的方法和成员能被直接访问，protected 及 private 均不予许：\n```\nscala> class Child3 ( x: Int, y: String, z: Double ) extends Parent(x, y, z ) {\n     | }\ndefined class Child3\n\nscala> val child = new Child3( 1, \"hello\", 3.1415926 )\nchild: Child3 = Child3@39529185\n\nscala> child.xx\nres6: Int = 1\n\nscala> child.yy\n<console>:11: error: value yy in class Parent cannot be accessed in Child3\n Access to protected value yy not permitted because\n enclosing object $iw is not a subclass of\n class Parent where target is defined\n              child.yy\n                    ^\n\nscala> child.zz\n<console>:11: error: value zz in class Parent cannot be accessed in Child3\n              child.zz\n                    ^\n\nscala>\n\nscala> child.getXX\nres9: Int = 1\n\nscala> child.getYY\n<console>:11: error: method getYY in class Parent cannot be accessed in Child3\n Access to protected method getYY not permitted because\n enclosing object $iw is not a subclass of\n class Parent where target is defined\n              child.getYY\n                    ^\n\nscala> child.getZZ\n<console>:11: error: method getZZ in class Parent cannot be accessed in Child3\n              child.getZZ\n                    ^\n```\n但我们可以通过父类提供的方法来间接访问 protected 和 private 的成员和方法：\n```\nscala> child.testYY\nres20: String = hello\n\nscala> child.testZZ\nres21: Double = 3.1415926\n\nscala> child.testGetYY\nres22: String = hello\n\nscala> child.testGetZZ\nres23: Double = 3.1415926\n```\n单例对象\n\n在 Scala 中，使用关键字 object 来定义单例对象：\n```\nscala> object T {}\ndefined module T\n```\n单例对象将在其首次被调用时初始化，且没有参数。单例对象一旦定义完毕，它的名字就代表了该单例对象的唯一实例。\n\n当单例对象与某个类的名字相同且两者定义在同一文件中，就形成了特殊的单例对象-伴生对象，对应的类称为伴生类，若单例没有相同名字的类的话成为孤立对象（好惨）。我们经常使用在伴生对象中对应 apply 方法来创建新的伴生类实例并且将半身列的可见性设置为 private，以便能方便的创建伴生类实例，更重要的是可以在伴生类对象中管理所有伴生类实例，例子如下：\n```\nclass Q ( qParam: String ) {\n  private val q = qParam\n}\n\nobject Q {\n  private val qList = ListBuffer[ Q ]()\n\n  def apply( qParam: String ) {\n    val qInstance = new Q( qParam )\n    qList.append( qInstance )\n    qInstance\n  }\n\n  def qListSize = qList.size\n}\n\nobject Test {\n  def main (args: Array[String]) {\n    val qIns1 = Q( \"q1\" )\n    val qIns2 = Q( \"q2\" )\n    println( Q.qListSize )\n  }\n}\n```\n输出：\n```\n2\n```\n另外伴生对象与伴生类可以互相访问 private 成员和方法，object 也可以继承父类或混入特质\n## 十.类和对象之进阶（二）\n\nScala 中的可见性非常灵活且复杂，这篇文章希望通过大量的示例来说清楚各种情况下的可见性是怎么样的。\n默认可见性\nScala 中的默认可见性为 public，所谓默认即你没有在类或者成员前显示加 private 或 protected 可见性关键字。虽然默认可见性为 public，但这是逻辑上的，实际上 Scala 中并没有 public 这个关键字，如果你用 public 来声明一个类或成员，编译器会报错。\n可见性作用域\n在 Scala 中，可以在类型的 class 或 trait 关键字之前、字段的 val 或 var 之前，方法定义的 def 关键字之前指定可见性。\n公有可见性\n对于公有可见性，任何作用域内都可以访问公有成员或公有类型。\nProtected 可见性\n对于受保护可见性，用 protected 声明，受保护成员对本类型、继承类型可见。而受保护的类型则只对包含该类的包内可见。\n下面例子是关于 protected 成员的：\n```\npackage P1 {\n  class C1 {\n    protected val c = 0\n\n    //< 受保护可见性中,嵌套类可访问 protected 成员\n    class C11 {\n      println( c )\n    }\n  }\n\n  package P11 {\n    //< 继承类客房为父类 protected 成员\n    class C1Child extends C1 {\n      println( c )\n    }\n  }\n\n}\n\npackage P2 {\n  //< 继承类客房为父类 protected 成员\n  class C2Child extends P1.C1 {\n    println( c )\n  }\n}\n```\n接下来是 protected 类型的：\n```\npackage P1 {\n  protected class C1 {\n  }\n\n  //< 对于 protected 类型,相同包内可见\n  class C1Child extends C1 {\n  }\n\n  package P11 {\n    //< 对于 protected 类型,子包内可见\n    class C11Child extends C1 {\n    }\n  }\n}\n\npackage P2 {\n//< 对于 protected 类型,外部包不可见\n  class C2Child extends P1.C1 {\n  }\n}\n```\n编译报错如下，这是因为 protected 类型只在包含该类的包内可见\n```\nError:(22, 28) class C1 in package P1 cannot be accessed in package P1\n Access to protected class C1 not permitted because\n enclosing package P2 is not a subclass of \n package P1 where target is defined\n  class C2Child extends P1.C1 {\n```\n私有可见性\n\n私有可见性将实现细节完全隐藏起来，即便是继承类也无法访问这些细节。声明中包含了 private 关键字的所有成员只对该类可见，该类型的其他实例也能访问这些成员。如果类型被声明为私有可见性类型，那么该类型的可见性将仅限于包含该类型的包内\n```\npackage P1 {\n  class C1 {\n    private val c = 0\n  }\n\n  //< 对于 private 类型,相同包内的子类都不可见\n  class C1Child extends C1 {\n    println( c )\n  }\n}\n\npackage P2 {\n  //< 对于 private 类型,外部包内的子类也不可见\n  class C2Child extends P1.C1 {\n    println( c )\n  }\n}\n```\n编译报错：\n```\nError:(12, 14) value c in class C1 cannot be accessed in P1.C1Child\n    println( c )\n             ^\n\nError:(19, 14) value c in class C1 cannot be accessed in P2.C2Child\n    println( c )\n             ^\n```\n另外，嵌套类中的私有成员也是无法访问的。在私有可见性中，私有类型只在包含该类型的包中可见，在子包或外部包中均不可见。我们用下面的例子进一步说明，具体说明见代码中的注释：\n```\npackage P1 {\n  private class C1\n\n  class C11 extends C1            //< 错误,这样相当于变相改变了C1的可见性,子包和外部包都能访问C11,也就间接能访问C1\n  protected class C12 extends C1  //< 错误这样相当于变相改变了C1的可见性,子包能访问C11,也就间接能访问C1\n  private class C13 extends C1    //< 正确,由于C13也为 private,是的C1的 private 可见性不会\n\n  class C14 {\n    val c14_1 = new C1            //< 正确,私有类型在其所在包内可见\n  }\n}\n\npackage P2 {\n\n  //< 对于私有类型,外部包内不可见\n  class C2 {\n    val c1 = new P1.C1\n  }\n}\n```\n编译报错：\n```\nError:(8, 21) private class C1 escapes its defining scope as part of type P1.C1\n  class C11 extends C1            //< 错误\n                    ^\n\nError:(9, 31) private class C1 escapes its defining scope as part of type P1.C1\n  protected class C12 extends C1  //< 错误\n                              ^\n\nError:(22, 21) class C1 in package P1 cannot be accessed in package P1\n    val c1 = new P1.C1\n                    ^\n```\n作用域内私有和作用域内受保护可见性\n\n所谓作用域内私有/受保护可见性，就是你可以更细粒度指定某个类或某个成员在某个作用域（可以是包或类）私有或受保护可见性\n\n成员在类和包中的 private/protected 可见性\n该可见性可以有16种组合，下面的例子列举除了这些组合\n```\npackage P1 {\n  class C1 {\n    private[C1] val m1 = 1\n    private[this] val m2 = 2\n    private[P1] val m3 = 3\n    private[P2] val m4 = 4\n\n    protected[C1] val n1 = 1\n    protected[this] val n2 = 2\n    protected[P1] val n3 = 3\n    protected[P2] val n4 = 4\n\n    //< 不管什么样的作用域内 private 或 protected,在自身类中都是可见的\n    println( m1 )\n    println( m2 )\n    println( m3 )\n    println( m4 )\n\n    println( n1 )\n    println( n2 )\n    println( n3 )\n    println( n4 )\n  }\n\n  class C11 extends C1 {\n    println( m1 )   //< 1, 错误\n    println( m2 )   //< 2, 错误\n    println( m3 )   //< 3, 正确\n    println( m4 )   //< 4, 正确\n\n    println( n1 )   //< 5, 正确\n    println( n2 )   //< 6, 正确\n    println( n3 )   //< 7, 正确\n    println( n4 )   //< 8, 正确\n  }\n}\n\npackage P2 {\n  class C21 extends P1.C1 {\n    println( m1 )   //< 9, 错误\n    println( m2 )   //< 10, 错误\n    println( m3 )   //< 11, 错误\n    println( m4 )   //< 12, 正确\n\n    println( n1 )   //< 13, 正确\n    println( n2 )   //< 14, 正确\n    println( n3 )   //< 15, 正确\n    println( n4 )   //< 16, 正确\n  }\n}\n```\n\n下面我们对每一项进行解释，并穿插介绍一些规则：\n\nprivate[C1]指定成员在自身类作用域 private，在该类所在的包内和包外均不可见（9也是这个道理）\nprivate[this]比 private[C1]更加严格，前者只对相同实例可见，相同类的不同实例都不可见；而后者对相同类的不同实例也可见\nprivate[P1]指定在包 P1 内 private，则在 P1 包中的类中均可见，而在 P1外的包均不可见\nprivate[P2]指定在包 P2 内 private，则在包 P2 及该类所在包内均可见\nprotected[C1]指定在 C1 中 protected，则在 C1 所在包内的继承类及外部包内所在的继承类均可见\n\n类型在类和包中的 private/protected 可见性\n类型的情况就会少一点：\n```\npackage P1 {\n\n  private[P1] class C1\n  protected[P1] class C2\n\n  package P11 {\n    private[P1] class C3\n    protected[P1] class C4\n    private[P11] class C5\n    protected[P11] class C6\n  }\n\n\n  class C11 extends C1  //< 1, 正确\n  class C12 extends C2  //< 2, 正确\n\n  import P11._\n  class C13 extends C3  //< 3, 正确\n  class C14 extends C4  //< 4, 正确\n  class C15 extends C5  //< 5, 错误\n  class C16 extends C6  //< 6, 正确\n}\n\npackage P2 {\n  import P1._\n  import P1.P11._\n\n\n  class C21 extends C1  //< 7, 错误\n  class C22 extends C2  //< 8, 正确\n\n  class C23 extends C3  //< 9, 错误\n  class C24 extends C4  //< 10, 正确\n  class C25 extends C5  //< 11, 错误\n  class C26 extends C6  //< 12, 正确\n}\n```\n从上面的例子我们可以得出以下结论：\n\n对于 private[package] 声明的类型，在 package 包内及 package 子包内可见；在外部包内不可见\n对于 protected[package] 声明的类型，在 package 包内、package 子包内及外部包均可见\n有包 package 的子包为 package1，对于 private[package1]，在 package1 包内、package1 子包及其父包即 package 内可见，在外部包不可见\n有包 package 的子包为 package1，对于 protected[package1]，在 package1包内、package1子包、package1父包及外部包可见\n\n## 十一.trait\n\n这是我以前在知乎上看到关于类继承作用的回答，虽不完全正确，却十分明确的表达出了好的代码应避免类继承而尽量使用类组合。Scala 显然也非常赞同这一点，以至于有了 trait，又叫做特质。当我们定义特质时，应该要遵循这样的原则：一个 trait 只干一件事，如果要干多件事，就定义多个 trait，然后使用一个类来 extends 这些 traits\n\n**定义 trait**\n\ntrait 的定义与 class 类似:\n```\nscala> trait T {\n     | }\ndefined trait T\n```\n当然，trait 可以包含成员和方法，并且：\n\ntrait 中的成员可以仅声明，也可以声明并指定值\ntrait 中的方法可以有实现，也可以只有声明而没有实现\n```\nscala> trait T {\n     |   val a: Int\n     |   val b: Int = 1\n     |\n     |   def getA(): Int\n     |   def getB() = b\n     | }\ndefined trait T\n```\n对比而言，类一旦包含未定义的方法就必须声明为 abstract；而 Java 的接口中的方法是不能实现的，必须是抽象方法。如果 trait 既为实现它所声明的方法，也没有定义或声明其他成员，那么在字节码级别，该 trait 其实是接口是相同的\n\n另一个与类不同的是，trait 主构造函数不允许有参数列表，并且不允许为 trait 定义辅助构造函数\n\n混入多个 trait\n\nScala 类只能有一个父类，但可以混入多个 trait，当要混入多个 traits 或已经继承了某个父类时，需要使用关键字 with，如下例：\n```\nscala> trait T {\n     |   val a: Int\n     |   val b: Int = 1\n     |\n     |   def getA(): Int\n     |   def getB() = b\n     | }\ndefined trait T\n\nscala>\n\nscala> trait Q {\n     |   def currentTime: String = System.currentTimeMillis().toString\n     | }\ndefined trait Q\n\nscala>\n\nscala> class X extends T with Q {\n     |   override val a = 1\n     |   override def getA(): Int = a\n     | }\ndefined class X\n```\n当类混入 trait 时，需要实现 trait 中为实现的成员和方法。要混入多个 trait 是为了保证『高内聚』，通俗说就是一个 trait 只干一件事，如果要干多件事，就定义多个 trait 然后混入它们\n\n当你继承的父类和混入的特质或混入的不同特质之间有同名方法时可能会有冲突，分为以下几种情况：\n\ntrait 中的方法未实现：不会冲突\n```\nscala> class C {\n     |   def a: String = \"a\"\n     | }\ndefined class C\n\nscala>\n\nscala> trait T {\n     |   def a: String\n     | }\ndefined trait T\n\nscala>\n\nscala> trait Q extends C with T {}\ndefined trait Q\n```\ntrait 中的方法实现了且与父类中的方法参数列表及返回类型相同：会冲突\n```\nscala> class C {\n     |   def a: String = \"a\"\n     | }\ndefined class C\n\nscala>\n\nscala> trait T {\n     |   def a: String = \"\"\n     | }\ndefined trait T\n\nscala>\n\nscala> trait Q extends C with T {}\n<console>:9: error: trait Q inherits conflicting members:\n  method a in class C of type => String  and\n  method a in trait T of type => String\n(Note: this can be resolved by declaring an override in trait Q.)\n       trait Q extends C with T {}\n             ^\n```\ntrait 中的方法实现了且与父类中的参数列表相同，返回类型不同：会冲突\n```\nscala> class C {\n     |   def a: String = \"a\"\n     | }\ndefined class C\n\nscala>\n\nscala> trait T {\n     |   def a: Int = 1\n     | }\ndefined trait T\n\nscala>\n\nscala> trait Q extends C with T {}\n<console>:9: error: trait Q inherits conflicting members:\n  method a in class C of type => String  and\n  method a in trait T of type => Int\n(Note: this can be resolved by declaring an override in trait Q.)\n       trait Q extends C with T {}\n             ^\n```\ntrait 中的方法实现了且与父类的参数列表不同，返回类型相同：不会冲突\n```\nscala> class C {\n     |   def a: String = \"a\"\n     | }\ndefined class C\n\nscala>\n\nscala> trait T {\n     |   def a( i: Int ): String = i.toString\n     | }\ndefined trait T\n\nscala>\n\nscala> trait Q extends C with T {}\ndefined trait Q\n```\n**trait 的继承**\n\n一个 trait 同样可以混入其他 trait 或继承类：\n```\nscala> class C {\n     |   def currentTime: String = System.currentTimeMillis().toString\n     | }\ndefined class C\n\nscala>\n\nscala> trait T {\n     |   def random: Int\n     | }\ndefined trait T\n\nscala>\n\nscala> trait Q extends C with T {}\ndefined trait Q\n```\n\n## 十二.case class样例类\n\n当你声明了一个 case class，Scala 编译器为你做了这些：\n创建 case class 和它的伴生 object\n实现了 apply 方法让你不需要通过 new 来创建类实例\n```\nscala> case class Person(lastname: String, firstname: String, birthYear: Int)\ndefined class Person\n\nscala> val p = Person(\"Lacava\", \"Alessandro\", 1976)\np: Person = Person(Lacava,Alessandro,1976)\n```\n默认为主构造函数参数列表的所有参数前加 val\n```\nscala> println( p.lastname )\nLacava\n\nscala> p.lastname = \"jhon\"\n<console>:10: error: reassignment to val\n   p.lastname = \"jhon\"\n              ^\n```\n添加天然的 hashCode、equals 和 toString 方法。由于 == 在 Scala 中总是代表 equals，所以 case class 实例总是可比较的\n```\nscala> val p_1 = new Person( \"Brown\", \"John\", 1969 )\np_1: Person = Person(Brown,John,1969)\n\nscala>val p_2 = new Person( \"Lacave\", \"Alessandro\", 1976)\np_2: Person = Person(Lacave,Alessandro,1976)\n\nscala> p_1.hashCode\nres1: Int = -1362628729\n\nscala> p_1.toString\nres2: String = Person(Brown,John,1969)\n\nscala> p_1.equals(p_2)\nres3: Boolean = false\n\nscala> p_1 == p_2\nres4: Boolean = false\n```\n\n生成一个 copy 方法以支持从实例 a 生成另一个实例 b，实例 b 可以指定构造函数参数与 a 一致或不一致\n```\n//< 保留 lastname 一致，修改 firstname 和 birthYear\nscala> val p_3 = p.copy(firstname = \"Michele\", birthYear = 1972)\np_3: Person = Person(Lacava,Michele,1972)\n```\n由于编译器实现了 unapply 方法，一个 case class 支持模式匹配\n```\nscala> case class A( a: Int )\ndefined class A\n\nscala> case class B( b: String )\ndefined class B\n\nscala> def classMath( x: AnyRef ): Unit = {\n     |   x match {\n     |     case A(a) => println( \"A:\" + a )\n     |     case B(b) => println( \"B:\" + b )\n     |     case A => println( A.apply(100) )\n     |   }\n     | }\nclassMath: (x: AnyRef)Unit\n\nscala> val a = A( 1 )\na: A = A(1)\n\nscala> val b = B( \"b\" )\nb: B = B(b)\n\nscala> classMath( a )\nA:1\n\nscala> classMath( b )\nB:b\n```\n\n也许你已经知道，在模式匹配中，当你的 case class 没有参数的时候，你是在使用 case object 而不是一个空参数列表的 case class\n```\nscala> classMath( A )\nA(100)\n```\n除了在模式匹配中使用之外，unapply 方法可以让你结构 case class 来提取它的字段，如：\n```\nscala> val Person(lastname, _, _) = p\nlastname: String = Lacava\n```\n\ncase class 接收一个 tuple 作为参数，该 tuple 的元素类型与个数与某 case class 相同，那么可以将该tuple 作为 case class 的 tuple 方法参数来构造 case class 实例\n```\nscala> val meAsTuple: (String, String, Int) = (\"Lacava\", \"Alessandro\", 1976)\nmeAsTuple: (String, String, Int) = (Lacava,Alessandro,1976)\n\nscala> Person.tupled( meAsTuple )\nres2: Person = Person(Lacava,Alessandro,1976)\n```\n相对用 tuple 来创建 case class 实例，还可以从 case class 实例中解构并提取出 tuple 对象\n```\nscala> val transform: Person => Option[ (String, String, Int) ] = {\n |   Person.unapply _\n | }\ntransform: Person => Option[(String, String, Int)] = <function1>\n\nscala> transform( p )\nres0: Option[(String, String, Int)] = Some((Lacava,Alessandro,1976))\n\n```\n\n**另一种定义 case class 的方式**\n\n还有另一种很少人知道的定义 case class 的方式，如：\n```\ncase class Person( lastname: String )( firstname: String, birthYear: Int )\n```\n这种方式有点像偏函数，有两个参数列表，要注意的是，对这两个参数列表是区别对待的。上文提到的所有 case class 的特性在这种定义方式下只作用于第一个参数列表中的参数（比如在参数前自动加 val，模式匹配，copy 支持等等），第二个及之后的参数列表中的参数和普通的 class 参数列表参数无异。\n\nfirstname和birthYear前不再自动添加 val，不再是类的成员\n```\nscala> val p = Person(\"Lacava\")(\"Alessandro\", 1976)\np: Person = Person(Lacava)\n\nscala> p.lastname\nres0: String = Lacava\n\nscala> p.firstname\n<console>:11: error: value firstname is not a member of Person\n              p.firstname\n                ^\n\nscala> p.birthYear\n<console>:11: error: value birthYear is not a member of Person\n              p.birthYear\n                ^\n```\ncopy 时，当不指定birthYear的值时，不会使用 p 中的birthYear，因为根本没这个值，会报错\n```\nscala> p.copy()(firstname = \"Jhon\")\n<console>:11: error: not enough arguments for method copy: (firstname: String, birthYear: Int)Person.\nUnspecified value parameter birthYear.\n              p.copy()(firstname = \"Jhon\")\n```\nequals 和 toString 方法也发生了改变：\n```\nscala> val p_1 = Person(\"Lacava\")(\"Jhon\", 2001)\np_1: Person = Person(Lacava)\n\nscala> p.equals(p_1)\nres9: Boolean = true\n\nscala> p == p_1\nres10: Boolean = true\n\nscala> println ( p.toString )\nPerson(Lacava)\n```\n\n## 十三.对象\n\n 1、Scala中没有静态方法和静态字段，但是可以用object语法来实现类似的功能。对象定义了某个类的单个实例。\n\nScala的object中可以用来实现类似的功能，用来存放工具函数或常量等。如\n\n```\nobject Sequence{\n    private var next_num = 0\n    val threshold = 100\n\n    def getSequence() = {\n        next_num += 1\n        next_num\n    }\n}\n```\n\n## 十四.常用操作符\n\n一、常用操作符（操作符其实也是函数）\n\n++ ++[B](that: GenTraversableOnce[B]): List[B] 从列表的尾部添加另外一个列表\n++: ++:[B >: A, That](that: collection.Traversable[B])(implicit bf: CanBuildFrom[List[A], B, That]): That 在列表的头部添加一个列表\n+: +:(elem: A): List[A] 在列表的头部添加一个元素\n:+ :+(elem: A): List[A] 在列表的尾部添加一个元素\n:: ::(x: A): List[A] 在列表的头部添加一个元素\n::: :::(prefix: List[A]): List[A] 在列表的头部添加另外一个列表\n:\\ :[B](z: B)(op: (A, B) ⇒ B): B 与foldRight等价\n\nval left = List(1,2,3)\nval right = List(4,5,6)\n\n//以下操作等价\nleft ++ right   // List(1,2,3,4,5,6)\nleft ++: right  // List(1,2,3,4,5,6)\nright.++:(left)    // Listval left = List(1,2,3)(1,2,3,4,5,6)\nright.:::(left)  // List(1,2,3,4,5,6)\n\n//以下操作等价\n0 +: left    //List(0,1,2,3)\nleft.+:(0)   //List(0,1,2,3)\n\n//以下操作等价\nleft :+ 4    //List(1,2,3,4)\nleft.:+(4)   //List(1,2,3,4)\n\n//以下操作等价\n0 :: left      //List(0,1,2,3)\nleft.::(0)     //List(0,1,2,3)\n\n\n看到这里大家应该跟我一样有一点晕吧，怎么这么多奇怪的操作符，这里给大家一个提示，任何以冒号结果的操作符，都是右绑定的，即 0 :: List(1,2,3) = List(1,2,3).::(0) = List(0,1,2,3) 从这里可以看出操作::其实是右边List的操作符，而非左边Int类型的操作符\n\n二、常用变换操作\n1.map\nmap[B](f: (A) ⇒ B): List[B]\n定义一个变换,把该变换应用到列表的每个元素中,原列表不变，返回一个新的列表数据\nExample1 平方变换\n```\nval nums = List(1,2,3)\nval square = (x: Int) => x*x   \nval squareNums1 = nums.map(num => num*num)    //List(1,4,9)\nval squareNums2 = nums.map(math.pow(_,2))    //List(1,4,9)\nval squareNums3 = nums.map(square)            //List(1,4,9)1\n```\nExample2 保存文本数据中的某几列\n```\nval text = List(\"Homeway,25,Male\",\"XSDYM,23,Female\")\nval usersList = text.map(_.split(\",\")(0))    \nval usersWithAgeList = text.map(line => {\n    val fields = line.split(\",\")\n    val user = fields(0)\n    val age = fields(1).toInt\n    (user,age)\n})\n```\n2.flatMap, flatten\nflatten: flatten[B]: List[B] 对列表的列表进行平坦化操作 flatMap: flatMap[B](f: (A) ⇒ GenTraversableOnce[B]): List[B] map之后对结果进行flatten\n\n定义一个变换f, 把f应用列表的每个元素中，每个f返回一个列表，最终把所有列表连结起来。\n```\nval text = List(\"A,B,C\",\"D,E,F\")\nval textMapped = text.map(_.split(\",\").toList) // List(List(\"A\",\"B\",\"C\"),List(\"D\",\"E\",\"F\"))\nval textFlattened = textMapped.flatten          // List(\"A\",\"B\",\"C\",\"D\",\"E\",\"F\")\nval textFlatMapped = text.flatMap(_.split(\",\").toList) // List(\"A\",\"B\",\"C\",\"D\",\"E\",\"F\")\n```\n\n3.reduce\nreduce[A1 >: A](op: (A1, A1) ⇒ A1): A1\n定义一个变换f, f把两个列表的元素合成一个，遍历列表，最终把列表合并成单一元素\nExample 列表求和\n```\nval nums = List(1,2,3)\nval sum1 = nums.reduce((a,b) => a+b)   //6\nval sum2 = nums.reduce(_+_)            //6\nval sum3 = nums.sum                 //6\n```\n4.reduceLeft,reduceRight\nreduceLeft: reduceLeft[B >: A](f: (B, A) ⇒ B): B\nreduceRight: reduceRight[B >: A](op: (A, B) ⇒ B): B\nreduceLeft从列表的左边往右边应用reduce函数，reduceRight从列表的右边往左边应用reduce函数\nExample\n```\nval nums = List(2.0,2.0,3.0)\nval resultLeftReduce = nums.reduceLeft(math.pow)  // = pow( pow(2.0,2.0) , 3.0) = 64.0\nval resultRightReduce = nums.reduceRight(math.pow) // = pow(2.0, pow(2.0,3.0)) = 256.0\n```\n5.fold,foldLeft,foldRight\nfold: fold[A1 >: A](z: A1)(op: (A1, A1) ⇒ A1): A1 带有初始值的reduce,从一个初始值开始，从左向右将两个元素合并成一个，最终把列表合并成单一元素。\nfoldLeft: foldLeft[B](z: B)(f: (B, A) ⇒ B): B 带有初始值的reduceLeft\nfoldRight: foldRight[B](z: B)(op: (A, B) ⇒ B): B 带有初始值的reduceRight\n```\nval nums = List(2,3,4)\nval sum = nums.fold(1)(_+_)  // = 1+2+3+4 = 9\n\nval nums = List(2.0,3.0)\nval result1 = nums.foldLeft(4.0)(math.pow) // = pow(pow(4.0,2.0),3.0) = 4096\nval result2 = nums.foldRight(1.0)(math.pow) // = pow(1.0,pow(2.0,3.0)) = 8.0\n```\n6.sortBy,sortWith,sorted\nsortBy: sortBy[B](f: (A) ⇒ B)(implicit ord: math.Ordering[B]): List[A] 按照应用函数f之后产生的元素进行排序\nsorted： sorted[B >: A](implicit ord: math.Ordering[B]): List[A] 按照元素自身进行排序\nsortWith： sortWith(lt: (A, A) ⇒ Boolean): List[A] 使用自定义的比较函数进行排序\n```\nval nums = List(1,3,2,4)\nval sorted = nums.sorted  //List(1,2,3,4)\n\nval users = List((\"HomeWay\",25),(\"XSDYM\",23))\nval sortedByAge = users.sortBy{case(user,age) => age}  //List((\"XSDYM\",23),(\"HomeWay\",25))\nval sortedWith = users.sortWith{case(user1,user2) => user1._2 < user2._2} //List((\"XSDYM\",23),(\"HomeWay\",25))\n```\n7.filter, filterNot\nfilter: filter(p: (A) ⇒ Boolean): List[A]\nfilterNot: filterNot(p: (A) ⇒ Boolean): List[A]\nfilter 保留列表中符合条件p的列表元素 ， filterNot，保留列表中不符合条件p的列表元素\n```\nval nums = List(1,2,3,4)\nval odd = nums.filter( _ % 2 != 0) // List(1,3)\nval even = nums.filterNot( _ % 2 != 0) // List(2,4)\n```\n\n8.count\ncount(p: (A) ⇒ Boolean): Int\n计算列表中所有满足条件p的元素的个数，等价于 filter(p).length\n```\nval nums = List(-1,-2,0,1,2) \nval plusCnt1 = nums.count(_> 0) \nval plusCnt2 = nums.filter(_> 0).length \n```\n9. diff, union, intersect\n  diff:diff(that: collection.Seq[A]): List[A] 保存列表中那些不在另外一个列表中的元素，即从集合中减去与另外一个集合的交集\n  union : union(that: collection.Seq[A]): List[A] 与另外一个列表进行连结\n  intersect: intersect(that: collection.Seq[A]): List[A] 与另外一个集合的交集\n```\nval nums1 = List(1,2,3)\nval nums2 = List(2,3,4)\nval diff1 = nums1 diff nums2   // List(1)\nval diff2 = nums2.diff(num1)   // List(4)\nval union1 = nums1 union nums2  // List(1,2,3,2,3,4)\nval union2 = nums2 ++ nums1        // List(2,3,4,1,2,3)\nval intersection = nums1 intersect nums2  //List(2,3)\n```\n10.distinct\n\ndistinct: List[A] 保留列表中非重复的元素，相同的元素只会被保留一次\n```\nval list = List(\"A\",\"B\",\"C\",\"A\",\"B\") val distincted = list.distinct // List(\"A\",\"B\",\"C\")1\n```\n11.groupBy, grouped\ngroupBy : groupBy[K](f: (A) ⇒ K): Map[K, List[A]] 将列表进行分组，分组的依据是应用f在元素上后产生的新元素 \ngrouped: grouped(size: Int): Iterator[List[A]] 按列表按照固定的大小进行分组\n```\nval data = List((\"HomeWay\",\"Male\"),(\"XSDYM\",\"Femail\"),(\"Mr.Wang\",\"Male\"))\nval group1 = data.groupBy(_._2) // = Map(\"Male\" -> List((\"HomeWay\",\"Male\"),(\"Mr.Wang\",\"Male\")),\"Female\" -> List((\"XSDYM\",\"Femail\")))\nval group2 = data.groupBy{case (name,sex) => sex} // = Map(\"Male\" -> List((\"HomeWay\",\"Male\"),(\"Mr.Wang\",\"Male\")),\"Female\" -> List((\"XSDYM\",\"Femail\")))\nval fixSizeGroup = data.grouped(2).toList // = Map(\"Male\" -> List((\"HomeWay\",\"Male\"),(\"XSDYM\",\"Femail\")),\"Female\" -> List((\"Mr.Wang\",\"Male\")))\n```\n12.scan\nscan[B >: A, That](z: B)(op: (B, B) ⇒ B)(implicit cbf: CanBuildFrom[List[A], B, That]): That\n由一个初始值开始，从左向右，进行积累的op操作，这个比较难解释，具体的看例子吧。\n```\nval nums = List(1,2,3)\nval result = nums.scan(10)(_+_)   // List(10,10+1,10+1+2,10+1+2+3) = List(10,11,13,16)\n```\n13.scanLeft,scanRight\nscanLeft: scanLeft[B, That](z: B)(op: (B, A) ⇒ B)(implicit bf: CanBuildFrom[List[A], B, That]): That\nscanRight: scanRight[B, That](z: B)(op: (A, B) ⇒ B)(implicit bf: CanBuildFrom[List[A], B, That]): That\nscanLeft: 从左向右进行scan函数的操作，scanRight：从右向左进行scan函数的操作\n```\nval nums = List(1.0,2.0,3.0)\nval result = nums.scanLeft(2.0)(math.pow)   // List(2.0,pow(2.0,1.0), pow(pow(2.0,1.0),2.0),pow(pow(pow(2.0,1.0),2.0),3.0) = List(2.0,2.0,4.0,64.0)\nval result = nums.scanRight(2.0)(math.pow)  // List(2.0,pow(3.0,2.0), pow(2.0,pow(3.0,2.0)), pow(1.0,pow(2.0,pow(3.0,2.0))) = List(1.0,512.0,9.0,2.0)\n```\n\n14.take,takeRight,takeWhile\ntake : takeRight(n: Int): List[A] 提取列表的前n个元素 takeRight: takeRight(n: Int): List[A] 提取列表的最后n个元素 takeWhile: takeWhile(p: (A) ⇒ Boolean): List[A] 从左向右提取列表的元素，直到条件p不成立\n```\nval nums = List(1,1,1,1,4,4,4,4)\nval left = nums.take(4)   // List(1,1,1,1)\nval right = nums.takeRight(4) // List(4,4,4,4)\nval headNums = nums.takeWhile( _ == nums.head)  // List(1,1,1,1)\n```\n\n15.drop,dropRight,dropWhile\ndrop: drop(n: Int): List[A] 丢弃前n个元素，返回剩下的元素 dropRight: dropRight(n: Int): List[A] 丢弃最后n个元素，返回剩下的元素 dropWhile: dropWhile(p: (A) ⇒ Boolean): List[A] 从左向右丢弃元素，直到条件p不成立\n```\nval nums = List(1,1,1,1,4,4,4,4)\nval left = nums.drop(4)   // List(4,4,4,4)\nval right = nums.dropRight(4) // List(1,1,1,1)\nval tailNums = nums.dropWhile( _ == nums.head)  // List(4,4,4,4)\n```\n\n16.span, splitAt, partition\nspan : span(p: (A) ⇒ Boolean): (List[A], List[A]) 从左向右应用条件p进行判断，直到条件p不成立，此时将列表分为两个列表\nsplitAt: splitAt(n: Int): (List[A], List[A]) 将列表分为前n个，与，剩下的部分\npartition: partition(p: (A) ⇒ Boolean): (List[A], List[A]) 将列表分为两部分，第一部分为满足条件p的元素，第二部分为不满足条件p的元素\n```\nval nums = List(1,1,1,2,3,2,1)\nval (prefix,suffix) = nums.span( _ == 1) // prefix = List(1,1,1), suffix = List(2,3,2,1)\nval (prefix,suffix) = nums.splitAt(3)  // prefix = List(1,1,1), suffix = List(2,3,2,1)\nval (prefix,suffix) = nums.partition( _ == 1) // prefix = List(1,1,1,1), suffix = List(2,3,2)\n```\n\n17.padTo\n```\npadTo(len: Int, elem: A): List[A]\n将列表扩展到指定长度，长度不够的时候，使用elem进行填充，否则不做任何操作。\n val nums = List(1,1,1)\n val padded = nums.padTo(6,2)   // List(1,1,1,2,2,2)\n```\n\n18.combinations,permutations\n```\ncombinations: combinations(n: Int): Iterator[List[A]] 取列表中的n个元素进行组合，返回不重复的组合列表，结果一个迭代器\npermutations: permutations: Iterator[List[A]] 对列表中的元素进行排列，返回不重得的排列列表，结果是一个迭代器\nval nums = List(1,1,3)\nval combinations = nums.combinations(2).toList //List(List(1,1),List(1,3))\nval permutations = nums.permutations.toList        // List(List(1,1,3),List(1,3,1),List(3,1,1))\n```\n19.zip, zipAll, zipWithIndex, unzip,unzip3\nzip: zip[B](that: GenIterable[B]): List[(A, B)] 与另外一个列表进行拉链操作，将对应位置的元素组成一个pair，返回的列表长度为两个列表中短的那个\nzipAll: zipAll[B](that: collection.Iterable[B], thisElem: A, thatElem: B): List[(A, B)] 与另外一个列表进行拉链操作，将对应位置的元素组成一个pair，若列表长度不一致，自身列表比较短的话使用thisElem进行填充，对方列表较短的话使用thatElem进行填充\nzipWithIndex：zipWithIndex: List[(A, Int)] 将列表元素与其索引进行拉链操作，组成一个pair\nunzip: unzip[A1, A2](implicit asPair: (A) ⇒ (A1, A2)): (List[A1], List[A2]) 解开拉链操作\nunzip3: unzip3[A1, A2, A3](implicit asTriple: (A) ⇒ (A1, A2, A3)): (List[A1], List[A2], List[A3]) 3个元素的解拉链操作\n```\nval alphabet = List(\"A\",B\",\"C\")\nval nums = List(1,2)\nval zipped = alphabet zip nums   // List((\"A\",1),(\"B\",2))\nval zippedAll = alphabet.zipAll(nums,\"*\",-1)   // List((\"A\",1),(\"B\",2),(\"C\",-1))\nval zippedIndex = alphabet.zipWithIndex  // List((\"A\",0),(\"B\",1),(\"C\",3))\nval (list1,list2) = zipped.unzip        // list1 = List(\"A\",\"B\"), list2 = List(1,2)\nval (l1,l2,l3) = List((1, \"one\", '1'),(2, \"two\", '2'),(3, \"three\", '3')).unzip3   // l1=List(1,2,3),l2=List(\"one\",\"two\",\"three\"),l3=List('1','2','3')\n```\n20.slice\nslice(from: Int, until: Int): List[A] 提取列表中从位置from到位置until(不含该位置)的元素列表\n```\nval nums = List(1,2,3,4,5)\nval sliced = nums.slice(2,4)  //List(3,4)\n```\n21.sliding\nsliding(size: Int, step: Int): Iterator[List[A]] 将列表按照固定大小size进行分组，步进为step，step默认为1,返回结果为迭代器\n```\nval nums = List(1,1,2,2,3,3,4,4)\nval groupStep2 = nums.sliding(2,2).toList  //List(List(1,1),List(2,2),List(3,3),List(4,4))\nval groupStep1 = nums.sliding(2).toList //List(List(1,1),List(1,2),List(2,2),List(2,3),List(3,3),List(3,4),List(4,4)) \n```\n\n22.updated\nupdated(index: Int, elem: A): List[A] 对列表中的某个元素进行更新操作\n```\nval nums = List(1,2,3,3)\nval fixed = nums.updated(3,4)  // List(1,2,3,4)\n```\n\n## 十五.快学scala练习题\n\n练习：\n\n1.设置一个映射,其中包含你想要的一些装备，以及它们的价格。然后构建另一个映射，采用同一组键，但是价格上打9折\n\n```\nscala> val price = Map(\"ipad\" -> 4000,\"iPhone\" -> 6000, \"iWatch\" -> 3000)\nprice: scala.collection.immutable.Map[String,Int] = Map(ipad -> 4000, iPhone ->\n6000, iWatch -> 3000)\n\nscala> val newprice = for((k,v) <- price) yield (k, v * 0.9)\nnewprice: scala.collection.immutable.Map[String,Double] = Map(ipad -> 3600.0, iP\nhone -> 5400.0, iWatch -> 2700.0)\n```\n2.编写一段程序，从文件中读取单词。用一个可变映射来清点每个单词出现的频率。读取这些单词的操作可以使用java.util.Scanner:\nval in = new java.util.Scanner(new java.io.File(\"myfile.txt\")) while(in.hasNext()) 处理 in.next()最后，打印出所有单词和它们出现的次数。\n```\nimport scala.io.Source\nimport scala.collection.mutable.HashMap\nobject Pract {\n   def main(args: Array[String])  = {\n      val source = Source.fromFile(\"file.txt\").mkString\n      val tokens = source.split(\"\\s+\")\n      val map = new HashMap[String,Int]\n  for(key <- tokens){\n    map(key) = map.getOrElse(key, 0) + 1\n  }\n  println(map.mkString(\",\"))      \n   }\n}\n```\n3.重复前一个练习，这次用不可变的映射\n不可变映射与可变映射的区别就是每次添加新的元素时都会返回一个新的映射。\n\n```\nimport scala.io.Source\nobject Pract {\n   def main(args: Array[String])  = {\n      val source = Source.fromFile(\"file.txt\").mkString\n      val tokens = source.split(\"\\s+\")\n      var map = MapString,Int //注意这里用的 var 了\n\n  for(key <- tokens){\n      map += (key -> (map.getOrElse(key, 0) + 1))\n  }\n  println(map.mkString(\",\"))      \n   }\n}\n```\n4.重复前一个练习，这次使用已排序的映射，以便单词可以按顺序打印出来\n```\nimport scala.io.Source\nimport scala.collection.SortedMap\n\nobject Pract {\n   def main(args: Array[String])  = {\n      val source = Source.fromFile(\"file.txt\").mkString\n      val tokens = source.split(\"\\s+\")\n      var sortedmap = SortedMapString,Int //注意这里用的 var 了\n\n  for(key <- tokens){\n      sortedmap += (key -> (sortedmap.getOrElse(key, 0) + 1))\n  }\n  println(sortedmap.mkString(\",\"))      \n   }\n}\n```\n5.重复前一个练习，这次使用java.util.TreeMap并使之适用于Scala API\n```\nimport scala.io.Source\nimport scala.collection.mutable.Map\nimport scala.collection.JavaConversions.mapAsScalaMap\nimport java.util.TreeMap\n\nobject Pract {\n   def main(args: Array[String])  = {\n      val source = Source.fromFile(\"file.txt\").mkString\n      val tokens = source.split(\"\\s+\")\n      val map:Map[String,Int] = new TreeMap[String,Int]\n\n  for(key <- tokens){\n     map(key) = map.getOrElse(key, 0) + 1\n  }\n  println(map.mkString(\",\"))   \n   }\n}\n```\n6.定义一个链式哈希映射,将\"Monday\"映射到java.util.Calendar.MONDAY,依次类推加入其他日期。展示元素是以插入的顺序被访问的\n```\nimport scala.collection.mutable.LinkedHashMap\nimport java.util.Calendar\n\nobject Pract {\n   def main(args: Array[String])  = {\n      val map = new LinkedHashMap[String, Int]\n      map += (\"MONDAY\" -> Calendar.MONDAY)\n      map += (\"TUESDAY\" -> Calendar.TUESDAY)\n      map += (\"WENDSDAY\" -> Calendar.WEDNESDAY)\n      map += (\"THURSDAY\" -> Calendar.THURSDAY)\n      map += (\"FRIDAY\" -> Calendar.FRIDAY)\n      map += (\"SATURDAY\" -> Calendar.SATURDAY)\n      map += (\"SUNDAY\" -> Calendar.SUNDAY)\n      println(map.mkString(\",\"))\n   }\n}\n```\n\n7.打印出所有Java系统属性的表格\n\nJAVA系统属性转scala map的使用\n\n```\nimport scala.collection.JavaConversions.propertiesAsScalaMap\nimport scala.collection.Map\n\nobject Pract {\n   def main(args: Array[String])  = {\n      val props: Map[String,String] = System.getProperties\n      val keys = props.keySet\n      val keylength = for( key <- keys) yield key.length\n      val maxlength = keylength.max\n      for( key <- keys) {\n        print(key)\n        print(\" \" * (maxlength - key.length))\n        print(\"| \")\n        println(props(key))\n      }\n\n   }\n}\n```\n8.编写一个函数minmax(values:Array[Int]),返回数组中最小值和最大值的对偶\n```\ndef minmax(values:Array[Int])  = {\n     (values.max,values.min)\n   }\n```\n9.编写一个函数Iteqgt(values:Array[int],v:Int),返回数组中小于v,等于v和大于v的数量，要求三个值一起返回\n\n```\ndef Iteqgt(values:Array[Int],v:Int) = {\n     var a,b,c=0\n     for(value <- values){\n       if(value > v) a += 1\n       else if(value == v) b += 1\n       else c += 1\n     }\n     (a,b,c)\n   }\n\n   def Iteqgt1(values:Array[Int],v:Int) = {\n     (values.count( > v),values.count( == v), values.count(_ < v))\n   }\n```\n10.当你将两个字符串拉链在一起，比如\"Hello\".zip(\"World\")，会是什么结果？想出一个讲得通的用例\n```\nscala> \"Hello\".zip(\"world\")\nres0: scala.collection.immutable.IndexedSeq[(Char, Char)] = Vector((H,w), (e,o),\n (l,r), (l,l), (o,d))\n\n```\n\n## 十六.构造器\n\nScala的类可以有一个主构造器和多个辅助构造器。每个辅助构造器的名称为this，每一个辅助构造器都必须以调用已经定义的辅助构造器或主构造器开始定义\n\n- 主构造器\n\n\n> 如果一个类没有显示定义主构造器，则有一个默认的无参主构造器     如定义一个Student类\n\n```\nclass Student(val name:String, var age:Int = 0, address:String = \"\", private var school:String = \"\"){\n    var grade:Int = if( age>7 ) age -7 else 0\n    println(\" I'm in main constructor. \")\n    def info() = \" name is \"+name+\", age is \"+age+\", address is \"+address\n}\n```\n　　对于Scala类，主构造器的参数放置在类名后，由括号括起来。且对于主构造器中var、val、private 等标注的参数，都会成为类的对应字段，并生成对应的默认getter、setter方法。如Student类中的name、age、school等。对于主构造器中的未用var、val标注的参数，如果在类的任何一个方法用用到该参数，该参数将会转换为类的字段，否则不会，如Student类的address属性。\n\n　　由于在Student类中的info方法中用到了参数address，所以Student共有name、age、address、school、grade等5个属性，且Scala根据对应属性的特点生成了默认的getter和setter方法。\n\n　　对于主构造器的参数，也可以提供参数默认值。通过为主构造器提供默认值可减少辅助构造器的个数\n　　主构造器的函数体，是类中除了方法定义以外的其他语句，如在Student类的主构造器中，包含grade属性的初始化和prinln这两行语句。\n\n![](https://static.oschina.net/uploads/space/2018/1116/110347_10HB_3005534.png)\n\n- 辅助构造器\n>  辅助构造器通过this来定义，且必须首先调用主构造器或者其他已经定义的辅助构造器。\n\n```\nclass Person(val name:String){\n    var age = 0\n    var sex:Char = 'f'\n    println(\"main constructor...\")\n\n    def this(name:String,  age:Int){\n        this(name)        //调用主构造器\n        this.age = age     //使用this关键字\n        println(\" auxiliary constructor1 \")\n    }\n\n    def this(name:String, age:Int, sex:Char){\n        this(name, age)\n        this.sex = sex\n        println(\" auxiliary constructor2 \")\n    }\n}\n```\n\n> 【注：辅助构造器的参数前不能添加val、var标志，否则会报错。】\n\n![](https://static.oschina.net/uploads/space/2018/1116/110550_hUV6_3005534.png)\n\n- 私有主构造器\n\n\n```\nclass Person private(val name:String){\n    var age:Int = 1\n    def this(name: String, age:Int){\n        this(name)\n        this.age = age\n    }\n}\n```\n\n\n\n\n\n# hadoop\n\n## 一.Nodepad远程linux插件NppFTP\n\n**1.在该github上下载自己notepad++对应版本位数的插件**\n[NppFTP下载地址](https://github.com/ashkulz/NppFTP/releases/tag/v0.27.6 )：https://github.com/ashkulz/NppFTP/releases/tag/v0.27.6\n\n> 下载时可以因为被墙的原因下载不了，如果有跨网服务器，直接wget 实际下载地址\n> ![输入图片说明](https://static.oschina.net/uploads/img/201901/11105326_7IeQ.png \"在这里输入图片标题\")\n\n> 软件如果下载不了 可以到百度网盘qq939598604/我的软件/NppFTP目录下下载\n\n**2.下载之后进行解压，然后将bin目录下的dll文件拷贝到notepad++的安装目录下的插件目录**\nnotepad++的安装目录可以右键notepad++的快捷方式，找到安装目录\n![输入图片说明](https://static.oschina.net/uploads/img/201901/11105635_bvCw.png \"在这里输入图片标题\")\n![输入图片说明](https://static.oschina.net/uploads/img/201901/11105728_rL2U.png \"在这里输入图片标题\") \n\n**3.重启notepad++**\n\n**4.重启后，在插件菜单中会显示该插件**\n![输入图片说明](https://static.oschina.net/uploads/img/201901/11105829_SBf5.png \"在这里输入图片标题\")\n\n**5.NppFTP使用**\n![输入图片说明](https://static.oschina.net/uploads/img/201901/11110929_I4h9.png \"在这里输入图片标题\")\n![输入图片说明](https://static.oschina.net/uploads/img/201901/11110936_ZoEY.png \"在这里输入图片标题\")\n![输入图片说明](https://static.oschina.net/uploads/img/201901/11110948_7ATB.png \"在这里输入图片标题\")\n![输入图片说明](https://static.oschina.net/uploads/img/201901/11110955_AfYH.png \"在这里输入图片标题\")\n\n![输入图片说明](https://static.oschina.net/uploads/img/201901/11112540_Mc1p.png \"在这里输入图片标题\")\n\n\n\n##  二.实现linux集群所有机器免密钥登录\n\n**1.先安装expect** \n```\nyum install expect\n```\n**2.生成密钥 **\n```\nssh-keygen(注,一路回车,不用管)\n```\n**3.修改host文件 /etc/hosts**\n```\n192.168.197.21 master\n192.168.197.25 slave1\n192.168.197.27 slave2 \n```\n**4.编写shell脚本 vim.ssh_copy_id_to_all.sh**\n```\n#!/bin/bash\nSERVERS=\"master slave1 slave2\"\nPASSWORD=root\nauto_ssh_copy_id() {\n    expect -c \"set timeout -1;\n        spawn ssh-copy-id $1;\n        expect {\n            *(yes/no)* {send -- yes\\r;exp_continue;}\n            *assword:* {send -- $2\\r;exp_continue;}\n            eof        {exit 0;}\n        }\";\n}\n\nssh_copy_id_to_all() {\n    for SERVER in $SERVERS\n    do\n        auto_ssh_copy_id $SERVER $PASSWORD\n    done\n}\n\nssh_copy_id_to_all\n```\n**5.chomd +x ssh_copy_id_to_all.sh**\n**6.执行脚本**\n./ssh_copy_id_to_all.sh\n\n## 三.Windows安装部署hadoop-2.7.5\n\n**(1).编辑“M:\\soft\\hadoop-2.7.5\\etc\\hadoop”下的core-site.xml文件，将下列文本粘贴进去，并保存；**\n\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n<configuration>\n    <property>\n        <name>hadoop.tmp.dir</name>\n        <value>/M:/soft/hadoop-2.7.5/tmp</value>\n    </property>\n    <property>\n        <name>dfs.name.dir</name>\n        <value>/M:/soft/hadoop-2.7.5/name</value>\n    </property>\n    <property>\n        <name>fs.default.name</name>\n        <value>hdfs://localhost:9000</value>\n    </property>\n</configuration>\n```\n\n**(2).编辑“M:\\soft\\hadoop-2.7.5\\etc\\hadoop”目录下的mapred-site.xml(没有就将mapred-site.xml.template重命名为mapred-site.xml)文件，粘贴一下内容并保存:**\n\n```\n<?xml version=\"1.0\"?>\n<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n<configuration>\n    <property>\n       <name>mapreduce.framework.name</name>\n       <value>yarn</value>\n    </property>\n    <property>\n       <name>mapred.job.tracker</name>\n       <value>hdfs://localhost:9001</value>\n    </property>\n</configuration>\n```\n\n**(3).编辑“M:\\soft\\hadoop-2.7.5\\etc\\hadoop”目录下的hdfs-site.xml文件，粘贴以下内容并保存。请自行创建data目录，在这里我是在HADOOP_HOME目录下创建了data目录:**\n\n```\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n<configuration>\n    <!-- 这个参数设置为1，因为是单机版hadoop -->\n    <property>\n        <name>dfs.replication</name>\n        <value>1</value>\n    </property>\n    <property>\n        <name>dfs.data.dir</name>\n        <value>/M:/soft/hadoop-2.7.5/data</value>\n    </property>\n</configuration>\n```\n\n**(4).编辑“M:\\soft\\hadoop-2.7.5\\etc\\hadoop”目录下的yarn-site.xml文件，粘贴以下内容并保存；**\n\n```\n<?xml version=\"1.0\"?>\n<configuration>\n    <property>\n       <name>yarn.nodemanager.aux-services</name>\n       <value>mapreduce_shuffle</value>\n    </property>\n    <property>\n       <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>\n       <value>org.apache.hadoop.mapred.ShuffleHandler</value>\n    </property>\n</configuration>\n```\n\n**(5).编辑“M:\\soft\\hadoop-2.7.5\\etc\\hadoop”目录下的hadoop-env.cmd文件，将JAVA_HOME用 @rem注释掉，编辑为JAVA_HOME的路径，然后保存:**\n\n```\n@rem set JAVA_HOME=%JAVA_HOME%\nset JAVA_HOME=M:\\soft\\Java\\jdk1.8.0_101\n```\n\n**替换文件** 将下载好的hadooponwindows-master.zip（笔记第一步有下载地址，不知道可以去笔记开头的需求栏目查看）解压，将解压后的**\\*bin目录下的所有文件直接覆盖Hadoop的bin目录***。\n\n## 四.hadoop集群安装\n\n**（一）.安装环境 ：所有的软件安装在根目录下的/soft目录**\n\njava---/soft/jdk1.0.8\nhadoop--/soft/hadoop2.7.4\n固定hadoop配置变量(JAVA_HOME,主机名称,hadoop的固定目录)可以不用安装那么多\nhadoop-env.sh 文件:\n```\nexport JAVA_HOME=/soft/jdk1.0.8\n```\ncore-site.xml文件: \n```\n<name>fs.defaultFS</name>\n<value>hdfs://node1:9000</value>\n```\nhdfs-site.xml文件：\n```\n<name>dfs.namenode.name.dir</name>\n<value>file:/soft/hadoop-2.7.4/tmp/dfs/name</value>\n```\nslaves文件\n```\nslave1   slave2 \n```\n\n集群规划\n主机名           ip          安装的软件         进程\nmaster   192.168.197.255  jdk、hadoop  namenode ressourcemanager\nslave1   192.168.197.256  jdk、hadoop  datanode secondnamenode\nslave2   192.168.197.257  jdk、hadoop  datanade\n\n**（二）.安装JDK** \n\n1.下载jdk1.8.0_161\n2.在/etc/profile中添加如下配置\nsudo vim /etc/profile\n```\nexport JAVA_HOME=/soft/jdk1.8.0_161\nexport JRE_HOME=${JAVA_HOME}/jre\nexport CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib\nexport PATH=${JAVA_HOME}/bin:$PATH\n```\n3.使环境变量生效，source /etc/profile\n4.安装验证# java -version \n\n\n**（三）.准备host文件和修改主机名称**\n1.vim /etc/hosts\n```\n192.168.197.225 master\n192.168.197.226 slave1\n192.168.197.227 slave2\n```\n2.拷贝/etc/hosts到其它主机\n   scp /etc/hosts slave1:/etc/\n   scp /etc/hosts slave2:/etc/\n\n3.修改主机名\n   vim /etc/hosts  \n   master slave1 slave2 \n\n**（四）.免登录**\n1.注意将防火墙关掉\nCentOS7 \n\n```\n (1)关闭防火墙：sudo systemctl stop firewalld.service\n (2)关闭开机启动：sudo systemctl disable firewalld.service\n (3)安装iptables防火墙：sudo yum install iptables-services\n (4)设置iptables防火墙开机启动：sudo systemctl enable iptables\n```\n\nubuntu\n\n```\n(1)关闭ubuntu的防火墙 ufw disable\n(2)开启防火墙 ufw enable\n(3)卸载了iptables apt-get remove iptables \n(4)关闭ubuntu中的防火墙的其余命令\n    iptables -P INPUT ACCEPT\n    iptables -P FORWARD ACCEPT\n    iptables -P OUTPUT ACCEPT\n    iptables -F\n```\n\n2.ssh无密登录,\n(1)在集群/etc/ssh/sshd_config 文件去掉以下选项的注释\nsudo vim /etc/ssh/sshd_config\n```\nPort 22\nProtocol 2\nRSAAuthentication yes      #开启私钥验证\nPubkeyAuthentication yes   #开启公钥验证\n```\n3.生成秘钥\n(1)在主从节点(集群的每一个节点节点)输入命令 ，生成 key，一律回车\n   ssh-keygen -t rsa -P ''\n(2)将从节点(集群的每一个节点节点)公钥收集到一个文件中authorized_keys，并发送到各个节点\n从节点配置：\n      在slave1的机器：scp /home/chen/.ssh/id_rsa.pub master:/home/chen/.ssh/id_rsa.pub.s1\n      在slave2的机器：scp /home/chen/.ssh/id_rsa.pub master:/home/chen/.ssh/id_rsa.pub.s2\n主节点配置：\n(3)将所有机器的id_rsa.pub文件收集到authorized_keys，并发送到各个节点\n   sudo cat /home/chen/.ssh/id_rsa.pub >> /home/chen/.ssh/authorized_keys\n   sudo cat /home/chen/.ssh/id_rsa.pub.s1 >> /home/chen/.ssh/authorized_keys\n   sudo cat /home/chen/.ssh/id_rsa.pub.s2 >> /home/chen/.ssh/authorized_keys\n(4)最后将生成的包含三个节点的秘钥的authorized_keys 复制到s1和s2的.ssh目录下（ \n   scp /home/chen/.ssh/authorized_keys slave1:/home/chen/.ssh/\n   scp /home/chen/.ssh/authorized_keys slave2:/home/chen/.ssh/\n\n验证ssh免密码登录\n1.输入命令ssh  localhost(主机名) 根据提示输入“yes” \n2.输入命令exit注销（Logout）\n3.再次输入命令ssh localhost即可直接登录\n\n\n**（五）hadoop的配置**\n(1)编辑 hadoop-env.sh 文件,找到 JAVA_HOME 改为 JDK 的安装目录\n   sudo vim /soft/hadoop-2.7.4/etc/hadoop/hadoop-env.sh\n   export JAVA_HOME=/soft/jdk1.8.0_161\n(2)修改 core-site.xml\n   sudo vim core-site.xml\n   ```\n<configuration>\n       <property>\n           <name>fs.defaultFS</name>\n           <value>hdfs://master:9000</value>\n       </property>\n       <property>\n           <name>hadoop.tmp.dir</name>\n           <value>file:/soft/hadoop-2.7.4/tmp</value>\n       </property>\n   </configuration>\n   ```\n(2)修改 hdfs-site.xml\n   sudo vim hdfs-site.xml\n```\n<configuration>\n    <property>\n        <name>dfs.namenode.secondary.http-address</name>\n        <value>master:50090</value>\n    </property>\n    <property>\n        <name>dfs.replication</name>\n        <value>2</value>\n    </property>\n    <property>\n        <name>dfs.namenode.name.dir</name>\n        <value>file:/soft/hadoop-2.7.4/tmp/dfs/name</value>\n    </property>\n    <property>\n        <name>dfs.datanode.data.dir</name>\n        <value>file:/soft/hadoop-2.7.4/tmp/dfs/data</value>\n    </property>\n</configuration>\n```\n(3)修改 mapred-site.xml\n目录下么没有这个文件,这有一个模板,我们需要先拷贝一份\n cp mapred-site.xml.template mapred-site.xml\n vim  mapred-site.xml\n```\n<configuration>\n    <property>\n        <name>mapreduce.framework.name</name>\n        <value>yarn</value>\n    </property>\n    <property>\n        <name>mapreduce.jobhistory.address</name>\n        <value>master:10020</value>\n    </property>\n    <property>\n        <name>mapreduce.jobhistory.webapp.address</name>\n        <value>master:19888</value>\n    </property>\n</configuration>\n```\n(4)修改 yarn-site.xml\nvi yarn-site.xml\n```\n<configuration>\n    <property>\n        <name>yarn.resourcemanager.hostname</name>\n        <value>master</value>\n    </property>\n    <property>\n        <name>yarn.nodemanager.aux-services</name>\n        <value>mapreduce_shuffle</value>\n    </property>\n</configuration>\n```\n\n**（六）配置集群**\n(1)复制节点,将hadoop-2.7.4 文件夹重打包后复制到其他子节点\n```\nscp /soft/hadoop-2.7.4/ chen@slave1:/soft\nscp /soft/hadoop-2.7.4/ chen@slave2:/soft\n```\n(2)配置slaves文件\n修改（Master主机）/soft/hadoop-2.7.4/etc/hadoop/slaves该文件指定哪些服务器节点是datanode节点。删除locahost，添加所有datanode节点的主机名\nsudo vim /soft/hadoop-2.7.4/etc/hadoop/slaves\n```\nslave1\nslave2\n```\n(3)格式化namenode和datanode并启动，（在master上执行就可以了 不需要在slave上执行）\n```\ncd /soft/hadoop-2.7.4/bin\n./hadoop namenode -format\n./hadoop datanode -format\n```\n\n**（七）启动 hadoop**\n\ncd /soft/hadoop-2.7.4/sbin\n./start-dfs.sh\n./start-yarn.sh\n./mr-jobhistory-daemon.sh start historyserver\n或者\n./start-all.sh\n./mr-jobhistory-daemon.sh start historyserver\n\n**（八）查看进程服务**\n查看启动进程,缺少以下任一进程都表示出错\n$ jps\n2528 NameNode\n2720 SecondaryNameNode\n2872 ResourceManager\n3151 JobHistoryServer\n查看端口占用情况\nnetstat -tnlp | grep java\n访问master\nhttp://192.168.197.255:50070\nhttp://192.168.197.255:8088\n\n**（九）停止 hadoop**\ncd /soft/hadoop-2.7.4/sbin\n./stop-all.sh\n\n#  \n\n#  hbase\n\n## 一.hbase在linux系统本地模式\n\n1.安装好jdk\n2.下载hbase hbase 下载地址：http://hbase.apache.org/\n\n```\nhbase-2.0.2-bin.tar.gz\n```\n3.上传到linux服务的/soft目录下\n4.tar 开hbase压缩包\n```\ntar -zxvf /soft/hbase-2.0.2-bin.tar.gz -C /soft/\n```\n5.修改conf/hbase-env.sh \nvim /soft/hbase-2.0.2/conf/hbase-env.sh\n```\nexport JAVA_HOME=/soft/jdk1.8.0_161\n```\n6.编辑hbase-site.xml \n```\n<configuration>\n    <property>\n        <name>hbase.rootdir</name>\n        <value>file:///soft/hbase-2.0.2/data</value>\n    </property>\n</configuration>\n\n```\n7.新建hbase数据存放目录\n```\nmkdir /soft/hbase-2.0.2/data\n```\n8.启动hbase\n```\ncd /soft/hbase-2.0.2/bin\n./bin/start-hbase.sh\n```\n9.jps 查看后 出现Hmaster就是启动成功 然后就可以进入shell进行对hbase的操作\n```\n[root@master hbase-2.0.2]# jps\n4359 Main\n5532 Jps\n4829 HMaster\n```\n10.进入hbase shell\n```\n./bin/hbase shell\n```\n11.访问web\n```\nhttp://192.168.197.21:16010/master-status\n```\n\n\n**shell环境测试**\n创建表\n```\nhbase(main):016:0> create 't1', {NAME => 'f1', VERSIONS => 1}\n```\n查看表\n```\nhbase(main):017:0> list\nTABLE\nt1\n1 row(s)\nTook 0.0053 seconds                                                                   \n=> [\"t1\"]\n```\n插入一条数据\n```\nhbase(main):019:0> put 't1', 'r1', 'f1', 'v1'\n```\n扫描t1表的全数据\n```\nhbase(main):018:0>  scan 't1'\nROW                       COLUMN+CELL                                                 \nr1                       column=f1:, timestamp=1540885480142, value=v1                \n1 row(s)\n```\n\n## 二.Hbase在linux集群搭建\n\n软件放置路径为初级配置的路径/soft/hbase-1.3.1\n1.解压已经安装整理过的压缩包hbase-1.3.1-install.tar.gz\n```\ntar -zxvf /soft/hbase-1.3.1-install.tar.gz -C /soft/\n```\n2.修改hbase-env环境变量\nvim /soft/hbase-1.3.1/conf/hbase-env.sh\n```\nexport JAVA_HOME=/soft/jdk1.8.0_161\nexport HBASE_CLASSPATH=/soft/hadoop-2.7.4\nexport HBASE_MANAGES_ZK=false          # 不使用自带的zk，使用独立的zookeeper\n```\n3.修改hbase-site.xml\nvim /soft/hbase-1.3.1/conf/hbase-site.xml    # 配置站点信息\n```\n<configuration>\n    <property>\n        <name>hbase.rootdir</name>\n        <value>hdfs://master:9000/hbase</value>\n    </property>\n    <property>\n        <name>hbase.master</name>\n        <value>master</value>\n    </property>\n    <property>\n        <name>hbase.cluster.distributed</name>\n        <value>true</value>\n    </property>\n    <property>\n        <name>hbase.zookeeper.property.clientPort</name>\n        <value>2181</value>                                     # 这里指的是zook的端口\n    </property>\n    <property>\n        <name>hbase.zookeeper.quorum</name>                     # 主机名一定要对应上\n        <value>master,slave1,slave2</value>\n    </property>\n    <property>\n        <name>zookeeper.session.timeout</name>                  # zook的session超时时长\n        <value>60000000</value>\n    </property>\n    <property>\n        <name>dfs.support.append</name>\n        <value>true</value>\n    </property>\n</configuration>\n```\n4.指定添加regionservers\nvim /soft/hbase-1.3.1/conf/regionservers# 配置从节点 一定要对应上\n```\nmaster\nslave1\nslave2\n```\n5.复制/soft/hbase-1.3.1到各个从的机器\n```\nscp /soft/hbase-1.3.1 root@slave1:/soft/\nscp /soft/hbase-1.3.1 root@slave2:/soft/\n```\n6.在各个节点添加hbase的环境变量\nvim /etc/profile\n```\nexport HBASE_HOME=/soft/hbase-1.3.1\nexport PATH=$HBASE_HOME/bin:$PATH\n```\n7.在master启动hbase\n```\n/soft/hbase-1.3.1/bin/start-hbase.sh\n```\n8.浏览器检查打开master机器的端口16010\nhttp://192.168.197.231:16010/master-status\n\n## 三.hbase在window环境下安装\n\n1.安装jdk\n```\n默认JDK已安装并配置好环境变量，本处用的jdk1.8.0_101 \n```\n2、下载hbase-2.0.2-bin.tar.gz\n```\n解压到C:\\hbase-2.0.2\\目录下\n```\n\n3、下载hadoop-common-2.2.0-bin-master\n```\nhadoop-common-2.2.0-bin-master(包含windows端开发Hadoop2.2需要的winutils.exe)，HBase在Windows下部署需要使用到。    \n地址：https://github.com/srccodes/hadoop-common-2.2.0-bin，下载hadoop-common-2.2.0-bin-master.zip，解压缩到D:\\hadoop\\hadoop-common-2.2.0-bin-master。\n```\n\n4、修改HBase下的conf/hbase-env.cmd\n```\nset JAVA_HOME=M:\\soft\\Java\\jdk1.8.0_101\nset HBASE_MANAGES_ZK=true\n```\n\n5.修改HBase下的hbase-site.xml\n```\n<?xml version=\"1.0\"?>\n<?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?>\n<configuration>\n\t<property>  \n\t\t<name>hbase.rootdir</name>  \n\t\t<value>file:///C:/hbase-2.0.2/data</value>  \n\t</property>  \n\t<property>  \n\t\t<name>hbase.tmp.dir</name>  \n\t\t<value>C:/hbase-2.0.2/tmp</value>  \n\t</property>  \n\t<property>  \n\t\t<name>hbase.zookeeper.quorum</name>  \n\t\t<value>127.0.0.1</value>  \n\t</property>  \n\t<property>  \n\t\t<name>hbase.zookeeper.property.dataDir</name>  \n\t\t<value>C:/hbase-2.0.2/tmp/zoo</value>  \n\t</property>  \n\t<property>  \n\t\t<name>hbase.cluster.distributed</name>  \n\t\t<value>false</value>  \n\t</property>\n</configuration>\n\n```\n\n6.配置用户变量HADOOP_HOME\n```\n新建环境变量HADOOP_HOME，值为C:\\hadoop-common-2.2.0-bin-master\n在path后添加：%HADOOP_HOME%\\bin\n\n```\n\n7.启动HBase\n```\n在C:\\hbase-2.0.2\\bin下打开命令行，输入start-hbase.cmd，启动HBase。\n```\n8.测试Shell\n```\n HBase启动后，在命令行输入hbase shell，打卡HBase的shell命令行\n```\n9.打开HBase主页，网址：http://127.0.0.1:16010/master-status\n10.可以通过测试命令建表测试等等\n\n##  四.hbase的filter操作\n\n**1.创建表**\n```\ncreate 'test1', 'lf', 'sf'\n```\n\n**2.导入数据**\n```\nput 'test1', 'user1|ts1', 'sf:c1', 'sku1'\nput 'test1', 'user1|ts2', 'sf:c1', 'sku188'\nput 'test1', 'user1|ts3', 'sf:s1', 'sku123'\nput 'test1', 'user2|ts4', 'sf:c1', 'sku2'\nput 'test1', 'user2|ts5', 'sf:c2', 'sku288'\nput 'test1', 'user2|ts6', 'sf:s1', 'sku222'\n```\n\n**3.查询案例：谁的值=sku188**\n```\nscan 'test1', FILTER=>\"ValueFilter(=,'binary:sku188')\"\n```\n**#查询结果\n```\nROW                         COLUMN+CELL                    \nuser1|ts2                   column=sf:c1, timestamp=1409122354918, value=sku188\n```\n\n**4.查询案例：谁的值包含88**\n```\nscan 'test1', FILTER=>\"ValueFilter(=,'substring:88')\"\n```\n**#查询结果\n```\n ROW                         COLUMN+CELL    \n user1|ts2                   column=sf:c1, timestamp=1409122354918, value=sku188\n user2|ts5                   column=sf:c2, timestamp=1409122355030, value=sku288\n```\n\n**5.查询案例：谁的值包含88**\n```\nscan 'test1', FILTER=>\"ValueFilter(=,'substring:88')\"\n```\n**#查询结果\n```\n ROW                         COLUMN+CELL    \n user1|ts2                   column=sf:c1, timestamp=1409122354918, value=sku188\n user2|ts5                   column=sf:c2, timestamp=1409122355030, value=sku288\n```\n\n**6.通过广告点击进来的(column为c2)值包含88的用户**\n```\nscan 'test1', FILTER=>\"ColumnPrefixFilter('c2') AND ValueFilter(=,'substring:88')\"\n```\n**#查询结果\n```\n ROW                         COLUMN+CELL\n user2|ts5                   column=sf:c2, timestamp=1409122355030, value=sku288\n```\n\n**7.通过搜索进来的(column为s)值包含123或者222的用户**\n```\nscan 'test1', FILTER=>\"ColumnPrefixFilter('s') AND ( ValueFilter(=,'substring:123') OR ValueFilter(=,'substring:222') )\"\n```\n**#查询结果\n```\n ROW                         COLUMN+CELL\n user1|ts3                   column=sf:s1, timestamp=1409122354954, value=sku123\n user2|ts6                   column=sf:s1, timestamp=1409122355970, value=sku222\n```\n\n**8.rowkey为user1开头的**\n```\nscan 'test1', FILTER => \"PrefixFilter ('user1')\"\n```\n**#查询结果\n```\n ROW                        COLUMN+CELL\n user1|ts1                   column=sf:c1, timestamp=1409122354868, value=sku1\n user1|ts2                   column=sf:c1, timestamp=1409122354918, value=sku188\n user1|ts3                   column=sf:s1, timestamp=1409122354954, value=sku123\n```\n**9.从user1|ts2开始,找到所有的rowkey以user1开头的**\n```\nscan 'test1', {STARTROW=>'user1|ts2', FILTER => \"PrefixFilter ('user1')\"}\n```\n**#查询结果\n```\n ROW                         COLUMN+CELL\n user1|ts2                   column=sf:c1, timestamp=1409122354918, value=sku188\n user1|ts3                   column=sf:s1, timestamp=1409122354954, value=sku123 \n```\n**10.从user1|ts2开始,找到所有的到rowkey以user2开头**\n```\nscan 'test1', {STARTROW=>'user1|ts2', STOPROW=>'user2'}\n```\n**#查询结果\n```\n ROW                          COLUMN+CELL\n user1|ts2                   column=sf:c1, timestamp=1409122354918, value=sku188\n user1|ts3                   column=sf:s1, timestamp=1409122354954, value=sku123\n```\n**11.查询rowkey里面包含ts3的**\n```\nimport org.apache.hadoop.hbase.filter.CompareFilter\nimport org.apache.hadoop.hbase.filter.SubstringComparator\nimport org.apache.hadoop.hbase.filter.RowFilter\nscan 'test1', {FILTER => RowFilter.new(CompareFilter::CompareOp.valueOf('EQUAL'), SubstringComparator.new('ts3'))}\n```\n**#查询结果\n```\n ROW                          COLUMN+CELL\n user1|ts3                   column=sf:s1, timestamp=1409122354954, value=sku123 \n```\n**12.查询rowkey里面包含ts的**\n```\nimport org.apache.hadoop.hbase.filter.CompareFilter\nimport org.apache.hadoop.hbase.filter.SubstringComparator\nimport org.apache.hadoop.hbase.filter.RowFilter\nscan 'test1', {FILTER => RowFilter.new(CompareFilter::CompareOp.valueOf('EQUAL'), SubstringComparator.new('ts'))}\n```\n**#查询结果\n```\n ROW                         COLUMN+CELL\n user1|ts1                   column=sf:c1, timestamp=1409122354868, value=sku1\n user1|ts2                   column=sf:c1, timestamp=1409122354918, value=sku188\n user1|ts3                   column=sf:s1, timestamp=1409122354954, value=sku123\n user2|ts4                   column=sf:c1, timestamp=1409122354998, value=sku2\n user2|ts5                   column=sf:c2, timestamp=1409122355030, value=sku288\n user2|ts6                   column=sf:s1, timestamp=1409122355970, value=sku222\n```\n**13.加入一条测试数据**\n```\nput 'test1', 'user2|err', 'sf:s1', 'sku999'\n```\n\n\n**14.查询rowkey里面以user开头的，新加入的测试数据并不符合正则表达式的规则，故查询不出来**\n```\nimport org.apache.hadoop.hbase.filter.RegexStringComparator\nimport org.apache.hadoop.hbase.filter.CompareFilter\nimport org.apache.hadoop.hbase.filter.SubstringComparator\nimport org.apache.hadoop.hbase.filter.RowFilter\nscan 'test1', {FILTER => RowFilter.new(CompareFilter::CompareOp.valueOf('EQUAL'),RegexStringComparator.new('^user\\d+\\|ts\\d+$'))}\n```\n**#查询结果\n```\n ROW                         COLUMN+CELL\n user1|ts1                   column=sf:c1, timestamp=1409122354868, value=sku1\n user1|ts2                   column=sf:c1, timestamp=1409122354918, value=sku188\n user1|ts3                   column=sf:s1, timestamp=1409122354954, value=sku123\n user2|ts4                   column=sf:c1, timestamp=1409122354998, value=sku2\n user2|ts5                   column=sf:c2, timestamp=1409122355030, value=sku288\n user2|ts6                   column=sf:s1, timestamp=1409122355970, value=sku222\n```\n**15.加入测试数据**\n```\nput 'test1', 'user1|ts9', 'sf:b1', 'sku1'\n```\n**16.b1开头的列中并且值为sku1的**\n```\nscan 'test1', FILTER=>\"ColumnPrefixFilter('b1') AND ValueFilter(=,'binary:sku1')\"\n```\n**#查询结果\n```\n ROW                          COLUMN+CELL                                                   user1|ts9                   column=sf:b1, timestamp=1409124908668, value=sku1\n```\n\n**17.SingleColumnValueFilter的使用，b1开头的列中并且值为sku1的**\n```\nimport org.apache.hadoop.hbase.filter.CompareFilter\nimport org.apache.hadoop.hbase.filter.SingleColumnValueFilter\nimport org.apache.hadoop.hbase.filter.SubstringComparator\nscan 'test1', {COLUMNS => 'sf:b1', FILTER => SingleColumnValueFilter.new(Bytes.toBytes('sf'), Bytes.toBytes('b1'), CompareFilter::CompareOp.valueOf('EQUAL'), Bytes.toBytes('sku1'))}\n```\n**#查询结果\n```\n ROW                         COLUMN+CELL\n user1|ts9                   column=sf:b1, timestamp=1409124908668, value=sku1\n```\n**18.KeyOnlyFilter: 只要key,不要value**\n```\nscan 'test1', FILTER=>\"FirstKeyOnlyFilter() AND ValueFilter(=,'binary:sku188') AND KeyOnlyFilter()\"\n```\n**#查询结果\n```\n ROW                         COLUMN+CELL\n user1|ts2                   column=sf:c1, timestamp=1409122354918, value=\n```\nFirstKeyOnlyFilter: 一个rowkey可以有多个version,同一个rowkey的同一个column也会有多个的值, 只拿出key中的第一个column的第一个version\n\n##  五.hbase的java操作 maven构建\n\n**1.pom.xml文件添加hbase依赖**\n```\n<properties>\n    <hbase.version>2.0.2</hbase.version>\n</properties>\n\n<dependencies>\n    <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-server</artifactId>\n        <version>${hbase.version}</version>\n    </dependency>\n    <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-client</artifactId>\n        <version>${hbase.version}</version>\n    </dependency>\n    <dependency>\n        <groupId>org.apache.hbase</groupId>\n        <artifactId>hbase-common</artifactId>\n        <version>${hbase.version}</version>\n    </dependency>\n</dependencies>\n```\n\n**2.初始化静态方法**\n```\nstatic {\n    Configuration configuration = HBaseConfiguration.create();\n    try {\n        connection = ConnectionFactory.createConnection(configuration);\n        admin = connection.getAdmin();\n    } catch (Exception e) {\n        e.printStackTrace();\n    }\n}\n```\n**3.判断表是否存在**\n```\npublic static boolean isExist(String tableName) throws Exception {\n    return admin.tableExists(TableName.valueOf(tableName));\n}\n```\n**4.创建表**\n```\npublic static void createTable(String tableName,String ... column) throws Exception {\n    if(isExist(tableName)){\n        System.out.println(tableName+\"已经存在\");\n        return;\n    }\n    HTableDescriptor tableDescriptor = new HTableDescriptor(TableName.valueOf(tableName));\n    for (String c : column) {\n        HColumnDescriptor hColumnDescriptor = new HColumnDescriptor(c);\n        tableDescriptor.addFamily(hColumnDescriptor);\n    }\n    admin.createTable(tableDescriptor);\n    System.out.println(tableName+\"创建成功\");\n    getAllTable();\n}\n```\n**5.删除表**\n```\npublic static void deleteTable(String tableName) throws Exception {\n    if(isExist(tableName)){\n        admin.disableTable(TableName.valueOf(tableName));\n        admin.deleteTable(TableName.valueOf(tableName));\n    }\n    System.out.println(tableName+\"已被删除\");\n    getAllTable();\n }\n```\n\n**6.获取所有表**\n```\npublic static void getAllTable() throws Exception {\n    TableName[] tableNames = admin.listTableNames();\n    for (TableName tableName : tableNames) {\n        System.out.println(Bytes.toString(tableName.getName()));\n    }\n}\n```\n**7.添加一行数据**\n```\npublic static void add1Row(String tableName,String rowkey,String cf,String column,String val) throws Exception {\n    Table table = connection.getTable(TableName.valueOf(tableName));\n    Put put = new Put(Bytes.toBytes(rowkey));\n    put.addColumn(Bytes.toBytes(cf),Bytes.toBytes(column),Bytes.toBytes(val));\n    table.put(put);\n}\n```\n**8.删除一行数据**\n```\npublic static void del1Row(String tableName,String rowkey) throws Exception {\n    Table table = connection.getTable(TableName.valueOf(tableName));\n    Delete delete = new Delete(Bytes.toBytes(rowkey));\n    table.delete(delete);\n}\n```\n**9.删除多行数据**\n```\npublic static void delMulRow(String tableName,String... rowkeys) throws Exception {\n    Table table = connection.getTable(TableName.valueOf(tableName));\n    List<Delete> deletes = new ArrayList<Delete>();\n    for (String rowkey : rowkeys) {\n        Delete delete = new Delete(Bytes.toBytes(rowkey));\n        deletes.add(delete);\n    }\n    table.delete(deletes);\n}\n```\n**10.获取多行数据**\n```\npublic static void getAllrows(String tableName) throws Exception {\n    Table table = connection.getTable(TableName.valueOf(tableName));\n    Scan scan = new Scan();\n    scan.setMaxVersions();\n    ResultScanner resultScanner = table.getScanner(scan);\n    for (Result result : resultScanner) {\n        Cell[] cells = result.rawCells();\n        for (Cell cell : cells) {\n            System.out.print(Bytes.toString(CellUtil.cloneFamily(cell))+\" \");\n            System.out.print(Bytes.toString(CellUtil.cloneQualifier(cell))+\" \");\n            System.out.print(Bytes.toString(CellUtil.cloneRow(cell))+\" \");\n            System.out.println(Bytes.toString(CellUtil.cloneValue(cell)));\n        }\n    }\n}\n```\n\n**11.获取一行数据**\n```\npublic static void getrow(String tableName,String rowkey) throws Exception {\n    Table table = connection.getTable(TableName.valueOf(tableName));\n    Get get = new Get(Bytes.toBytes(rowkey));\n    Result result = table.get(get);\n    Cell[] cells = result.rawCells();\n    for (Cell cell : cells) {\n        System.out.print(Bytes.toString(CellUtil.cloneFamily(cell))+\" \");\n        System.out.print(Bytes.toString(CellUtil.cloneQualifier(cell))+\" \");\n        System.out.print(Bytes.toString(CellUtil.cloneRow(cell))+\" \");\n        System.out.println(Bytes.toString(CellUtil.cloneValue(cell)));\n    }\n}\n```\n\n**hbase的demo**\n\n```\npackage com.chen;\n\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.hbase.*;\nimport org.apache.hadoop.hbase.client.*;\nimport org.apache.hadoop.hbase.util.Bytes;\n\nimport java.io.IOException;\nimport java.util.ArrayList;\nimport java.util.List;\n\npublic class App {\n    static Admin admin = null;\n    static Connection connection = null;\n\n    /**\n     * 静态初始化\n     */\n    static {\n        Configuration configuration = HBaseConfiguration.create();\n        try {\n            connection = ConnectionFactory.createConnection(configuration);\n            admin = connection.getAdmin();\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n\n    /**\n     * 判断表是否存在\n     * @param tableName\n     * @return\n     * @throws Exception\n     */\n    public static boolean isExist(String tableName) throws Exception {\n        return admin.tableExists(TableName.valueOf(tableName));\n    }\n\n    /**\n     * 创建表\n     * @param tableName\n     * @param column\n     * @throws Exception\n     */\n    public static void createTable(String tableName,String ... column) throws Exception {\n        if(isExist(tableName)){\n            System.out.println(tableName+\"已经存在\");\n            return;\n        }\n        HTableDescriptor tableDescriptor = new HTableDescriptor(TableName.valueOf(tableName));\n        for (String c : column) {\n            HColumnDescriptor hColumnDescriptor = new HColumnDescriptor(c);\n            tableDescriptor.addFamily(hColumnDescriptor);\n        }\n        admin.createTable(tableDescriptor);\n        System.out.println(tableName+\"创建成功\");\n        getAllTable();\n    }\n\n    /**\n     * 删除表\n     * @param tableName\n     * @throws Exception\n     */\n    public static void deleteTable(String tableName) throws Exception {\n        if(isExist(tableName)){\n            admin.disableTable(TableName.valueOf(tableName));\n            admin.deleteTable(TableName.valueOf(tableName));\n        }\n        System.out.println(tableName+\"已被删除\");\n        getAllTable();\n    }\n\n    /**\n     * 获取所有表\n     * @throws Exception\n     */\n    public static void getAllTable() throws Exception {\n        TableName[] tableNames = admin.listTableNames();\n        for (TableName tableName : tableNames) {\n            System.out.println(Bytes.toString(tableName.getName()));\n        }\n    }\n\n\n    /**\n     * 添加一行数据\n     * @param tableName\n     * @param rowkey\n     * @param cf\n     * @param column\n     * @param val\n     * @throws Exception\n     */\n    public static void add1Row(String tableName,String rowkey,String cf,String column,String val) throws Exception {\n        Table table = connection.getTable(TableName.valueOf(tableName));\n        Put put = new Put(Bytes.toBytes(rowkey));\n        put.addColumn(Bytes.toBytes(cf),Bytes.toBytes(column),Bytes.toBytes(val));\n        table.put(put);\n    }\n\n\n    /**\n     * 删除一行数据\n     * @param tableName\n     * @param rowkey\n     * @throws Exception\n     */\n    public static void del1Row(String tableName,String rowkey) throws Exception {\n        Table table = connection.getTable(TableName.valueOf(tableName));\n        Delete delete = new Delete(Bytes.toBytes(rowkey));\n        table.delete(delete);\n    }\n\n    /**\n     * 删除多行数据\n     * @param tableName\n     * @param rowkeys\n     * @throws Exception\n     */\n    public static void delMulRow(String tableName,String... rowkeys) throws Exception {\n        Table table = connection.getTable(TableName.valueOf(tableName));\n        List&lt;Delete&gt; deletes = new ArrayList&lt;Delete&gt;();\n        for (String rowkey : rowkeys) {\n            Delete delete = new Delete(Bytes.toBytes(rowkey));\n            deletes.add(delete);\n        }\n        table.delete(deletes);\n    }\n\n    /**\n     * 获取多行数据\n     * @param tableName\n     * @throws Exception\n     */\n    public static void getAllrows(String tableName) throws Exception {\n        Table table = connection.getTable(TableName.valueOf(tableName));\n        Scan scan = new Scan();\n        scan.setMaxVersions();\n        ResultScanner resultScanner = table.getScanner(scan);\n        for (Result result : resultScanner) {\n            Cell[] cells = result.rawCells();\n            for (Cell cell : cells) {\n                System.out.print(Bytes.toString(CellUtil.cloneFamily(cell))+\" \");\n                System.out.print(Bytes.toString(CellUtil.cloneQualifier(cell))+\" \");\n                System.out.print(Bytes.toString(CellUtil.cloneRow(cell))+\" \");\n                System.out.println(Bytes.toString(CellUtil.cloneValue(cell)));\n            }\n        }\n    }\n\n    public static void main(String[] args) throws Exception {\n        /*String table=\"t3\";\n        System.out.println(isExist(table));*/\n        //createTable(\"test1\",\"info\",\"extra\");\n        //deleteTable(\"test1\");\n        add1Row(\"test1\",\"r2\",\"extra\",\"age\",\"11\");\n        //del1Row(\"test1\",\"r1\");\n        getAllrows(\"test1\");\n    }\n}\n\n```\n\n# flume\n\n## 一.flume的搭建\n\n1.将在qq939598604的百度网盘中的路径，我的软件/apache-flume-1.8.0-bin.tar.gz下载并上传到/soft/elk目录下\n2.解压\n```\ncd /soft/elk\ntar –zxvf apache-flume-1.8.0-bin.tar.gz\n```\n3.配置java_home\ncp flume-env.sh.template flume-env.sh\nvim flume-env.sh\n```\nexport JAVA_HOME=/soft/jdk1.8.0_161\n```\n4.编辑配置文件\nvim  spool1.conf \n```\na1.sources = r1\na1.sinks = k1\na1.channels = c1\n\n# Describe/configure the source\na1.sources.r1.type = netcat\na1.sources.r1.bind = localhost\na1.sources.r1.port = 44444\n\n# Describe the sink\na1.sinks.k1.type = logger\n\n# Use a channel which buffers events in memory\na1.channels.c1.type = memory\na1.channels.c1.capacity = 1000\na1.channels.c1.transactionCapacity = 100\n\n# Bind the source and sink to the channel\na1.sources.r1.channels = c1\na1.sinks.k1.channel = c1\n```\n5.启动flume\n```\n/soft/elk/apache-flume-1.8.0-bin/bin/flume-ng agent -c /soft/elk/apache-flume-1.8.0-bin/conf -f /soft/elk/apache-flume-1.8.0-bin/conf/spool1.conf --name a1 -Dflume.root.logger=INFO,console\n```\n6.安装telnet工具\n```\nyum install telnet -y\ntelnet localhost 4444\n```\n7.在telnet终端发送数据到flume中并查看是否有接收到\n\n\n\n# zookpeer\n\n##  一.Zookeeper集群搭建\n\n（一）先把Java环境配好，三台机器，配置Zookeeper \n（二）下载zookeeper-3.4.10.tar.gz，并且上传到/soft/目录下，直接解压zookeeper-3.4.10.tar.gz\n tar -zxvf zookeeper-3.4.10.tar.gz\n（三）修改配置文件名称\n\n```\nmv /soft/zookeeper-3.4.10/conf/zoo_simple.cfg /soft/zookeeper-3.4.10/conf/zoo.cfg\n```\n\n（四）编辑配置文件\n\n```\nvim /soft/zookeeper-3.4.10/conf/zoo.cfg\n```\n\n修改**dataDir=/soft/zookeeper-3.4.10/data**\n同时增加\n\n```\nserver.1=192.168.197.231:2888:3888\nserver.2=192.168.197.232:2888:3888\nserver.3=192.168.197.233:2888:3888\n```\n\n**server.X=A:B:C**  X-代表服务器编号 A-代表ip  B和C-代表端口，这个端口用来系统之间通信\n\n（五）编辑配置myid文件\n\nvim /soft/zookeeper-3.4.10/data/myid\n之后会产生一个新文件，直接在里面写X即可，比如我配置的三个server，当前服务器的ip是多少，myid里面写的X就是server.X=ip:2888:3888 中ip所对应的X\n\n```\nserver.1=192.168.197.231:2888:3888【192.168.197.231服务器上面的myid填写1】\nserver.2=192.168.197.232:2888:3888【192.168.197.232服务器上面的myid填写2】\nserver.3=192.168.197.233:2888:3888【192.168.197.233服务器上面的myid填写3】\n```\n\n（六）修改环境\n\n​\tvim /etc/profile\n　　在export PATH语句前添加两行：\n\n```\nZOOKEEPER=/soft/zookeeper-3.4.10\nPATH=PATH:ZOOKEEPER/bin\n```\n\n（六）并执行 source /etc/profile\n（七）启动zookeeper\n分别在3台机器启动 zookeeper\n\n\n\n# kafka\n\n##  一.认识\n\n**首先几个概念：**\n\n1. **kafka作为一个集群运**行在一个或多个服务器上。\n2. kafka集群存储的消息是以topic为类别记录的。\n3. 每个消息（也叫记录record，我习惯叫消息）是由一个key，一个value和时间戳构成。\n4. kafka是基于点对点的拉取（pull）模式（看到尚硅谷视频讲到，便记下来）\n\n**kafka有四个核心API：**\n\n- 应用程序使用 `Producer API` 发布消息到1个或多个topic（主题）。\n\n- 应用程序使用 `Consumer API` 来订阅一个或多个topic，并处理产生的消息。\n\n- 应用程序使用 `Streams API` 充当一个流处理器，从1个或多个topic消费输入流，并生产一个输出流到1个或多个输出topic，有效地将输入流转换到输出流。\n\n- `Connector API`允许构建或运行可重复使用的生产者或消费者，将topic连接到现有的应用程序或数据系统。例如，一个关系数据库的连接器可捕获每一个变化。\n\n  ![1565660315040](C:\\Users\\Administrator\\Desktop\\Md笔记\\pic\\product.png)\n\n \n\n**基本术语：**\n\n**Topic**\n\nKafka将消息种子(Feed)分门别类，每一类的消息称之为一个主题(Topic).\n\n- Topic是Kafka数据写入操作的基本单元，可以指定副本\n- 一个Topic包含一个或多个Partition，建Topic时可手动指定Partition个数，个数必须少于服务器个数\n- 每条消息属于且仅属于一个Topic\n- Producer发布数据时，必须指定将该消息发布到哪个Topic\n- Consumer订阅消息时，也必须指定订阅哪个Topic的信息\n\n **Partition**\n\n- 每个Partition只会在一个Broker上，物理上每个Partition对应的是一个文件夹\n- Kafka默认使用的是hash进行分区，所以会出现不同的分区数据不一样的情况，但是partitioner是可以override的\n- Partition包含多个Segment，每个Segment对应一个文件，Segment可以手动指定大小，当Segment达到阈值时，将不再写数据，每个Segment都是大小相同的\n- Segment由多个不可变的记录组成，记录只会被append到Segment中，不会被单独删除或者修改，每个Segment中的Message数量不一定相等\n\n **Producer**\n\n发布消息的对象称之为主题生产者(Kafka topic producer)，写数据只会找leader\n\n**Consumer**\n\n订阅消息并处理发布的消息的对象称之为主题消费者(consumers)\n\n **Broker**\n\n已发布的消息保存在一组服务器中，称之为Kafka集群。集群中的每一个服务器都是一个代理(Broker). 消费者可以订阅一个或多个主题（topic），并从Broker拉数据，从而消费这些已发布的消息。\n\n **主题**\n\n Topic是发布的消息的类别或者种子Feed名。对于每一个Topic，Kafka集群维护这一个分区的log，就像下图中的示例： \n\n![1565660685648](C:\\Users\\Administrator\\Desktop\\Md笔记\\pic\\1565660685648.png)\n\n 每一个分区都是一个顺序的、不可变的消息队列， 并且可以持续的添加。分区中的消息都被分了一个序列号，称之为偏移量(offset)，在每个分区中此偏移量都是唯一的。 \n\nKafka集群保持所有的消息，直到它们过期， 无论消息是否被消费了。 实际上消费者所持有的仅有的元数据就是这个偏移量，也就是消费者在这个log中的位置。 这个偏移量由消费者控制：正常情况当消费者消费消息的时候，偏移量也线性的的增加。但是实际偏移量由消费者控制，消费者可以将偏移量重置为更老的一个偏移量，重新读取消息。 可以看到这种设计对消费者来说操作自如， 一个消费者的操作不会影响其它消费者对此log的处理。 再说说分区。Kafka中采用分区的设计有几个目的。一是可以处理更多的消息，不受单台服务器的限制。Topic拥有多个分区意味着它可以不受限的处理更多的数据。第二，分区可以作为并行处理的单元，稍后会谈到这一点。\n\nkafka存储数据有2个地方：broker里面的patition下的log文件，broker的存储策略是文件的大小和存储时间，zookpeer里面的元数据\n\n\n\n##  二.window安装kafka\n\n**（一）zookeeper在Windows下的安装**\n\n1.把下载的zookeeper的文件解压到指定目录：D:\\zookeeper-3.4.14\n\n2.复制conf目录下的zoo_sample.cfg文件为zoo.cfg\n\n3.修改内容如下：\n\n```\ndataDir=D:\\data\\zookeeper\n```\n\n4.进入到bin目录，双击启动zkServer.cmd\n\n5.启动后jps可以看到QuorumPeerMain的进程\n\n```\nD:\\zookeeper-3.4.14\\bin >jps\n```\n\n6.启动客户端运行查看一下\n\n```\nD:\\zookeeper-3.4.14\\bin>zkCli.cmd -server 127.0.0.1:2181\n```\n\n**（二）kafka在Windows下的安装**\n\n1.下载kafka\n\n下载kafka，必须scala的版本对应kafka_2.11-2.3.0，其中前面的是2.12是scala的 版本号\n\nhttps://www.apache.org/dyn/closer.cgi?path=/kafka/2.3.0/kafka_2.11-2.3.0.tgz\n\n2.解压文件（我的目录是D:\\kafka_2.11-2.3.0  【这里不要在Program Files等文件名之间有空格的目录下，不然一会执行会不识别路径】）\n\n3.修改D:\\kafka_2.11-2.3.0\\config下server.properties文件\n\n```\nlog.dirs=D:\\kafka_2.11-2.3.0\\kafka-logs\nbroker.id=0\nport=9092\nzookeeper.connect=localhost:2181\n```\n\n4.进入kafka文件目录D:\\kafka_2.11-2.3.0，执行以下命令，启动kafka通讯的服务器broker\n\n```\n.\\bin\\windows\\kafka-server-start.bat .\\config\\server.properties\n```\n\n5.进入kafka文件目录D:\\kafka_2.11-2.3.0\\bin\\windows，创建kafka的消息topics\n\n```\nkafka-topics.bat --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test\n```\n\n 6.分别打开两个cmd窗口，进入目录D:\\kafka_2.11-2.3.0\\bin\\windows，创建Producer和Consumer\n\n（1）Producer\n\n进入目录D:\\kafka_2.11-2.3.0\\bin\\windows输入如下命令\n\n```\nkafka-console-producer.bat --broker-list localhost:9092 --topic test\n```\n\n（2）Consumer\n\n进入目录D:\\kafka_2.11-2.3.0\\bin\\windows输入如下命令\n\n```\nkafka-console-consumer.bat --zookeeper localhost:2181 --topic testDemo\n```\n\n然后就可以在Producer中发信息，在Consumer中收信息了\n\n**（三）kafka集群在Windows下的安装**\n\n1.复制上面的kafka单机版文件夹\n\n修改文件名为：kafka_2.11-2.3.0--1和 kafka_2.11-2.3.0--2\n\n![1565773682533](C:\\Users\\Administrator\\Desktop\\Md笔记\\pic\\1565773682533.png)\n\n2.修改D:\\kafka_2.11-2.3.0--1\\config下server.properties文件\n\n```\nlog.dirs=D:\\kafka_2.11-2.3.0--1\\kafka-logs\nbroker.id=1\nport=9093\nzookeeper.connect=localhost:2181\n```\n\n3.修改D:\\kafka_2.11-2.3.0--2\\config下server.properties文件\n\n```\nlog.dirs=D:\\kafka_2.11-2.3.0--2\\kafka-logs\nbroker.id=2\nport=9094\nzookeeper.connect=localhost:2181\n```\n\n4.分别进入kafka文件目录D:\\kafka_2.11-2.3.0和kafka_2.11-2.3.0--1和 kafka_2.11-2.3.0--2三个文件夹，执行以下命令，启动kafka通讯的服务器broker\n\n```\n.\\bin\\windows\\kafka-server-start.bat .\\config\\server.properties\n```\n\n  5.查看kafka集群中所有broker节点\n\nbroker的配置文件中有zookeeper的地址,也有自己的broker ID \n\n当broker启动后,会在zookeeper中新建一个znode,访问zk并执行ls /brokers/ids 就可以看到zk中存的所有的broker id list，然后确认你增加的broker的ID是否在list里面 \n\n```\nD:\\zookeeper-3.4.14\\bin>zkCli.cmd -server 127.0.0.1:2181\n[zk: 127.0.0.1:2181(CONNECTED) 2] ls /\n[cluster, controller_epoch, controller, brokers, zookeeper, admin, isr_change_no\ntification, consumers, log_dir_event_notification, latest_producer_id_block, config]\n[zk: 127.0.0.1:2181(CONNECTED) 3] ls /brokers\n[ids, topics, seqid]\n[zk: 127.0.0.1:2181(CONNECTED) 4] ls /brokers/ids\n[0, 1, 2]\n```\n\n上面可以看到/brokers/ids有[0, 1, 2]，说明是一个集群了\n\n6.windows下kafka集群的批处理启动脚本\n\n```\nstart d:\\windows_install\\zookeeper-3.4.14\\bin\\zkServer.cmd\nstart d:\\windows_install\\kafka_2.11-2.3.0\\bin\\windows\\kafka-server-start.bat d:\\windows_install\\kafka_2.11-2.3.0\\config\\server.properties\nstart d:\\windows_install\\kafka_2.11-2.3.0--1\\bin\\windows\\kafka-server-start.bat d:\\windows_install\\kafka_2.11-2.3.0--1\\config\\server.properties\nstart d:\\windows_install\\kafka_2.11-2.3.0--2\\bin\\windows\\kafka-server-start.bat d:\\windows_install\\kafka_2.11-2.3.0--2\\config\\server.properties\n```\n\n##  三.**消费者组案例测试**\n\n**案例一**\n\n生产者：如果topicA只有一个patition，即patition0，启动一个生产者实例\n\n消费者组中有A和B，其中消费者A先启动，A会绑定topicA中的patition0，然后再启动消费者B，启动的时候会提示，没有patition被绑定，则topicA中的生产数据的时候只有消费者A消费。\n\n**案例二**\n\n在前面的kafka集群3台机器中，连接测试192.168.197.30测试，以下测试是在windows的D:\\windows_install\\kafka_2.11-2.3.0\\bin\\windows>目录下进行\n\n1.新建一个topic，指定复制因子为3，分区为3\n\n```\nkafka-topics.bat --create --zookeeper 192.168.197.30:2181 --replication-factor 3 --partitions 3 --topic test\nCreated topic test.\n```\n\n2.启动一个生产者\n\n```\nkafka-console-producer.bat --broker-list 192.168.197.30:9092 --topic test\n```\n\n3.启动消费者A，并指定组id为t\n\n```\nkafka-console-consumer.bat --bootstrap-server 192.168.197.30:9092 --topic test --group t\n```\n\n4.启动消费者B，并指定组id为t\n\n```\nkafka-console-consumer.bat --bootstrap-server 192.168.197.30:9092 --topic test --group t\n```\n\n5.在生产者端输入消息\n\n```\nD:\\windows_install\\kafka_2.11-2.3.0\\bin\\windows>kafka-console-producer.bat --broker-list 192.168.197.30:9092 --topic test\n>dafads\n>sdfa\n>fadsads\n>dfads\n```\n\n6.可以观察到，同个消费者组的消费者，消费消息只能由一个完成，并且只有一次\n\n消费者A获取到的消息如下：\n\n```\nD:\\windows_install\\kafka_2.11-2.3.0\\bin\\windows>kafka-console-consumer.bat --botstrap-server 192.168.197.30:9092 --topic test --group t\ndafads\nfadsads\n```\n\n消费者B获取到的消息如下：\n\n```\nD:\\windows_install\\kafka_2.11-2.3.0\\bin\\windows>kafka-console-consumer.bat --bootstrap-server 192.168.197.30:9092 --topic test --group t\nsdfa\ndfads\n```\n\n**同个消费者组的消费者，消费消息只能由一个完成，并且只有一次**\n\n\n\n##  四.消费者连接集群只需一个broker\n\n在前面的kafka集群3台机器中，连接测试192.168.197.30测试，以下测试是在windows的D:\\windows_install\\kafka_2.11-2.3.0\\bin\\windows>目录下进行\n\n1.新建一个topic，指定复制因子为3，分区为3\n\n```\nkafka-topics.bat --create --zookeeper 192.168.197.30:2181 --replication-factor 3 --partitions 3 --topic test\nCreated topic test.\n```\n\n2.启动一个生产者\n\n```\nkafka-console-producer.bat --broker-list 192.168.197.30:9092 --topic test\n```\n\n3.启动消费者A，连接的bootstrap-server,参数指定为 `--bootstrap-server 192.168.197.30:9092`并指定组id为t\n\n```\nkafka-console-consumer.bat --bootstrap-server 192.168.197.30:9092 --topic test --group t\n```\n\n4.启动消费者B，连接的bootstrap-server和消费者A不一样,参数指定为 `--bootstrap-server 192.168.197.30:9093`并指定组id为t\n\n```\nkafka-console-consumer.bat --bootstrap-server 192.168.197.30:9092 --topic test --group t\n```\n\n5.在生产者端输入消息\n\n```\nD:\\windows_install\\kafka_2.11-2.3.0\\bin\\windows>kafka-console-producer.bat --broker-list 192.168.197.30:9092 --topic test\n>ghjhh67\n>ljgty\n>tyetw\n>uioqw\n```\n\n6.可以观察到，消费者连接集群只需一个broker，即可获取到整个集群的消息\n\n消费者A获取到的消息如下：\n\n```\nD:\\windows_install\\kafka_2.11-2.3.0\\bin\\windows>kafka-console-consumer.bat --botstrap-server 192.168.197.30:9092 --topic test --group t\nghjhh67\ntyetw\n```\n\n消费者B获取到的消息如下：\n\n```\nD:\\windows_install\\kafka_2.11-2.3.0\\bin\\windows>kafka-console-consumer.bat --bootstrap-server 192.168.197.30:9093 --topic test --group t\nljgty\nuioqw\n```\n\n**消费者连接集群只需一个broker，即可获取到整个集群的消息**\n\n##  五.生产者的java版本代码编写\n\n**(一)最简单的调用方式**\n\n1.新建一个MyProduce.java，发送消息到test的topic\n\n```java\npublic class MyProduce {\n    public static void main(String[] args) {\n        Properties props = new Properties();\n        props.put(\"bootstrap.servers\",\"192.168.197.30:9092\");\n        props.put(\"acks\",\"all\");\n        props.put(\"retries\",0);\n        props.put(\"batch.size\",16384);\n        props.put(\"linger.ms\",1);\n        props.put(\"buffer.memory\",33554432);\n        props.put(\"key.serializer\",\"org.apache.kafka.common.serialization.StringSerializer\");\n        props.put(\"value.serializer\",\"org.apache.kafka.common.serialization.StringSerializer\");\n        Producer<String, String> producer = new KafkaProducer<>(props);\n        for(int i=0;i<10;i++){\n          producer.send(new ProducerRecord<>(\"test\", Integer.toString(i), Integer.toString(i)));\n        }\n        producer.close();\n    }\n}\n```\n\n**(二)有回调的生产者**\n\n```\npackage com.gzstrong.TestKafka;\n\nimport org.apache.kafka.clients.producer.*;\n\nimport java.util.Properties;\n\n/**\n * @author 陈锦华\n * @version V1.0\n * @Title:\n * @Description: create by Intellij Idea\n * @date 2019/8/15 0015 上午 9:08\n **/\npublic class MyProduce {\n    public static void main(String[] args) {\n        Properties props = new Properties();\n        props.put(\"bootstrap.servers\",\"192.168.197.30:9092\");\n        props.put(\"acks\",\"all\");\n        props.put(\"retries\",0);\n        props.put(\"batch.size\",16384);\n        props.put(\"linger.ms\",1);\n        props.put(\"buffer.memory\",33554432);\n        props.put(\"key.serializer\",\"org.apache.kafka.common.serialization.StringSerializer\");\n        props.put(\"value.serializer\",\"org.apache.kafka.common.serialization.StringSerializer\");\n        Producer<String, String> producer = new KafkaProducer<>(props);\n        for(int i=0;i<10;i++){\n            producer.send(new ProducerRecord<>(\"test\", Integer.toString(i), Integer.toString(i)), new Callback() {\n                @Override\n                public void onCompletion(RecordMetadata metadata, Exception exception) {\n                    System.out.println(metadata.partition()+\"---\"+metadata.offset());\n                }\n            });\n\n        }\n        producer.close();\n    }\n}\n```\n\n**(二)指定分区发送，且有回调的生产者**\n\n1.新建ProducePatition.java实现Partitioner接口\n\n```\npublic class ProducePatition implements Partitioner {\n\n    @Override\n    public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {\n        return 0;\n    }\n\n    @Override\n    public void close() {\n\n    }\n\n    @Override\n    public void configure(Map<String, ?> configs) {\n\n    }\n}\n```\n\n2.在生产者里面设置参数`props.put(\"partitioner.class\",\"com.gzstrong.TestKafka.ProducePatition\");`\n\n```\npublic class MyProduce {\n    public static void main(String[] args) {\n        Properties props = new Properties();\n        props.put(\"bootstrap.servers\",\"192.168.197.30:9092\");\n        props.put(\"acks\",\"all\");\n        props.put(\"retries\",0);\n        props.put(\"batch.size\",16384);\n        props.put(\"linger.ms\",1);\n        props.put(\"buffer.memory\",33554432);\n        props.put(\"partitioner.class\",\"com.gzstrong.TestKafka.ProducePatition\");\n        props.put(\"key.serializer\",\"org.apache.kafka.common.serialization.StringSerializer\");\n        props.put(\"value.serializer\",\"org.apache.kafka.common.serialization.StringSerializer\");\n        Producer<String, String> producer = new KafkaProducer<>(props);\n        for(int i=0;i<10;i++){\n            producer.send(new ProducerRecord<>(\"test\", Integer.toString(i), Integer.toString(i)), (metadata, exception) -> System.out.println(metadata.partition()+\"---\"+metadata.offset()));\n        }\n        producer.close();\n    }\n}\n```\n\n##  六.消费者java编码\n\n（一）高级消费者\n\n```\npublic class MyComSumer {\n    public static void main(String[] args){\n        Properties props = new Properties();\n        props.put(\"bootstrap.servers\", \"192.168.197.30:9092\");\n        props.put(\"group.id\", \"test\");\n        props.put(\"enable.auto.commit\", \"false\");\n        props.put(\"auto.commit.interval.ms\", \"1000\");\n        props.put(\"session.timeout.ms\", \"30000\");\n        props.put(\"key.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");\n        props.put(\"value.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");\n        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n        consumer.subscribe(Arrays.asList(\"test\", \"bar\"));\n        final int minBatchSize = 200;\n        List<ConsumerRecord<String, String>> buffer = new ArrayList<>();\n        while (true) {\n            ConsumerRecords<String, String> records = consumer.poll(100);\n            for (ConsumerRecord<String, String> record : records) {\n                System.out.println(\"offset:\"+record.offset()+\" partition: \"+record.partition()+\" record: \"+ record);\n            }\n        }\n    }\n}\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#  spark\n\n##  一.spark集群搭建\n\n**（一）.安装基础环境（JAVA和SCALA环境）**\n\n**1.安装JDK**\n\n(1)下载jdk1.8.0_161\n(2)在/etc/profile中添加如下配置\n vim /etc/profile\n```\n    export JAVA_HOME=/soft/jdk1.8.0_161\n    export JRE_HOME=${JAVA_HOME}/jre\n    export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib\n    export PATH=${JAVA_HOME}/bin:$PATH\n```\n(3)使环境变量生效，source /etc/profile\n(4)安装验证# java -version \n\n**2.安装SCALA**\n\n(1)到http://www.scala-lang.org/download/2.11.8.html下载scala2.11.8.tar.gz\n将下载的文件上传到/soft目录下\n```\ntar -zxvf /soft/scala-2.11.8.tgz -C /soft/\n```\n(2)在/etc/profile中添加如下配置\n  vim /etc/profile\n```\n  export SCALA_HOME=/soft/scala-2.11.8\n  export PATH=$SCALA_HOME/bin:$PATH\n```\n(3)使环境变量生效，source /etc/profile\n(4)安装验证# java -version \n\n**（二）Hadoop2.7.4完全分布式搭建**\n\n**（三）Spark2.1.0完全分布式环境搭建 **\n\n以下操作都在Master节点进行。\n1.下载二进制包spark-2.1.0-bin-hadoop2.7.tgz\n2.解压并移动到相应目录，命令如下：\n```\ntar -zxvf spark-2.2.1-bin-hadoop2.7.tgz -C /soft/\n```\n3.修改相应的配置文件。\n　　在/etc/profile中添加如下配置\n      \tvim /etc/profile\n```　　\n  export SPARK_HOME=/soft/spark-2.2.1-bin-hadoop2.7/\n  export PATH=$PATH:$SPARK_HOME/bin\n```\n    使环境变量生效，source /etc/profile\n4.复制spark-env.sh.template成spark-env.sh\n　  　cp /soft/spark-2.2.1-bin-hadoop2.7/conf/spark-env.sh.template /soft/spark-2.2.1-bin-\t\thadoop2.7/conf/spark-env.sh\n5.修改$SPARK_HOME/conf/spark-env.sh，添加如下内容：\n```　\nexport JAVA_HOME=/soft/jdk1.8.0_161/\nexport SCALA_HOME=/soft/scala-2.11.8\nexport HADOOP_HOME=/soft/hadoop-2.7.4\nexport HADOOP_CONF_DIR=/soft/hadoop-2.7.4/etc/hadoop\nexport SPARK_MASTER_IP=master\nexport SPARK_MASTER_HOST=master\nexport SPARK_WORKER_MEMORY=512m\nexport SPARK_HOME=/soft/spark-2.2.1-bin-hadoop2.7\nexport SPARK_DIST_CLASSPATH=$(/soft/hadoop-2.7.4/bin/hadoop classpath)\n```\n6.复制slaves.template成slaves\n7.cp /soft/spark-2.2.1-bin-hadoop2.7/conf/slaves.template /soft/spark-2.2.1-bin-hadoop2.7/conf/slaves\n8.修改$SPARK_HOME/conf/slaves，添加如下内容：\n```　\nmaster\nslave1\nslave2\n```\n9.将配置好的spark文件复制到Slave1和Slave2节点。\n\tscp /opt/spark-2.1.0-bin-hadoop2.7 root@Slave1:/opt\n      \tscp /opt/spark-2.1.0-bin-hadoop2.7 root@Slave2:/opt\n10.修改Slave1和Slave2配置。\n　　在slave1和slave2上分别修改/etc/profile，增加Spark的配置，过程同Master一样。\n　　在slave1和slave2修改$SPARK_HOME/conf/spark-env.sh，将export SPARK_LOCAL_IP=114.55.246.88改成slave1和slave2对应节点的IP。\n11.在master节点启动集群。\n　　/opt/spark-2.1.0-bin-hadoop2.7/sbin/start-all.sh\n12.查看集群是否启动成功：\n　　jps\n　　master在Hadoop的基础上新增了：\n　　master\n　　slave在Hadoop的基础上新增了：\n　　Worker\n\n## 二.spark的maven项目构建（基于idea 和maven）\n\n首先idea安装scala插件\n![输入图片说明](https://images.gitee.com/uploads/images/2019/0521/154430_f3a9b447_429848.png \"QQ截图20190521154225.png\")\n\n新建一个maven项目\n开始创建项目体系结构\nFile --> Project \n![输入图片说明](https://static.oschina.net/uploads/img/201802/11153035_Ac2b.png \"在这里输入图片标题\")\n![输入图片说明](https://static.oschina.net/uploads/img/201802/11153132_Ijqk.png \"在这里输入图片标题\")\n![输入图片说明](https://static.oschina.net/uploads/img/201802/11153403_6Rrj.png \"在这里输入图片标题\")\n![输入图片说明](https://static.oschina.net/uploads/img/201802/11153427_h2XW.png \"在这里输入图片标题\")\n\npom.xml\n\n```\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n    <groupId>com.chen</groupId>\n    <artifactId>Spark_Test</artifactId>\n    <version>1.0-SNAPSHOT</version>\n    <inceptionYear>2008</inceptionYear>\n    <properties>\n        <scala.version>2.11.0</scala.version>\n        <spark.version>2.0.2</spark.version>\n        <scala>2.11</scala>\n    </properties>\n\n    <repositories>\n        <repository>\n            <id>scala-tools.org</id>\n            <name>Scala-Tools Maven2 Repository</name>\n            <url>http://scala-tools.org/repo-releases</url>\n        </repository>\n    </repositories>\n\n    <pluginRepositories>\n        <pluginRepository>\n            <id>scala-tools.org</id>\n            <name>Scala-Tools Maven2 Repository</name>\n            <url>http://scala-tools.org/repo-releases</url>\n        </pluginRepository>\n    </pluginRepositories>\n\n    <dependencies>\n        <dependency>\n            <groupId>org.scala-lang</groupId>\n            <artifactId>scala-library</artifactId>\n            <version>${scala.version}</version>\n        </dependency>\n        <dependency>\n            <groupId>junit</groupId>\n            <artifactId>junit</artifactId>\n            <version>4.4</version>\n            <scope>test</scope>\n        </dependency>\n        <dependency>\n            <groupId>org.specs</groupId>\n            <artifactId>specs</artifactId>\n            <version>1.2.5</version>\n            <scope>test</scope>\n        </dependency>\n\n        <dependency>\n            <groupId>org.apache.spark</groupId>\n            <artifactId>spark-core_${scala}</artifactId>\n            <version>${spark.version}</version>\n        </dependency>\n        <dependency>\n            <groupId>org.apache.spark</groupId>\n            <artifactId>spark-streaming_${scala}</artifactId>\n            <version>${spark.version}</version>\n        </dependency>\n        <dependency>\n            <groupId>org.apache.spark</groupId>\n            <artifactId>spark-sql_${scala}</artifactId>\n            <version>${spark.version}</version>\n        </dependency>\n        <dependency>\n            <groupId>org.apache.spark</groupId>\n            <artifactId>spark-hive_${scala}</artifactId>\n            <version>${spark.version}</version>\n        </dependency>\n        <dependency>\n            <groupId>org.apache.spark</groupId>\n            <artifactId>spark-mllib_${scala}</artifactId>\n            <version>${spark.version}</version>\n        </dependency>\n    </dependencies>\n\n    <build>\n        <sourceDirectory>src/main/scala</sourceDirectory>\n        <testSourceDirectory>src/test/scala</testSourceDirectory>\n        <plugins>\n            <plugin>\n                <groupId>org.scala-tools</groupId>\n                <artifactId>maven-scala-plugin</artifactId>\n                <executions>\n                    <execution>\n                        <goals>\n                            <goal>compile</goal>\n                            <goal>testCompile</goal>\n                        </goals>\n                    </execution>\n                </executions>\n                <configuration>\n                    <scalaVersion>2.11</scalaVersion>\n                    <args>\n                        <arg>-target:jvm-1.5</arg>\n                    </args>\n                </configuration>\n            </plugin>\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-surefire-plugin</artifactId>\n                <version>2.19</version>\n                <configuration>\n                    <skip>true</skip>\n                </configuration>\n            </plugin>\n\n            <plugin>\n                <artifactId>maven-compiler-plugin</artifactId>\n                <version>3.6.0</version>\n                <configuration>\n                    <source>1.8</source>\n                    <target>1.8</target>\n                    <excludes>\n                        <exclude>**/*.java</exclude>\n                    </excludes>\n                </configuration>\n            </plugin>\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-eclipse-plugin</artifactId>\n                <configuration>\n                    <downloadSources>true</downloadSources>\n                    <buildcommands>\n                        <buildcommand>ch.epfl.lamp.sdt.core.scalabuilder</buildcommand>\n                    </buildcommands>\n                    <additionalProjectnatures>\n                        <projectnature>ch.epfl.lamp.sdt.core.scalanature</projectnature>\n                    </additionalProjectnatures>\n                    <classpathContainers>\n                        <classpathContainer>org.eclipse.jdt.launching.JRE_CONTAINER</classpathContainer>\n                        <classpathContainer>ch.epfl.lamp.sdt.launching.SCALA_CONTAINER</classpathContainer>\n                    </classpathContainers>\n                </configuration>\n            </plugin>\n        </plugins>\n    </build>\n    <reporting>\n        <plugins>\n            <plugin>\n                <groupId>org.scala-tools</groupId>\n                <artifactId>maven-scala-plugin</artifactId>\n                <configuration>\n                    <scalaVersion>${scala.version}</scalaVersion>\n                </configuration>\n            </plugin>\n        </plugins>\n    </reporting>\n</project>\n\n```\n\n目录结构如下:\n![输入图片说明](https://static.oschina.net/uploads/img/201803/29141709_MjWs.png \"在这里输入图片标题\")\n在src的main目录下新建java和scala文件夹\n![输入图片说明](https://static.oschina.net/uploads/img/201803/29142045_fhmF.png \"在这里输入图片标题\")\n同时修改java和scala文件夹为源码文件夹\n![输入图片说明](https://static.oschina.net/uploads/img/201803/29142301_rELw.png \"在这里输入图片标题\")\n![输入图片说明](https://static.oschina.net/uploads/img/201803/29142317_bdXa.png \"在这里输入图片标题\")\n在src的test目录下新建java和scala文件夹\n![输入图片说明](https://static.oschina.net/uploads/img/201803/29142115_RNRo.png \"在这里输入图片标题\")\n同时修改java和scala文件夹为测试文件夹\n![输入图片说明](https://static.oschina.net/uploads/img/201803/29142409_KwUu.png \"在这里输入图片标题\")\n\n然后设置scal为项目的sdk\n\n## 三.spark的java7代码编写\n\n新建package名称为\n![输入图片说明](https://static.oschina.net/uploads/img/201803/29142627_StWH.png \"在这里输入图片标题\")\n新建Java7WordCount.java的文件\n\nJava7WordCount.java\n\n    package com.chen;\n    \n    import org.apache.spark.SparkConf;\n    import org.apache.spark.api.java.JavaPairRDD;\n    import org.apache.spark.api.java.JavaRDD;\n    import org.apache.spark.api.java.JavaSparkContext;\n    import org.apache.spark.api.java.function.FlatMapFunction;\n    import org.apache.spark.api.java.function.Function2;\n    import org.apache.spark.api.java.function.PairFunction;\n    import org.apache.spark.api.java.function.VoidFunction;\n    import scala.Tuple2;\n    \n    import java.util.Arrays;\n    import java.util.Iterator;\n    \n    /**\n     * @author 陈锦华\n     * @version V1.0\n     * @Title:\n     * @Description: create by Intellij Idea\n     * @date 2018/3/29 0029 上午 10:57\n     **/\n    public class Java7WordCount {\n    \n        /**\n         * 使用Java的方式开发进行本地测试Spark的WordCount程序\n         *\n         */\n            public static void main(String[] args) {\n                /**\n                 * * setAppName：设置应用名字，此名字会在Spark web UI显示\n                 * setMaster：设置主节点URL，本例使用“local”是指本机单线程，另外还有以下选项：\n                 * local[K]：本机K线程\n                 * local[*]：本机多线程，线程数与服务器核数相同\n                 * spark://HOST:PORT：Spark集群地址和端口，默认端口为7077\n                 * mesos://HOST:PORT：Mesos集群地址和端口，默认端口为5050\n                 * yarn：YARN集群\n                 * 第1步：创建Spark的配置对象SparkConf，设置Spark程序的运行时的配置信息，\n                 * 例如说通过setMaster来设置程序要链接的Spark集群的Master的URL,如果设置\n                 * 为local，则代表Spark程序在本地运行，特别适合于机器配置条件非常差（例如 只有1G的内存）的初学者 *\n                 */\n                SparkConf conf = new SparkConf().setAppName(\"Spark WordCount written by Java\").setMaster(\"local\");\n                /**\n                 * 第2步：创建SparkContext对象\n                 * SparkContext是Spark程序所有功能的唯一入口，无论是采用Scala、Java、Python\n                 * 、R等都必须有一个SparkContext(不同的语言具体的类名称不同，如果是Java的话则为JavaSparkContext)\n                 * SparkContext核心作用：初始化Spark应用程序运行所需要的核心组件，包括DAGScheduler、TaskScheduler、\n                 * SchedulerBackend 同时还会负责Spark程序往Master注册程序等\n                 * SparkContext是整个Spark应用程序中最为至关重要的一个对象\n                 */\n                JavaSparkContext sc = new JavaSparkContext(conf); // 其底层实际上就是Scala的SparkContext\n                /**\n                 * 第3步：根据具体的数据来源（HDFS、HBase、Local FS、DB、S3等）通过JavaSparkContext来创建JavaRDD\n                 * JavaRDD的创建基本有三种方式：根据外部的数据来源（例如HDFS）、根据Scala集合、由其它的RDD操作\n                 * 数据会被RDD划分成为一系列的Partitions，分配到每个Partition的数据属于一个Task的处理范畴\n                 * 注意：文件路径不能直接用Windows路径中的反斜扛\\，要改成Linux下的斜扛/\n                 */\n                JavaRDD<String> lines = sc.textFile(\"C:\\\\offline_FtnInfo.txt\");\n                /**\n                 * 第4步：对初始的JavaRDD进行Transformation级别的处理，例如map、filter等高阶函数等的编程，来进行具体的数据计算\n                 * 第4.1步：讲每一行的字符串拆分成单个的单词\n                 */\n                JavaRDD<String> words = lines.flatMap(new FlatMapFunction<String, String>() {\n                            @Override\n                            public Iterator<String> call(String line) throws Exception {\n                                return Arrays.asList(line.split(\" \")).iterator();\n                            }\n                        });\n                /**\n                 * 第4步：对初始的JavaRDD进行Transformation级别的处理，例如map、filter等高阶函数等的编程，来进行具体的数据计算\n                 * 第4.2步：在单词拆分的基础上对每个单词实例计数为1，也就是word => (word, 1)\n                 */\n                JavaPairRDD<String, Integer> pairs = words.mapToPair(new PairFunction<String, String, Integer>() {\n                            public Tuple2<String, Integer> call(String word) throws Exception {\n                                return new Tuple2<String, Integer>(word, 1);\n                            }\n                        });\n                /**\n                 * 第4步：对初始的RDD进行Transformation级别的处理，例如map、filter等高阶函数等的编程，来进行具体的数据计算\n                 * 第4.3步：在每个单词实例计数为1基础之上统计每个单词在文件中出现的总次数\n                 */\n                JavaPairRDD<String, Integer> wordsCount = pairs.reduceByKey(new Function2<Integer, Integer, Integer>() { // 对相同的Key，进行Value的累计（包括Local和Reducer级别同时Reduce）\n                            public Integer call(Integer v1, Integer v2) throws Exception {\n                                return v1 + v2;\n                            }\n                        });\n                wordsCount.foreach(new VoidFunction<Tuple2<String, Integer>>() {\n                    public void call(Tuple2<String, Integer> pairs) throws Exception {\n                        System.out.println(pairs._1 + \" : \" + pairs._2);\n                    }\n                });\n                sc.close();\n            }\n        }\n\n## 四.spark的java8代码编写\n\n新建package名称为com.chen\n\n新建Java8WordCount.java的文件\n\nJava8WordCount.java\n\n    package com.chen;\n    \n    import org.apache.spark.SparkConf;\n    import org.apache.spark.api.java.JavaPairRDD;\n    import org.apache.spark.api.java.JavaRDD;\n    import org.apache.spark.api.java.JavaSparkContext;\n    import scala.Tuple2;\n    \n    import java.util.Arrays;\n    import java.util.List;\n    \n    /**\n     * @author 陈锦华\n     * @version V1.0\n     * @Title:\n     * @Description: create by Intellij Idea\n     * @date 2018/3/29 0029 上午 10:57\n     **/\n    public class Java8WordCount {\n        /**\n         * 使用Java的方式开发进行本地测试Spark的WordCount程序\n         */\n        public static void main(String[] args) {\n            WordCount2();\n        }\n    \n        public static void WordCount1(){\n            /**\n             * 第4步：对初始的JavaRDD进行Transformation级别的处理，例如map、filter等高阶函数等的编程，来进行具体的数据计算\n             * 第4.2步：在单词拆分的基础上对每个单词实例计数为1，也就是word => (word, 1)\n             * 第4步：对初始的RDD进行Transformation级别的处理，例如map、filter等高阶函数等的编程，来进行具体的数据计算\n             * 第4.3步：在每个单词实例计数为1基础之上统计每个单词在文件中出现的总次数\n             */\n            SparkConf conf = new SparkConf().setAppName(\"Spark WordCount written by Java\").setMaster(\"local\");\n            JavaSparkContext sc = new JavaSparkContext(conf); // 其底层实际上就是Scala的SparkContext\n            JavaRDD<String> lines = sc.textFile(\"C:\\\\offline_FtnInfo.txt\");\n            JavaRDD<String> words = lines.flatMap((line) ->Arrays.asList(line.split(\" \")).iterator());\n            JavaPairRDD<String, Integer> pairs = words.mapToPair((word)->new Tuple2<>(word, 1));\n            JavaPairRDD<String, Integer> wordsCount = pairs.reduceByKey((Integer v1, Integer v2) ->v1 + v2);\n            wordsCount.foreach((Tuple2<String, Integer> pair)->System.out.println(pair._1 + \" : \" + pair._2));\n            sc.close();\n        }\n    \n        public static void WordCount2(){\n            SparkConf conf = new SparkConf().setAppName(\"Spark WordCount written by Java\").setMaster(\"local\");\n            JavaSparkContext sc = new JavaSparkContext(conf); // 其底层实际上就是Scala的SparkContext\n            JavaRDD<String> lines = sc.textFile(\"C:\\\\offline_FtnInfo.txt\");\n            JavaRDD<String> words = lines.flatMap(line -> Arrays.asList(line.split(\" \")).iterator());\n            JavaPairRDD<String, Integer> counts = words.mapToPair(w -> new Tuple2<String, Integer>(w, 1))\n                .reduceByKey((x, y) -> x + y);\n            List<Tuple2<String, Integer>> output = counts.collect();\n                for (Tuple2<?, ?> tuple : output) {\n                    System.out.println(tuple._1() + \":== \" + tuple._2());\n                }\n            sc.close();\n        }\n    }    \n\n## 五.spark的scalar代码编写\n\n1.新建package名称为\n\ncom.chen\n\n2.新建scalaWordCount.scala的文件\n\nscalaWordCount.scala\n\n    package com.chen\n    \n    import org.apache.spark.{SparkConf, SparkContext}\n    \n        object scalaWordCount{\n            def main(args: Array[String]) {\n                //setMaster(\"local\") 本机的spark就用local，远端的就写ip\n                //如果是打成jar包运行则需要去掉 setMaster(\"local\")因为在参数中会指定。\n                val conf = new SparkConf().setAppName(\"local Application\").setMaster(\"local\")\n                val sc = new SparkContext(conf)\n                val rdd = sc.textFile(\"C:\\\\offline_FtnInfo.txt\")\n                val wordcount = rdd\n                        .flatMap(_.split(\" \"))\n                        .map((_,1))\n                        .reduceByKey(_ + _)\n                        .map(x => (x._2,x._1))\n                        .sortByKey(false)\n                        .map(x => (x._2,x._1)\n                    )\n                wordcount.foreach(x=>println(x._1+\"的数量是:\"+x._2))\n                sc.stop()\n            }\n        }\n\n##  六.RDD\n\n###  （一）rdd的创建方式\n\n**1.parallelize从集合创建**\n\n```\nvar rdd = sc.parallelize(1 to 10)\n```\n\n**2.makeRdd创建**\n\n```\nval seq = List((1, List(\"iteblog.com\", \"sparkhost1.com\", \"sparkhost2.com\")),(2, List(\"iteblog.com\", \"sparkhost2.com\")))\nval rdd = sc.makeRDD(seq)\n```\n\n**3.从外部存储创建RDD**\n\n```\nvar rdd = sc.textFile(\"hdfs:///tmp/lxw1234/1.txt\")\n```\n\n**4.从其他HDFS文件格式创建**\n\nhadoopFile\n\nsequenceFile\n\nobjectFile\n\nnewAPIHadoopFile\n\n从Hadoop接口API创建\n\nhadoopRDD\n\nnewAPIHadoopRDD\n\n**5.从HBase创建RDD** \n\n```scala\nimport org.apache.hadoop.hbase.{HBaseConfiguration, HTableDescriptor, TableName}\nimport org.apache.hadoop.hbase.{HBaseConfiguration, HTableDescriptor, TableName}\nimport org.apache.hadoop.hbase.mapreduce.TableInputFormat\nimport org.apache.hadoop.hbase.mapreduce.TableInputFormat\nimport org.apache.hadoop.hbase.client.HBaseAdmin\nimport org.apache.hadoop.hbase.client.HBaseAdmin\nval conf = HBaseConfiguration.create()\nconf.set(TableInputFormat.INPUT_TABLE,\"lxw1234\")\nvar hbaseRDD = sc.newAPIHadoopRDD(conf,classOf[org.apache.hadoop.hbase.mapreduce.TableInputFormat],classOf[org.apache.hadoop.hbase.io.ImmutableBytesWritable],classOf[org.apache.hadoop.hbase.client.Result])\n```\n\n\n\n## 七.spark Sql\n\n### （一）.spark sql的join\n\n1.spark直接传入List列表用createDataset方法进行创建dataset，然后转DataFrame\n\n```\npackage com.chen\nimport org.apache.spark.sql.{DataFrame, Dataset, SparkSession}\n\nobject TestSpark{\n    def main(args: Array[String]): Unit = {\n        val spark: SparkSession = SparkSession.builder().master(\"local[*]\").appName(\"sparkTest\").getOrCreate()\n        import spark.implicits._\n        val lines: Dataset[(String)] = spark.createDataset(List(\"1,chenjinhua,cn\",\"2,Lisi,usa\",\"3,jony,usa\"))\n        val empDataset: Dataset[(String, String, String)] = lines.map(line => {\n            val field: Array[String] = line.split(\",\")\n            var id = field(0)\n            var empName = field(1)\n            var code = field(2)\n            (id, empName, code)\n        })\n        val empDataFrame: DataFrame = empDataset.toDF(\"id\", \"empName\", \"code\")\n        empDataFrame.createTempView(\"emp\")\n\n        val nations: Dataset[(String)] = spark.createDataset(List(\"cn,中国\",\"usa,美国\"))\n        val nationDataset: Dataset[(String, String)] = nations.map(line => {\n            val field: Array[String] = line.split(\",\")\n            val code = field(0)\n            val name = field(1)\n            (code, name)\n        })\n        val nationDataFrame: DataFrame = nationDataset.toDF(\"code\",\"name\")\n        nationDataFrame.createTempView(\"nation\")\n        val dframe: DataFrame = spark.sql(\"select * from emp left join nation on emp.code=nation.code\")\n        dframe.show()\n        spark.stop()\n    }\n}\n```\n\n执行之后展示结果如下\n\n```\n+---+----------+----+----+----+\n| id|   empName|code|code|name|\n+---+----------+----+----+----+\n|  1|chenjinhua|  cn|  cn|  中国|\n|  2|      Lisi| usa| usa|  美国|\n|  3|      jony| usa| usa|  美国|\n+---+----------+----+----+----+\n```\n\n###  （二）spark Sql计算nginx的日志\n\n1.access.log\n\n```\n192.168.197.50 - - [20/Dec/2018:15:46:15 +0800] \"GET /api/rep/scRepairBusHouse/datagrid?pageNum=1&pageRow=10&busHouseCode=&orgId= HTTP/1.1\" 200 1745 \"http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg\" \"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36\"\n192.168.197.50 - - [20/Dec/2018:15:46:15 +0800] \"GET /api/sys/coreDepart/showCompsTreeByUser HTTP/1.1\" 200 809 \"http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg\" \"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36\"\n192.168.197.50 - - [20/Dec/2018:15:46:15 +0800] \"GET /api/sys/coreDepart/showCompsTreeByUser HTTP/1.1\" 200 809 \"http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg\" \"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36\"\n192.168.197.50 - - [20/Dec/2018:15:46:26 +0800] \"GET /api/rep/scRepairBusHouse/datagrid?pageNum=1&pageRow=10&busHouseCode=&orgId=1 HTTP/1.1\" 200 1745 \"http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg\" \"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36\"\n192.168.197.50 - - [20/Dec/2018:15:46:28 +0800] \"GET /api/rep/scRepairBusHouse/datagrid?pageNum=1&pageRow=10&busHouseCode=&orgId=6 HTTP/1.1\" 200 1340 \"http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg\" \"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36\"\n192.168.197.50 - - [20/Dec/2018:15:46:29 +0800] \"GET /api/rep/scRepairBusHouse/datagrid?pageNum=1&pageRow=10&busHouseCode=&orgId=7 HTTP/1.1\" 200 483 \"http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg\" \"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36\"\n192.168.197.50 - - [20/Dec/2018:15:46:30 +0800] \"GET /api/rep/scRepairBusHouse/datagrid?pageNum=1&pageRow=10&busHouseCode=&orgId=6 HTTP/1.1\" 200 1340 \"http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg\" \"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36\"\n192.168.197.50 - - [20/Dec/2018:15:46:30 +0800] \"GET /api/rep/scRepairBusHouse/datagrid?pageNum=1&pageRow=10&busHouseCode=&orgId=1 HTTP/1.1\" 200 1745 \"http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg\" \"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36\"\n192.168.197.145 - - [20/Dec/2018:15:46:30 +0800] \"GET /static/js/13.c5de91a3a5351c406417.js HTTP/1.1\" 304 0 \"http://192.168.197.28:9090/\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299\"\n192.168.197.145 - - [20/Dec/2018:15:46:31 +0800] \"GET /api/rep/scRepairFixPlace/datagrid?pageNum=1&pageRow=10&positionCode=&orgId= HTTP/1.1\" 200 1559 \"http://192.168.197.28:9090/\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299\"\n192.168.197.145 - - [20/Dec/2018:15:46:31 +0800] \"GET /api/sys/coreDepart/showCompsTreeByUser HTTP/1.1\" 200 809 \"http://192.168.197.28:9090/\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299\"\n192.168.197.145 - - [20/Dec/2018:15:46:31 +0800] \"GET /api/sys/coreDepart/showCompsTreeByUser HTTP/1.1\" 200 809 \"http://192.168.197.28:9090/\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299\"\n192.168.197.50 - - [20/Dec/2018:15:46:31 +0800] \"GET /api/rep/scRepairBusHouse/datagrid?pageNum=1&pageRow=10&busHouseCode=&orgId=1 HTTP/1.1\" 200 1745 \"http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg\" \"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36\"\n192.168.197.145 - - [20/Dec/2018:15:46:33 +0800] \"GET /api/rep/scRepairFixitemInfo/datagrid?pageNum=1&pageRow=10&lineCode=&fixItemTypeId= HTTP/1.1\" 200 906 \"http://192.168.197.28:9090/\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299\"\n192.168.197.145 - - [20/Dec/2018:15:46:33 +0800] \"GET /api/rep/scRepairFixitemType/datagrid?fixItemTypeCode= HTTP/1.1\" 200 861 \"http://192.168.197.28:9090/\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299\"\n192.168.197.145 - - [20/Dec/2018:15:46:33 +0800] \"GET /api/rep/scRepairFixitemType/selectTreeData HTTP/1.1\" 200 861 \"http://192.168.197.28:9090/\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299\"\n192.168.197.145 - - [20/Dec/2018:15:46:34 +0800] \"GET /api/rep/scRepairFaultInfo/datagrid?pageNum=1&pageRow=10&lineCode=&faultTypeId= HTTP/1.1\" 200 816 \"http://192.168.197.28:9090/\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299\"\n192.168.197.145 - - [20/Dec/2018:15:46:34 +0800] \"GET /api/rep/scRepairFaultType/selectTreeData HTTP/1.1\" 200 992 \"http://192.168.197.28:9090/\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299\"\n192.168.197.145 - - [20/Dec/2018:15:46:34 +0800] \"GET /api/rep/scRepairFaultType/datagrid?faultTypeCode= HTTP/1.1\" 200 992 \"http://192.168.197.28:9090/\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299\"\n192.168.197.50 - - [20/Dec/2018:15:46:37 +0800] \"GET /static/js/45.f9d68fececdbd4771c9f.js HTTP/1.1\" 200 14268 \"http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg\" \"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36\"\n192.168.197.50 - - [20/Dec/2018:15:46:37 +0800] \"GET /api/mat/scClRelationClient/datagrid?pageNum=1&pageRow=10&clientName= HTTP/1.1\" 200 1815 \"http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg\" \"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36\"\n```\n\n2.计算每个ip访问的次数，并保存到mysql数据库中\n\n```\nimport org.apache.spark.sql.{DataFrame, Dataset, SparkSession}\nobject SparkSqlTest2{\n    def main(args: Array[String]): Unit = {\n        val spark: SparkSession = SparkSession.builder().master(\"local[*]\").appName(\"sparkTest\").getOrCreate()\n        import spark.implicits._\n        val lines: Dataset[String] = spark.read.textFile(\"file:///C:/Users/Administrator/Desktop/access.log\")\n        val data = lines.map(line => {\n            val fields: Array[String] = line.split(\" \")\n            var ip = fields(0)\n            var method = fields(5)\n            var path = fields(6)\n            var HTTPmethod = fields(7)\n            var status = fields(8)\n            var server = fields(10)\n            (ip, method, path, HTTPmethod,status,server)\n        }).toDF(\"ip\", \"method\", \"path\", \"HTTPmethod\",\"status\", \"server\")\n        data.createTempView(\"logs\")\n        val frame: DataFrame = spark.sql(\"select ip,count(ip) from  logs group by ip\")\n\n        val url=\"jdbc:mysql://localhost:3306/anfu\"\n        val table=\"logs\"\n        val prop=new java.util.Properties()\n        prop.put(\"driver\",\"com.mysql.jdbc.Driver\")\n        prop.put(\"user\",\"root\")\n        prop.put(\"password\",\"root\")\n\n        //表自动创建\n        frame.write.jdbc(url,table,prop)\n        spark.stop()\n    }\n}\n```\n\n###  （三）dataset创建方式\n\n**1.spark读取text文件**\n\n```\nval lines=spark.read.textFile(\"file:///c:/text\")\n```\n\n**2.spark传入list创建**\n\n```scala\nval lines = spark.createDataset(List(\"1,chenjinhua,cn\",\"2,Lisi,usa\",\"3,jony,usa\"))\n```\n\n**3.spark传入Seq创建**\n\n```\nval dataset = Seq(\n  (1, \"zhangyuhang\", java.sql.Date.valueOf(\"2018-05-15\")),\n  (2, \"zhangqiuyue\", java.sql.Date.valueOf(\"2018-05-15\"))\n)\n```\n\n**4.spark传入Rdd创建**\n\n```\nval dataset = spark.createDataset(spark.sparkContext.parallelize(1 to 10))\n```\n\n###  （四）dataFrame创建方式\n\n**1.使用toDF函数创建DataFrame** \n\n```\nimport spark.implicits._\nval df = Seq(\n  (1, \"zhangyuhang\", java.sql.Date.valueOf(\"2018-05-15\")),\n  (2, \"zhangqiuyue\", java.sql.Date.valueOf(\"2018-05-15\"))\n).toDF(\"id\", \"name\", \"created_time\")\n```\n\n**2.使用createDataFrame函数创建DataFrame** ，**通过schema + row 来创建** \n\n可以理解为schema为表的表头，row为表的数据记录 \n\n```\nimport org.apache.spark.sql.types._\n//定义dataframe的结构的schema\nval schema = StructType(List(\n    StructField(\"id\", IntegerType, nullable = false),\n    StructField(\"name\", StringType, nullable = true),\n    StructField(\"create_time\", DateType, nullable = true)\n))\n\n//定义dataframe内容的rdd\nval rdd = sc.parallelize(Seq(\n  Row(1, \"zhangyuhang\", java.sql.Date.valueOf(\"2018-05-15\")),\n  Row(2, \"zhangqiuyue\", java.sql.Date.valueOf(\"2018-05-15\"))\n))\n//创建dataframe\nval df = spark.createDataFrame(rdd, schema)\n```\n\n或者\n\n```\nimport org.apache.spark.sql.types._\n//传入属性参数\nval schemaString = \" id name create_time\"\n//解析参数变成StructField\nval fields = schemaString.split(\" \").map(fieldName => StructField(fieldname, StringType, nullable = true))\n//定义dataframe的结构的schema\nval schema = StructType(fields)\n//定义dataframe内容的rdd\nval lines = sc.textFile(\"file:///people.txt\")\nval rdd = lines.spilt(_.split(\",\")).map(field=>ROW(field(0),field(1).trim) )\n//创建dataframe\nval df = spark.createDataFrame(rdd, schema) \n```\n\n**3.通过反射机制创建DataFrame**\n\n 首先要定义一个case class，因为只有case class才能被Spark隐式转化为DataFrame\n\n```\nimport org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\nimport org.apache.spark.sql.Encoder\nimport spark.implicits._\n//创建匹配类\ncase class Person(id:Int,name:String,age:Long)\n//读取文件生成rdd\nval rdd = sc.textFile(\"file:///\")\n//通过匹配类把rdd转化成dataframe\nval df = rdd.map(_.split(\",\")).map(attributes => Person(attributes(0),attributes(1),attributes(2).trim.toInt)).toDF()　\n```\n\n\n\n### （五）spark sql设置分区数量\n\n保存文件时可以设置分区为一个，文件数量就会是一个\n\n```\nspark.sqlContext.setConf(\"spark.sql.shuffle.partitions\",\"1\")\n```\n\n### （六）spark sql数据读取数据\n\n**1.读取parquet文件** \n\n```\nval df = spark.read.parquet(\"hdfs:/path/to/file\")\n```\n\n**2.读取json文件 **\n\n```\nval df = spark.read.json(\"examples/src/main/resources/people.json\")\n```\n\n**3.读取csv**\n\n```\nval df = spark.read.format(\"com.databricks.spark.csv\")\n        .option(\"header\", \"true\") //reading the headers\n        .option(\"mode\", \"DROPMALFORMED\")\n        .load(\"csv/file/path\")\n```\n\n**4.读取Hive表**\n\n```\nspark.table(\"test.person\") // 库名.表名 的格式\n     .registerTempTable(\"person\")  // 注册成临时表\nspark.sql(\n      \"\"\"\n        | select *\n        | from person\n        | limit 10\n      \"\"\".stripMargin).show()\n```\n\n \n\n###  （七）spark sql数据保存\n\n**1.通过df.write.format().save(\"file:///\")保存** \n\nwrite.format()支持输出的格式有parquet、 JSON、csv、JDBC、text等文件格式,save()定义保存的位置\n\n当我们保存成功后可以在保存位置的目录下看到文件，但是这个文件并不是一个文件而是一个目录。\n\n**（1）parquet格式**\n\n```\ndf.write.mode(SaveMode.Append).format(\"parquet\").save(\"file:///C:/Users/Administrator/Desktop/parquet\")\ndf.write.mode(SaveMode.Append).parquet(\"file:///C:/Users/Administrator/Desktop/parquet2\")\n```\n\n**（2）json格式**\n\n```\ndf.write.format(\"json\").save(\"file:///C:/Users/Administrator/Desktop/myjson\")\n```\n\n**（3）csv格式**\n\n```\ndf.write.format(\"csv\").save(\"file:///C:/Users/Administrator/Desktop/mycsv\")\n```\n\n**（4）jdbc格式，保存到mysql数据库**\n\n```scala\nval url=\"jdbc:mysql://localhost:3306/anfu\"\nval table=\"logs\"\nval prop=new java.util.Properties()\nprop.put(\"driver\",\"com.mysql.jdbc.Driver\")\nprop.put(\"user\",\"root\")\nprop.put(\"password\",\"root\")\n//表自动创建\nframe.write.jdbc(url,table,prop)\n```\n\n**（5）text格式，保存的时候必须是一列，否则报错**\n\n```\ndf.write.format(\"text\").save(\"file:///C:/Users/Administrator/Desktop/mytext\")\n```\n\n**2.通过df.rdd.saveAsTextFile(\"file:///\")转化成rdd再保存**\n\n\n\n**我们对于不同格式的文件读写来说，我们一般使用两套对应方式**\n\n## 八.spark Stream\n\n### （一）netcat运用\n\n**1.netcat在windows下使用**\n\nWindows间传输：\n\n1、安装NetCat\n\n2、开启服务端：nc -l -p 9999\n\n3、开启客户端：nc localhost 9999\n\n4、客户端和服务端间通信\n\n**2.netcat在linux下使用**\n\n**（1）netcat的安装**\n\n```\nyum install nc -y\n```\n\n**（2）netcat使用**\n\n```\nnc -lk 9000\n```\n\n### （二）spark Stream的socketTextStream\n\n**（1）代码编写**\n\n```\nimport org.apache.spark.SparkContext\nimport org.apache.spark.sql.{DataFrame, Dataset, SparkSession}\nimport org.apache.spark.streaming.dstream.{DStream, ReceiverInputDStream}\nimport org.apache.spark.streaming.{Duration, StreamingContext}\n\nobject SparkStreamTest1{\n    def main(args: Array[String]): Unit = {\n        val spark: SparkSession = SparkSession.builder().master(\"local[*]\").appName(\"sparkTest\").getOrCreate()\n        val sc= spark.sparkContext\n        val ssc = new StreamingContext(sc,Duration(5000))\n        val line: ReceiverInputDStream[String] = ssc.socketTextStream(\"192.168.232.140\",9000)\n        val ds: DStream[(String, Int)] = line.flatMap(_.split(\" \")).map((_,1)).reduceByKey(_+_)\n        ds.print()\n        ssc.start()\n        ssc.awaitTermination()\n    }\n}\n```\n\n**（2）在192.168.232.140的netcat下输入数据**\n\n```\n[root@master ~]# nc -lk 9000\ndsfadsfad\nl1l\nkj\nhjhj\n```\n\n**（3）输出结果**\n\n```\n(dsfadsfad,1)\n(hjhj,1)\n(l1l,1)\n(kj,1)\n```\n\n###  （三）spark Stream的结果集保存到数据库\n\n**（1）获取socketTextStream中的数据进行计算之后保存mysql**\n\n```\npackage com.chen\nimport java.sql.{Connection, DriverManager, Statement}\nimport org.apache.log4j.{Level, Logger}\nimport org.apache.spark.sql.SparkSession\nimport org.apache.spark.streaming.dstream.{DStream, ReceiverInputDStream}\nimport org.apache.spark.streaming.{Duration, StreamingContext}\n\nobject SparkStream2MysqlTest1{\n    def main(args: Array[String]): Unit = {\n        Logger.getLogger(\"com.chen\").setLevel(Level.OFF)\n        val spark: SparkSession = SparkSession.builder().master(\"local[*]\").appName(\"sparkTest\").getOrCreate()\n        val sc= spark.sparkContext\n        val ssc = new StreamingContext(sc,Duration(5000))\n        val line: ReceiverInputDStream[String] = ssc.socketTextStream(\"192.168.232.140\",9000)\n        val ds: DStream[(String, Int)] = line.flatMap(_.split(\" \")).map((_,1)).reduceByKey(_+_)\n\n        ds.foreachRDD(rdd=>rdd.foreachPartition(line=>{\n                Class.forName(\"com.mysql.jdbc.Driver\")\n                val connection: Connection = DriverManager.getConnection(\"jdbc:mysql://192.168.197.28:3306/sys\",\"dev\",\"dev@gzstrong\")\n                try{\n                    for (row<-line){\n                        val statement: Statement = connection.createStatement()\n                        val sql=\"INSERT INTO `sys`.`test` (`value`, `valueCount`) VALUES ('\"+row._1+\"','\"+row._2+\"');\"\n                        statement.execute(sql)\n                    }\n                }finally {\n                    connection.close()\n                }\n            })\n        )\n        ssc.start()\n        ssc.awaitTermination()\n    }\n}\n```\n\n**（2）在192.168.232.140的netcat下输入数据**\n\n```\n[root@master ~]# nc -lk 9000\ntest\nsichuang\ngzstrong\n```\n\n**（3）查看数据库中的结果**\n\n|  value   | valuecount |\n| :------: | :--------: |\n|   test   |     1      |\n| sichuang |     1      |\n| gzstrong |     1      |\n\n\n\n###  （四）spark Stream与kafka的集成\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## 九.Structured Streaming\n\n\n\n\n\n## 十.spark案例分析与编程实现\n\n案例一\n\na. 案例描述\n\n提起 Word Count(词频数统计)，相信大家都不陌生，就是统计一个或者多个文件中单词出现的次数。本文将此作为一个入门级案例，由浅入深的开启使用 Scala 编写 Spark 大数据处理程序的大门。\n\nb．案例分析\n\n对于词频数统计，用 Spark 提供的算子来实现，我们首先需要将文本文件中的每一行转化成一个个的单词, 其次是对每一个出现的单词进行记一次数，最后就是把所有相同单词的计数相加得到最终的结果。\n\n对于第一步我们自然的想到使用 flatMap 算子把一行文本 split 成多个单词，然后对于第二步我们需要使用 map 算子把单个的单词转化成一个有计数的 Key-Value 对，即 word -> (word,1). 对于最后一步统计相同单词的出现次数，我们需要使用 reduceByKey 算子把相同单词的计数相加得到最终结果。\n\nc. 编程实现\n\n清单 1.SparkWordCount 类源码\n\nSparkWordCount.scala\n\n    import org.apache.spark.SparkConf\n    import org.apache.spark.SparkContext\n    import org.apache.spark.SparkContext._\n     \n    object SparkWordCount {\n     def FILE_NAME:String = \"word_count_results_\";\n     def main(args:Array[String]) {\n     if (args.length < 1) {\n     println(\"Usage:SparkWordCount FileName\");\n     System.exit(1);\n     }\n     val conf = new SparkConf().setAppName(\"Spark Exercise: Spark Version Word Count Program\");\n     val sc = new SparkContext(conf);\n     val textFile = sc.textFile(args(0));\n     val wordCounts = textFile.flatMap(line => line.split(\" \")).map(\n                                            word => (word, 1)).reduceByKey((a, b) => a + b)\n     //print the results,for debug use.\n     //println(\"Word Count program running results:\");\n     //wordCounts.collect().foreach(e => {\n     //val (k,v) = e\n     //println(k+\"=\"+v)\n     //});\n     wordCounts.saveAsTextFile(FILE_NAME+System.currentTimeMillis());\n     println(\"Word Count program running results are successfully saved.\");\n     }\n    }\n\n\nd. 提交到集群执行\n\n本实例中, 我们将统计 HDFS 文件系统中/user/fams 目录下所有 txt 文件中词频数。其中 spark-exercise.jar 是 Spark 工程打包后的 jar 包，这个 jar 包执行时会被上传到目标服务器的/home/fams 目录下。运行此实例的具体命令如下：\n\n    ./spark-submit \\\n    --class com.ibm.spark.exercise.basic.SparkWordCount \\\n    --master spark://hadoop036166:7077 \\\n    --num-executors 3 \\\n    --driver-memory 6g --executor-memory 2g \\\n    --executor-cores 2 \\\n    /home/fams/sparkexercise.jar \\\n    hdfs://hadoop036166:9000/user/fams/*.txt\n\n\n**案例二**\n\na. 案例描述\n\n该案例中，我们将假设我们需要统计一个 1000 万人口的所有人的平均年龄，当然如果您想测试 Spark 对于大数据的处理能力，您可以把人口数放的更大，比如 1 亿人口，当然这个取决于测试所用集群的存储容量。假设这些年龄信息都存储在一个文件里，并且该文件的格式如下，第一列是 ID，第二列是年龄。\n\n案例二age.txt测试数据格式预览\n\n![è¾å¥å¾çè¯´æ](https://static.oschina.net/uploads/img/201803/29143845_eRx4.jpg) \n\n现在我们需要用 Scala 写一个生成 1000 万人口年龄数据的文件，源程序如下：\n\n清单 3. 年龄信息文件生成类源码\n\n    import java.io.FileWriter\n    import java.io.File\n    import scala.util.Random\n     \n    object SampleDataFileGenerator {\n     \n    def main(args:Array[String]) {\n    val writer = new FileWriter(new File(\"C: \\\\sample_age_data.txt\"),false)\n    val rand = new Random()\n    for ( i <- 1 to 10000000) {\n    writer.write( i + \" \" + rand.nextInt(100))\n    writer.write(System.getProperty(\"line.separator\"))\n    }\n    writer.flush()\n    writer.close()\n    }\n    }\n\n\nb. 案例分析\n\n要计算平均年龄，那么首先需要对源文件对应的 RDD 进行处理，也就是将它转化成一个只包含年龄信息的 RDD，其次是计算元素个数即为总人数，然后是把所有年龄数加起来，最后平均年龄=总年龄/人数。\n\n对于第一步我们需要使用 map 算子把源文件对应的 RDD 映射成一个新的只包含年龄数据的 RDD，很显然需要对在 map 算子的传入函数中使用 split 方法，得到数组后只取第二个元素即为年龄信息；第二步计算数据元素总数需要对于第一步映射的结果 RDD 使用 count 算子；第三步则是使用 reduce 算子对只包含年龄信息的 RDD 的所有元素用加法求和；最后使用除法计算平均年龄即可。\n\n由于本例输出结果很简单，所以只打印在控制台即可。\n\nc. 编程实现\n\n清单 4.AvgAgeCalculator 类源码\n\n    import org.apache.spark.SparkConf\n    import org.apache.spark.SparkContext\n    object AvgAgeCalculator {\n     def main(args:Array[String]) {\n     if (args.length < 1){\n     println(\"Usage:AvgAgeCalculator datafile\")\n     System.exit(1)\n     }\n     val conf = new SparkConf().setAppName(\"Spark Exercise:Average Age Calculator\")\n     val sc = new SparkContext(conf)\n     val dataFile = sc.textFile(args(0), 5);\n     val count = dataFile.count()\n     val ageData = dataFile.map(line => line.split(\" \")(1))\n     val totalAge = ageData.map(age => Integer.parseInt(\n                                    String.valueOf(age))).collect().reduce((a,b) => a+b)\n     println(\"Total Age:\" + totalAge + \";Number of People:\" + count )\n     val avgAge : Double = totalAge.toDouble / count.toDouble\n     println(\"Average Age is \" + avgAge)\n     }\n    }\n\n\n案例三\n\na. 案例描述\n\n本案例假设我们需要对某个省的人口 (1 亿) 性别还有身高进行统计，需要计算出男女人数，男性中的最高和最低身高，以及女性中的最高和最低身高。本案例中用到的源文件有以下格式, 三列分别是 ID，性别，身高 (cm)。\n\n案例三测试数据格式预览\n\n\n\n我们将用以下 Scala 程序生成这个文件，源码如下：\n\n清单 7. 人口信息生成类源码\n\n    import java.io.FileWriter\n    import java.io.File\n    import scala.util.Random\n     \n    object PeopleInfoFileGenerator {\n     def main(args:Array[String]) {\n     val writer = new FileWriter(new File(\"C:\\\\LOCAL_DISK_D\\\\sample_people_info.txt\"),false)\n     val rand = new Random()\n     for ( i <- 1 to 100000000) {\n     var height = rand.nextInt(220)\n     if (height < 50) {\n     height = height + 50\n     }\n     var gender = getRandomGender\n     if (height < 100 && gender == \"M\")\n     height = height + 100\n     if (height < 100 && gender == \"F\")\n     height = height + 50\n     writer.write( i + \" \" + getRandomGender + \" \" + height)\n     writer.write(System.getProperty(\"line.separator\"))\n     }\n     writer.flush()\n     writer.close()\n     println(\"People Information File generated successfully.\")\n     }\n      \n     def getRandomGender() :String = {\n     val rand = new Random()\n     val randNum = rand.nextInt(2) + 1\n     if (randNum % 2 == 0) {\n     \"M\"\n     } else {\n     \"F\"\n     }\n     }\n    }\n\n\nb. 案例分析\n\n对于这个案例，我们要分别统计男女的信息，那么很自然的想到首先需要对于男女信息从源文件的对应的 RDD 中进行分离，这样会产生两个新的 RDD，分别包含男女信息；其次是分别对男女信息对应的 RDD 的数据进行进一步映射，使其只包含身高数据，这样我们又得到两个 RDD，分别对应男性身高和女性身高；最后需要对这两个 RDD 进行排序，进而得到最高和最低的男性或女性身高。\n\n对于第一步，也就是分离男女信息，我们需要使用 filter 算子，过滤条件就是包含”M” 的行是男性，包含”F”的行是女性；第二步我们需要使用 map 算子把男女各自的身高数据从 RDD 中分离出来；第三步我们需要使用 sortBy 算子对男女身高数据进行排序。\n\nc. 编程实现\n\n在实现上，有一个需要注意的点是在 RDD 转化的过程中需要把身高数据转换成整数，否则 sortBy 算子会把它视为字符串，那么排序结果就会受到影响，例如 身高数据如果是：123,110,84,72,100，那么升序排序结果将会是 100,110,123,72,84，显然这是不对的。\n\n清单 8.PeopleInfoCalculator 类源码\n\n    object PeopleInfoCalculator {\n     def main(args:Array[String]) {\n     if (args.length < 1){\n     println(\"Usage:PeopleInfoCalculator datafile\")\n     System.exit(1)\n     }\n     val conf = new SparkConf().setAppName(\"Spark Exercise:People Info(Gender & Height) Calculator\")\n     val sc = new SparkContext(conf)\n     val dataFile = sc.textFile(args(0), 5);\n     val maleData = dataFile.filter(line => line.contains(\"M\")).map(\n                                  line => (line.split(\" \")(1) + \" \" + line.split(\" \")(2)))\n     val femaleData = dataFile.filter(line => line.contains(\"F\")).map(\n                                  line => (line.split(\" \")(1) + \" \" + line.split(\" \")(2)))\n     //for debug use\n     //maleData.collect().foreach { x => println(x)}\n     //femaleData.collect().foreach { x => println(x)}\n     val maleHeightData = maleData.map(line => line.split(\" \")(1).toInt)\n     val femaleHeightData = femaleData.map(line => line.split(\" \")(1).toInt)\n     //for debug use\n     //maleHeightData.collect().foreach { x => println(x)}\n     //femaleHeightData.collect().foreach { x => println(x)}\n     val lowestMale = maleHeightData.sortBy(x => x,true).first()\n     val lowestFemale = femaleHeightData.sortBy(x => x,true).first()\n     //for debug use\n     //maleHeightData.collect().sortBy(x => x).foreach { x => println(x)}\n     //femaleHeightData.collect().sortBy(x => x).foreach { x => println(x)}\n     val highestMale = maleHeightData.sortBy(x => x, false).first()\n     val highestFemale = femaleHeightData.sortBy(x => x, false).first()\n     println(\"Number of Male Peole:\" + maleData.count())\n     println(\"Number of Female Peole:\" + femaleData.count())\n     println(\"Lowest Male:\" + lowestMale)\n     println(\"Lowest Female:\" + lowestFemale)\n     println(\"Highest Male:\" + highestMale)\n     println(\"Highest Female:\" + highestFemale)\n     }\n    }\n\n\n案例四\n\na. 案例描述\n\n该案例中我们假设某搜索引擎公司要统计过去一年搜索频率最高的 K 个科技关键词或词组，为了简化问题，我们假设关键词组已经被整理到一个或者多个文本文件中，并且文档具有以下格式。\n\n图 13. 案例四测试数据格式预览\n\n\n\n我们可以看到一个关键词或者词组可能出现多次，并且大小写格式可能不一致。\n\nb. 案例分析\n\n要解决这个问题，首先我们需要对每个关键词出现的次数进行计算，在这个过程中需要识别不同大小写的相同单词或者词组，如”Spark”和“spark” 需要被认定为一个单词。对于出现次数统计的过程和 word count 案例类似；其次我们需要对关键词或者词组按照出现的次数进行降序排序，在排序前需要把 RDD 数据元素从 (k,v) 转化成 (v,k)；最后取排在最前面的 K 个单词或者词组。\n\n对于第一步，我们需要使用 map 算子对源数据对应的 RDD 数据进行全小写转化并且给词组记一次数，然后调用 reduceByKey 算子计算相同词组的出现次数；第二步我们需要对第一步产生的 RDD 的数据元素用 sortByKey 算子进行降序排序；第三步再对排好序的 RDD 数据使用 take 算子获取前 K 个数据元素。\n\nc. 编程实现\n\n清单 10.TopKSearchKeyWords 类源码\n\n    import org.apache.spark.SparkConf\n    import org.apache.spark.SparkContext\n     \n    object TopKSearchKeyWords {\n     def main(args:Array[String]){\n     if (args.length < 2) {\n     println(\"Usage:TopKSearchKeyWords KeyWordsFile K\");\n     System.exit(1)\n     }\n     val conf = new SparkConf().setAppName(\"Spark Exercise:Top K Searching Key Words\")\n     val sc = new SparkContext(conf)\n     val srcData = sc.textFile(args(0))\n     val countedData = srcData.map(line => (line.toLowerCase(),1)).reduceByKey((a,b) => a+b)\n     //for debug use\n     //countedData.foreach(x => println(x))\n     val sortedData = countedData.map{ case (k,v) => (v,k) }.sortByKey(false)\n     val topKData = sortedData.take(args(1).toInt).map{ case (v,k) => (k,v) }\n     topKData.foreach(println)\n     }\n    }\n\n**案例二的age.txt文件**\n\n1 16\n\n2 73\n\n3 74\n\n4 76 \n\n5 75\n\n6 78\n\n7 66\n\n8 55\n\n9 85\n\n11 25\n\n12 43\n\n13 45\n\n14 61\n\n15 35\n\n16 38\n\n17 69\n\n18 45\n\n19 55\n\n20 45\n\n21 16\n\n22 73\n\n23 74\n\n24 76 \n\n25 75\n\n26 78\n\n27 66\n\n28 55\n\n29 85\n\n30 85\n\n31 25\n\n32 43\n\n33 45\n\n34 61\n\n35 35\n\n36 38\n\n37 69\n\n38 45\n\n39 55\n\n40 45\n\n七.算子reduceByKey和groupByKey，sortByKey和sortBy区别\n\n1. Spark算子reduceByKey深度解析\n   那么这就基本奠定了reduceByKey的作用域是key-value类型的键值对，并且是只对每个key的value进行处理，如果含有多个key的话，那么就对多个values进行处理。这里的函数是我们自己传入的，也就是说是可人为控制的【其实这是废话，人为控制不了这算子一点用没有】。那么举个例子：\n\n    scala> val x = sc.parallelize(Array((\"a\", 1), (\"b\", 1), (\"a\", 1),\n         | (\"a\", 1), (\"b\", 1), (\"b\", 1),\n         | (\"b\", 1), (\"b\", 1)), 3)\n\n\n我们创建了一个Array的字符串，并把其存入spark的集群上，设置了三个分区【这里我们不关注分区，只关注操作】。那么我们调用reduceByKey并且传入函数进行相应操作【本处我们对相同key的value进行相加操作，类似于统计单词出现次数】：\n\n    scala> val y = x.reduceByKey((pre, after) => (pre + after))\n\n\n这里两个参数我们逻辑上让他分别代表同一个key的两个不同values，那么结果想必大家应该猜到了： \n\n    scala> y.collect\n    res0: Array[(String, Int)] = Array((a,3), (b,5))\n\n\n1. reduceByKey和groupByKey区别与用法\n   首先，看一看spark官网[1]是怎么解释的：\n   reduceByKey(func, numPartitions=None)\n   reduceByKey用于对每个key对应的多个value进行merge操作，最重要的是它能够在本地先进行merge操作，并且merge操作可以通过函数自定义。\n\ngroupByKey(numPartitions=None)\n\n也就是，groupByKey也是对每个key进行操作，但只生成一个sequence。需要特别注意“Note”中的话，它告诉我们：如果需要对sequence进行aggregation操作（注意，groupByKey本身不能自定义操作函数），那么，选择reduceByKey/aggregateByKey更好。这是因为groupByKey不能自定义函数，我们需要先用groupByKey生成RDD，然后才能对此RDD通过map进行自定义函数操作。 \n\n    val words = Array(\"one\", \"two\", \"two\", \"three\", \"three\", \"three\")\n    val wordPairsRDD = sc.parallelize(words).map(word => (word, 1))\n    val wordCountsWithReduce = wordPairsRDD.reduceByKey(_ + _)\n    val wordCountsWithGroup = wordPairsRDD.groupByKey().map(t => (t._1, t._2.sum))\n\n\n上面得到的wordCountsWithReduce和wordCountsWithGroup是完全一样的，但是，它们的内部运算过程是不同的。 \n\n（1）当采用reduceByKeyt时，Spark可以在每个分区移动数据之前将待输出数据与一个共用的key结合。借助下图可以理解在reduceByKey里究竟发生了什么。 注意在数据对被搬移前同一机器上同样的key是怎样被组合的(reduceByKey中的lamdba函数)。然后lamdba函数在每个区上被再次调用来将所有值reduce成一个最终结果。整个过程如下：\n\n\n\n（2）当采用groupByKey时，由于它不接收函数，spark只能先将所有的键值对(key-value pair)都移动，这样的后果是集群节点之间的开销很大，导致传输延时。整个过程如下：\n\n\n\n因此，在对大数据进行复杂计算时，reduceByKey优于groupByKey。\n\n另外，如果仅仅是group处理，那么以下函数应该优先于 groupByKey ：\n\n 　　（1）、combineByKey 组合数据，但是组合之后的数据类型与输入时值的类型不一样。\n\n 　　（2）、foldByKey合并每一个 key 的所有值，在级联函数和“零值”中使用。\n\n1. sortByKey和sortBy区别\n   SortByKey()函数\n\nsortBy函数是在org.apache.spark.rdd.RDD类中实现的，它的实现如下：\n\n    def sortBy[K](f: (T) => K,ascending: Boolean = true,\n        numPartitions: Int = this.partitions.size)\n        (implicit ord: Ordering[K], ctag: ClassTag[K]): RDD[T] =\n        this.keyBy[K](f).sortByKey(ascending, numPartitions).values\n\n\n　该函数最多可以传三个参数：\n\n　　第一个参数是一个函数，该函数的也有一个带T泛型的参数，返回类型和RDD中元素的类型是一致的；\n\n　　第二个参数是ascending，从字面的意思大家应该可以猜到，是的，这参数决定排序后RDD中的元素是升序还是降序，默认是true，也就是升序；\n\n　　第三个参数是numPartitions，该参数决定排序后的RDD的分区个数，默认排序后的分区个数和排序之前的个数相等，即为this.partitions.size。\n\n　　从sortBy函数的实现可以看出，第一个参数是必须传入的，而后面的两个参数可以不传入。而且sortBy函数函数的实现依赖于sortByKey函数，关于sortByKey函数后面会进行说明。\n\n   那么，如何使用sortBy函数呢？\n\n    scala> val data = List(3,1,90,3,5,12)\n    data: List[Int] = List(3, 1, 90, 3, 5, 12)\n     \n    scala> val rdd = sc.parallelize(data)\n    rdd: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[0] at parallelize at <console>:14\n     \n    scala> rdd.collect\n    res0: Array[Int] = Array(3, 1, 90, 3, 5, 12)\n     \n    scala> rdd.sortBy(x => x).collect\n    res1: Array[Int] = Array(1, 3, 3, 5, 12, 90)\n     \n    scala> rdd.sortBy(x => x, false).collect\n    res3: Array[Int] = Array(90, 12, 5, 3, 3, 1)\n     \n    scala> val result = rdd.sortBy(x => x, false)\n    result: org.apache.spark.rdd.RDD[Int] = MappedRDD[23] at sortBy at <console>:16\n     \n    scala> result.partitions.size\n    res9: Int = 2\n     \n    scala> val result = rdd.sortBy(x => x, false, 1)\n    result: org.apache.spark.rdd.RDD[Int] = MappedRDD[26] at sortBy at <console>:16\n     \n    scala> result.partitions.size\n    res10: Int = 1\n\n\n上面的实例对rdd中的元素进行升序排序。并对排序后的RDD的分区个数进行了修改，上面的result就是排序后的RDD，默认的分区个数是2，而我们对它进行了修改，所以最后变成了1。\n\n    val data = sc.parallelize(Array((\"cc\",12),(\"bb\",32),(\"cc\",22),(\"aa\",18),(\"bb\",16),(\"dd\",16),(\"ee\",54),(\"cc\",1),(\"ff\",13),(\"gg\",68),(\"bb\",4)))\n    var sortbykey=data.sortByKey(false).collect\n    sortbykey.foreach(x=>(println(x._1+\" \"+x._2)))\n\n\n结果如下\n\n\n\n测到的测试结果如上图所示，显然是根据Key进行了排序。\n\nSortBy()函数\n\nsortByKey函数作用于Key-Value形式的RDD，并对Key进行排序。它是在org.apache.spark.rdd.OrderedRDDFunctions中实现的，实现如下\n\n    def sortByKey(ascending: Boolean = true, numPartitions: Int = self.partitions.size)\n        : RDD[(K, V)] =\n    {\n      val part = new RangePartitioner(numPartitions, self, ascending)\n      new ShuffledRDD[K, V, V](self, part)\n        .setKeyOrdering(if (ascending) ordering else ordering.reverse)\n    }\n\n\n从函数的实现可以看出，它主要接受两个函数，含义和sortBy一样，这里就不进行解释了。该函数返回的RDD一定是ShuffledRDD类型的，因为对源RDD进行排序，必须进行Shuffle操作，而Shuffle操作的结果RDD就是ShuffledRDD。其实这个函数的实现很优雅，里面用到了RangePartitioner，它可以使得相应的范围Key数据分到同一个partition中，然后内部用到了mapPartitions对每个partition中的数据进行排序，而每个partition中数据的排序用到了标准的sort机制，避免了大量数据的shuffle。下面对sortByKey的使用进行说明：\n\n    scala> val a = sc.parallelize(List(\"wyp\", \"iteblog\", \"com\", \"397090770\", \"test\"), 2)\n    a: org.apache.spark.rdd.RDD[String] =ParallelCollectionRDD[30] at parallelize at <console>:12\n     \n    scala> val b = sc. parallelize (1 to a.count.toInt , 2)\n    b: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[31] at parallelize at <console>:14\n     \n    scala> val c = a.zip(b)\n    c: org.apache.spark.rdd.RDD[(String, Int)] = ZippedPartitionsRDD2[32] at zip at <console>:16\n     \n    scala> c.sortByKey().collect\n    res11: Array[(String, Int)] = Array((397090770,4), (com,3), (iteblog,2), (test,5), (wyp,1))\n\n\n    val data = sc.parallelize(Array((\"cc\",12),(\"bb\",32),(\"cc\",22),(\"aa\",18),(\"bb\",16),(\"dd\",16),(\"ee\",54),(\"cc\",1),(\"ff\",13),(\"gg\",68),(\"bb\",4)))\n    var sort=data.reduceByKey(_+_).sortBy(_._2,false).collect()\n    sort.foreach(x=>(println(x._1+\" \"+x._2)))\n\n\n结果如下\n\n\n\n 显然，上图显示的结果是根据Value中的数据进行的排序。\n\n\n\n\n\n# 海量数据算法\n\n**数据倾斜的算子**\n\n数据倾斜只会发生在shuffle过程中。这里给大家罗列一些常用的并且可能会触发shuffle操作的算子：distinct、groupByKey、reduceByKey、aggregateByKey、join、cogroup、repartition等。出现数据倾斜时，可能就是你的代码中使用了这些算子中的某一个所导致的。\n\n## （一）mapjoin解析\n\n利用hive进行join连接操作，相较于MR有两种执行方案，一种为common join，另一种为map join ，map join是相对于common join的一种优化，省去shullfe和reduce的过程，大大的降低的作业运行的时间。 \n\nselect f.a,f.b from A t join B f  on ( f.a=t.a and f.ftime=20110802)  \n\n该语句中B表有30亿行记录，A表只有100行记录，而且B表中数据倾斜特别严重，有一个key上有15亿行记录，在运行过程中特别的慢，而且在reduece的过程中遇有内存不够而报错。\n\n为了解决用户的这个问题，考虑使用mapjoin,mapjoin的原理： \n\n> **MAPJION会把小表全部读入内存中，在map阶段直接拿另外一个表的数据和内存中表数据做匹配，由于在map是进行了join操作，省去了reduce运行的效率也会高很多** \n\n这样就不会由于数据倾斜导致某个reduce上落数据太多而失败。于是原来的sql可以通过使用hint的方式指定join时使用mapjoin。 \n\n> select /*+ mapjoin(A)*/ f.a,f.b from A t join B f  on ( f.a=t.a and f.ftime=20110802)  \n\n再运行发现执行的效率比以前的写法高了好多。 \n\nmapjoin还有一个很大的好处是能够进行不等连接的join操作，如果将不等条件写在where中，那么mapreduce过程中会进行笛卡尔积，运行效率特别低，如果使用mapjoin操作，在map的过程中就完成了不等值的join操作，效率会高很多。 \n\n例子： \n\nselect A.a ,A.b from A join B where A.a>B.a \n\n**简单总结一下，mapjoin的使用场景：**\n\n1.关联操作中有一张表非常小\n\n 2.不等值的链接操作\n\n **MapJoin原理**\n\n![1565833762509](C:\\Users\\Administrator\\Desktop\\Md笔记\\pic\\1565833762509.png)\n\n\n\nMapJoin简单说就是在Map阶段将小表读入内存，顺序扫描大表完成Join。\n\n上图是Hive MapJoin的原理图，出自Facebook工程师Liyin Tang的一篇介绍Join优化的slice，从图中可以看出MapJoin分为两个阶段：\n\n1. 通过MapReduce Local Task，将小表读入内存，生成HashTableFiles上传至Distributed Cache中，这里会对HashTableFiles进行压缩。\n2. MapReduce Job在Map阶段，每个Mapper从Distributed Cache读取HashTableFiles到内存中，顺序扫描大表，在Map阶段直接进行Join，将数据传递给下一个MapReduce任务。\n\n##  （二）美团网的spark调优\n\n基础版  https://tech.meituan.com/2016/04/29/spark-tuning-basic.html\n\n高级版  https://tech.meituan.com/2016/05/12/spark-tuning-pro.html\n\n##  （三） 两阶段聚合（局部聚合+全局聚合）\n\n**方案适用场景：**对RDD执行reduceByKey等聚合类shuffle算子或者在Spark SQL中使用group by语句进行分组聚合时，比较适用这种方案。\n\n**方案实现思路：**这个方案的核心实现思路就是进行两阶段聚合。第一次是局部聚合，先给每个key都打上一个随机数，比如10以内的随机数，此时原先一样的key就变成不一样的了，比如(hello, 1) (hello, 1) (hello, 1) (hello, 1)，就会变成(1_hello, 1) (1_hello, 1) (2_hello, 1) (2_hello, 1)。接着对打上随机数后的数据，执行reduceByKey等聚合操作，进行局部聚合，那么局部聚合结果，就会变成了(1_hello, 2) (2_hello, 2)。然后将各个key的前缀给去掉，就会变成(hello,2)(hello,2)，再次进行全局聚合操作，就可以得到最终结果了，比如(hello, 4)。\n\n**方案实现原理：**将原本相同的key通过附加随机前缀的方式，变成多个不同的key，就可以让原本被一个task处理的数据分散到多个task上去做局部聚合，进而解决单个task处理数据量过多的问题。接着去除掉随机前缀，再次进行全局聚合，就可以得到最终的结果。具体原理见下图。\n\n**方案优点：**对于聚合类的shuffle操作导致的数据倾斜，效果是非常不错的。通常都可以解决掉数据倾斜，或者至少是大幅度缓解数据倾斜，将Spark作业的性能提升数倍以上。\n\n**方案缺点：**仅仅适用于聚合类的shuffle操作，适用范围相对较窄。如果是join类的shuffle操作，还得用其他的解决方案。","slug":"总-大数据","published":1,"updated":"2019-09-05T02:03:04.644Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck061x9520011qguiu9gjn7hd","content":"<h1 id=\"scala\"><a href=\"#scala\" class=\"headerlink\" title=\"scala\"></a>scala</h1><h2 id=\"一-scala的maven在IDE中的搭建\"><a href=\"#一-scala的maven在IDE中的搭建\" class=\"headerlink\" title=\"一.scala的maven在IDE中的搭建\"></a>一.scala的maven在IDE中的搭建</h2><p>1.开始创建项目体系结构<br>File –&gt; Project </p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904175253.png\" alt></p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904175319.png\" alt></p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904175417.png\" alt></p>\n<p><img src=\"https://static.oschina.net/uploads/img/201802/11153427_h2XW.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"></p>\n<p>2.修改pom.xml</p>\n<pre><code>&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt;\n  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\n  &lt;groupId&gt;scala_maven&lt;/groupId&gt;\n  &lt;artifactId&gt;com.chen&lt;/artifactId&gt;\n  &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;\n  &lt;inceptionYear&gt;2008&lt;/inceptionYear&gt;\n  &lt;properties&gt;\n    &lt;scala.version&gt;2.11.7&lt;/scala.version&gt;\n  &lt;/properties&gt;\n\n  &lt;dependencies&gt;\n    &lt;dependency&gt;\n      &lt;groupId&gt;org.scala-lang&lt;/groupId&gt;\n      &lt;artifactId&gt;scala-library&lt;/artifactId&gt;\n      &lt;version&gt;${scala.version}&lt;/version&gt;\n    &lt;/dependency&gt;\n\n    &lt;dependency&gt;\n      &lt;groupId&gt;com.typesafe.akka&lt;/groupId&gt;\n      &lt;artifactId&gt;akka-actor_2.11&lt;/artifactId&gt;\n      &lt;version&gt;2.5.3&lt;/version&gt;\n    &lt;/dependency&gt;\n    &lt;dependency&gt;\n      &lt;groupId&gt;org.specs&lt;/groupId&gt;\n      &lt;artifactId&gt;specs&lt;/artifactId&gt;\n      &lt;version&gt;1.2.5&lt;/version&gt;\n      &lt;scope&gt;test&lt;/scope&gt;\n    &lt;/dependency&gt;\n  &lt;/dependencies&gt;\n\n  &lt;build&gt;\n    &lt;sourceDirectory&gt;src/main/scala&lt;/sourceDirectory&gt;\n    &lt;testSourceDirectory&gt;src/test/scala&lt;/testSourceDirectory&gt;\n    &lt;plugins&gt;\n      &lt;plugin&gt;\n        &lt;groupId&gt;org.scala-tools&lt;/groupId&gt;\n        &lt;artifactId&gt;maven-scala-plugin&lt;/artifactId&gt;\n        &lt;executions&gt;\n          &lt;execution&gt;\n            &lt;goals&gt;\n              &lt;goal&gt;compile&lt;/goal&gt;\n              &lt;goal&gt;testCompile&lt;/goal&gt;\n            &lt;/goals&gt;\n          &lt;/execution&gt;\n        &lt;/executions&gt;\n        &lt;configuration&gt;\n          &lt;scalaVersion&gt;${scala.version}&lt;/scalaVersion&gt;\n          &lt;args&gt;\n            &lt;arg&gt;-target:jvm-1.5&lt;/arg&gt;\n          &lt;/args&gt;\n        &lt;/configuration&gt;\n      &lt;/plugin&gt;\n      &lt;plugin&gt;\n        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n        &lt;artifactId&gt;maven-eclipse-plugin&lt;/artifactId&gt;\n        &lt;configuration&gt;\n          &lt;downloadSources&gt;true&lt;/downloadSources&gt;\n          &lt;buildcommands&gt;\n            &lt;buildcommand&gt;ch.epfl.lamp.sdt.core.scalabuilder&lt;/buildcommand&gt;\n          &lt;/buildcommands&gt;\n          &lt;additionalProjectnatures&gt;\n            &lt;projectnature&gt;ch.epfl.lamp.sdt.core.scalanature&lt;/projectnature&gt;\n          &lt;/additionalProjectnatures&gt;\n          &lt;classpathContainers&gt;\n            &lt;classpathContainer&gt;org.eclipse.jdt.launching.JRE_CONTAINER&lt;/classpathContainer&gt;\n            &lt;classpathContainer&gt;ch.epfl.lamp.sdt.launching.SCALA_CONTAINER&lt;/classpathContainer&gt;\n          &lt;/classpathContainers&gt;\n        &lt;/configuration&gt;\n      &lt;/plugin&gt;\n    &lt;/plugins&gt;\n  &lt;/build&gt;\n  &lt;reporting&gt;\n    &lt;plugins&gt;\n      &lt;plugin&gt;\n        &lt;groupId&gt;org.scala-tools&lt;/groupId&gt;\n        &lt;artifactId&gt;maven-scala-plugin&lt;/artifactId&gt;\n        &lt;configuration&gt;\n          &lt;scalaVersion&gt;${scala.version}&lt;/scalaVersion&gt;\n        &lt;/configuration&gt;\n      &lt;/plugin&gt;\n    &lt;/plugins&gt;\n  &lt;/reporting&gt;\n&lt;/project&gt;\n</code></pre><blockquote>\n<p><strong>注意：如果有akka-actor的话  要和scala的版本相对应</strong></p>\n</blockquote>\n<p><img src=\"https://static.oschina.net/uploads/space/2018/0211/155017_Suab_3005534.png\" alt></p>\n<h2 id=\"二-scala的单词拆分\"><a href=\"#二-scala的单词拆分\" class=\"headerlink\" title=\"二.scala的单词拆分\"></a>二.scala的单词拆分</h2><pre><code>var word=Array(&quot;hello tom hello jelly&quot;,&quot;tom jelly&quot;,&quot;hello world hello tom&quot;,&quot;hello jelly&quot;,&quot;hello tom&quot;)\nvar b=word.flatMap(_.split(&quot; &quot;)).map((_,1)).groupBy(_._1).map(m=&gt;(m._1,m._2.map(x=&gt;x._2).sum)).toArray\nb.sortWith(_._2 &gt; _._2).toMap\nres33: scala.collection.immutable.Map[String,Int] = Map(hello -&gt; 6, tom -&gt; 4, jelly -&gt; 3, world -&gt; 1)</code></pre><p>或者</p>\n<pre><code>scala&gt; b.toSeq.sortWith(_._2&gt;_._2).toMap\nres32: scala.collection.immutable.Map[String,Int] = Map(hello -&gt; 6, tom -&gt; 4, jelly -&gt; 3, world -&gt; 1)</code></pre><p>扩展：</p>\n<pre><code>a=Map()//数据清空使用再次new\nprintln(a.size)\na.toSeq.sortBy(_._1)//升序排序 key\na.toSeq.sortBy(_._2)//升序排序 value\na.toSeq.sortWith(_._1&gt;_._1) //降序排序 key\na.toSeq.sortWith(_._2&gt;_._2) //降序排序 value</code></pre><pre><code>scala&gt; var word=Array(&quot;hello tom hello jelly&quot;,&quot;tom jelly&quot;,&quot;hello world hello tom&quot;,&quot;hello jelly&quot;,&quot;hello tom&quot;)\n\nscala&gt; word.flatMap(_.split(&quot; &quot;))  //将数组中每个元素，按照空格切分并且扁平化\nres34: Array[String] = Array(hello, tom, hello, jelly, tom, jelly, hello, world, hello, tom, hello, jelly, hello, tom)\n\nscala&gt; word.flatMap(_.split(&quot; &quot;)).map((_,1))  //将数组中每个单词，转成元组，并标记1\nres35: Array[(String, Int)] = Array((hello,1), (tom,1), (hello,1), (jelly,1), (tom,1), (jelly,1), (hello,1), (world,1), (hello,1), (tom,1), (hello,1), (jelly,1), (hello,1), (tom,1))\n\nscala&gt; word.flatMap(_.split(&quot; &quot;)).map((_,1)).groupBy(_._1)//将元组的数组中按照元组的第一个元素排序\nres36: scala.collection.immutable.Map[String,Array[(String, Int)]] = Map(world -&gt; Array((world,1)), tom -&gt; Array((tom,1), (tom,1), (tom,1), (tom,1)), hello -&gt; Array((hello,1), (hello,1), (hello,1), (hello,1), (hello,1), (hello,1)), jelly -&gt; Array((jelly,1), (jelly,1), (jelly,1)))\n\nscala&gt; word.flatMap(_.split(&quot; &quot;)).map((_,1)).groupBy(_._1).map(m=&gt;(m._1,m._2.map(x=&gt;x._2).sum)) //将排序后的元组进行数值求和\nres37: scala.collection.immutable.Map[String,Int] = Map(world -&gt; 1, tom -&gt; 4, hello -&gt; 6, jelly -&gt; 3)\n\nscala&gt; word.flatMap(_.split(&quot; &quot;)).map((_,1)).groupBy(_._1).map(m=&gt;(m._1,m._2.map(x=&gt;x._2).sum)).toArray\n//将排序求和后的map转化成元组方便排序\nres38: Array[(String, Int)] = Array((world,1), (tom,4), (hello,6), (jelly,3))\n\nscala&gt; word.flatMap(_.split(&quot; &quot;)).map((_,1)).groupBy(_._1).map(m=&gt;(m._1,m._2.map(x=&gt;x._2).sum)).toArray.sortWith(_._2 &gt; _._2) //将排序求和后的map转化成元组排序\nres39: Array[(String, Int)] = Array((hello,6), (tom,4), (jelly,3), (world,1))\n\nscala&gt; word.flatMap(_.split(&quot; &quot;)).map((_,1)).groupBy(_._1).map(m=&gt;(m._1,m._2.map(x=&gt;x._2).sum)).toArray.sortWith(_._2 &gt; _._2).toMap //转化回来map\nres40: scala.collection.immutable.Map[String,Int] = Map(hello -&gt; 6, tom -&gt; 4, jelly -&gt; 3, world -&gt; 1)\n\n\n</code></pre><h2 id=\"三-数组常见方法汇总\"><a href=\"#三-数组常见方法汇总\" class=\"headerlink\" title=\"三.数组常见方法汇总\"></a>三.数组常见方法汇总</h2><p><strong>array学习笔记</strong></p>\n<p>数组要点<br>1.若长度固定则使用Array，若长度可能有变化则使用ArrayBuffer<br>2.提供初始值时不要使用new<br>3.用()来访问元素<br>4.用for(elem &lt;- arr) 来遍历元素<br>5.用for(elem &lt;- array if …) … yield 来将原数组转型为新数组<br>6.Scala数组和Java数组可以互操作，用ArrayBuffer，使用scala.collection.JavaConversions中的转换函数。<br>定长数组 如果数组长度不变，则可使用scala中的Array，例如：</p>\n<pre><code>val nums = new Array[Int](10)    //10个整数的数组，所有元素初始化为0\nval string = new Array[String](10) //10个元素的字符串数组，所有元素被初始化为null\nval s = Array(&quot;hello&quot;,&quot;scala&quot;)  //长度为2的Array[String]——类型是推断出来的。已提供初始值，不需要new</code></pre><p>变长数组<br>对于那种长度按需要变化的数组，Java有ArrayList，C++有vector。Scalable中有等效的数据结构为：ArrayBuffer</p>\n<pre><code>import scala.collection.mutable.ArrayBuffer\nval b = ArrayBuffer[Int]()\n//或者new ArrayBuffer[Int]\n//一个空的数组缓冲，准备存放整数\nb += 1   //ArrayBuffer(1),用+=在尾部添加元素\nb += (1,2,3,4)     //在尾部添加多个元素\n\nb ++= Array(8,12,13)   //可以用++=操作符追加任何集合\nb.trimEnd(5)  //移除最后5个元素\n\n//在任意 位置添加元素\nb.insert(2,6)   //在下标2之前插入\nb.insert(2,6,7,8)   //在下标2之前插入6,7,8\n\nb.remove(2)   //移除下标为2的位置开始移除元素\nb.remove(2,3)  //从下标为2开始移除3个元素；第二个参数是表示移除元素的个数</code></pre><p>在使用时，有时不确定数组需要装元素的个数。此时，可以先构建一个数组缓冲，然后调用</p>\n<pre><code>b.toArray   //将缓冲数组转换为定长数组</code></pre><p>定长数组也可以转换为缓冲数组</p>\n<pre><code>a.toBuffer</code></pre><p>遍历数组和数组缓冲</p>\n<p>使用for循环遍历数组和数组缓冲<br>使用下标的方式</p>\n<pre><code>for (i &lt;- 0 until a.length){\n    println( i + &quot;:&quot; + a(i))\n}</code></pre><p>until用法扩展：这只步长–&gt; 0 until (a.length,2)  从数组尾部开始–&gt;(0 until a.length).reverse<br>不使用下标访问数组元素</p>\n<pre><code>for (elem &lt;- arrName) {println(elem)}</code></pre><p>数组转换</p>\n<pre><code>val a = Array(2,3,4)\nval result = for (elem &lt;- a) yield 2 * elem\nfor (elem &lt;-  a if elem %2==0) yield 2 * elem</code></pre><p>常用算法</p>\n<pre><code>sum: Array(1,2,3).sum\nmax/min : Array(1,2,3).max/min\nsorted : Array(1,2,3).sorted(_ &lt; ) ; Array(1,2,3).sorted( &gt; _) //不能对缓冲数组排序\nquickSort方法排序：scala.util.Sorting.quickSort(a)\n显示数组内容：mkString; a.mkString(&quot; and &quot;) //可以设置分隔符</code></pre><p>1、定长数组定义：</p>\n<pre><code>//定义一个长度为10的数值数组\nscala&gt; val numberArray = new Array[int](10)\nnumberArray:Array[Int] = Array(0,0,0,0,0,0,0,0,0,0)\n//定义一个长度为10的String类数组\nscala&gt; val strArray = new Array[String](10)\nstrArray:Array[String] = Array(null, null, null, null, null, null, null, null, null, null)\n\n//由上可以看出，复杂对象类型在数组定义时被初始化为null，数值型呗初始化为0，并且上面复杂类型定义的时候必须加new，否则会报错\n\n//提供初始值的定义数组\nscala&gt; val strArray2 = Array(&quot;First&quot;, &quot;Second&quot;)  //这里说明已提供初始值就不需要new\nstrArray2:Array[String] = Array(First, Second)\n\nscala&gt; strArray2(0) = &quot;Goodbye&quot;\nstrArray2:Array[String] = Array(Goodbye, Second)\n</code></pre><p>2、变长数组定义</p>\n<pre><code>对于长度需要变化的数组，Java有ArrayList,C++有vector。Scala中的等效数据结构为ArrayBuffer\n\n//导入可变包，Scala中的可变集合都是放在mutable中，使用时要导入\nscala&gt; import scala.collection.mutable.ArrayBuffer\nimport scala.collection.mutable.ArrayBuffer\n\nscala&gt; val arrayBuffer = ArrayBuffer[Int]()\narrayBuffer: scala.collection.mutable.ArrayBuffer[Int] = ArrayBuffer()\n\n//在尾部添加一个值\nscala&gt; arrayBuffer += 1\nres17: arrayBuffer.type = ArrayBuffer(1)\n\n//在尾部添加多个元素\nscala&gt; arrayBuffer += (2, 3, 4, 5)\nres19: arrayBuffer.type = ArrayBuffer(1, 2, 3, 4, 5)\n\n//在尾部添加一个集合\nscala&gt; arrayBuffer ++= Array(6, 7, 8, 9)\nres20: arrayBuffer.type = ArrayBuffer(1, 2, 3, 4, 5, 6, 7, 8, 9)\n\n//移除最后2个元素\nscala&gt; arrayBuffer.trimEnd(2)\n\n//在开头移除1一个元素\nscala&gt; arrayBuffer.trimStart(2)\n\nscala&gt; arrayBuffer\nres23: scala.collection.mutable.ArrayBuffer[Int] = ArrayBuffer(2, 3, 4, 5, 6, 7)\n\n\n//在任意位置插入或者删除元素\nscala&gt; arrayBuffer.insert(2, 6)\n//ArrayBuffer(2, 3, 6, 4, 5, 6, 7)\n\nscala&gt; arrayBuffer.insert(1, 2, 3, 4)\n//ArrayBuffer(2, 1, 2, 3, 4, 3, 6, 4, 5, 6, 7)\n\nscala&gt; arrayBuffer.remove(2)\n//ArrayBuffer(2, 1, 3, 4, 3, 6, 4, 5, 6, 7)\n\nscala&gt; arrayBuffer.remover(1, 8)\n//ArrayBuffer(2, 7)\n</code></pre><p>3、变长数组和定长数组转换</p>\n<pre><code>//变长转换长定长\nscala &gt; arrayBuffer.toArray\n//Array(2, 7)\n\n//定长转换成变长\nscala&gt;res7.toBuffer\n//ArrayBuffer(2, 7)\n</code></pre><p>4、遍历定长和变长数组</p>\n<pre><code>for(i &lt;- 0 until.arrayBuffer.length)\n    println(i + &quot;: &quot; + a(i))\n0 until.arrayBuffer.length实际上是一个方法调用，返回的是一个区间Range： 0.until(arrayBuffer.length)\nfor(i &lt;- 区间)会让变量i遍历该区间的所有值\n如果想要在区间中步长不为1，则：0 until (arrayBuffer.length, 2)\n如果想要数组从尾端开始，则遍历的写法为:(0 until (arrayBuffer.length, 2)).reverse\n\nScala也提供了一个和Java增强for循环类似的for\n\n//增强for\nfor(i &lt;- arrayBuffer)\n    println(i + &quot;: &quot; + a(i))\n</code></pre><p>5、数组转换</p>\n<p>在《Scala入门学习笔记二-基本数据类型、程序控制结构》提到在for循环推导式，可以利用原来的数组产生一个新的数组。</p>\n<pre><code>scala&gt; val a = Array(2, 3, 5, 7, 11)\na: Array[Int] = Array(2, 3, 5, 7, 11)\n//这里产生了一个新的数组，原来的数组也在\nscala&gt; val result = for(elem &lt;- a) yield 2 * elem\nresult: Array[Int] = Array(4, 6, 10, 14, 22)\n如果for中使用的是定长数组，则for(...)...yield之后得到的是定长数组;如果使用的是变长数组，则会得到变长数组\n\nScala也提供了另外一种做法\nscala&gt; a.filter(_ % 2 == 0).map(2 * _)\n\n甚至\nscala&gt;a.filter(_ % 2 == 0).map{2 * _}\n例子：\n给定一个整数的缓冲数组，我们想要移除第一个负数之外的所有负数。有几种做法\n\n//第一种做法：\nvar first = true\nvar n = a.length\nvar i = 0\nwhile(i &lt; n){\n    if(a(i) &gt; 0) i += 1\n    else{\n        if(first) {first = false; i += 1}\n        else {a.remove(i); n-= 1}\n    }\n}\n\n//第二种做法：\n//首先使用一个新数组用于记录满足条件的数组的下标\nval first = true\nval indexes = for(i &lt;- 0 until a.length if first || a(i) &gt; 0) yield {\n    if(a(i) &lt; 0) first = false; i\n}\n//然后将元素移动到该去的位置，截断尾端\nfor(j &lt;- o until indexes.length) a(j) = a(indexes(j))\na.trimEnd(a.length-indexes.length)</code></pre><p>6、常用算法<br>Scala针对数组提供了一个常用的函数</p>\n<pre><code>//定义一个整型数组\nscala&gt; val intArr=Array(1,2,3,4,5,6,7,8,9,10)\nintArr: Array[Int] = Array(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n\n//求和\nscala&gt; intArr.sum\nres87: Int = 55\n\n//求最大值\nscala&gt; intArr.max\nres88: Int = 10\n\nscala&gt; ArrayBuffer(&quot;Hello&quot;,&quot;Hell&quot;,&quot;Hey&quot;,&quot;Happy&quot;).max\nres90: String = Hey\n\n//求最小值\nscala&gt; intArr.min\nres89: Int = 1\n\n//排序\n//sorted方法将数组或数组缓冲排序并返回经过排序的数组或数组缓冲，原始数组被保留\nscala&gt;val b = ArrayBuffer(1, 7, 2, 9)\nb:ArrayBuffer[Int] = ArrayBuffer(1, 7, 2, 9)\nscala&gt;val bSorted = b.sorted(_&lt;_) \nbSorted: ArrayBuffer[Int] = ArrayBuffer(1, 2, 7, 9)\n\n//toString()方法\nscala&gt; intArr.toString()\nres94: String = [I@141aba8\n\n//mkString()方法\nscala&gt; intArr.mkString(&quot;,&quot;)\nres96: String = 1,2,3,4,5,6,7,8,9,10\n\nscala&gt; intArr.mkString(&quot;&lt;&quot;,&quot;,&quot;,&quot;&gt;&quot;)\nres97: String = &lt;1,2,3,4,5,6,7,8,9,10&gt;</code></pre><p>7、ArrayBuffer Scaladoc解析</p>\n<pre><code>初学者在查看sacaladoc时常常会感到困惑，不用担心，随着学习的深入，api文档中的内容将逐渐清晰\n下面给出两个示例：\n++=方法传入的参数类型是TraversableOnce Trait的子类，它返回的是更新好的ArrayBuffer\n\n++=方法解析\n\ndropWhile传入的是一个函数，该函数返回值是布尔类型，dropWhile反回的是操作后的ArrayBuffer\n\ndropWith方法解析</code></pre><p>8、多维数组<br>和Java一样，多维数组是通过数组的数组来实现的。</p>\n<pre><code>//第一种构造方式\nval metrix = Array.ofDim[Double](3, 4) //3行 4列\n\n//访问其中的元素\nmetrix(row)(column)  =42\n\n//可以创建不规则的数组，每一行的长度不相同\nval triangle = new Array[Array[Int]](10)\nfor(i &lt;- 0 until triangle.length)\n    trianglr(i) = new Array[Int](i+1)\n\n//在创建的时候赋值\nscala&gt; val metrix = Array(Array(1, 2, 3), Array(2.3, 3.4), Array(&quot;asdf&quot;, &quot;asdfas&quot;))\nmetrix: Array[Array[_ &gt;: String with Double with Int]] = Array(Array(1, 2, 3), Array(2.3, 3.4), Arra\ny(asdf, asdfas))\n\n//打印输出数组\nscala&gt; for(i &lt;- metrix) println(i.mkString(&quot; &quot;))\n1 2 3\n2.3 3.4\nasdf asdfas\n\n//输出二维数组的每个值\nscala&gt; for(i &lt;- metrix; from = i; j &lt;- from) println(j)\n1\n2\n3\n2.3\n3.4\nasdf\nasdfas</code></pre><h2 id=\"四-数组操作-二\"><a href=\"#四-数组操作-二\" class=\"headerlink\" title=\"四.数组操作(二)\"></a>四.数组操作(二)</h2><p>Scala数组操作：</p>\n<p>1.定长数组<br> 长度不变的数组的声明：</p>\n<pre><code>//长度为10的整数数组，所有元素初始化为0\n val numArr = new Array[Int](10)\n\n//长度为10的字符串数组，所有元素初始化为null\nval numArr = new Array[String](10)\n\n//长度为2的数组，数据类型自动推断出来，已经提供初始值就不需要new关键字\nval s = Array(&quot;cai&quot;,&quot;yong&quot;)\n\n//通过ArrayName(index)访问数组元素和更改数组元素\nval s = Array(&quot;cai&quot;,&quot;yong&quot;)\n println(s(0))\ns(0) = &quot;haha&quot;\nprintln(s(0))\n输出：\n cai\n haha\n</code></pre><p>2.变长数组：数组缓冲<br> Scala也支持长度变化的数组，支持的数据结构是ArrayBuffer</p>\n<pre><code>//一个空的数组缓冲，准备存放整数\n val ab = ArrayBuffer[Int]()\n val ab2 = new ArrayBuffer[Int]\n\n//用+=在尾部添加元素\nab += 2\n\n//在尾部添加多个元素\nab += (1,2,3,4,5)\n\n//通过++=往数组缓冲后面追加集合\n ab ++= Array(6,7,8,9)\n\n//使用trimEnd(n)移除尾部n个元素\nab.trimEnd(3)\n\n//在下标3之前插入元素\nab.insert(3, 33)\n\n//插入多个元素，第一个值为index，后面所有的值为要插入的值\nab.insert(3,3,4,5,6)\n\n//移除某个位置的元素\nab.remove(3)\n\n//移除从下标为n开始（包括n）的count个元素\nab.remove(n, count)</code></pre><p> 有时候需要构造一个Array，但是不知道具体要存放多少元素，可以先构造ArrayBuffer,再调用toArray方法转化成Array，同样，对Array调用toBuffer方法可以转成ArrayBuffer.</p>\n<p> 注：在数组缓冲的尾部进行元素添加移除操作的效率很高，但是在任意位置插入或移除元素的效率并不太高效，因为涉及到数组元素的移动。</p>\n<p>3.遍历数组</p>\n<pre><code>//for循环遍历\nfor(i &lt;- 0 until ab.length){\n print(ab(i) + &quot;, &quot;)\n }\n\n//根据特定步长遍历数组\nfor(i &lt;- 0 until (ab.length, 2)){\n print(ab(i) + &quot;, &quot;)\n }\n\n//从数组的尾部开始向前遍历数组\nfor(i &lt;- (0 until ab.length).reverse){\n print(ab(i) + &quot;, &quot;)\n}\n\n//类似于Java中的foreach遍历数组\n for(elem &lt;- ab){\n print(elem + &quot;, &quot;)\n}</code></pre><p>4.数组转换</p>\n<pre><code>//进行数组转换会生成一个新的数组，而不会修改原始数组\n val change = for(elem &lt;- ab) yield elem * 2\nfor(elem &lt;- change){\nprint(elem + &quot;, &quot;)\n }\n\n//添加一个守卫的数组转换\nval change = for(elem &lt;- ab if elem%2 == 0) yield elem * 2</code></pre><p>5.数组操作常用算法</p>\n<pre><code>//sum求和(数组与阿奴必须是数值型数据)\nprintln(change.sum)\n\n//min max 输出数组中最小和最大元素\nprintln(change.min)\nprintln(change.max)\n\n//使用sorted方法对数组或数组缓冲进行升序排序，这个过程不会修改原始数组\n val sortArr = ab.sorted \n for(elem &lt;- sortArr)\n print(elem + &quot;, &quot;)\n\n//使用比较函数sortWith进行排序\nval sortArr = ab.sortWith(_&gt;_)\n\n//数组显示\n println(sortArr.mkString(&quot;|&quot;))\n println(sortArr.mkString(&quot;startFlag&quot;,&quot;|&quot;,&quot;endFlag&quot;))</code></pre><p>6.多维数组</p>\n<pre><code>//构造一个2行3列的数组\nval arr = Array.ofDim[Int](2,3)\nprintln(arr.length)\nprintln(arr(0).length)\narr(0)(0) = 20\nprintln(arr(0)(0))\n\n//创建长度不规则的数组\nval arr = new Array[Array[Int]](3)\n\n for(i &lt;- 0 until arr.length){\narr(i) = new Array[Int](i + 2)\n}\n\nfor(i &lt;- 0 until arr.length){\nprintln(arr(i).length)\n}</code></pre><h2 id=\"五-Tuple常见方法汇总\"><a href=\"#五-Tuple常见方法汇总\" class=\"headerlink\" title=\"五.Tuple常见方法汇总\"></a>五.Tuple常见方法汇总</h2><pre><code>tuple的定义\n\n对偶是元组(tuple)的最简单形态——元组是不同类型的值的聚集。\n元组的值是通过将单个值包含在圆括号中构成。Example：（1，1.3415，“Fred”)\ntuple的访问\n\n可以通过_1,_2,_3访问元组的元素\nval first = tuple._1 //元组的位置从1开始，而非从0开始</code></pre><p>与列表一样，元组也是不可变的，但与列表不同的是元组可以包含不同类型的元素。<br>元组的值是通过将单个的值包含在圆括号中构成的。例如：</p>\n<pre><code>val t = (1, 3.14, &quot;Fred&quot;)  </code></pre><p>以上实例在元组中定义了三个元素，对应的类型分别为[Int, Double, java.lang.String]。<br>此外我们也可以使用以上方式来定义：</p>\n<pre><code>val t = new Tuple3(1, 3.14, &quot;Fred&quot;)</code></pre><p>元组的实际类型取决于它的元素的类型，比如 (99, “runoob”) 是 Tuple2[Int, String]。 (‘u’, ‘r’, “the”, 1, 4, “me”) 为 Tuple6[Char, Char, String, Int, Int, String]。<br>目前 Scala 支持的元组最大长度为 22。对于更大长度你可以使用集合，或者扩展元组。<br>访问元组的元素可以通过数字索引，如下一个元组：</p>\n<pre><code>val t = (4,3,2,1)\nval sum = t._1 + t._2 + t._3 + t._4\nprintln( &quot;元素之和为: &quot;  + sum )//10</code></pre><p>迭代元组</p>\n<pre><code>val t = (4,3,2,1)\nt.productIterator.foreach{ i =&gt;println(&quot;Value = &quot; + i )}\nValue = 4\nValue = 3\nValue = 2\nValue = 1</code></pre><p>元组转为字符串<br>你可以使用 Tuple.toString() 方法将元组的所有元素组合成一个字符串，实例如下：</p>\n<pre><code>val t = new Tuple3(1, &quot;hello&quot;, Console)\nprintln(&quot;连接后的字符串为: &quot; + t.toString() )\n连接后的字符串为: (1,hello,scala.Console$@4dd8dc3)</code></pre><h2 id=\"六-List常见方法汇总\"><a href=\"#六-List常见方法汇总\" class=\"headerlink\" title=\"六.List常见方法汇总\"></a>六.List常见方法汇总</h2><p>List的4种操作符的区别和联</p>\n<p>(1):+和+: 两者的区别在于:+方法用于在尾部追加元素，+:方法用于在头部追加元素，和::很类似，但是::可以用于pattern match ，而+:则不行. 关于+:和:+,只要记住冒号永远靠近集合类型就OK了。</p>\n<pre><code>scala&gt; a\nres23: List[Int] = List(1, 2, 3, 4)\n\nscala&gt; var b=a:+9\nb: List[Int] = List(1, 2, 3, 4, 9)\n\nscala&gt; var c=9:+a\n&lt;console&gt;:15: error: value :+ is not a member of Int\n       var c=9:+a\n              ^\nscala&gt; var c=9+:a\nc: List[Int] = List(9, 1, 2, 3, 4)\n\nscala&gt; var r1=&quot;A&quot;+:&quot;B&quot;+:Nil\nr1: List[String] = List(A, B)\n\nscala&gt;var r2=Nil:+&quot;A&quot;:+&quot;B&quot;\nr2: List[String] = List(A, B)</code></pre><p>(2):: 该方法被称为cons，意为构造，向队列的头部追加数据，创造新的列表。用法为 x::list,其中x为加入到头部的元素，无论x是列表与否，它都只将成为新生成列表的第一个元素，也就是说新生成的列表长度为list的长度＋1(btw, x::list等价于list.::(x))</p>\n<pre><code>scala&gt;&quot;A&quot;::&quot;B&quot;::Nil\nres0: List[String] = List(A, B)\n\nscala&gt;List(&quot;A&quot;,&quot;B&quot;)::List(&quot;C&quot;,&quot;D&quot;)\nres1: List[java.io.Serializable] = List(List(A, B), C, D)</code></pre><p>(3) ++ 该方法用于连接两个集合，list1++list2</p>\n<pre><code>scala&gt;List(&quot;A&quot;,&quot;B&quot;) ++ List(&quot;C&quot;,&quot;D&quot;)\nres2: List[String] = List(A, B, C, D)</code></pre><p>(4)::: 该方法只能用于连接两个List类型的集合</p>\n<pre><code>scala&gt;List(&quot;A&quot;,&quot;B&quot;) ::: List(&quot;C&quot;,&quot;D&quot;)\nres3: List[String] = List(A, B, C, D)</code></pre><p><strong>List常用用法</strong></p>\n<p>1）List类型定义以及List的特点：</p>\n<pre><code>//字符串类型List\nscala&gt; val fruit=List(&quot;Apple&quot;,&quot;Banana&quot;,&quot;Orange&quot;)\nfruit: List[String] = List(Apple, Banana, Orange)\n\n//前一个语句与下面语句等同\nscala&gt; val fruit=List.apply(&quot;Apple&quot;,&quot;Banana&quot;,&quot;Orange&quot;)\nfruit: List[String] = List(Apple, Banana, Orange)\n\n//数值类型List\nscala&gt; val nums=List(1,2,3,4,5)\nnums: List[Int] = List(1, 2, 3, 4, 5)\n\n//多重List，List的子元素为List\nscala&gt; val list = List(List(1, 2, 3), List(&quot;adfa&quot;, &quot;asdfa&quot;, &quot;asdf&quot;))\nlist: List[List[Any]] = List(List(1, 2, 3), List(adfa, asdfa, asdf))\n\n//遍历List\nscala&gt; for(i &lt;- list; from=i; j&lt;-from)println(j)\n1\n2\n3\nadfa\nasdfa\nasdf</code></pre><p>（2）List与Array的区别：</p>\n<pre><code>1、List一旦创建，已有元素的值不能改变，可以使用添加元素或删除元素生成一个新的集合返回。\n如前面的nums，改变其值的话，编译器就会报错。而Array就可以成功\n\nscala&gt;nums(3)=4\n&lt;console&gt;:10: error: value update is not a member of List[Int]\n              nums(3)=4\n              ^\n2、List具有递归结构(Recursive Structure),例如链表结构\nList类型和气他类型集合一样，它具有协变性(Covariant),即对于类型S和T，如果S是T的子类型，则List[S]也是List[T]的子类型。\n例如:\n\nscala&gt;var listStr:List[Object] = List(&quot;This&quot;, &quot;Is&quot;, &quot;Covariant&quot;, &quot;Example&quot;)\nlistStr:List[Object] = List(This, Is, Covariant, Example)\n\n//空的List,其类行为Nothing,Nothing在Scala的继承层次中的最底层\n//,即Nothing是任何Scala其它类型如String,Object等的子类\nscala&gt; var listStr = List()\nlistStr:List[Nothing] = List()\n\nscala&gt;var listStr:List[String] = List()\nlistStr:List[String] = List()</code></pre><p>（3）List常用构造方法</p>\n<pre><code>//1、常用::及Nil进行列表构建\nscala&gt; val nums = 1 :: (2:: (3:: (4 :: Nil)))\nnums: List[Int] = List(1, 2, 3, 4)\n\n\n//由于::操作符的优先级是从右向左的，因此上一条语句等同于下面这条语句\nscala&gt; val nums = 1::2::3::4::Nil\nnums:List[Int] = List(1, 2, 3, 4)\n至于::操作符的使用将在下面介绍</code></pre><p>（4）List常用操作</p>\n<pre><code>//判断是否为空\nscala&gt; nums.isEmpty\nres5: Boolean = false\n\n//取第一个元素\nscala&gt; nums.head\nres6: Int = 1\n\n//取列表第二个元素\nscala&gt;nums.tail.head\nres7: Int = 2\n\n//取第三个元素\nscala&gt;nums.tail.tail.head\nres8: Int = 3\n\n//插入操作\n//在第二个位置插入一个元素\nscala&gt;nums.head::(3::nums.tail)\nres11: List[Int] = List(1, 3, 2, 3, 4)\n\nscala&gt; nums.head::(nums.tail.head::(4::nums.tail.tail))\nres12: List[Int] = List(1, 2, 4, 3, 4)\n\n//插入排序算法实现\ndef isort(xs: List[Int]):List[Int] = {\n    if(xs.isEmpty) Nil\n    else insert(xs.head, issort(xs.tail))\n}\n\ndef insert(x:Int, xs:List[Int]):List[Int] = {\n    if(xs.isEmpty || x &lt;= xs.head) x::xs\n    else xs.head :: insert(x, xs.tail)\n}\n\n//连接操作\nscala&gt;List(1, 2, 3):::List(4, 5, 6)\nres13: List[Int] = List(1, 2, 3, 4, 5, 6)\n\n//去除最后一个元素外的元素，返回的是列表\nscala&gt; nums.init\nres13: List[Int] = List(1, 2, 3)\n\n//取出列表最后一个元素\nscala&gt;nums.last\nres14: Int = 4\n\n//列表元素倒置\nscala&gt; nums.reverse\nres15: List[Int] = List(4, 3, 2, 1)\n\n//一些好玩的方法调用\nscala&gt; nums.reverse.reverse == nums\n\n\n//丢弃前面n个元素\nscala&gt;nums drop 3\nres16: List[Int] = List(4)\n\n//获取前面n个元素\nscala&gt;nums take 1\nres17: List[Int] = List[1]\n\n//将列表进行分割\nscala&gt; nums.splitAt(2)\nres18: (List[Int], List[Int]) = (List(1, 2),List(3, 4))\n\n//前一个操作与下列语句等同\nscala&gt; (nums.take(2),nums.drop(2))\nres19: (List[Int], List[Int]) = (List(1, 2),List(3, 4))\n\n//Zip操作\nscala&gt; val nums=List(1,2,3,4)\nnums: List[Int] = List(1, 2, 3, 4)\n\nscala&gt; val chars=List(&#39;1&#39;,&#39;2&#39;,&#39;3&#39;,&#39;4&#39;)\nchars: List[Char] = List(1, 2, 3, 4)\n\n//返回的是List类型的元组(Tuple），返回的元素个数与最小的List集合的元素个数一样\nscala&gt; nums zip chars\nres20: List[(Int, Char)] = List((1,1), (2,2), (3,3), (4,4))\n\n//List toString方法\nscala&gt; nums.toString\nres21: String = List(1, 2, 3, 4)\n\n//List mkString方法\nscala&gt; nums.mkString\nres22: String = 1234\n\n//转换成数组\nscala&gt; nums.toArray\nres23: Array[Int] = Array(1, 2, 3, 4)</code></pre><p>（5）List伴生对象方法</p>\n<pre><code>//apply方法\nscala&gt;  List.apply(1, 2, 3)\nres24: List[Int] = List(1, 2, 3)\n\n//range方法，构建某一值范围内的List\nscala&gt;  List.range(2, 6)\nres25: List[Int] = List(2, 3, 4, 5)\n\n//步长为2\nscala&gt;  List.range(2, 6,2)\nres26: List[Int] = List(2, 4)\n\n//步长为-1\nscala&gt;  List.range(2, 6,-1)\nres27: List[Int] = List()\n\nscala&gt;  List.range(6,2 ,-1)\nres28: List[Int] = List(6, 5, 4, 3)\n\n//构建相同元素的List\nscala&gt; List.make(5, &quot;hey&quot;)\nres29: List[String] = List(hey, hey, hey, hey, hey)\n\n//unzip方法\nscala&gt; List.unzip(res20)\nres30: (List[Int], List[Char]) = (List(1, 2, 3, 4),List(1, 2, 3, 4))\n\n//list.flatten，将列表平滑成第一个无素\nscala&gt; val xss =\n     | List(List(&#39;a&#39;, &#39;b&#39;), List(&#39;c&#39;), List(&#39;d&#39;, &#39;e&#39;))\nxss: List[List[Char]] = List(List(a, b), List(c), List(d, e))\nscala&gt; xss.flatten\nres31: List[Char] = List(a, b, c, d, e)\n\n//列表连接\nscala&gt; List.concat(List(&#39;a&#39;, &#39;b&#39;), List(&#39;c&#39;))\nres32: List[Char] = List(a\n, b, c)</code></pre><p>（6）::和:::操作符介绍</p>\n<pre><code>List中常用&#39;::&#39;,发音为&quot;cons&quot;。Cons把一个新元素组合到已有元素的最前端，然后返回结果List。\n\nscala&gt; val twoThree = List(2, 3)\nscala&gt; val oneTwoThree = 1 :: twoThree\nscala&gt; oneTwoThree\noneTwoThree: List[Int] = List(1, 2, 3)\n上面表达式&quot;1::twoThree&quot;中，::是右操作数，列表twoThree的方法。可能会有疑惑。表达式怎么是右边参数的方法，这是Scala语言的一个例外的情况:如果一个方法操作符标注，如a * b,那么方法被左操作数调用，就像a.* (b)--除非方法名以冒号结尾。这种情况下，方法被右操作数调用。\nList有个方法叫&quot;:::&quot;，用于实现叠加两个列表。\n\nscala&gt; val one = List(&#39;A&#39;, &#39;B&#39;)\nval one = List(&#39;A&#39;, &#39;B&#39;)\nscala&gt; val two = List(&#39;C&#39;, &#39;D&#39;)\n\nscala&gt; one:::two\nres1: List[Char] = List(A, B, C, D)</code></pre><p>创建列表</p>\n<pre><code>scala&gt; val days = List(&quot;Sunday&quot;, &quot;Monday&quot;, &quot;Tuesday&quot;, &quot;Wednesday&quot;, &quot;Thursday&quot;, &quot;Friday&quot;, &quot;Saturday&quot;)\ndays: List[String] = List(Sunday, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday)</code></pre><p>创建空列表</p>\n<pre><code>scala&gt; val l = Nil //scala.collection.immutable.Nil继承了List[Nothing]  这是空列表\nl: scala.collection.immutable.Nil.type = List()\n\nscala&gt; val l = List()\nl: List[Nothing] = List()</code></pre><p>用字符串创建列表</p>\n<pre><code>scala&gt; val l = &quot;Hello&quot; :: &quot;Hi&quot; :: &quot;Hah&quot; :: &quot;WOW&quot; :: &quot;WOOW&quot; :: Nil\nl: List[String] = List(Hello, Hi, Hah, WOW, WOOW)</code></pre><p>用“:::”叠加创建新列表</p>\n<pre><code>scala&gt; val wow = l ::: List(&quot;WOOOW&quot;, &quot;WOOOOW&quot;)\nwow: List[String] = List(Hello, Hi, Hah, WOW, WOOW, WOOOW, WOOOOW)</code></pre><p>通过索引获取列表值</p>\n<pre><code>scala&gt; l(3)\nres0: String = WOW</code></pre><p>获取值长度为3的元素数目</p>\n<pre><code>scala&gt; l.count(s =&gt; s.length == 3)\nres1: Int = 2</code></pre><p>返回去掉l头两个元素的新列表</p>\n<pre><code>scala&gt; l.drop(2)\nres2: List[String] = List(Hah, WOW, WOOW)\n\nscala&gt; l\nres3: List[String] = List(Hello, Hi, Hah, WOW, WOOW)</code></pre><p>返回去掉l后两个元素的新列表</p>\n<pre><code>scala&gt; l.dropRight(2)\nres5: List[String] = List(Hello, Hi, Hah)\n\nscala&gt; l\nres6: List[String] = List(Hello, Hi, Hah, WOW, WOOW)</code></pre><p>判断l是否存在某个元素</p>\n<pre><code>scala&gt; l.exists(s =&gt; s == &quot;Hah&quot;)\nres7: Boolean = true</code></pre><p>滤出长度为3的元素</p>\n<pre><code>scala&gt; l.filter(s =&gt; s.length == 3)\nres8: List[String] = List(Hah, WOW)</code></pre><p>判断所有元素是否以“H”打头</p>\n<pre><code>scala&gt; l.forall(s =&gt; s.startsWith(&quot;H&quot;))\nres10: Boolean = false</code></pre><p>判断所有元素是否以“H”结尾</p>\n<pre><code>scala&gt; l.forall(s =&gt; s.endsWith(&quot;W&quot;))\nres11: Boolean = false</code></pre><p>打印每个元素</p>\n<pre><code>scala&gt; l.foreach(s =&gt; print(s + &#39; &#39;))\nHello Hi Hah WOW WOOW</code></pre><p>取出第一个元素</p>\n<pre><code>scala&gt; l.head\nres17: String = Hello</code></pre><p>取出最后一个元素</p>\n<pre><code>scala&gt; l.last\nres20: String = WOOW</code></pre><p>剔除最后一个元素，生成新列表</p>\n<pre><code>scala&gt; l.init\nres18: List[String] = List(Hello, Hi, Hah, WOW)</code></pre><p>剔除第一个元素，生成新列表</p>\n<pre><code>scala&gt; l.tail\nres49: List[String] = List(Hi, Hah, WOW, WOOW)</code></pre><p>判断列表是否为空</p>\n<pre><code>scala&gt; l.isEmpty\nres19: Boolean = false</code></pre><p>获得列表长度</p>\n<pre><code>scala&gt; l.length\nres21: Int = 5</code></pre><p>修改每个元素，再反转每个元素形成新列表</p>\n<pre><code>scala&gt; l.map(s =&gt; {val s1 = s + &quot; - 01&quot;; s1.reverse})\nres29: List[String] = List(10 - olleH, 10 - iH, 10 - haH, 10 - WOW, 10 - WOOW)</code></pre><p>生成用逗号隔开的字符串</p>\n<pre><code>scala&gt; l.mkString(&quot;, &quot;)\nres30: String = Hello, Hi, Hah, WOW, WOOW</code></pre><p>反序生成新列表</p>\n<pre><code>scala&gt; l.reverse\nres41: List[String] = List(WOOW, WOW, Hah, Hi, Hello)</code></pre><p>按字母递增排序</p>\n<pre><code>scala&gt; l.sortWith(_.compareTo(_) &lt; 0)\nres48: List[String] = List(Hah, Hello, Hi, WOOW, WOW)</code></pre><p><strong>List定义的方法</strong></p>\n<pre><code>def  ++[B &gt;: A, That](that: GenTraversableOnce[B])(implicit bf: CanBuildFrom[List[A], B, That]): That\nReturns a new list containing the elements from the left hand operand followed by the elements from the right hand operand.</code></pre><pre><code>def  ++:[B &gt;: A, That](that: collection.Traversable[B])(implicit bf: CanBuildFrom[List[A], B, That]): That\nAs with ++, returns a new collection containing the elements from the left operand followed by the elements from the right operand.</code></pre><pre><code>def  ++:[B](that: TraversableOnce[B]): List[B]\n[use case] As with ++, returns a new collection containing the elements from the left operand followed by the elements from the right operand.</code></pre><pre><code>def  +:(elem: A): List[A]\n[use case]\nA copy of the list with an element prepended.\n\nNote that :-ending operators are right associative (see example). A mnemonic for +: vs. :+ is: the COLon goes on the COLlection side.\n\nAlso, the original list is not modified, so you will want to capture the result.\n\nExample:\n\nscala&gt; val x = List(1)\nx: List[Int] = List(1)\n\nscala&gt; val y = 2 +: x\ny: List[Int] = List(2, 1)\n\nscala&gt; println(x)\nList(1)\nelem\nthe prepended element\nreturns\na new list consisting of elem followed by all elements of this list.</code></pre><pre><code>def inition Classes\nList → SeqLike → GenSeqLike\n Full Signature</code></pre><pre><code>def  /:[B](z: B)(op: (B, A) ⇒ B): B\nApplies a binary operator to a start value and all elements of this traversable or iterator, going left to right.</code></pre><pre><code>def  :+(elem: A): List[A]\n[use case] A copy of this list with an element appended.</code></pre><pre><code>def  ::(x: A): List[A]\n[use case] Adds an element at the beginning of this list.</code></pre><pre><code>def  :::(prefix: List[A]): List[A]\n[use case] Adds the elements of a given list in front of this list.</code></pre><pre><code>def  :\\[B](z: B)(op: (A, B) ⇒ B): B\nApplies a binary operator to all elements of this traversable or iterator and a start value, going right to left.</code></pre><pre><code>def  addString(b: StringBuilder): StringBuilder\nAppends all elements of this traversable or iterator to a string builder.</code></pre><pre><code>def  addString(b: StringBuilder, sep: String): StringBuilder\nAppends all elements of this traversable or iterator to a string builder using a separator string.</code></pre><pre><code>def  addString(b: StringBuilder, start: String, sep: String, end: String): StringBuilder\nAppends all elements of this traversable or iterator to a string builder using start, end, and separator strings.</code></pre><pre><code>def  aggregate[B](z: ⇒ B)(seqop: (B, A) ⇒ B, combop: (B, B) ⇒ B): B\nAggregates the results of applying an operator to subsequent elements.</code></pre><pre><code>def  andThen[C](k: (A) ⇒ C): PartialFunction[Int, C]\nComposes this partial function with a transformation function that gets applied to results of this partial function.</code></pre><pre><code>def  apply(n: Int): A\nSelects an element by its index in the sequence.</code></pre><pre><code>def  applyOrElse[A1 &lt;: Int, B1 &gt;: A](x: A1, ```</code></pre><p>def ault: (A1) ⇒ B1): B1<br>Applies this partial function to the given argument when it is contained in the function domain.</p>\n<pre><code></code></pre><p>def  canEqual(that: Any): Boolean<br>Method called from equality methods, so that user-```</p>\n<pre><code>def ined subclasses can refuse to be equal to other collections of the same kind.\nfinal ```</code></pre><p>def  collect[B](pf: PartialFunction[A, B]): List[B]<br>[use case] Builds a new collection by applying a partial function to all elements of this list on which the function is ```</p>\n<pre><code>def ined.</code></pre><pre><code>def  collectFirst[B](pf: PartialFunction[A, B]): Option[B]\nFinds the first element of the traversable or iterator for which the given partial function is ```</code></pre><p>def ined, and applies the partial function to it.</p>\n<pre><code></code></pre><p>def  combinations(n: Int): Iterator[List[A]]<br>Iterates over combinations.</p>\n<pre><code></code></pre><p>def  companion: GenericCompanion[List]<br>The factory companion object that builds instances of class List.</p>\n<pre><code></code></pre><p>def  compose[A](g: (A) ⇒ Int): (A) ⇒ A<br>Composes two instances of Function1 in a new Function1, with this function applied last.</p>\n<pre><code></code></pre><p>def  contains[A1 &gt;: A](elem: A1): Boolean<br>Tests whether this sequence contains a given value as an element.</p>\n<pre><code></code></pre><p>def  containsSlice[B](that: GenSeq[B]): Boolean<br>Tests whether this sequence contains a given sequence as a slice.</p>\n<pre><code></code></pre><p>def  copyToArray(xs: Array[A], start: Int, len: Int): Unit<br>[use case] Copies the elements of this list to an array.</p>\n<pre><code></code></pre><p>def  copyToArray(xs: Array[A]): Unit<br>[use case] Copies the elements of this list to an array.</p>\n<pre><code></code></pre><p>def  copyToArray(xs: Array[A], start: Int): Unit<br>[use case] Copies the elements of this list to an array.</p>\n<pre><code></code></pre><p>def  copyToBuffer[B &gt;: A](dest: Buffer[B]): Unit<br>Copies all elements of this traversable or iterator to a buffer.<br>final ```</p>\n<pre><code>def  corresponds[B](that: GenSeq[B])(p: (A, B) ⇒ Boolean): Boolean\nTests whether every element of this sequence relates to the corresponding element of another sequence by satisfying a test predicate.</code></pre><pre><code>def  count(p: (A) ⇒ Boolean): Int\nCounts the number of elements in the traversable or iterator which satisfy a predicate.</code></pre><pre><code>def  diff(that: collection.Seq[A]): List[A]\n[use case] Computes the multiset difference between this list and another sequence.</code></pre><pre><code>def  distinct: List[A]\nBuilds a new sequence from this sequence without any duplicate elements.</code></pre><pre><code>def  drop(n: Int): List[A]\nSelects all elements except first n ones.</code></pre><pre><code>def  dropRight(n: Int): List[A]\nSelects all elements except last n ones.\nfinal ```</code></pre><p>def  dropWhile(p: (A) ⇒ Boolean): List[A]<br>Drops longest prefix of elements that satisfy a predicate.</p>\n<pre><code></code></pre><p>def  endsWith[B](that: GenSeq[B]): Boolean<br>Tests whether this sequence ends with the given sequence.</p>\n<pre><code></code></pre><p>def  equals(that: Any): Boolean<br>The equals method for arbitrary sequences.</p>\n<pre><code></code></pre><p>def  exists(p: (A) ⇒ Boolean): Boolean<br>Tests whether a predicate holds for at least one element of this sequence.</p>\n<pre><code></code></pre><p>def  filter(p: (A) ⇒ Boolean): List[A]<br>Selects all elements of this traversable collection which satisfy a predicate.</p>\n<pre><code></code></pre><p>def  filterNot(p: (A) ⇒ Boolean): List[A]<br>Selects all elements of this traversable collection which do not satisfy a predicate.</p>\n<pre><code></code></pre><p>def  find(p: (A) ⇒ Boolean): Option[A]<br>Finds the first element of the sequence satisfying a predicate, if any.<br>final ```</p>\n<pre><code>def  flatMap[B](f: (A) ⇒ GenTraversableOnce[B]): List[B]\n[use case] Builds a new collection by applying a function to all elements of this list and using the elements of the resulting collections.</code></pre><pre><code>def  flatten[B]: List[B]\n[use case] Converts this list of traversable collections into a list formed by the elements of these traversable collections.</code></pre><pre><code>def  fold[A1 &gt;: A](z: A1)(op: (A1, A1) ⇒ A1): A1\nFolds the elements of this traversable or iterator using the specified associative binary operator.</code></pre><pre><code>def  foldLeft[B](z: B)(op: (B, A) ⇒ B): B\nApplies a binary operator to a start value and all elements of this sequence, going left to right.</code></pre><pre><code>def  foldRight[B](z: B)(op: (A, B) ⇒ B): B\nApplies a binary operator to all elements of this list and a start value, going right to left.</code></pre><pre><code>def  forall(p: (A) ⇒ Boolean): Boolean\nTests whether a predicate holds for all elements of this sequence.\nfinal ```</code></pre><p>def  foreach(f: (A) ⇒ Unit): Unit<br>[use case] Applies a function f to all elements of this list.</p>\n<pre><code></code></pre><p>def  genericBuilder[B]: Builder[B, List[B]]<br>The generic builder that builds instances of Traversable at arbitrary element types.</p>\n<pre><code></code></pre><p>def  groupBy[K](f: (A) ⇒ K): Map[K, List[A]]<br>Partitions this traversable collection into a map of traversable collections according to some discriminator function.</p>\n<pre><code></code></pre><p>def  grouped(size: Int): Iterator[List[A]]<br>Partitions elements in fixed size iterable collections.</p>\n<pre><code></code></pre><p>def  has```</p>\n<pre><code>def initeSize: Boolean\nTests whether this traversable collection is known to have a finite size.</code></pre><pre><code>def  hashCode(): Int\nHashcodes for Seq produce a value from the hashcodes of all the elements of the sequence.</code></pre><pre><code>def  head: A\nSelects the first element of this iterable collection.</code></pre><pre><code>def  headOption: Option[A]\nOptionally selects the first element.</code></pre><pre><code>def  indexOf(elem: A, from: Int): Int\n[use case] Finds index of first occurrence of some value in this list after or at some start index.</code></pre><pre><code>def  indexOf(elem: A): Int\n[use case] Finds index of first occurrence of some value in this list.</code></pre><pre><code>def  indexOfSlice[B &gt;: A](that: GenSeq[B], from: Int): Int\nFinds first index after or at a start index where this sequence contains a given sequence as a slice.</code></pre><pre><code>def  indexOfSlice[B &gt;: A](that: GenSeq[B]): Int\nFinds first index where this sequence contains a given sequence as a slice.</code></pre><pre><code>def  indexWhere(p: (A) ⇒ Boolean, from: Int): Int\nFinds index of the first element satisfying some predicate after or at some start index.</code></pre><pre><code>def  indexWhere(p: (A) ⇒ Boolean): Int\nFinds index of first element satisfying some predicate.</code></pre><pre><code>def  indices: Range\nProduces the range of all indices of this sequence.</code></pre><pre><code>def  init: List[A]\nSelects all elements except the last.</code></pre><pre><code>def  inits: Iterator[List[A]]\nIterates over the inits of this traversable collection.</code></pre><pre><code>def  intersect(that: collection.Seq[A]): List[A]\n[use case] Computes the multiset intersection between this list and another sequence.</code></pre><pre><code>def  is```</code></pre><p>def inedAt(x: Int): Boolean<br>Tests whether this sequence contains given index.</p>\n<pre><code></code></pre><p>def  isEmpty: Boolean<br>Tests whether this sequence is empty.<br>final ```</p>\n<pre><code>def  isTraversableAgain: Boolean\nTests whether this traversable collection can be repeatedly traversed.</code></pre><pre><code>def  iterator: Iterator[A]\nCreates a new iterator over all elements contained in this iterable object.</code></pre><pre><code>def  last: A\nSelects the last element.</code></pre><pre><code>def  lastIndexOf(elem: A, end: Int): Int\n[use case] Finds index of last occurrence of some value in this list before or at a given end index.</code></pre><pre><code>def  lastIndexOf(elem: A): Int\n[use case] Finds index of last occurrence of some value in this list.</code></pre><pre><code>def  lastIndexOfSlice[B &gt;: A](that: GenSeq[B], end: Int): Int\nFinds last index before or at a given end index where this sequence contains a given sequence as a slice.</code></pre><pre><code>def  lastIndexOfSlice[B &gt;: A](that: GenSeq[B]): Int\nFinds last index where this sequence contains a given sequence as a slice.</code></pre><pre><code>def  lastIndexWhere(p: (A) ⇒ Boolean, end: Int): Int\nFinds index of last element satisfying some predicate before or at given end index.</code></pre><pre><code>def  lastIndexWhere(p: (A) ⇒ Boolean): Int\nFinds index of last element satisfying some predicate.</code></pre><pre><code>def  lastOption: Option[A]\nOptionally selects the last element.</code></pre><pre><code>def  length: Int\nThe length of the sequence.</code></pre><pre><code>def  lengthCompare(len: Int): Int\nCompares the length of this sequence to a test value.</code></pre><pre><code>def  lift: (Int) ⇒ Option[A]\nTurns this partial function into a plain function returning an Option result.\nfinal ```</code></pre><p>def  map[B](f: (A) ⇒ B): List[B]<br>[use case] Builds a new collection by applying a function to all elements of this list.<br>final ```</p>\n<pre><code>def  mapConserve(f: (A) ⇒ A): List[A]\n[use case] Builds a new list by applying a function to all elements of this list.</code></pre><pre><code>def  max: A\n[use case] Finds the largest element.</code></pre><pre><code>def  maxBy[B](f: (A) ⇒ B): A\n[use case] Finds the first element which yields the largest value measured by function f.</code></pre><pre><code>def  min: A\n[use case] Finds the smallest element.</code></pre><pre><code>def  minBy[B](f: (A) ⇒ B): A\n[use case] Finds the first element which yields the smallest value measured by function f.</code></pre><pre><code>def  mkString: String\nDisplays all elements of this traversable or iterator in a string.</code></pre><pre><code>def  mkString(sep: String): String\nDisplays all elements of this traversable or iterator in a string using a separator string.</code></pre><pre><code>def  mkString(start: String, sep: String, end: String): String\nDisplays all elements of this traversable or iterator in a string using start, end, and separator strings.</code></pre><pre><code>def  nonEmpty: Boolean\nTests whether the traversable or iterator is not empty.</code></pre><pre><code>def  orElse[A1 &lt;: Int, B1 &gt;: A](that: PartialFunction[A1, B1]): PartialFunction[A1, B1]\nComposes this partial function with a fallback partial function which gets applied where this partial function is not ```</code></pre><p>def ined.</p>\n<pre><code></code></pre><p>def  padTo(len: Int, elem: A): List[A]<br>[use case] A copy of this list with an element value appended until a given target length is reached.</p>\n<pre><code></code></pre><p>def  par: ParSeq[A]<br>Returns a parallel implementation of this collection.</p>\n<pre><code></code></pre><p>def  partition(p: (A) ⇒ Boolean): (List[A], List[A])<br>Partitions this traversable collection in two traversable collections according to a predicate.</p>\n<pre><code></code></pre><p>def  patch(from: Int, that: GenSeq[A], replaced: Int): List[A]<br>[use case] Produces a new list where a slice of elements in this list is replaced by another sequence.</p>\n<pre><code></code></pre><p>def  permutations: Iterator[List[A]]<br>Iterates over distinct permutations.</p>\n<pre><code></code></pre><p>def  prefixLength(p: (A) ⇒ Boolean): Int<br>Returns the length of the longest prefix whose elements all satisfy some predicate.</p>\n<pre><code></code></pre><p>def  product: A<br>[use case] Multiplies up the elements of this collection.</p>\n<pre><code></code></pre><p>def  productIterator: scala.Iterator[Any]<br>An iterator over all the elements of this product.</p>\n<pre><code></code></pre><p>def  productPrefix: String<br>A string used in the toString methods of derived classes.</p>\n<pre><code></code></pre><p>def  reduce[A1 &gt;: A](op: (A1, A1) ⇒ A1): A1<br>Reduces the elements of this traversable or iterator using the specified associative binary operator.</p>\n<pre><code></code></pre><p>def  reduceLeft[B &gt;: A](op: (B, A) ⇒ B): B<br>Applies a binary operator to all elements of this sequence, going left to right.</p>\n<pre><code></code></pre><p>def  reduceLeftOption[B &gt;: A](op: (B, A) ⇒ B): Option[B]<br>Optionally applies a binary operator to all elements of this traversable or iterator, going left to right.</p>\n<pre><code></code></pre><p>def  reduceOption[A1 &gt;: A](op: (A1, A1) ⇒ A1): Option[A1]<br>Reduces the elements of this traversable or iterator, if any, using the specified associative binary operator.</p>\n<pre><code></code></pre><p>def  reduceRight[B &gt;: A](op: (A, B) ⇒ B): B<br>Applies a binary operator to all elements of this sequence, going right to left.</p>\n<pre><code></code></pre><p>def  reduceRightOption[B &gt;: A](op: (A, B) ⇒ B): Option[B]<br>Optionally applies a binary operator to all elements of this traversable or iterator, going right to left.</p>\n<pre><code></code></pre><p>def  repr: List[A]<br>The collection of type traversable collection underlying this TraversableLike object.</p>\n<pre><code></code></pre><p>def  reverse: List[A]<br>Returns new list with elements in reversed order.</p>\n<pre><code></code></pre><p>def  reverseIterator: Iterator[A]<br>An iterator yielding elements in reversed order.</p>\n<pre><code></code></pre><p>def  reverseMap[B](f: (A) ⇒ B): List[B]<br>[use case] Builds a new collection by applying a function to all elements of this list and collecting the results in reversed order.</p>\n<pre><code></code></pre><p>def  reverse_:::(prefix: List[A]): List[A]<br>[use case] Adds the elements of a given list in reverse order in front of this list.</p>\n<pre><code></code></pre><p>def  runWith[U](action: (A) ⇒ U): (Int) ⇒ Boolean<br>Composes this partial function with an action function which gets applied to results of this partial function.</p>\n<pre><code></code></pre><p>def  sameElements(that: GenIterable[A]): Boolean<br>[use case] Checks if the other iterable collection contains the same elements in the same order as this list.</p>\n<pre><code></code></pre><p>def  scan[B &gt;: A, That](z: B)(op: (B, B) ⇒ B)(implicit cbf: CanBuildFrom[List[A], B, That]): That<br>Computes a prefix scan of the elements of the collection.</p>\n<pre><code></code></pre><p>def  scanLeft[B, That](z: B)(op: (B, A) ⇒ B)(implicit bf: CanBuildFrom[List[A], B, That]): That<br>Produces a collection containing cumulative results of applying the operator going left to right.</p>\n<pre><code></code></pre><p>def  scanRight[B, That](z: B)(op: (A, B) ⇒ B)(implicit bf: CanBuildFrom[List[A], B, That]): That<br>Produces a collection containing cumulative results of applying the operator going right to left.</p>\n<pre><code></code></pre><p>def  segmentLength(p: (A) ⇒ Boolean, from: Int): Int<br>Computes length of longest segment whose elements all satisfy some predicate.</p>\n<pre><code></code></pre><p>def  seq: LinearSeq[A]<br>A version of this collection with all of the operations implemented sequentially (i.e., in a single-threaded manner).</p>\n<pre><code></code></pre><p>def  size: Int<br>The size of this sequence, equivalent to length.</p>\n<pre><code></code></pre><p>def  slice(from: Int, until: Int): List[A]</p>\n<pre><code></code></pre><p>def  sliding(size: Int, step: Int): Iterator[List[A]]<br>Groups elements in fixed size blocks by passing a “sliding window” over them (as opposed to partitioning them, as is done in grouped.)</p>\n<pre><code></code></pre><p>def  sliding(size: Int): Iterator[List[A]]<br>Groups elements in fixed size blocks by passing a “sliding window” over them (as opposed to partitioning them, as is done in grouped.) The “sliding window” step is set to one.</p>\n<pre><code></code></pre><p>def  sortBy[B](f: (A) ⇒ B)(implicit ord: math.Ordering[B]): List[A]<br>Sorts this Seq according to the Ordering which results from transforming an implicitly given Ordering with a transformation function.</p>\n<pre><code></code></pre><p>def  sortWith(lt: (A, A) ⇒ Boolean): List[A]<br>Sorts this sequence according to a comparison function.</p>\n<pre><code></code></pre><p>def  sorted[B &gt;: A](implicit ord: math.Ordering[B]): List[A]<br>Sorts this sequence according to an Ordering.<br>final ```</p>\n<pre><code>def  span(p: (A) ⇒ Boolean): (List[A], List[A])\nSplits this list into a prefix/suffix pair according to a predicate.</code></pre><pre><code>def  splitAt(n: Int): (List[A], List[A])\nSplits this list into two at a given position.</code></pre><pre><code>def  startsWith[B](that: GenSeq[B], offset: Int): Boolean\nTests whether this sequence contains the given sequence at a given index.</code></pre><pre><code>def  startsWith[B](that: GenSeq[B]): Boolean\nTests whether this general sequence starts with the given sequence.</code></pre><pre><code>def  stringPrefix: String</code></pre><pre><code>def ines the prefix of this object&#39;s toString representation.</code></pre><pre><code>def  sum: A\n[use case] Sums up the elements of this collection.</code></pre><pre><code>def  tail: List[A]\nSelects all elements except the first.</code></pre><pre><code>def  tails: Iterator[List[A]]\nIterates over the tails of this traversable collection.</code></pre><pre><code>def  take(n: Int): List[A]\nSelects first n elements.</code></pre><pre><code>def  takeRight(n: Int): List[A]\nSelects last n elements.\nfinal ```</code></pre><p>def  takeWhile(p: (A) ⇒ Boolean): List[A]<br>Takes longest prefix of elements that satisfy a predicate.</p>\n<pre><code></code></pre><p>def  to[Col[_]]: Col[A]<br>[use case] Converts this list into another by copying all elements.</p>\n<pre><code></code></pre><p>def  toArray: Array[A]<br>[use case] Converts this list to an array.</p>\n<pre><code></code></pre><p>def  toBuffer[B &gt;: A]: Buffer[B]<br>Uses the contents of this traversable or iterator to create a new mutable buffer.</p>\n<pre><code></code></pre><p>def  toIndexedSeq: IndexedSeq[A]<br>Converts this traversable or iterator to an indexed sequence.</p>\n<pre><code></code></pre><p>def  toIterable: collection.Iterable[A]<br>Returns this iterable collection as an iterable collection.</p>\n<pre><code></code></pre><p>def  toIterator: Iterator[A]<br>Returns an Iterator over the elements in this iterable collection.</p>\n<pre><code></code></pre><p>def  toList: List[A]<br>Converts this list to a list.</p>\n<pre><code></code></pre><p>def  toMap[T, U]: collection.Map[T, U]<br>[use case] Converts this list to a map.</p>\n<pre><code></code></pre><p>def  toParArray: ParArray[T]</p>\n<pre><code></code></pre><p>def  toSeq: Seq[A]<br>Converts this immutable sequence to a sequence.</p>\n<pre><code></code></pre><p>def  toSet[B &gt;: A]: Set[B]<br>Converts this traversable or iterator to a set.</p>\n<pre><code></code></pre><p>def  toStream: Stream[A]<br>Converts this list to a stream.</p>\n<pre><code></code></pre><p>def  toString(): String<br>Converts this sequence to a string.</p>\n<pre><code></code></pre><p>def  toTraversable: collection.Traversable[A]<br>Converts this traversable collection to an unspecified Traversable.</p>\n<pre><code></code></pre><p>def  toVector: scala.Vector[A]<br>Converts this traversable or iterator to a Vector.</p>\n<pre><code></code></pre><p>def  transpose[B](implicit asTraversable: (A) ⇒ GenTraversableOnce[B]): List[List[B]]<br>Transposes this collection of traversable collections into a collection of collections.</p>\n<pre><code></code></pre><p>def  union(that: collection.Seq[A]): List[A]<br>[use case] Produces a new sequence which contains all elements of this list and also all elements of a given sequence.</p>\n<pre><code></code></pre><p>def  unzip[A1, A2](implicit asPair: (A) ⇒ (A1, A2)): (List[A1], List[A2])<br>Converts this collection of pairs into two collections of the first and second half of each pair.</p>\n<pre><code></code></pre><p>def  unzip3[A1, A2, A3](implicit asTriple: (A) ⇒ (A1, A2, A3)): (List[A1], List[A2], List[A3])<br>Converts this collection of triples into three collections of the first, second, and third element of each triple.</p>\n<pre><code></code></pre><p>def  updated(index: Int, elem: A): List[A]<br>[use case] A copy of this list with one single replaced element.</p>\n<pre><code></code></pre><p>def  view(from: Int, until: Int): SeqView[A, List[A]]<br>Creates a non-strict view of a slice of this sequence.</p>\n<pre><code></code></pre><p>def  view: SeqView[A, List[A]]<br>Creates a non-strict view of this sequence.</p>\n<pre><code></code></pre><p>def  withFilter(p: (A) ⇒ Boolean): FilterMonadic[A, List[A]]<br>Creates a non-strict filter of this traversable collection.</p>\n<pre><code></code></pre><p>def  zip[B](that: GenIterable[B]): List[(A, B)]<br>[use case] Returns a list formed from this list and another iterable collection by combining corresponding elements in pairs.</p>\n<pre><code></code></pre><p>def  zipAll[B](that: collection.Iterable[B], thisElem: A, thatElem: B): List[(A, B)]<br>[use case] Returns a list formed from this list and another iterable collection by combining corresponding elements in pairs.</p>\n<pre><code></code></pre><p>def  zipWithIndex: List[(A, Int)]<br>[use case] Zips this list with its indices.</p>\n<pre><code>\n</code></pre><h2 id=\"七-Map的常见方法汇总\"><a href=\"#七-Map的常见方法汇总\" class=\"headerlink\" title=\"七.Map的常见方法汇总\"></a>七.Map的常见方法汇总</h2><p>（1）不可变Map</p>\n<pre><code>var a:Map[String,Int]=Map(&quot;k1&quot;-&gt;1,&quot;k2&quot;-&gt;2)//初始化构造函数\na += (&quot;k3&quot;-&gt;3)//添加元素\na += (&quot;k4&quot;-&gt;4)//添加元素\na += (&quot;k1&quot;-&gt;100)//已经存在添加元素会覆盖\na -= (&quot;k2&quot;,&quot;k1&quot;)//删除元素    //a(&quot;k1&quot;) = &quot;foo&quot;//不支持\nprintln(a.contains(&quot;k6&quot;))//是否包含某元素\nprintln(a.size)//打印大小\nprintln(a.get(&quot;k1&quot;).getOrElse(&quot;default&quot;)) //根据key读取元素，不存在就替换成默认值\na.foreach{case (e,i) =&gt; println(e,i)} //遍历打印1\nfor( (k,v)&lt;-a ) println(k,v) //遍历打印2\nprintln(a.isEmpty)//判断是否为空\na.keys.foreach(println)//只打印key\na.values.foreach(println)//只打印value\n\na=Map()//数据清空使用再次new\nprintln(a.size)\na.toSeq.sortBy(_._1)//升序排序 key\na.toSeq.sortBy(_._2)//升序排序 value\na.toSeq.sortWith(_._1&gt;_._1) //降序排序 key\na.toSeq.sortWith(_._2&gt;_._2) //降序排序 value\n\n//下面自定义按英文字母或数字排序\nimplicit  val KeyOrdering=new Ordering[String] {\n      override def compare(x: String, y: String): Int = {\n        x.compareTo(y)\n      }\n}\nprintln(a.toSeq.sorted)</code></pre><p>2）可变Map例子</p>\n<pre><code>var a:scala.collection.mutable.Map[String,Int]=scala.collection.mutable.Map(&quot;k1&quot;-&gt;1,&quot;k2&quot;-&gt;2)//初始化构造函数\n  a += (&quot;k3&quot;-&gt;3)//添加元素\n  a += (&quot;k4&quot;-&gt;4)//添加元素\n  a += (&quot;k1&quot;-&gt;100)//已经存在添加元素会覆盖\n  a += (&quot;k1&quot;-&gt;100,&quot;k9&quot;-&gt;9)//添加多个元素\n  a -= (&quot;k2&quot;,&quot;k1&quot;)//删除元素\n  a ++= List(&quot;CA&quot; -&gt; 23, &quot;CO&quot; -&gt; 25)//追加集合\n  a --= List(&quot;AL&quot;, &quot;AZ&quot;)//删除集合\n\n  a.retain((k,v)=&gt; k==&quot;k1&quot;)//只保留等于k1元素，其他的删除\n  a.put(&quot;put1&quot;,200)//put\n  a.remove(&quot;k2&quot;)//remove\n  a.clear()//清空\n  a(&quot;k3&quot;)=100//支持\n\n  println(a.contains(&quot;k6&quot;))//是否包含某元素\n  println(a.size)//打印大小\n  println(a.get(&quot;k1&quot;).getOrElse(&quot;default&quot;)) //根据key读取元素，不存在就替换成默认值\n  a.foreach{case (e,i) =&gt; println(e,i)} //遍历打印1\n  for( (k,v)&lt;-a ) println(k,v) //遍历打印2\n  println(a.isEmpty)//判断是否为空\n  a.keys.foreach(println)//只打印key\n  a.values.foreach(println)//只打印value\n  a=scala.collection.mutable.Map()//引用能变\n  println(a.size)\n  a.toSeq.sortBy(_._1)//排序 key\n  a.toSeq.sortBy(_._2)//排序 value\n  a.toSeq.sortWith(_._1&gt;_._1) //降序排序 key\n  a.toSeq.sortWith(_._2&gt;_._2) //降序排序 value\n\n//下面自定义按英文字母或数字排序\n  implicit  val KeyOrdering=new Ordering[String] {\n    override def compare(x: String, y: String): Int = {\n      x.compareTo(y)\n    }\n  }\n  println(a.toSeq.sorted)\n}</code></pre><p>默认情况下，Scala使用不可变映射(Map)。如果要使用可变集合(Set)，则必须明确导入scala.collection.mutable.Map类。如果想同时使用可变的和不可变映射(Map)，那么可以继续引用不可变映射(Map)，但是可以将mutable集合引用mutable.Map。<br>以下是声明不可变映射(Map)的示例声明<br>集合基本操作</p>\n<pre><code>scala&gt; val colors = Map(&quot;red&quot; -&gt; &quot;#FF0000&quot;, &quot;azure&quot; -&gt; &quot;#F0FFFF&quot;, &quot;peru&quot; -&gt; &quot;#CD853F&quot;)\ncolors: scala.collection.immutable.Map[String,String] = Map(red -&gt; #FF0000, azure -&gt; #F0FFFF, peru -&gt; #CD853F)\n\nscala&gt; val nums: Map[Int, Int] = Map()\nnums: Map[Int,Int] = Map()\n\nscala&gt;println( &quot;Keys in colors : &quot; + colors.keys )\nKeys in colors : Set(red, azure, peru)\n\nscala&gt;println( &quot;Values in colors : &quot; + colors.values )\nValues in colors : MapLike(#FF0000, #F0FFFF, #CD853F)\n\nscala&gt;println( &quot;Check if colors is empty : &quot; + colors.isEmpty )\nCheck if colors is empty : false\n\nscala&gt;println( &quot;Check if nums is empty : &quot; + nums.isEmpty )\nCheck if nums is empty : true</code></pre><p>连接映射</p>\n<pre><code>scala&gt;val colors1 = Map(&quot;red&quot; -&gt; &quot;#FF0000&quot;, &quot;azure&quot; -&gt; &quot;#F0FFFF&quot;, &quot;peru&quot; -&gt; &quot;#CD853F&quot;)\ncolors1: scala.collection.immutable.Map[String,String] = Map(red -&gt; #FF0000, azure -&gt; #F0FFFF, peru -&gt; #CD853F)\n\nscala&gt;val colors2 = Map(&quot;blue&quot; -&gt; &quot;#0033FF&quot;, &quot;yellow&quot; -&gt; &quot;#FFFF00&quot;, &quot;red&quot; -&gt; &quot;#FF0000&quot;)\ncolors2: scala.collection.immutable.Map[String,String] = Map(blue -&gt; #0033FF, yellow -&gt; #FFFF00, red -&gt; #FF0000)\n\nscala&gt;var colors = colors1 ++ colors2\ncolors: scala.collection.immutable.Map[String,String] = Map(blue -&gt; #0033FF, azure -&gt; #F0FFFF, peru -&gt; #CD853F, yellow -&gt; #FFFF00, red -&gt; #FF0000)\n\nscala&gt;println( &quot;colors1 ++ colors2 : &quot; + colors )\ncolors1 ++ colors2 : Map(blue -&gt; #0033FF, azure -&gt; #F0FFFF, peru -&gt; #CD853F, yellow -&gt; #FFFF00, red -&gt; #FF0000)\n\nscala&gt;colors = colors1.++(colors2)\ncolors: scala.collection.immutable.Map[String,String] = Map(blue -&gt; #0033FF, azure -&gt; #F0FFFF, peru -&gt; #CD853F, yellow -&gt; #FFFF00, red -&gt; #FF0000)\n\nscala&gt;println( &quot;colors1.++(colors2)) : &quot; + colors )\ncolors1.++(colors2)) : Map(blue -&gt; #0033FF, azure -&gt; #F0FFFF, peru -&gt; #CD853F, yellow -&gt; #FFFF00, red -&gt; #FF0000)\n</code></pre><p>打印映射的键和值</p>\n<pre><code>val colors = Map(&quot;red&quot; -&gt; &quot;#FF0000&quot;, &quot;azure&quot; -&gt; &quot;#F0FFFF&quot;,&quot;peru&quot; -&gt; &quot;#CD853F&quot;)\ncolors.keys.foreach{ i =&gt;  \n    print( &quot;Key = &quot; + i )\n    println(&quot; Value = &quot; + colors(i) )}\n}\n\nKey = red Value = #FF0000\nKey = azure Value = #F0FFFF\nKey = peru Value = #CD853F</code></pre><p>查找检查映射中的键</p>\n<pre><code>val colors = Map(&quot;red&quot; -&gt; &quot;#FF0000&quot;, &quot;azure&quot; -&gt; &quot;#F0FFFF&quot;, &quot;peru&quot; -&gt; &quot;#CD853F&quot;)\nif( colors.contains( &quot;red&quot; )) {\n    println(&quot;Red key exists with value :&quot;  + colors(&quot;red&quot;))\n} else {\n    println(&quot;Red key does not exist&quot;)\n}\nif( colors.contains( &quot;maroon&quot; )) {\n    println(&quot;Maroon key exists with value :&quot;  + colors(&quot;maroon&quot;))\n} else {\n    println(&quot;Maroon key does not exist&quot;)\n}</code></pre><p>scala - Map基础<br>构造Map:不可变：</p>\n<pre><code>val map = Map(&quot;sa&quot; -&gt; 1, &quot;s&quot; -&gt; 2)\nmap(&quot;sa&quot;) = 3 // error\nval emptyMap = new scala.collection.immutable.HashMap[String, Int]</code></pre><p>可变：</p>\n<pre><code>val map2 = scala.collection.mutable.Map(&quot;sa&quot; -&gt; 2)\nmap2(&quot;sa&quot;) = 3\nval emptyMap = new scala.collection.mutable.HashMap[String, Int]</code></pre><p>注：-&gt;用来创建元组， “sa” -&gt; 1即(“sa”, 1) 初始化完全可以 val map = Map((“sa”, 1), (“s”, 2))<br>获取Map中的值：</p>\n<pre><code>如果map中不包含请求中使用的key值，则抛异常。NoSuchElementException\nmap(&quot;sa&quot;) // 类似于java中的map.get(&quot;sa&quot;)</code></pre><p>要检查map中是否包含某个key，使用contains方法。</p>\n<pre><code>val sa = if (map2.contains(&quot;sa3&quot;)) map2(&quot;sa3&quot;) else 0;\n快捷的方式：\nval sa2 = map.getOrElse(&quot;sa2&quot;, 0)\n一次得到是否包含key，并获取值：\nval sa3 = map.get(&quot;sa3&quot;); // Option类型，\nprintln(sa3.isEmpty)</code></pre><p>更新Map中的值：</p>\n<pre><code>添加或更新：map(&quot;sa&quot;) = 3\n添加或更新多个：map += (&quot;aa&quot; -&gt; 4, &quot;bb&quot; -&gt; 5)</code></pre><p>移除某个key和对应的值：</p>\n<pre><code>map -= &quot;aa&quot;\n不可变的map也可以使用+和-操作，但是会生成新的map\nvar map = Map(&quot;aa&quot; -&gt; 1)\nmap = map + (&quot;bb&quot; -&gt; 2)\nmap += (&quot;cc&quot; -&gt; 2)\nmap -= &quot;aa&quot;</code></pre><p>迭代map：</p>\n<pre><code>for ((k, v) &lt;- map) {\n\n}\n所有key：map.keySet\n所有值：map.values\n反转：map2 = for((k, v) &lt;- map) yield (v, k)</code></pre><p>已排序Map：<br>按key排序：SortedMap<br>按添加顺序：LinkedHashMap<br>Map与Java互操作：<br>Java Properties转为scala.collection.Map：</p>\n<pre><code>import scala.collection.JavaConversions.propertiesAsScalaMap\nval prop: scala.collection.Map[String, String] = System.getProperties();</code></pre><p>Java Map转为scala.collection.mutable.Map[String, Int]：</p>\n<pre><code>import scala.collection.JavaConversions.mapAsScalaMap\nval map: scala.collection.mutable.Map[String, Int] = new TreeMap[String, Int]</code></pre><p>Scala Map转为Java Map:</p>\n<pre><code>import scala.collection.JavaConversions.mapAsJavaMap\nimport java.awt.font.TextAttribute._\nvar fs = Map(FAMILY -&gt; &quot;Serif&quot;, SIZE -&gt; 12)\nvar fonts = new Font(fs)</code></pre><p><strong>Map的操作方法</strong></p>\n<pre><code>def ++(xs: Map[(A, B)]): Map[A, B]\n返回一个新的 Map，新的 Map xs 组成</code></pre><pre><code>def -(elem1: A, elem2: A, elems: A*): Map[A, B]\n返回一个新的 Map, 移除 key 为 elem1, elem2 或其他 elems。</code></pre><pre><code>def --(xs: GTO[A]): Map[A, B]\n返回一个新的 Map, 移除 xs 对象中对应的 key</code></pre><pre><code>def get(key: A): Option[B]\n返回指定 key 的值</code></pre><pre><code>def iterator: Iterator[(A, B)]\n创建新的迭代器，并输出 key/value 对</code></pre><pre><code>def addString(b: StringBuilder): StringBuilder\n将 Map 中的所有元素附加到StringBuilder，可加入分隔符</code></pre><pre><code>def addString(b: StringBuilder, sep: String): StringBuilder\n将 Map 中的所有元素附加到StringBuilder，可加入分隔符</code></pre><pre><code>def apply(key: A): B\n返回指定键的值，如果不存在返回 Map 的默认方法</code></pre><pre><code>def clear(): Unit\n清空 Map</code></pre><pre><code>def clone(): Map[A, B]\n从一个 Map 复制到另一个 Map</code></pre><pre><code>def contains(key: A): Boolean\n如果 Map 中存在指定 key，返回 true，否则返回 false。</code></pre><pre><code>def copyToArray(xs: Array[(A, B)]): Unit\n复制集合到数组</code></pre><pre><code>def count(p: ((A, B)) =&gt; Boolean): Int\n计算满足指定条件的集合元素数量</code></pre><pre><code>def default(key: A): B\n定义 Map 的默认值，在 key 不存在时返回。</code></pre><pre><code>def drop(n: Int): Map[A, B]\n返回丢弃前n个元素新集合</code></pre><pre><code>def dropRight(n: Int): Map[A, B]\n返回丢弃最后n个元素新集合</code></pre><pre><code>def dropWhile(p: ((A, B)) =&gt; Boolean): Map[A, B]\n从左向右丢弃元素，直到条件p不成立</code></pre><pre><code>def empty: Map[A, B]\n返回相同类型的空 Map</code></pre><pre><code>def equals(that: Any): Boolean\n如果两个 Map 相等(key/value 均相等)，返回true，否则返回false</code></pre><pre><code>def exists(p: ((A, B)) =&gt; Boolean): Boolean\n判断集合中指定条件的元素是否存在</code></pre><pre><code>def filter(p: ((A, B))=&gt; Boolean): Map[A, B]\n返回满足指定条件的所有集合</code></pre><pre><code>def filterKeys(p: (A) =&gt; Boolean): Map[A, B]\n返回符合指定条件的的不可变 Map</code></pre><pre><code>def find(p: ((A, B)) =&gt; Boolean): Option[(A, B)]\n查找集合中满足指定条件的第一个元素</code></pre><pre><code>def foreach(f: ((A, B)) =&gt; Unit): Unit\n将函数应用到集合的所有元素</code></pre><pre><code>def init: Map[A, B]\n返回所有元素，除了最后一个</code></pre><pre><code>def isEmpty: Boolean\n检测 Map 是否为空</code></pre><pre><code>def keys: Iterable[A]\n返回所有的key/p&gt;</code></pre><pre><code>def last: (A, B)\n返回最后一个元素</code></pre><pre><code>def max: (A, B)\n查找最大元素</code></pre><pre><code>def min: (A, B)\n查找最小元素</code></pre><pre><code>def mkString: String\n集合所有元素作为字符串显示</code></pre><pre><code>def product: (A, B)\n返回集合中数字元素的积。</code></pre><pre><code>def remove(key: A): Option[B]\n移除指定 key</code></pre><pre><code>def retain(p: (A, B) =&gt; Boolean): Map.this.type\n如果符合满足条件的返回 true</code></pre><pre><code>def size: Int\n返回 Map 元素的个数</code></pre><pre><code>def sum: (A, B)\n返回集合中所有数字元素之和</code></pre><pre><code>def tail: Map[A, B]\n返回一个集合中除了第一元素之外的其他元素</code></pre><pre><code>def take(n: Int): Map[A, B]\n返回前 n 个元素</code></pre><pre><code>def takeRight(n: Int): Map[A, B]\n返回后 n 个元素</code></pre><pre><code>def takeWhile(p: ((A, B)) =&gt; Boolean): Map[A, B]\n返回满足指定条件的元素</code></pre><pre><code>def toArray: Array[(A, B)]\n集合转数组</code></pre><pre><code>def toBuffer[B &gt;: A]: Buffer[B]\n返回缓冲区，包含了 Map 的所有元素</code></pre><pre><code>def toList: List[A]\n返回 List，包含了 Map 的所有元素</code></pre><pre><code>def toSeq: Seq[A]\n返回 Seq，包含了 Map 的所有元素</code></pre><pre><code>def toSet: Set[A]\n返回 Set，包含了 Map 的所有元素</code></pre><pre><code>def toString(): String\n返回字符串对象</code></pre><h2 id=\"八-类的定义及构造器\"><a href=\"#八-类的定义及构造器\" class=\"headerlink\" title=\"八.类的定义及构造器\"></a>八.类的定义及构造器</h2><p><strong>类和对象之基础</strong></p>\n<p><strong>定义</strong></p>\n<p>Scala 中以 class 来作为类的声明，在类中可以定义成员和方法，成员和方法可以有不同的可见性（这个会在后文详述）</p>\n<pre><code>scala&gt; class Company {\n     |   private var employeeCount = 0\n     |   def getEmployeeCount(): Int = employeeCount\n     |   def setEmployeeCount( count: Int)= {\n     |     employeeCount = count\n     |   }\n     |\n     |   def m( i: Int ) {}\n     |   def m( str: String ) {}\n     | }\ndefined class Company</code></pre><p><strong>构造器</strong></p>\n<p>Scala 中，类有一个主构造器，主构造器必须包含所需的所有参数。除了一个主构造器，还可以有0个或多个辅助构造器，辅助构造器又称次构造器。辅助构造器命名为 this，其第一条语句必须调用主构造器或其他辅助构造器，来看下面的例子：</p>\n<pre><code>scala&gt; class T ( x1: Int, y1: String, z1: Double ) {\n     |   private val xx1 = x1\n     |   private val yy1 = y1\n     |   private val zz1 = z1\n     |\n     |   def this ( x1: Int, y1: String ) {\n     |     this( x1, y1, 1.0 )\n     |   }\n     |\n     |   def this ( x1: Int ) {\n     |     this( x1, &quot;&quot; )\n     |   }\n     | }\ndefined class T</code></pre><p>还有一点需要注意的是，被调用的辅助构造函数的定义必须放在主动调用的辅助构造函数前面，不然会报错：</p>\n<pre><code>scala&gt; class T ( x1: Int, y1: String, z1: Double ) {\n     |   private val xx1 = x1\n     |   private val yy1 = y1\n     |   private val zz1 = z1\n     |\n     |   def this ( x1: Int ) {\n     |     this( x1, &quot;&quot; )\n     |   }\n     |\n     |   def this ( x1: Int, y1: String ) {\n     |     this( x1, y1, 1.0 )\n     |   }\n     | }\n&lt;console&gt;:13: error: called constructor&#39;s definition must precede calling constructor&#39;s definition\n           this( x1, &quot;&quot; )\n           ^</code></pre><p>不管辅助函数调来调去，最终都还是要调用到主构造函数，这确保了新实例的初始化逻辑一致。</p>\n<p>如果在主构造函数的参数前加 var 或 val，该参数就成为实例的一个成员，这部分知识在Scala case class那些你不知道的知识有更详细的介绍</p>\n<p><strong>重载</strong></p>\n<p>Scala 类方法允许重载，如类 Company 中的 m 方法。重载要求参数列表和返回类型不完全相同，但参数名可相同，这是因为编译后是通过方法名、参数列表、返回类型综合来区分各个方法的。</p>\n<p>在方法重载时，有一点需要注意：对于『高级类型』，存在类型擦除机制，所谓的高级类型就是包含类型参数的类型，比如 List[A]，下面这个例子可以展示了类型擦除：</p>\n<pre><code>scala&gt; class Tmp {\n     |   def m( data: List[Int] ) {}\n     |   def m( data: List[String] ) {}\n     | }\n&lt;console&gt;:9: error: double definition:\nmethod m:(data: List[String])Unit and\nmethod m:(data: List[Int])Unit at line 8\nhave same type after erasure: (data: List)Unit\n         def m( data: List[String] ) {}\n             ^</code></pre><p>报了有相同类型的参数的错误。</p>\n<p><strong>类型成员</strong></p>\n<p>Scala 允许你在类内部定义类型成员，在构造类实例的时候指定该类型成员对应的具体类型。类型成员可用于类内部的成员或函数，提供了更好的泛华能力，从下面这个简单的例子可以看出：</p>\n<pre><code>scala&gt; class T {\n     |   type X\n     |\n     |   def getClassName( x: X): String = {\n     |     x.getClass.getTypeName\n     |   }\n     | }\ndefined class T\n\nscala&gt; val x1 = new T{ type X = Int }\nx1: T{type X = Int} = $anon$1@515f550a\n\nscala&gt; x1.getClassName(10)\nres0: String = java.lang.Integer\n\nscala&gt; val x2 = new T{ type X = String }\nx2: T{type X = String} = $anon$1@61a52fbd\n\nscala&gt; x2.getClassName(&quot;string&quot;)\nres1: String = java.lang.String</code></pre><p>当然，也可以在类外部定义类型变量，如：</p>\n<pre><code>scala&gt; type L = List[Int]\ndefined type alias L</code></pre><p><strong>方法与成员同名</strong></p>\n<p>与 JAVA 不同，如果方法参数列表不为空，该方法可以与成员同名，如：</p>\n<pre><code>scala&gt; class T {\n     |   private val m = 0\n     |\n     |   def m( i: Int ): Int = m + i\n     | }\ndefined class T\n</code></pre><h2 id=\"九-类和对象之进阶（一）\"><a href=\"#九-类和对象之进阶（一）\" class=\"headerlink\" title=\"九.类和对象之进阶（一）\"></a>九.类和对象之进阶（一）</h2><p> 1、Scala中的类是公有可见性的，且多个类可以包含在同一个源文件中；</p>\n<pre><code>class Counter{\n    private var value = 0　　//类成员变量必须初始化，否则报错\n    def increment(){    //类中的方法默认是公有可见性\n        value += 1\n    }\n    def current() = value //对于类中的“取值方法”，在定义时可省略掉括号，直接 def current = value\n}</code></pre><p>继承</p>\n<p>只能有一个父类</p>\n<p>与其他支持面向对象的语言一样，Scala 也支持继承，并且子类只能有一个父类，不能继承于多个父类，如果希望实现类似继承多个父类的功能，应该考虑引入 trait。虽然只支持一个父类，但是父类还可以有父类，也就是爷爷类，对于类继承的层数是没有具体要求的，这几点在下面这个例子中都有体现：</p>\n<pre><code>scala&gt; class A {\n     | }\ndefined class A\n\nscala&gt; class B {\n     | }\ndefined class B\n\nscala&gt; class AA extends A {\n     | }\ndefined class AA\n\nscala&gt; class AB extends A with B {\n     | }\n&lt;console&gt;:9: error: class B needs to be a trait to be mixed in\n       class AB extends A with B {\n                               ^\n\nscala&gt; class AAA extends AA {\n     | }\ndefined class AAA\n\nscala&gt; class AAAA extends AAA {\n     | }\ndefined class AAAA</code></pre><p>都继承了什么</p>\n<p>子类继承父类时都会继承些什么呢，这里结合可见性（可见性的详细内容会在下文介绍）进行分析，先定义这样一组父子类：</p>\n<pre><code>scala&gt; class Parent ( x: Int, y: String, z: Double ) {\n     |   val xx = x\n     |   protected val yy = y\n     |   private val zz = z\n     |\n     |   def getXX = xx\n     |   protected def getYY = yy\n     |   private def getZZ = zz\n     |\n     |   def testYY = yy\n     |   def testZZ = zz\n     |   def testGetYY = getYY\n     |   def testGetZZ = getZZ\n     | }\ndefined class Parent</code></pre><p>在 Scala 类继承中，允许在子类内部直接访问父类的 public 及 protected 成员及方法，但不允许子类直接访问父类的 private 成员及方法，如下例：</p>\n<pre><code>scala&gt; class Child1 ( x: Int, y: String, z: Double ) extends Parent(x, y, z ) {\n     |   println( xx )\n     |   println( yy )\n     |   println( getXX )\n     |   println( getYY )\n     | }\ndefined class Child1\n\nscala&gt; class Child2 ( x: Int, y: String, z: Double ) extends Parent(x, y, z ) {\n     |   println( zz )\n     |   println( getZZ )\n     | }\n&lt;console&gt;:9: error: value zz in class Parent cannot be accessed in Child2\n         println( zz )\n                  ^\n&lt;console&gt;:10: error: method getZZ in class Parent cannot be accessed in Child2\n         println( getZZ )\n                  ^</code></pre><p>在类外部，只有 public 的方法和成员能被直接访问，protected 及 private 均不予许：</p>\n<pre><code>scala&gt; class Child3 ( x: Int, y: String, z: Double ) extends Parent(x, y, z ) {\n     | }\ndefined class Child3\n\nscala&gt; val child = new Child3( 1, &quot;hello&quot;, 3.1415926 )\nchild: Child3 = Child3@39529185\n\nscala&gt; child.xx\nres6: Int = 1\n\nscala&gt; child.yy\n&lt;console&gt;:11: error: value yy in class Parent cannot be accessed in Child3\n Access to protected value yy not permitted because\n enclosing object $iw is not a subclass of\n class Parent where target is defined\n              child.yy\n                    ^\n\nscala&gt; child.zz\n&lt;console&gt;:11: error: value zz in class Parent cannot be accessed in Child3\n              child.zz\n                    ^\n\nscala&gt;\n\nscala&gt; child.getXX\nres9: Int = 1\n\nscala&gt; child.getYY\n&lt;console&gt;:11: error: method getYY in class Parent cannot be accessed in Child3\n Access to protected method getYY not permitted because\n enclosing object $iw is not a subclass of\n class Parent where target is defined\n              child.getYY\n                    ^\n\nscala&gt; child.getZZ\n&lt;console&gt;:11: error: method getZZ in class Parent cannot be accessed in Child3\n              child.getZZ\n                    ^</code></pre><p>但我们可以通过父类提供的方法来间接访问 protected 和 private 的成员和方法：</p>\n<pre><code>scala&gt; child.testYY\nres20: String = hello\n\nscala&gt; child.testZZ\nres21: Double = 3.1415926\n\nscala&gt; child.testGetYY\nres22: String = hello\n\nscala&gt; child.testGetZZ\nres23: Double = 3.1415926</code></pre><p>单例对象</p>\n<p>在 Scala 中，使用关键字 object 来定义单例对象：</p>\n<pre><code>scala&gt; object T {}\ndefined module T</code></pre><p>单例对象将在其首次被调用时初始化，且没有参数。单例对象一旦定义完毕，它的名字就代表了该单例对象的唯一实例。</p>\n<p>当单例对象与某个类的名字相同且两者定义在同一文件中，就形成了特殊的单例对象-伴生对象，对应的类称为伴生类，若单例没有相同名字的类的话成为孤立对象（好惨）。我们经常使用在伴生对象中对应 apply 方法来创建新的伴生类实例并且将半身列的可见性设置为 private，以便能方便的创建伴生类实例，更重要的是可以在伴生类对象中管理所有伴生类实例，例子如下：</p>\n<pre><code>class Q ( qParam: String ) {\n  private val q = qParam\n}\n\nobject Q {\n  private val qList = ListBuffer[ Q ]()\n\n  def apply( qParam: String ) {\n    val qInstance = new Q( qParam )\n    qList.append( qInstance )\n    qInstance\n  }\n\n  def qListSize = qList.size\n}\n\nobject Test {\n  def main (args: Array[String]) {\n    val qIns1 = Q( &quot;q1&quot; )\n    val qIns2 = Q( &quot;q2&quot; )\n    println( Q.qListSize )\n  }\n}</code></pre><p>输出：</p>\n<pre><code>2</code></pre><p>另外伴生对象与伴生类可以互相访问 private 成员和方法，object 也可以继承父类或混入特质</p>\n<h2 id=\"十-类和对象之进阶（二）\"><a href=\"#十-类和对象之进阶（二）\" class=\"headerlink\" title=\"十.类和对象之进阶（二）\"></a>十.类和对象之进阶（二）</h2><p>Scala 中的可见性非常灵活且复杂，这篇文章希望通过大量的示例来说清楚各种情况下的可见性是怎么样的。<br>默认可见性<br>Scala 中的默认可见性为 public，所谓默认即你没有在类或者成员前显示加 private 或 protected 可见性关键字。虽然默认可见性为 public，但这是逻辑上的，实际上 Scala 中并没有 public 这个关键字，如果你用 public 来声明一个类或成员，编译器会报错。<br>可见性作用域<br>在 Scala 中，可以在类型的 class 或 trait 关键字之前、字段的 val 或 var 之前，方法定义的 def 关键字之前指定可见性。<br>公有可见性<br>对于公有可见性，任何作用域内都可以访问公有成员或公有类型。<br>Protected 可见性<br>对于受保护可见性，用 protected 声明，受保护成员对本类型、继承类型可见。而受保护的类型则只对包含该类的包内可见。<br>下面例子是关于 protected 成员的：</p>\n<pre><code>package P1 {\n  class C1 {\n    protected val c = 0\n\n    //&lt; 受保护可见性中,嵌套类可访问 protected 成员\n    class C11 {\n      println( c )\n    }\n  }\n\n  package P11 {\n    //&lt; 继承类客房为父类 protected 成员\n    class C1Child extends C1 {\n      println( c )\n    }\n  }\n\n}\n\npackage P2 {\n  //&lt; 继承类客房为父类 protected 成员\n  class C2Child extends P1.C1 {\n    println( c )\n  }\n}</code></pre><p>接下来是 protected 类型的：</p>\n<pre><code>package P1 {\n  protected class C1 {\n  }\n\n  //&lt; 对于 protected 类型,相同包内可见\n  class C1Child extends C1 {\n  }\n\n  package P11 {\n    //&lt; 对于 protected 类型,子包内可见\n    class C11Child extends C1 {\n    }\n  }\n}\n\npackage P2 {\n//&lt; 对于 protected 类型,外部包不可见\n  class C2Child extends P1.C1 {\n  }\n}</code></pre><p>编译报错如下，这是因为 protected 类型只在包含该类的包内可见</p>\n<pre><code>Error:(22, 28) class C1 in package P1 cannot be accessed in package P1\n Access to protected class C1 not permitted because\n enclosing package P2 is not a subclass of \n package P1 where target is defined\n  class C2Child extends P1.C1 {</code></pre><p>私有可见性</p>\n<p>私有可见性将实现细节完全隐藏起来，即便是继承类也无法访问这些细节。声明中包含了 private 关键字的所有成员只对该类可见，该类型的其他实例也能访问这些成员。如果类型被声明为私有可见性类型，那么该类型的可见性将仅限于包含该类型的包内</p>\n<pre><code>package P1 {\n  class C1 {\n    private val c = 0\n  }\n\n  //&lt; 对于 private 类型,相同包内的子类都不可见\n  class C1Child extends C1 {\n    println( c )\n  }\n}\n\npackage P2 {\n  //&lt; 对于 private 类型,外部包内的子类也不可见\n  class C2Child extends P1.C1 {\n    println( c )\n  }\n}</code></pre><p>编译报错：</p>\n<pre><code>Error:(12, 14) value c in class C1 cannot be accessed in P1.C1Child\n    println( c )\n             ^\n\nError:(19, 14) value c in class C1 cannot be accessed in P2.C2Child\n    println( c )\n             ^</code></pre><p>另外，嵌套类中的私有成员也是无法访问的。在私有可见性中，私有类型只在包含该类型的包中可见，在子包或外部包中均不可见。我们用下面的例子进一步说明，具体说明见代码中的注释：</p>\n<pre><code>package P1 {\n  private class C1\n\n  class C11 extends C1            //&lt; 错误,这样相当于变相改变了C1的可见性,子包和外部包都能访问C11,也就间接能访问C1\n  protected class C12 extends C1  //&lt; 错误这样相当于变相改变了C1的可见性,子包能访问C11,也就间接能访问C1\n  private class C13 extends C1    //&lt; 正确,由于C13也为 private,是的C1的 private 可见性不会\n\n  class C14 {\n    val c14_1 = new C1            //&lt; 正确,私有类型在其所在包内可见\n  }\n}\n\npackage P2 {\n\n  //&lt; 对于私有类型,外部包内不可见\n  class C2 {\n    val c1 = new P1.C1\n  }\n}</code></pre><p>编译报错：</p>\n<pre><code>Error:(8, 21) private class C1 escapes its defining scope as part of type P1.C1\n  class C11 extends C1            //&lt; 错误\n                    ^\n\nError:(9, 31) private class C1 escapes its defining scope as part of type P1.C1\n  protected class C12 extends C1  //&lt; 错误\n                              ^\n\nError:(22, 21) class C1 in package P1 cannot be accessed in package P1\n    val c1 = new P1.C1\n                    ^</code></pre><p>作用域内私有和作用域内受保护可见性</p>\n<p>所谓作用域内私有/受保护可见性，就是你可以更细粒度指定某个类或某个成员在某个作用域（可以是包或类）私有或受保护可见性</p>\n<p>成员在类和包中的 private/protected 可见性<br>该可见性可以有16种组合，下面的例子列举除了这些组合</p>\n<pre><code>package P1 {\n  class C1 {\n    private[C1] val m1 = 1\n    private[this] val m2 = 2\n    private[P1] val m3 = 3\n    private[P2] val m4 = 4\n\n    protected[C1] val n1 = 1\n    protected[this] val n2 = 2\n    protected[P1] val n3 = 3\n    protected[P2] val n4 = 4\n\n    //&lt; 不管什么样的作用域内 private 或 protected,在自身类中都是可见的\n    println( m1 )\n    println( m2 )\n    println( m3 )\n    println( m4 )\n\n    println( n1 )\n    println( n2 )\n    println( n3 )\n    println( n4 )\n  }\n\n  class C11 extends C1 {\n    println( m1 )   //&lt; 1, 错误\n    println( m2 )   //&lt; 2, 错误\n    println( m3 )   //&lt; 3, 正确\n    println( m4 )   //&lt; 4, 正确\n\n    println( n1 )   //&lt; 5, 正确\n    println( n2 )   //&lt; 6, 正确\n    println( n3 )   //&lt; 7, 正确\n    println( n4 )   //&lt; 8, 正确\n  }\n}\n\npackage P2 {\n  class C21 extends P1.C1 {\n    println( m1 )   //&lt; 9, 错误\n    println( m2 )   //&lt; 10, 错误\n    println( m3 )   //&lt; 11, 错误\n    println( m4 )   //&lt; 12, 正确\n\n    println( n1 )   //&lt; 13, 正确\n    println( n2 )   //&lt; 14, 正确\n    println( n3 )   //&lt; 15, 正确\n    println( n4 )   //&lt; 16, 正确\n  }\n}</code></pre><p>下面我们对每一项进行解释，并穿插介绍一些规则：</p>\n<p>private[C1]指定成员在自身类作用域 private，在该类所在的包内和包外均不可见（9也是这个道理）<br>private[this]比 private[C1]更加严格，前者只对相同实例可见，相同类的不同实例都不可见；而后者对相同类的不同实例也可见<br>private[P1]指定在包 P1 内 private，则在 P1 包中的类中均可见，而在 P1外的包均不可见<br>private[P2]指定在包 P2 内 private，则在包 P2 及该类所在包内均可见<br>protected[C1]指定在 C1 中 protected，则在 C1 所在包内的继承类及外部包内所在的继承类均可见</p>\n<p>类型在类和包中的 private/protected 可见性<br>类型的情况就会少一点：</p>\n<pre><code>package P1 {\n\n  private[P1] class C1\n  protected[P1] class C2\n\n  package P11 {\n    private[P1] class C3\n    protected[P1] class C4\n    private[P11] class C5\n    protected[P11] class C6\n  }\n\n\n  class C11 extends C1  //&lt; 1, 正确\n  class C12 extends C2  //&lt; 2, 正确\n\n  import P11._\n  class C13 extends C3  //&lt; 3, 正确\n  class C14 extends C4  //&lt; 4, 正确\n  class C15 extends C5  //&lt; 5, 错误\n  class C16 extends C6  //&lt; 6, 正确\n}\n\npackage P2 {\n  import P1._\n  import P1.P11._\n\n\n  class C21 extends C1  //&lt; 7, 错误\n  class C22 extends C2  //&lt; 8, 正确\n\n  class C23 extends C3  //&lt; 9, 错误\n  class C24 extends C4  //&lt; 10, 正确\n  class C25 extends C5  //&lt; 11, 错误\n  class C26 extends C6  //&lt; 12, 正确\n}</code></pre><p>从上面的例子我们可以得出以下结论：</p>\n<p>对于 private[package] 声明的类型，在 package 包内及 package 子包内可见；在外部包内不可见<br>对于 protected[package] 声明的类型，在 package 包内、package 子包内及外部包均可见<br>有包 package 的子包为 package1，对于 private[package1]，在 package1 包内、package1 子包及其父包即 package 内可见，在外部包不可见<br>有包 package 的子包为 package1，对于 protected[package1]，在 package1包内、package1子包、package1父包及外部包可见</p>\n<h2 id=\"十一-trait\"><a href=\"#十一-trait\" class=\"headerlink\" title=\"十一.trait\"></a>十一.trait</h2><p>这是我以前在知乎上看到关于类继承作用的回答，虽不完全正确，却十分明确的表达出了好的代码应避免类继承而尽量使用类组合。Scala 显然也非常赞同这一点，以至于有了 trait，又叫做特质。当我们定义特质时，应该要遵循这样的原则：一个 trait 只干一件事，如果要干多件事，就定义多个 trait，然后使用一个类来 extends 这些 traits</p>\n<p><strong>定义 trait</strong></p>\n<p>trait 的定义与 class 类似:</p>\n<pre><code>scala&gt; trait T {\n     | }\ndefined trait T</code></pre><p>当然，trait 可以包含成员和方法，并且：</p>\n<p>trait 中的成员可以仅声明，也可以声明并指定值<br>trait 中的方法可以有实现，也可以只有声明而没有实现</p>\n<pre><code>scala&gt; trait T {\n     |   val a: Int\n     |   val b: Int = 1\n     |\n     |   def getA(): Int\n     |   def getB() = b\n     | }\ndefined trait T</code></pre><p>对比而言，类一旦包含未定义的方法就必须声明为 abstract；而 Java 的接口中的方法是不能实现的，必须是抽象方法。如果 trait 既为实现它所声明的方法，也没有定义或声明其他成员，那么在字节码级别，该 trait 其实是接口是相同的</p>\n<p>另一个与类不同的是，trait 主构造函数不允许有参数列表，并且不允许为 trait 定义辅助构造函数</p>\n<p>混入多个 trait</p>\n<p>Scala 类只能有一个父类，但可以混入多个 trait，当要混入多个 traits 或已经继承了某个父类时，需要使用关键字 with，如下例：</p>\n<pre><code>scala&gt; trait T {\n     |   val a: Int\n     |   val b: Int = 1\n     |\n     |   def getA(): Int\n     |   def getB() = b\n     | }\ndefined trait T\n\nscala&gt;\n\nscala&gt; trait Q {\n     |   def currentTime: String = System.currentTimeMillis().toString\n     | }\ndefined trait Q\n\nscala&gt;\n\nscala&gt; class X extends T with Q {\n     |   override val a = 1\n     |   override def getA(): Int = a\n     | }\ndefined class X</code></pre><p>当类混入 trait 时，需要实现 trait 中为实现的成员和方法。要混入多个 trait 是为了保证『高内聚』，通俗说就是一个 trait 只干一件事，如果要干多件事，就定义多个 trait 然后混入它们</p>\n<p>当你继承的父类和混入的特质或混入的不同特质之间有同名方法时可能会有冲突，分为以下几种情况：</p>\n<p>trait 中的方法未实现：不会冲突</p>\n<pre><code>scala&gt; class C {\n     |   def a: String = &quot;a&quot;\n     | }\ndefined class C\n\nscala&gt;\n\nscala&gt; trait T {\n     |   def a: String\n     | }\ndefined trait T\n\nscala&gt;\n\nscala&gt; trait Q extends C with T {}\ndefined trait Q</code></pre><p>trait 中的方法实现了且与父类中的方法参数列表及返回类型相同：会冲突</p>\n<pre><code>scala&gt; class C {\n     |   def a: String = &quot;a&quot;\n     | }\ndefined class C\n\nscala&gt;\n\nscala&gt; trait T {\n     |   def a: String = &quot;&quot;\n     | }\ndefined trait T\n\nscala&gt;\n\nscala&gt; trait Q extends C with T {}\n&lt;console&gt;:9: error: trait Q inherits conflicting members:\n  method a in class C of type =&gt; String  and\n  method a in trait T of type =&gt; String\n(Note: this can be resolved by declaring an override in trait Q.)\n       trait Q extends C with T {}\n             ^</code></pre><p>trait 中的方法实现了且与父类中的参数列表相同，返回类型不同：会冲突</p>\n<pre><code>scala&gt; class C {\n     |   def a: String = &quot;a&quot;\n     | }\ndefined class C\n\nscala&gt;\n\nscala&gt; trait T {\n     |   def a: Int = 1\n     | }\ndefined trait T\n\nscala&gt;\n\nscala&gt; trait Q extends C with T {}\n&lt;console&gt;:9: error: trait Q inherits conflicting members:\n  method a in class C of type =&gt; String  and\n  method a in trait T of type =&gt; Int\n(Note: this can be resolved by declaring an override in trait Q.)\n       trait Q extends C with T {}\n             ^</code></pre><p>trait 中的方法实现了且与父类的参数列表不同，返回类型相同：不会冲突</p>\n<pre><code>scala&gt; class C {\n     |   def a: String = &quot;a&quot;\n     | }\ndefined class C\n\nscala&gt;\n\nscala&gt; trait T {\n     |   def a( i: Int ): String = i.toString\n     | }\ndefined trait T\n\nscala&gt;\n\nscala&gt; trait Q extends C with T {}\ndefined trait Q</code></pre><p><strong>trait 的继承</strong></p>\n<p>一个 trait 同样可以混入其他 trait 或继承类：</p>\n<pre><code>scala&gt; class C {\n     |   def currentTime: String = System.currentTimeMillis().toString\n     | }\ndefined class C\n\nscala&gt;\n\nscala&gt; trait T {\n     |   def random: Int\n     | }\ndefined trait T\n\nscala&gt;\n\nscala&gt; trait Q extends C with T {}\ndefined trait Q</code></pre><h2 id=\"十二-case-class样例类\"><a href=\"#十二-case-class样例类\" class=\"headerlink\" title=\"十二.case class样例类\"></a>十二.case class样例类</h2><p>当你声明了一个 case class，Scala 编译器为你做了这些：<br>创建 case class 和它的伴生 object<br>实现了 apply 方法让你不需要通过 new 来创建类实例</p>\n<pre><code>scala&gt; case class Person(lastname: String, firstname: String, birthYear: Int)\ndefined class Person\n\nscala&gt; val p = Person(&quot;Lacava&quot;, &quot;Alessandro&quot;, 1976)\np: Person = Person(Lacava,Alessandro,1976)</code></pre><p>默认为主构造函数参数列表的所有参数前加 val</p>\n<pre><code>scala&gt; println( p.lastname )\nLacava\n\nscala&gt; p.lastname = &quot;jhon&quot;\n&lt;console&gt;:10: error: reassignment to val\n   p.lastname = &quot;jhon&quot;\n              ^</code></pre><p>添加天然的 hashCode、equals 和 toString 方法。由于 == 在 Scala 中总是代表 equals，所以 case class 实例总是可比较的</p>\n<pre><code>scala&gt; val p_1 = new Person( &quot;Brown&quot;, &quot;John&quot;, 1969 )\np_1: Person = Person(Brown,John,1969)\n\nscala&gt;val p_2 = new Person( &quot;Lacave&quot;, &quot;Alessandro&quot;, 1976)\np_2: Person = Person(Lacave,Alessandro,1976)\n\nscala&gt; p_1.hashCode\nres1: Int = -1362628729\n\nscala&gt; p_1.toString\nres2: String = Person(Brown,John,1969)\n\nscala&gt; p_1.equals(p_2)\nres3: Boolean = false\n\nscala&gt; p_1 == p_2\nres4: Boolean = false</code></pre><p>生成一个 copy 方法以支持从实例 a 生成另一个实例 b，实例 b 可以指定构造函数参数与 a 一致或不一致</p>\n<pre><code>//&lt; 保留 lastname 一致，修改 firstname 和 birthYear\nscala&gt; val p_3 = p.copy(firstname = &quot;Michele&quot;, birthYear = 1972)\np_3: Person = Person(Lacava,Michele,1972)</code></pre><p>由于编译器实现了 unapply 方法，一个 case class 支持模式匹配</p>\n<pre><code>scala&gt; case class A( a: Int )\ndefined class A\n\nscala&gt; case class B( b: String )\ndefined class B\n\nscala&gt; def classMath( x: AnyRef ): Unit = {\n     |   x match {\n     |     case A(a) =&gt; println( &quot;A:&quot; + a )\n     |     case B(b) =&gt; println( &quot;B:&quot; + b )\n     |     case A =&gt; println( A.apply(100) )\n     |   }\n     | }\nclassMath: (x: AnyRef)Unit\n\nscala&gt; val a = A( 1 )\na: A = A(1)\n\nscala&gt; val b = B( &quot;b&quot; )\nb: B = B(b)\n\nscala&gt; classMath( a )\nA:1\n\nscala&gt; classMath( b )\nB:b</code></pre><p>也许你已经知道，在模式匹配中，当你的 case class 没有参数的时候，你是在使用 case object 而不是一个空参数列表的 case class</p>\n<pre><code>scala&gt; classMath( A )\nA(100)</code></pre><p>除了在模式匹配中使用之外，unapply 方法可以让你结构 case class 来提取它的字段，如：</p>\n<pre><code>scala&gt; val Person(lastname, _, _) = p\nlastname: String = Lacava</code></pre><p>case class 接收一个 tuple 作为参数，该 tuple 的元素类型与个数与某 case class 相同，那么可以将该tuple 作为 case class 的 tuple 方法参数来构造 case class 实例</p>\n<pre><code>scala&gt; val meAsTuple: (String, String, Int) = (&quot;Lacava&quot;, &quot;Alessandro&quot;, 1976)\nmeAsTuple: (String, String, Int) = (Lacava,Alessandro,1976)\n\nscala&gt; Person.tupled( meAsTuple )\nres2: Person = Person(Lacava,Alessandro,1976)</code></pre><p>相对用 tuple 来创建 case class 实例，还可以从 case class 实例中解构并提取出 tuple 对象</p>\n<pre><code>scala&gt; val transform: Person =&gt; Option[ (String, String, Int) ] = {\n |   Person.unapply _\n | }\ntransform: Person =&gt; Option[(String, String, Int)] = &lt;function1&gt;\n\nscala&gt; transform( p )\nres0: Option[(String, String, Int)] = Some((Lacava,Alessandro,1976))\n</code></pre><p><strong>另一种定义 case class 的方式</strong></p>\n<p>还有另一种很少人知道的定义 case class 的方式，如：</p>\n<pre><code>case class Person( lastname: String )( firstname: String, birthYear: Int )</code></pre><p>这种方式有点像偏函数，有两个参数列表，要注意的是，对这两个参数列表是区别对待的。上文提到的所有 case class 的特性在这种定义方式下只作用于第一个参数列表中的参数（比如在参数前自动加 val，模式匹配，copy 支持等等），第二个及之后的参数列表中的参数和普通的 class 参数列表参数无异。</p>\n<p>firstname和birthYear前不再自动添加 val，不再是类的成员</p>\n<pre><code>scala&gt; val p = Person(&quot;Lacava&quot;)(&quot;Alessandro&quot;, 1976)\np: Person = Person(Lacava)\n\nscala&gt; p.lastname\nres0: String = Lacava\n\nscala&gt; p.firstname\n&lt;console&gt;:11: error: value firstname is not a member of Person\n              p.firstname\n                ^\n\nscala&gt; p.birthYear\n&lt;console&gt;:11: error: value birthYear is not a member of Person\n              p.birthYear\n                ^</code></pre><p>copy 时，当不指定birthYear的值时，不会使用 p 中的birthYear，因为根本没这个值，会报错</p>\n<pre><code>scala&gt; p.copy()(firstname = &quot;Jhon&quot;)\n&lt;console&gt;:11: error: not enough arguments for method copy: (firstname: String, birthYear: Int)Person.\nUnspecified value parameter birthYear.\n              p.copy()(firstname = &quot;Jhon&quot;)</code></pre><p>equals 和 toString 方法也发生了改变：</p>\n<pre><code>scala&gt; val p_1 = Person(&quot;Lacava&quot;)(&quot;Jhon&quot;, 2001)\np_1: Person = Person(Lacava)\n\nscala&gt; p.equals(p_1)\nres9: Boolean = true\n\nscala&gt; p == p_1\nres10: Boolean = true\n\nscala&gt; println ( p.toString )\nPerson(Lacava)</code></pre><h2 id=\"十三-对象\"><a href=\"#十三-对象\" class=\"headerlink\" title=\"十三.对象\"></a>十三.对象</h2><p> 1、Scala中没有静态方法和静态字段，但是可以用object语法来实现类似的功能。对象定义了某个类的单个实例。</p>\n<p>Scala的object中可以用来实现类似的功能，用来存放工具函数或常量等。如</p>\n<pre><code>object Sequence{\n    private var next_num = 0\n    val threshold = 100\n\n    def getSequence() = {\n        next_num += 1\n        next_num\n    }\n}</code></pre><h2 id=\"十四-常用操作符\"><a href=\"#十四-常用操作符\" class=\"headerlink\" title=\"十四.常用操作符\"></a>十四.常用操作符</h2><p>一、常用操作符（操作符其实也是函数）</p>\n<p>++ ++[B](that: GenTraversableOnce[B]): List[B] 从列表的尾部添加另外一个列表<br>++: ++:[B &gt;: A, That](that: collection.Traversable[B])(implicit bf: CanBuildFrom[List[A], B, That]): That 在列表的头部添加一个列表<br>+: +:(elem: A): List[A] 在列表的头部添加一个元素<br>:+ :+(elem: A): List[A] 在列表的尾部添加一个元素<br>:: ::(x: A): List[A] 在列表的头部添加一个元素<br>::: :::(prefix: List[A]): List[A] 在列表的头部添加另外一个列表<br>:\\ :[B](z: B)(op: (A, B) ⇒ B): B 与foldRight等价</p>\n<p>val left = List(1,2,3)<br>val right = List(4,5,6)</p>\n<p>//以下操作等价<br>left ++ right   // List(1,2,3,4,5,6)<br>left ++: right  // List(1,2,3,4,5,6)<br>right.++:(left)    // Listval left = List(1,2,3)(1,2,3,4,5,6)<br>right.:::(left)  // List(1,2,3,4,5,6)</p>\n<p>//以下操作等价<br>0 +: left    //List(0,1,2,3)<br>left.+:(0)   //List(0,1,2,3)</p>\n<p>//以下操作等价<br>left :+ 4    //List(1,2,3,4)<br>left.:+(4)   //List(1,2,3,4)</p>\n<p>//以下操作等价<br>0 :: left      //List(0,1,2,3)<br>left.::(0)     //List(0,1,2,3)</p>\n<p>看到这里大家应该跟我一样有一点晕吧，怎么这么多奇怪的操作符，这里给大家一个提示，任何以冒号结果的操作符，都是右绑定的，即 0 :: List(1,2,3) = List(1,2,3).::(0) = List(0,1,2,3) 从这里可以看出操作::其实是右边List的操作符，而非左边Int类型的操作符</p>\n<p>二、常用变换操作<br>1.map<br>map[B](f: (A) ⇒ B): List[B]<br>定义一个变换,把该变换应用到列表的每个元素中,原列表不变，返回一个新的列表数据<br>Example1 平方变换</p>\n<pre><code>val nums = List(1,2,3)\nval square = (x: Int) =&gt; x*x   \nval squareNums1 = nums.map(num =&gt; num*num)    //List(1,4,9)\nval squareNums2 = nums.map(math.pow(_,2))    //List(1,4,9)\nval squareNums3 = nums.map(square)            //List(1,4,9)1</code></pre><p>Example2 保存文本数据中的某几列</p>\n<pre><code>val text = List(&quot;Homeway,25,Male&quot;,&quot;XSDYM,23,Female&quot;)\nval usersList = text.map(_.split(&quot;,&quot;)(0))    \nval usersWithAgeList = text.map(line =&gt; {\n    val fields = line.split(&quot;,&quot;)\n    val user = fields(0)\n    val age = fields(1).toInt\n    (user,age)\n})</code></pre><p>2.flatMap, flatten<br>flatten: flatten[B]: List[B] 对列表的列表进行平坦化操作 flatMap: flatMap[B](f: (A) ⇒ GenTraversableOnce[B]): List[B] map之后对结果进行flatten</p>\n<p>定义一个变换f, 把f应用列表的每个元素中，每个f返回一个列表，最终把所有列表连结起来。</p>\n<pre><code>val text = List(&quot;A,B,C&quot;,&quot;D,E,F&quot;)\nval textMapped = text.map(_.split(&quot;,&quot;).toList) // List(List(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;),List(&quot;D&quot;,&quot;E&quot;,&quot;F&quot;))\nval textFlattened = textMapped.flatten          // List(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;,&quot;E&quot;,&quot;F&quot;)\nval textFlatMapped = text.flatMap(_.split(&quot;,&quot;).toList) // List(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;,&quot;E&quot;,&quot;F&quot;)</code></pre><p>3.reduce<br>reduce[A1 &gt;: A](op: (A1, A1) ⇒ A1): A1<br>定义一个变换f, f把两个列表的元素合成一个，遍历列表，最终把列表合并成单一元素<br>Example 列表求和</p>\n<pre><code>val nums = List(1,2,3)\nval sum1 = nums.reduce((a,b) =&gt; a+b)   //6\nval sum2 = nums.reduce(_+_)            //6\nval sum3 = nums.sum                 //6</code></pre><p>4.reduceLeft,reduceRight<br>reduceLeft: reduceLeft[B &gt;: A](f: (B, A) ⇒ B): B<br>reduceRight: reduceRight[B &gt;: A](op: (A, B) ⇒ B): B<br>reduceLeft从列表的左边往右边应用reduce函数，reduceRight从列表的右边往左边应用reduce函数<br>Example</p>\n<pre><code>val nums = List(2.0,2.0,3.0)\nval resultLeftReduce = nums.reduceLeft(math.pow)  // = pow( pow(2.0,2.0) , 3.0) = 64.0\nval resultRightReduce = nums.reduceRight(math.pow) // = pow(2.0, pow(2.0,3.0)) = 256.0</code></pre><p>5.fold,foldLeft,foldRight<br>fold: fold[A1 &gt;: A](z: A1)(op: (A1, A1) ⇒ A1): A1 带有初始值的reduce,从一个初始值开始，从左向右将两个元素合并成一个，最终把列表合并成单一元素。<br>foldLeft: foldLeft[B](z: B)(f: (B, A) ⇒ B): B 带有初始值的reduceLeft<br>foldRight: foldRight[B](z: B)(op: (A, B) ⇒ B): B 带有初始值的reduceRight</p>\n<pre><code>val nums = List(2,3,4)\nval sum = nums.fold(1)(_+_)  // = 1+2+3+4 = 9\n\nval nums = List(2.0,3.0)\nval result1 = nums.foldLeft(4.0)(math.pow) // = pow(pow(4.0,2.0),3.0) = 4096\nval result2 = nums.foldRight(1.0)(math.pow) // = pow(1.0,pow(2.0,3.0)) = 8.0</code></pre><p>6.sortBy,sortWith,sorted<br>sortBy: sortBy[B](f: (A) ⇒ B)(implicit ord: math.Ordering[B]): List[A] 按照应用函数f之后产生的元素进行排序<br>sorted： sorted[B &gt;: A](implicit ord: math.Ordering[B]): List[A] 按照元素自身进行排序<br>sortWith： sortWith(lt: (A, A) ⇒ Boolean): List[A] 使用自定义的比较函数进行排序</p>\n<pre><code>val nums = List(1,3,2,4)\nval sorted = nums.sorted  //List(1,2,3,4)\n\nval users = List((&quot;HomeWay&quot;,25),(&quot;XSDYM&quot;,23))\nval sortedByAge = users.sortBy{case(user,age) =&gt; age}  //List((&quot;XSDYM&quot;,23),(&quot;HomeWay&quot;,25))\nval sortedWith = users.sortWith{case(user1,user2) =&gt; user1._2 &lt; user2._2} //List((&quot;XSDYM&quot;,23),(&quot;HomeWay&quot;,25))</code></pre><p>7.filter, filterNot<br>filter: filter(p: (A) ⇒ Boolean): List[A]<br>filterNot: filterNot(p: (A) ⇒ Boolean): List[A]<br>filter 保留列表中符合条件p的列表元素 ， filterNot，保留列表中不符合条件p的列表元素</p>\n<pre><code>val nums = List(1,2,3,4)\nval odd = nums.filter( _ % 2 != 0) // List(1,3)\nval even = nums.filterNot( _ % 2 != 0) // List(2,4)</code></pre><p>8.count<br>count(p: (A) ⇒ Boolean): Int<br>计算列表中所有满足条件p的元素的个数，等价于 filter(p).length</p>\n<pre><code>val nums = List(-1,-2,0,1,2) \nval plusCnt1 = nums.count(_&gt; 0) \nval plusCnt2 = nums.filter(_&gt; 0).length </code></pre><ol start=\"9\">\n<li>diff, union, intersect<br>diff:diff(that: collection.Seq[A]): List[A] 保存列表中那些不在另外一个列表中的元素，即从集合中减去与另外一个集合的交集<br>union : union(that: collection.Seq[A]): List[A] 与另外一个列表进行连结<br>intersect: intersect(that: collection.Seq[A]): List[A] 与另外一个集合的交集<pre><code>val nums1 = List(1,2,3)\nval nums2 = List(2,3,4)\nval diff1 = nums1 diff nums2   // List(1)\nval diff2 = nums2.diff(num1)   // List(4)\nval union1 = nums1 union nums2  // List(1,2,3,2,3,4)\nval union2 = nums2 ++ nums1        // List(2,3,4,1,2,3)\nval intersection = nums1 intersect nums2  //List(2,3)</code></pre></li>\n<li>distinct</li>\n</ol>\n<p>distinct: List[A] 保留列表中非重复的元素，相同的元素只会被保留一次</p>\n<pre><code>val list = List(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;A&quot;,&quot;B&quot;) val distincted = list.distinct // List(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;)1</code></pre><p>11.groupBy, grouped<br>groupBy : groupBy[K](f: (A) ⇒ K): Map[K, List[A]] 将列表进行分组，分组的依据是应用f在元素上后产生的新元素<br>grouped: grouped(size: Int): Iterator[List[A]] 按列表按照固定的大小进行分组</p>\n<pre><code>val data = List((&quot;HomeWay&quot;,&quot;Male&quot;),(&quot;XSDYM&quot;,&quot;Femail&quot;),(&quot;Mr.Wang&quot;,&quot;Male&quot;))\nval group1 = data.groupBy(_._2) // = Map(&quot;Male&quot; -&gt; List((&quot;HomeWay&quot;,&quot;Male&quot;),(&quot;Mr.Wang&quot;,&quot;Male&quot;)),&quot;Female&quot; -&gt; List((&quot;XSDYM&quot;,&quot;Femail&quot;)))\nval group2 = data.groupBy{case (name,sex) =&gt; sex} // = Map(&quot;Male&quot; -&gt; List((&quot;HomeWay&quot;,&quot;Male&quot;),(&quot;Mr.Wang&quot;,&quot;Male&quot;)),&quot;Female&quot; -&gt; List((&quot;XSDYM&quot;,&quot;Femail&quot;)))\nval fixSizeGroup = data.grouped(2).toList // = Map(&quot;Male&quot; -&gt; List((&quot;HomeWay&quot;,&quot;Male&quot;),(&quot;XSDYM&quot;,&quot;Femail&quot;)),&quot;Female&quot; -&gt; List((&quot;Mr.Wang&quot;,&quot;Male&quot;)))</code></pre><p>12.scan<br>scan[B &gt;: A, That](z: B)(op: (B, B) ⇒ B)(implicit cbf: CanBuildFrom[List[A], B, That]): That<br>由一个初始值开始，从左向右，进行积累的op操作，这个比较难解释，具体的看例子吧。</p>\n<pre><code>val nums = List(1,2,3)\nval result = nums.scan(10)(_+_)   // List(10,10+1,10+1+2,10+1+2+3) = List(10,11,13,16)</code></pre><p>13.scanLeft,scanRight<br>scanLeft: scanLeft[B, That](z: B)(op: (B, A) ⇒ B)(implicit bf: CanBuildFrom[List[A], B, That]): That<br>scanRight: scanRight[B, That](z: B)(op: (A, B) ⇒ B)(implicit bf: CanBuildFrom[List[A], B, That]): That<br>scanLeft: 从左向右进行scan函数的操作，scanRight：从右向左进行scan函数的操作</p>\n<pre><code>val nums = List(1.0,2.0,3.0)\nval result = nums.scanLeft(2.0)(math.pow)   // List(2.0,pow(2.0,1.0), pow(pow(2.0,1.0),2.0),pow(pow(pow(2.0,1.0),2.0),3.0) = List(2.0,2.0,4.0,64.0)\nval result = nums.scanRight(2.0)(math.pow)  // List(2.0,pow(3.0,2.0), pow(2.0,pow(3.0,2.0)), pow(1.0,pow(2.0,pow(3.0,2.0))) = List(1.0,512.0,9.0,2.0)</code></pre><p>14.take,takeRight,takeWhile<br>take : takeRight(n: Int): List[A] 提取列表的前n个元素 takeRight: takeRight(n: Int): List[A] 提取列表的最后n个元素 takeWhile: takeWhile(p: (A) ⇒ Boolean): List[A] 从左向右提取列表的元素，直到条件p不成立</p>\n<pre><code>val nums = List(1,1,1,1,4,4,4,4)\nval left = nums.take(4)   // List(1,1,1,1)\nval right = nums.takeRight(4) // List(4,4,4,4)\nval headNums = nums.takeWhile( _ == nums.head)  // List(1,1,1,1)</code></pre><p>15.drop,dropRight,dropWhile<br>drop: drop(n: Int): List[A] 丢弃前n个元素，返回剩下的元素 dropRight: dropRight(n: Int): List[A] 丢弃最后n个元素，返回剩下的元素 dropWhile: dropWhile(p: (A) ⇒ Boolean): List[A] 从左向右丢弃元素，直到条件p不成立</p>\n<pre><code>val nums = List(1,1,1,1,4,4,4,4)\nval left = nums.drop(4)   // List(4,4,4,4)\nval right = nums.dropRight(4) // List(1,1,1,1)\nval tailNums = nums.dropWhile( _ == nums.head)  // List(4,4,4,4)</code></pre><p>16.span, splitAt, partition<br>span : span(p: (A) ⇒ Boolean): (List[A], List[A]) 从左向右应用条件p进行判断，直到条件p不成立，此时将列表分为两个列表<br>splitAt: splitAt(n: Int): (List[A], List[A]) 将列表分为前n个，与，剩下的部分<br>partition: partition(p: (A) ⇒ Boolean): (List[A], List[A]) 将列表分为两部分，第一部分为满足条件p的元素，第二部分为不满足条件p的元素</p>\n<pre><code>val nums = List(1,1,1,2,3,2,1)\nval (prefix,suffix) = nums.span( _ == 1) // prefix = List(1,1,1), suffix = List(2,3,2,1)\nval (prefix,suffix) = nums.splitAt(3)  // prefix = List(1,1,1), suffix = List(2,3,2,1)\nval (prefix,suffix) = nums.partition( _ == 1) // prefix = List(1,1,1,1), suffix = List(2,3,2)</code></pre><p>17.padTo</p>\n<pre><code>padTo(len: Int, elem: A): List[A]\n将列表扩展到指定长度，长度不够的时候，使用elem进行填充，否则不做任何操作。\n val nums = List(1,1,1)\n val padded = nums.padTo(6,2)   // List(1,1,1,2,2,2)</code></pre><p>18.combinations,permutations</p>\n<pre><code>combinations: combinations(n: Int): Iterator[List[A]] 取列表中的n个元素进行组合，返回不重复的组合列表，结果一个迭代器\npermutations: permutations: Iterator[List[A]] 对列表中的元素进行排列，返回不重得的排列列表，结果是一个迭代器\nval nums = List(1,1,3)\nval combinations = nums.combinations(2).toList //List(List(1,1),List(1,3))\nval permutations = nums.permutations.toList        // List(List(1,1,3),List(1,3,1),List(3,1,1))</code></pre><p>19.zip, zipAll, zipWithIndex, unzip,unzip3<br>zip: zip[B](that: GenIterable[B]): List[(A, B)] 与另外一个列表进行拉链操作，将对应位置的元素组成一个pair，返回的列表长度为两个列表中短的那个<br>zipAll: zipAll[B](that: collection.Iterable[B], thisElem: A, thatElem: B): List[(A, B)] 与另外一个列表进行拉链操作，将对应位置的元素组成一个pair，若列表长度不一致，自身列表比较短的话使用thisElem进行填充，对方列表较短的话使用thatElem进行填充<br>zipWithIndex：zipWithIndex: List[(A, Int)] 将列表元素与其索引进行拉链操作，组成一个pair<br>unzip: unzip[A1, A2](implicit asPair: (A) ⇒ (A1, A2)): (List[A1], List[A2]) 解开拉链操作<br>unzip3: unzip3[A1, A2, A3](implicit asTriple: (A) ⇒ (A1, A2, A3)): (List[A1], List[A2], List[A3]) 3个元素的解拉链操作</p>\n<pre><code>val alphabet = List(&quot;A&quot;,B&quot;,&quot;C&quot;)\nval nums = List(1,2)\nval zipped = alphabet zip nums   // List((&quot;A&quot;,1),(&quot;B&quot;,2))\nval zippedAll = alphabet.zipAll(nums,&quot;*&quot;,-1)   // List((&quot;A&quot;,1),(&quot;B&quot;,2),(&quot;C&quot;,-1))\nval zippedIndex = alphabet.zipWithIndex  // List((&quot;A&quot;,0),(&quot;B&quot;,1),(&quot;C&quot;,3))\nval (list1,list2) = zipped.unzip        // list1 = List(&quot;A&quot;,&quot;B&quot;), list2 = List(1,2)\nval (l1,l2,l3) = List((1, &quot;one&quot;, &#39;1&#39;),(2, &quot;two&quot;, &#39;2&#39;),(3, &quot;three&quot;, &#39;3&#39;)).unzip3   // l1=List(1,2,3),l2=List(&quot;one&quot;,&quot;two&quot;,&quot;three&quot;),l3=List(&#39;1&#39;,&#39;2&#39;,&#39;3&#39;)</code></pre><p>20.slice<br>slice(from: Int, until: Int): List[A] 提取列表中从位置from到位置until(不含该位置)的元素列表</p>\n<pre><code>val nums = List(1,2,3,4,5)\nval sliced = nums.slice(2,4)  //List(3,4)</code></pre><p>21.sliding<br>sliding(size: Int, step: Int): Iterator[List[A]] 将列表按照固定大小size进行分组，步进为step，step默认为1,返回结果为迭代器</p>\n<pre><code>val nums = List(1,1,2,2,3,3,4,4)\nval groupStep2 = nums.sliding(2,2).toList  //List(List(1,1),List(2,2),List(3,3),List(4,4))\nval groupStep1 = nums.sliding(2).toList //List(List(1,1),List(1,2),List(2,2),List(2,3),List(3,3),List(3,4),List(4,4)) </code></pre><p>22.updated<br>updated(index: Int, elem: A): List[A] 对列表中的某个元素进行更新操作</p>\n<pre><code>val nums = List(1,2,3,3)\nval fixed = nums.updated(3,4)  // List(1,2,3,4)</code></pre><h2 id=\"十五-快学scala练习题\"><a href=\"#十五-快学scala练习题\" class=\"headerlink\" title=\"十五.快学scala练习题\"></a>十五.快学scala练习题</h2><p>练习：</p>\n<p>1.设置一个映射,其中包含你想要的一些装备，以及它们的价格。然后构建另一个映射，采用同一组键，但是价格上打9折</p>\n<pre><code>scala&gt; val price = Map(&quot;ipad&quot; -&gt; 4000,&quot;iPhone&quot; -&gt; 6000, &quot;iWatch&quot; -&gt; 3000)\nprice: scala.collection.immutable.Map[String,Int] = Map(ipad -&gt; 4000, iPhone -&gt;\n6000, iWatch -&gt; 3000)\n\nscala&gt; val newprice = for((k,v) &lt;- price) yield (k, v * 0.9)\nnewprice: scala.collection.immutable.Map[String,Double] = Map(ipad -&gt; 3600.0, iP\nhone -&gt; 5400.0, iWatch -&gt; 2700.0)</code></pre><p>2.编写一段程序，从文件中读取单词。用一个可变映射来清点每个单词出现的频率。读取这些单词的操作可以使用java.util.Scanner:<br>val in = new java.util.Scanner(new java.io.File(“myfile.txt”)) while(in.hasNext()) 处理 in.next()最后，打印出所有单词和它们出现的次数。</p>\n<pre><code>import scala.io.Source\nimport scala.collection.mutable.HashMap\nobject Pract {\n   def main(args: Array[String])  = {\n      val source = Source.fromFile(&quot;file.txt&quot;).mkString\n      val tokens = source.split(&quot;\\s+&quot;)\n      val map = new HashMap[String,Int]\n  for(key &lt;- tokens){\n    map(key) = map.getOrElse(key, 0) + 1\n  }\n  println(map.mkString(&quot;,&quot;))      \n   }\n}</code></pre><p>3.重复前一个练习，这次用不可变的映射<br>不可变映射与可变映射的区别就是每次添加新的元素时都会返回一个新的映射。</p>\n<pre><code>import scala.io.Source\nobject Pract {\n   def main(args: Array[String])  = {\n      val source = Source.fromFile(&quot;file.txt&quot;).mkString\n      val tokens = source.split(&quot;\\s+&quot;)\n      var map = MapString,Int //注意这里用的 var 了\n\n  for(key &lt;- tokens){\n      map += (key -&gt; (map.getOrElse(key, 0) + 1))\n  }\n  println(map.mkString(&quot;,&quot;))      \n   }\n}</code></pre><p>4.重复前一个练习，这次使用已排序的映射，以便单词可以按顺序打印出来</p>\n<pre><code>import scala.io.Source\nimport scala.collection.SortedMap\n\nobject Pract {\n   def main(args: Array[String])  = {\n      val source = Source.fromFile(&quot;file.txt&quot;).mkString\n      val tokens = source.split(&quot;\\s+&quot;)\n      var sortedmap = SortedMapString,Int //注意这里用的 var 了\n\n  for(key &lt;- tokens){\n      sortedmap += (key -&gt; (sortedmap.getOrElse(key, 0) + 1))\n  }\n  println(sortedmap.mkString(&quot;,&quot;))      \n   }\n}</code></pre><p>5.重复前一个练习，这次使用java.util.TreeMap并使之适用于Scala API</p>\n<pre><code>import scala.io.Source\nimport scala.collection.mutable.Map\nimport scala.collection.JavaConversions.mapAsScalaMap\nimport java.util.TreeMap\n\nobject Pract {\n   def main(args: Array[String])  = {\n      val source = Source.fromFile(&quot;file.txt&quot;).mkString\n      val tokens = source.split(&quot;\\s+&quot;)\n      val map:Map[String,Int] = new TreeMap[String,Int]\n\n  for(key &lt;- tokens){\n     map(key) = map.getOrElse(key, 0) + 1\n  }\n  println(map.mkString(&quot;,&quot;))   \n   }\n}</code></pre><p>6.定义一个链式哈希映射,将”Monday”映射到java.util.Calendar.MONDAY,依次类推加入其他日期。展示元素是以插入的顺序被访问的</p>\n<pre><code>import scala.collection.mutable.LinkedHashMap\nimport java.util.Calendar\n\nobject Pract {\n   def main(args: Array[String])  = {\n      val map = new LinkedHashMap[String, Int]\n      map += (&quot;MONDAY&quot; -&gt; Calendar.MONDAY)\n      map += (&quot;TUESDAY&quot; -&gt; Calendar.TUESDAY)\n      map += (&quot;WENDSDAY&quot; -&gt; Calendar.WEDNESDAY)\n      map += (&quot;THURSDAY&quot; -&gt; Calendar.THURSDAY)\n      map += (&quot;FRIDAY&quot; -&gt; Calendar.FRIDAY)\n      map += (&quot;SATURDAY&quot; -&gt; Calendar.SATURDAY)\n      map += (&quot;SUNDAY&quot; -&gt; Calendar.SUNDAY)\n      println(map.mkString(&quot;,&quot;))\n   }\n}</code></pre><p>7.打印出所有Java系统属性的表格</p>\n<p>JAVA系统属性转scala map的使用</p>\n<pre><code>import scala.collection.JavaConversions.propertiesAsScalaMap\nimport scala.collection.Map\n\nobject Pract {\n   def main(args: Array[String])  = {\n      val props: Map[String,String] = System.getProperties\n      val keys = props.keySet\n      val keylength = for( key &lt;- keys) yield key.length\n      val maxlength = keylength.max\n      for( key &lt;- keys) {\n        print(key)\n        print(&quot; &quot; * (maxlength - key.length))\n        print(&quot;| &quot;)\n        println(props(key))\n      }\n\n   }\n}</code></pre><p>8.编写一个函数minmax(values:Array[Int]),返回数组中最小值和最大值的对偶</p>\n<pre><code>def minmax(values:Array[Int])  = {\n     (values.max,values.min)\n   }</code></pre><p>9.编写一个函数Iteqgt(values:Array[int],v:Int),返回数组中小于v,等于v和大于v的数量，要求三个值一起返回</p>\n<pre><code>def Iteqgt(values:Array[Int],v:Int) = {\n     var a,b,c=0\n     for(value &lt;- values){\n       if(value &gt; v) a += 1\n       else if(value == v) b += 1\n       else c += 1\n     }\n     (a,b,c)\n   }\n\n   def Iteqgt1(values:Array[Int],v:Int) = {\n     (values.count( &gt; v),values.count( == v), values.count(_ &lt; v))\n   }</code></pre><p>10.当你将两个字符串拉链在一起，比如”Hello”.zip(“World”)，会是什么结果？想出一个讲得通的用例</p>\n<pre><code>scala&gt; &quot;Hello&quot;.zip(&quot;world&quot;)\nres0: scala.collection.immutable.IndexedSeq[(Char, Char)] = Vector((H,w), (e,o),\n (l,r), (l,l), (o,d))\n</code></pre><h2 id=\"十六-构造器\"><a href=\"#十六-构造器\" class=\"headerlink\" title=\"十六.构造器\"></a>十六.构造器</h2><p>Scala的类可以有一个主构造器和多个辅助构造器。每个辅助构造器的名称为this，每一个辅助构造器都必须以调用已经定义的辅助构造器或主构造器开始定义</p>\n<ul>\n<li>主构造器</li>\n</ul>\n<blockquote>\n<p>如果一个类没有显示定义主构造器，则有一个默认的无参主构造器     如定义一个Student类</p>\n</blockquote>\n<pre><code>class Student(val name:String, var age:Int = 0, address:String = &quot;&quot;, private var school:String = &quot;&quot;){\n    var grade:Int = if( age&gt;7 ) age -7 else 0\n    println(&quot; I&#39;m in main constructor. &quot;)\n    def info() = &quot; name is &quot;+name+&quot;, age is &quot;+age+&quot;, address is &quot;+address\n}</code></pre><p>　　对于Scala类，主构造器的参数放置在类名后，由括号括起来。且对于主构造器中var、val、private 等标注的参数，都会成为类的对应字段，并生成对应的默认getter、setter方法。如Student类中的name、age、school等。对于主构造器中的未用var、val标注的参数，如果在类的任何一个方法用用到该参数，该参数将会转换为类的字段，否则不会，如Student类的address属性。</p>\n<p>　　由于在Student类中的info方法中用到了参数address，所以Student共有name、age、address、school、grade等5个属性，且Scala根据对应属性的特点生成了默认的getter和setter方法。</p>\n<p>　　对于主构造器的参数，也可以提供参数默认值。通过为主构造器提供默认值可减少辅助构造器的个数<br>　　主构造器的函数体，是类中除了方法定义以外的其他语句，如在Student类的主构造器中，包含grade属性的初始化和prinln这两行语句。</p>\n<p><img src=\"https://static.oschina.net/uploads/space/2018/1116/110347_10HB_3005534.png\" alt></p>\n<ul>\n<li>辅助构造器<blockquote>\n<p> 辅助构造器通过this来定义，且必须首先调用主构造器或者其他已经定义的辅助构造器。</p>\n</blockquote>\n</li>\n</ul>\n<pre><code>class Person(val name:String){\n    var age = 0\n    var sex:Char = &#39;f&#39;\n    println(&quot;main constructor...&quot;)\n\n    def this(name:String,  age:Int){\n        this(name)        //调用主构造器\n        this.age = age     //使用this关键字\n        println(&quot; auxiliary constructor1 &quot;)\n    }\n\n    def this(name:String, age:Int, sex:Char){\n        this(name, age)\n        this.sex = sex\n        println(&quot; auxiliary constructor2 &quot;)\n    }\n}</code></pre><blockquote>\n<p>【注：辅助构造器的参数前不能添加val、var标志，否则会报错。】</p>\n</blockquote>\n<p><img src=\"https://static.oschina.net/uploads/space/2018/1116/110550_hUV6_3005534.png\" alt></p>\n<ul>\n<li>私有主构造器</li>\n</ul>\n<pre><code>class Person private(val name:String){\n    var age:Int = 1\n    def this(name: String, age:Int){\n        this(name)\n        this.age = age\n    }\n}</code></pre><h1 id=\"hadoop\"><a href=\"#hadoop\" class=\"headerlink\" title=\"hadoop\"></a>hadoop</h1><h2 id=\"一-Nodepad远程linux插件NppFTP\"><a href=\"#一-Nodepad远程linux插件NppFTP\" class=\"headerlink\" title=\"一.Nodepad远程linux插件NppFTP\"></a>一.Nodepad远程linux插件NppFTP</h2><p><strong>1.在该github上下载自己notepad++对应版本位数的插件</strong><br><a href=\"https://github.com/ashkulz/NppFTP/releases/tag/v0.27.6\" target=\"_blank\" rel=\"noopener\">NppFTP下载地址</a>：<a href=\"https://github.com/ashkulz/NppFTP/releases/tag/v0.27.6\" target=\"_blank\" rel=\"noopener\">https://github.com/ashkulz/NppFTP/releases/tag/v0.27.6</a></p>\n<blockquote>\n<p>下载时可以因为被墙的原因下载不了，如果有跨网服务器，直接wget 实际下载地址<br><img src=\"https://static.oschina.net/uploads/img/201901/11105326_7IeQ.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"></p>\n</blockquote>\n<blockquote>\n<p>软件如果下载不了 可以到百度网盘qq939598604/我的软件/NppFTP目录下下载</p>\n</blockquote>\n<p><strong>2.下载之后进行解压，然后将bin目录下的dll文件拷贝到notepad++的安装目录下的插件目录</strong><br>notepad++的安装目录可以右键notepad++的快捷方式，找到安装目录<br><img src=\"https://static.oschina.net/uploads/img/201901/11105635_bvCw.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"><br><img src=\"https://static.oschina.net/uploads/img/201901/11105728_rL2U.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"> </p>\n<p><strong>3.重启notepad++</strong></p>\n<p><strong>4.重启后，在插件菜单中会显示该插件</strong><br><img src=\"https://static.oschina.net/uploads/img/201901/11105829_SBf5.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"></p>\n<p><strong>5.NppFTP使用</strong><br><img src=\"https://static.oschina.net/uploads/img/201901/11110929_I4h9.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"><br><img src=\"https://static.oschina.net/uploads/img/201901/11110936_ZoEY.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"><br><img src=\"https://static.oschina.net/uploads/img/201901/11110948_7ATB.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"><br><img src=\"https://static.oschina.net/uploads/img/201901/11110955_AfYH.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"></p>\n<p><img src=\"https://static.oschina.net/uploads/img/201901/11112540_Mc1p.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"></p>\n<h2 id=\"二-实现linux集群所有机器免密钥登录\"><a href=\"#二-实现linux集群所有机器免密钥登录\" class=\"headerlink\" title=\"二.实现linux集群所有机器免密钥登录\"></a>二.实现linux集群所有机器免密钥登录</h2><p><strong>1.先安装expect</strong> </p>\n<pre><code>yum install expect</code></pre><p>*<em>2.生成密钥 *</em></p>\n<pre><code>ssh-keygen(注,一路回车,不用管)</code></pre><p><strong>3.修改host文件 /etc/hosts</strong></p>\n<pre><code>192.168.197.21 master\n192.168.197.25 slave1\n192.168.197.27 slave2 </code></pre><p><strong>4.编写shell脚本 vim.ssh_copy_id_to_all.sh</strong></p>\n<pre><code>#!/bin/bash\nSERVERS=&quot;master slave1 slave2&quot;\nPASSWORD=root\nauto_ssh_copy_id() {\n    expect -c &quot;set timeout -1;\n        spawn ssh-copy-id $1;\n        expect {\n            *(yes/no)* {send -- yes\\r;exp_continue;}\n            *assword:* {send -- $2\\r;exp_continue;}\n            eof        {exit 0;}\n        }&quot;;\n}\n\nssh_copy_id_to_all() {\n    for SERVER in $SERVERS\n    do\n        auto_ssh_copy_id $SERVER $PASSWORD\n    done\n}\n\nssh_copy_id_to_all</code></pre><p><strong>5.chomd +x ssh_copy_id_to_all.sh</strong><br><strong>6.执行脚本</strong><br>./ssh_copy_id_to_all.sh</p>\n<h2 id=\"三-Windows安装部署hadoop-2-7-5\"><a href=\"#三-Windows安装部署hadoop-2-7-5\" class=\"headerlink\" title=\"三.Windows安装部署hadoop-2.7.5\"></a>三.Windows安装部署hadoop-2.7.5</h2><p><strong>(1).编辑“M:\\soft\\hadoop-2.7.5\\etc\\hadoop”下的core-site.xml文件，将下列文本粘贴进去，并保存；</strong></p>\n<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;\n&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;\n        &lt;value&gt;/M:/soft/hadoop-2.7.5/tmp&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.name.dir&lt;/name&gt;\n        &lt;value&gt;/M:/soft/hadoop-2.7.5/name&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;fs.default.name&lt;/name&gt;\n        &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;</code></pre><p><strong>(2).编辑“M:\\soft\\hadoop-2.7.5\\etc\\hadoop”目录下的mapred-site.xml(没有就将mapred-site.xml.template重命名为mapred-site.xml)文件，粘贴一下内容并保存:</strong></p>\n<pre><code>&lt;?xml version=&quot;1.0&quot;?&gt;\n&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;\n&lt;configuration&gt;\n    &lt;property&gt;\n       &lt;name&gt;mapreduce.framework.name&lt;/name&gt;\n       &lt;value&gt;yarn&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n       &lt;name&gt;mapred.job.tracker&lt;/name&gt;\n       &lt;value&gt;hdfs://localhost:9001&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;</code></pre><p><strong>(3).编辑“M:\\soft\\hadoop-2.7.5\\etc\\hadoop”目录下的hdfs-site.xml文件，粘贴以下内容并保存。请自行创建data目录，在这里我是在HADOOP_HOME目录下创建了data目录:</strong></p>\n<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;\n&lt;configuration&gt;\n    &lt;!-- 这个参数设置为1，因为是单机版hadoop --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.replication&lt;/name&gt;\n        &lt;value&gt;1&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.data.dir&lt;/name&gt;\n        &lt;value&gt;/M:/soft/hadoop-2.7.5/data&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;</code></pre><p><strong>(4).编辑“M:\\soft\\hadoop-2.7.5\\etc\\hadoop”目录下的yarn-site.xml文件，粘贴以下内容并保存；</strong></p>\n<pre><code>&lt;?xml version=&quot;1.0&quot;?&gt;\n&lt;configuration&gt;\n    &lt;property&gt;\n       &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;\n       &lt;value&gt;mapreduce_shuffle&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n       &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;\n       &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;</code></pre><p><strong>(5).编辑“M:\\soft\\hadoop-2.7.5\\etc\\hadoop”目录下的hadoop-env.cmd文件，将JAVA_HOME用 @rem注释掉，编辑为JAVA_HOME的路径，然后保存:</strong></p>\n<pre><code>@rem set JAVA_HOME=%JAVA_HOME%\nset JAVA_HOME=M:\\soft\\Java\\jdk1.8.0_101</code></pre><p><strong>替换文件</strong> 将下载好的hadooponwindows-master.zip（笔记第一步有下载地址，不知道可以去笔记开头的需求栏目查看）解压，将解压后的<strong>*bin目录下的所有文件直接覆盖Hadoop的bin目录*</strong>。</p>\n<h2 id=\"四-hadoop集群安装\"><a href=\"#四-hadoop集群安装\" class=\"headerlink\" title=\"四.hadoop集群安装\"></a>四.hadoop集群安装</h2><p><strong>（一）.安装环境 ：所有的软件安装在根目录下的/soft目录</strong></p>\n<p>java—/soft/jdk1.0.8<br>hadoop–/soft/hadoop2.7.4<br>固定hadoop配置变量(JAVA_HOME,主机名称,hadoop的固定目录)可以不用安装那么多<br>hadoop-env.sh 文件:</p>\n<pre><code>export JAVA_HOME=/soft/jdk1.0.8</code></pre><p>core-site.xml文件: </p>\n<pre><code>&lt;name&gt;fs.defaultFS&lt;/name&gt;\n&lt;value&gt;hdfs://node1:9000&lt;/value&gt;</code></pre><p>hdfs-site.xml文件：</p>\n<pre><code>&lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;\n&lt;value&gt;file:/soft/hadoop-2.7.4/tmp/dfs/name&lt;/value&gt;</code></pre><p>slaves文件</p>\n<pre><code>slave1   slave2 </code></pre><p>集群规划<br>主机名           ip          安装的软件         进程<br>master   192.168.197.255  jdk、hadoop  namenode ressourcemanager<br>slave1   192.168.197.256  jdk、hadoop  datanode secondnamenode<br>slave2   192.168.197.257  jdk、hadoop  datanade</p>\n<p><strong>（二）.安装JDK</strong> </p>\n<p>1.下载jdk1.8.0_161<br>2.在/etc/profile中添加如下配置<br>sudo vim /etc/profile</p>\n<pre><code>export JAVA_HOME=/soft/jdk1.8.0_161\nexport JRE_HOME=${JAVA_HOME}/jre\nexport CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib\nexport PATH=${JAVA_HOME}/bin:$PATH</code></pre><p>3.使环境变量生效，source /etc/profile<br>4.安装验证# java -version </p>\n<p><strong>（三）.准备host文件和修改主机名称</strong><br>1.vim /etc/hosts</p>\n<pre><code>192.168.197.225 master\n192.168.197.226 slave1\n192.168.197.227 slave2</code></pre><p>2.拷贝/etc/hosts到其它主机<br>   scp /etc/hosts slave1:/etc/<br>   scp /etc/hosts slave2:/etc/</p>\n<p>3.修改主机名<br>   vim /etc/hosts<br>   master slave1 slave2 </p>\n<p><strong>（四）.免登录</strong><br>1.注意将防火墙关掉<br>CentOS7 </p>\n<pre><code> (1)关闭防火墙：sudo systemctl stop firewalld.service\n (2)关闭开机启动：sudo systemctl disable firewalld.service\n (3)安装iptables防火墙：sudo yum install iptables-services\n (4)设置iptables防火墙开机启动：sudo systemctl enable iptables</code></pre><p>ubuntu</p>\n<pre><code>(1)关闭ubuntu的防火墙 ufw disable\n(2)开启防火墙 ufw enable\n(3)卸载了iptables apt-get remove iptables \n(4)关闭ubuntu中的防火墙的其余命令\n    iptables -P INPUT ACCEPT\n    iptables -P FORWARD ACCEPT\n    iptables -P OUTPUT ACCEPT\n    iptables -F</code></pre><p>2.ssh无密登录,<br>(1)在集群/etc/ssh/sshd_config 文件去掉以下选项的注释<br>sudo vim /etc/ssh/sshd_config</p>\n<pre><code>Port 22\nProtocol 2\nRSAAuthentication yes      #开启私钥验证\nPubkeyAuthentication yes   #开启公钥验证</code></pre><p>3.生成秘钥<br>(1)在主从节点(集群的每一个节点节点)输入命令 ，生成 key，一律回车<br>   ssh-keygen -t rsa -P ‘’<br>(2)将从节点(集群的每一个节点节点)公钥收集到一个文件中authorized_keys，并发送到各个节点<br>从节点配置：<br>      在slave1的机器：scp /home/chen/.ssh/id_rsa.pub master:/home/chen/.ssh/id_rsa.pub.s1<br>      在slave2的机器：scp /home/chen/.ssh/id_rsa.pub master:/home/chen/.ssh/id_rsa.pub.s2<br>主节点配置：<br>(3)将所有机器的id_rsa.pub文件收集到authorized_keys，并发送到各个节点<br>   sudo cat /home/chen/.ssh/id_rsa.pub &gt;&gt; /home/chen/.ssh/authorized_keys<br>   sudo cat /home/chen/.ssh/id_rsa.pub.s1 &gt;&gt; /home/chen/.ssh/authorized_keys<br>   sudo cat /home/chen/.ssh/id_rsa.pub.s2 &gt;&gt; /home/chen/.ssh/authorized_keys<br>(4)最后将生成的包含三个节点的秘钥的authorized_keys 复制到s1和s2的.ssh目录下（<br>   scp /home/chen/.ssh/authorized_keys slave1:/home/chen/.ssh/<br>   scp /home/chen/.ssh/authorized_keys slave2:/home/chen/.ssh/</p>\n<p>验证ssh免密码登录<br>1.输入命令ssh  localhost(主机名) 根据提示输入“yes”<br>2.输入命令exit注销（Logout）<br>3.再次输入命令ssh localhost即可直接登录</p>\n<p><strong>（五）hadoop的配置</strong><br>(1)编辑 hadoop-env.sh 文件,找到 JAVA_HOME 改为 JDK 的安装目录<br>   sudo vim /soft/hadoop-2.7.4/etc/hadoop/hadoop-env.sh<br>   export JAVA_HOME=/soft/jdk1.8.0_161<br>(2)修改 core-site.xml<br>   sudo vim core-site.xml</p>\n<pre><code>&lt;configuration&gt;\n       &lt;property&gt;\n           &lt;name&gt;fs.defaultFS&lt;/name&gt;\n           &lt;value&gt;hdfs://master:9000&lt;/value&gt;\n       &lt;/property&gt;\n       &lt;property&gt;\n           &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;\n           &lt;value&gt;file:/soft/hadoop-2.7.4/tmp&lt;/value&gt;\n       &lt;/property&gt;\n   &lt;/configuration&gt;</code></pre><p>(2)修改 hdfs-site.xml<br>   sudo vim hdfs-site.xml</p>\n<pre><code>&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;\n        &lt;value&gt;master:50090&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.replication&lt;/name&gt;\n        &lt;value&gt;2&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;\n        &lt;value&gt;file:/soft/hadoop-2.7.4/tmp/dfs/name&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;\n        &lt;value&gt;file:/soft/hadoop-2.7.4/tmp/dfs/data&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;</code></pre><p>(3)修改 mapred-site.xml<br>目录下么没有这个文件,这有一个模板,我们需要先拷贝一份<br> cp mapred-site.xml.template mapred-site.xml<br> vim  mapred-site.xml</p>\n<pre><code>&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;\n        &lt;value&gt;yarn&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;\n        &lt;value&gt;master:10020&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;\n        &lt;value&gt;master:19888&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;</code></pre><p>(4)修改 yarn-site.xml<br>vi yarn-site.xml</p>\n<pre><code>&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;\n        &lt;value&gt;master&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;\n        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;</code></pre><p><strong>（六）配置集群</strong><br>(1)复制节点,将hadoop-2.7.4 文件夹重打包后复制到其他子节点</p>\n<pre><code>scp /soft/hadoop-2.7.4/ chen@slave1:/soft\nscp /soft/hadoop-2.7.4/ chen@slave2:/soft</code></pre><p>(2)配置slaves文件<br>修改（Master主机）/soft/hadoop-2.7.4/etc/hadoop/slaves该文件指定哪些服务器节点是datanode节点。删除locahost，添加所有datanode节点的主机名<br>sudo vim /soft/hadoop-2.7.4/etc/hadoop/slaves</p>\n<pre><code>slave1\nslave2</code></pre><p>(3)格式化namenode和datanode并启动，（在master上执行就可以了 不需要在slave上执行）</p>\n<pre><code>cd /soft/hadoop-2.7.4/bin\n./hadoop namenode -format\n./hadoop datanode -format</code></pre><p><strong>（七）启动 hadoop</strong></p>\n<p>cd /soft/hadoop-2.7.4/sbin<br>./start-dfs.sh<br>./start-yarn.sh<br>./mr-jobhistory-daemon.sh start historyserver<br>或者<br>./start-all.sh<br>./mr-jobhistory-daemon.sh start historyserver</p>\n<p><strong>（八）查看进程服务</strong><br>查看启动进程,缺少以下任一进程都表示出错<br>$ jps<br>2528 NameNode<br>2720 SecondaryNameNode<br>2872 ResourceManager<br>3151 JobHistoryServer<br>查看端口占用情况<br>netstat -tnlp | grep java<br>访问master<br><a href=\"http://192.168.197.255:50070\" target=\"_blank\" rel=\"noopener\">http://192.168.197.255:50070</a><br><a href=\"http://192.168.197.255:8088\" target=\"_blank\" rel=\"noopener\">http://192.168.197.255:8088</a></p>\n<p><strong>（九）停止 hadoop</strong><br>cd /soft/hadoop-2.7.4/sbin<br>./stop-all.sh</p>\n<h1 id><a href=\"#\" class=\"headerlink\" title=\" \"></a> </h1><h1 id=\"hbase\"><a href=\"#hbase\" class=\"headerlink\" title=\"hbase\"></a>hbase</h1><h2 id=\"一-hbase在linux系统本地模式\"><a href=\"#一-hbase在linux系统本地模式\" class=\"headerlink\" title=\"一.hbase在linux系统本地模式\"></a>一.hbase在linux系统本地模式</h2><p>1.安装好jdk<br>2.下载hbase hbase 下载地址：<a href=\"http://hbase.apache.org/\" target=\"_blank\" rel=\"noopener\">http://hbase.apache.org/</a></p>\n<pre><code>hbase-2.0.2-bin.tar.gz</code></pre><p>3.上传到linux服务的/soft目录下<br>4.tar 开hbase压缩包</p>\n<pre><code>tar -zxvf /soft/hbase-2.0.2-bin.tar.gz -C /soft/</code></pre><p>5.修改conf/hbase-env.sh<br>vim /soft/hbase-2.0.2/conf/hbase-env.sh</p>\n<pre><code>export JAVA_HOME=/soft/jdk1.8.0_161</code></pre><p>6.编辑hbase-site.xml </p>\n<pre><code>&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;hbase.rootdir&lt;/name&gt;\n        &lt;value&gt;file:///soft/hbase-2.0.2/data&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>7.新建hbase数据存放目录</p>\n<pre><code>mkdir /soft/hbase-2.0.2/data</code></pre><p>8.启动hbase</p>\n<pre><code>cd /soft/hbase-2.0.2/bin\n./bin/start-hbase.sh</code></pre><p>9.jps 查看后 出现Hmaster就是启动成功 然后就可以进入shell进行对hbase的操作</p>\n<pre><code>[root@master hbase-2.0.2]# jps\n4359 Main\n5532 Jps\n4829 HMaster</code></pre><p>10.进入hbase shell</p>\n<pre><code>./bin/hbase shell</code></pre><p>11.访问web</p>\n<pre><code>http://192.168.197.21:16010/master-status</code></pre><p><strong>shell环境测试</strong><br>创建表</p>\n<pre><code>hbase(main):016:0&gt; create &#39;t1&#39;, {NAME =&gt; &#39;f1&#39;, VERSIONS =&gt; 1}</code></pre><p>查看表</p>\n<pre><code>hbase(main):017:0&gt; list\nTABLE\nt1\n1 row(s)\nTook 0.0053 seconds                                                                   \n=&gt; [&quot;t1&quot;]</code></pre><p>插入一条数据</p>\n<pre><code>hbase(main):019:0&gt; put &#39;t1&#39;, &#39;r1&#39;, &#39;f1&#39;, &#39;v1&#39;</code></pre><p>扫描t1表的全数据</p>\n<pre><code>hbase(main):018:0&gt;  scan &#39;t1&#39;\nROW                       COLUMN+CELL                                                 \nr1                       column=f1:, timestamp=1540885480142, value=v1                \n1 row(s)</code></pre><h2 id=\"二-Hbase在linux集群搭建\"><a href=\"#二-Hbase在linux集群搭建\" class=\"headerlink\" title=\"二.Hbase在linux集群搭建\"></a>二.Hbase在linux集群搭建</h2><p>软件放置路径为初级配置的路径/soft/hbase-1.3.1<br>1.解压已经安装整理过的压缩包hbase-1.3.1-install.tar.gz</p>\n<pre><code>tar -zxvf /soft/hbase-1.3.1-install.tar.gz -C /soft/</code></pre><p>2.修改hbase-env环境变量<br>vim /soft/hbase-1.3.1/conf/hbase-env.sh</p>\n<pre><code>export JAVA_HOME=/soft/jdk1.8.0_161\nexport HBASE_CLASSPATH=/soft/hadoop-2.7.4\nexport HBASE_MANAGES_ZK=false          # 不使用自带的zk，使用独立的zookeeper</code></pre><p>3.修改hbase-site.xml<br>vim /soft/hbase-1.3.1/conf/hbase-site.xml    # 配置站点信息</p>\n<pre><code>&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;hbase.rootdir&lt;/name&gt;\n        &lt;value&gt;hdfs://master:9000/hbase&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;hbase.master&lt;/name&gt;\n        &lt;value&gt;master&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;\n        &lt;value&gt;true&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt;\n        &lt;value&gt;2181&lt;/value&gt;                                     # 这里指的是zook的端口\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;                     # 主机名一定要对应上\n        &lt;value&gt;master,slave1,slave2&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;zookeeper.session.timeout&lt;/name&gt;                  # zook的session超时时长\n        &lt;value&gt;60000000&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.support.append&lt;/name&gt;\n        &lt;value&gt;true&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;</code></pre><p>4.指定添加regionservers<br>vim /soft/hbase-1.3.1/conf/regionservers# 配置从节点 一定要对应上</p>\n<pre><code>master\nslave1\nslave2</code></pre><p>5.复制/soft/hbase-1.3.1到各个从的机器</p>\n<pre><code>scp /soft/hbase-1.3.1 root@slave1:/soft/\nscp /soft/hbase-1.3.1 root@slave2:/soft/</code></pre><p>6.在各个节点添加hbase的环境变量<br>vim /etc/profile</p>\n<pre><code>export HBASE_HOME=/soft/hbase-1.3.1\nexport PATH=$HBASE_HOME/bin:$PATH</code></pre><p>7.在master启动hbase</p>\n<pre><code>/soft/hbase-1.3.1/bin/start-hbase.sh</code></pre><p>8.浏览器检查打开master机器的端口16010<br><a href=\"http://192.168.197.231:16010/master-status\" target=\"_blank\" rel=\"noopener\">http://192.168.197.231:16010/master-status</a></p>\n<h2 id=\"三-hbase在window环境下安装\"><a href=\"#三-hbase在window环境下安装\" class=\"headerlink\" title=\"三.hbase在window环境下安装\"></a>三.hbase在window环境下安装</h2><p>1.安装jdk</p>\n<pre><code>默认JDK已安装并配置好环境变量，本处用的jdk1.8.0_101 </code></pre><p>2、下载hbase-2.0.2-bin.tar.gz</p>\n<pre><code>解压到C:\\hbase-2.0.2\\目录下</code></pre><p>3、下载hadoop-common-2.2.0-bin-master</p>\n<pre><code>hadoop-common-2.2.0-bin-master(包含windows端开发Hadoop2.2需要的winutils.exe)，HBase在Windows下部署需要使用到。    \n地址：https://github.com/srccodes/hadoop-common-2.2.0-bin，下载hadoop-common-2.2.0-bin-master.zip，解压缩到D:\\hadoop\\hadoop-common-2.2.0-bin-master。</code></pre><p>4、修改HBase下的conf/hbase-env.cmd</p>\n<pre><code>set JAVA_HOME=M:\\soft\\Java\\jdk1.8.0_101\nset HBASE_MANAGES_ZK=true</code></pre><p>5.修改HBase下的hbase-site.xml</p>\n<pre><code>&lt;?xml version=&quot;1.0&quot;?&gt;\n&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;\n&lt;configuration&gt;\n    &lt;property&gt;  \n        &lt;name&gt;hbase.rootdir&lt;/name&gt;  \n        &lt;value&gt;file:///C:/hbase-2.0.2/data&lt;/value&gt;  \n    &lt;/property&gt;  \n    &lt;property&gt;  \n        &lt;name&gt;hbase.tmp.dir&lt;/name&gt;  \n        &lt;value&gt;C:/hbase-2.0.2/tmp&lt;/value&gt;  \n    &lt;/property&gt;  \n    &lt;property&gt;  \n        &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;  \n        &lt;value&gt;127.0.0.1&lt;/value&gt;  \n    &lt;/property&gt;  \n    &lt;property&gt;  \n        &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;  \n        &lt;value&gt;C:/hbase-2.0.2/tmp/zoo&lt;/value&gt;  \n    &lt;/property&gt;  \n    &lt;property&gt;  \n        &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;  \n        &lt;value&gt;false&lt;/value&gt;  \n    &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>6.配置用户变量HADOOP_HOME</p>\n<pre><code>新建环境变量HADOOP_HOME，值为C:\\hadoop-common-2.2.0-bin-master\n在path后添加：%HADOOP_HOME%\\bin\n</code></pre><p>7.启动HBase</p>\n<pre><code>在C:\\hbase-2.0.2\\bin下打开命令行，输入start-hbase.cmd，启动HBase。</code></pre><p>8.测试Shell</p>\n<pre><code> HBase启动后，在命令行输入hbase shell，打卡HBase的shell命令行</code></pre><p>9.打开HBase主页，网址：<a href=\"http://127.0.0.1:16010/master-status\" target=\"_blank\" rel=\"noopener\">http://127.0.0.1:16010/master-status</a><br>10.可以通过测试命令建表测试等等</p>\n<h2 id=\"四-hbase的filter操作\"><a href=\"#四-hbase的filter操作\" class=\"headerlink\" title=\"四.hbase的filter操作\"></a>四.hbase的filter操作</h2><p><strong>1.创建表</strong></p>\n<pre><code>create &#39;test1&#39;, &#39;lf&#39;, &#39;sf&#39;</code></pre><p><strong>2.导入数据</strong></p>\n<pre><code>put &#39;test1&#39;, &#39;user1|ts1&#39;, &#39;sf:c1&#39;, &#39;sku1&#39;\nput &#39;test1&#39;, &#39;user1|ts2&#39;, &#39;sf:c1&#39;, &#39;sku188&#39;\nput &#39;test1&#39;, &#39;user1|ts3&#39;, &#39;sf:s1&#39;, &#39;sku123&#39;\nput &#39;test1&#39;, &#39;user2|ts4&#39;, &#39;sf:c1&#39;, &#39;sku2&#39;\nput &#39;test1&#39;, &#39;user2|ts5&#39;, &#39;sf:c2&#39;, &#39;sku288&#39;\nput &#39;test1&#39;, &#39;user2|ts6&#39;, &#39;sf:s1&#39;, &#39;sku222&#39;</code></pre><p><strong>3.查询案例：谁的值=sku188</strong></p>\n<pre><code>scan &#39;test1&#39;, FILTER=&gt;&quot;ValueFilter(=,&#39;binary:sku188&#39;)&quot;</code></pre><p>**#查询结果</p>\n<pre><code>ROW                         COLUMN+CELL                    \nuser1|ts2                   column=sf:c1, timestamp=1409122354918, value=sku188</code></pre><p><strong>4.查询案例：谁的值包含88</strong></p>\n<pre><code>scan &#39;test1&#39;, FILTER=&gt;&quot;ValueFilter(=,&#39;substring:88&#39;)&quot;</code></pre><p>**#查询结果</p>\n<pre><code> ROW                         COLUMN+CELL    \n user1|ts2                   column=sf:c1, timestamp=1409122354918, value=sku188\n user2|ts5                   column=sf:c2, timestamp=1409122355030, value=sku288</code></pre><p><strong>5.查询案例：谁的值包含88</strong></p>\n<pre><code>scan &#39;test1&#39;, FILTER=&gt;&quot;ValueFilter(=,&#39;substring:88&#39;)&quot;</code></pre><p>**#查询结果</p>\n<pre><code> ROW                         COLUMN+CELL    \n user1|ts2                   column=sf:c1, timestamp=1409122354918, value=sku188\n user2|ts5                   column=sf:c2, timestamp=1409122355030, value=sku288</code></pre><p><strong>6.通过广告点击进来的(column为c2)值包含88的用户</strong></p>\n<pre><code>scan &#39;test1&#39;, FILTER=&gt;&quot;ColumnPrefixFilter(&#39;c2&#39;) AND ValueFilter(=,&#39;substring:88&#39;)&quot;</code></pre><p>**#查询结果</p>\n<pre><code> ROW                         COLUMN+CELL\n user2|ts5                   column=sf:c2, timestamp=1409122355030, value=sku288</code></pre><p><strong>7.通过搜索进来的(column为s)值包含123或者222的用户</strong></p>\n<pre><code>scan &#39;test1&#39;, FILTER=&gt;&quot;ColumnPrefixFilter(&#39;s&#39;) AND ( ValueFilter(=,&#39;substring:123&#39;) OR ValueFilter(=,&#39;substring:222&#39;) )&quot;</code></pre><p>**#查询结果</p>\n<pre><code> ROW                         COLUMN+CELL\n user1|ts3                   column=sf:s1, timestamp=1409122354954, value=sku123\n user2|ts6                   column=sf:s1, timestamp=1409122355970, value=sku222</code></pre><p><strong>8.rowkey为user1开头的</strong></p>\n<pre><code>scan &#39;test1&#39;, FILTER =&gt; &quot;PrefixFilter (&#39;user1&#39;)&quot;</code></pre><p>**#查询结果</p>\n<pre><code> ROW                        COLUMN+CELL\n user1|ts1                   column=sf:c1, timestamp=1409122354868, value=sku1\n user1|ts2                   column=sf:c1, timestamp=1409122354918, value=sku188\n user1|ts3                   column=sf:s1, timestamp=1409122354954, value=sku123</code></pre><p><strong>9.从user1|ts2开始,找到所有的rowkey以user1开头的</strong></p>\n<pre><code>scan &#39;test1&#39;, {STARTROW=&gt;&#39;user1|ts2&#39;, FILTER =&gt; &quot;PrefixFilter (&#39;user1&#39;)&quot;}</code></pre><p>**#查询结果</p>\n<pre><code> ROW                         COLUMN+CELL\n user1|ts2                   column=sf:c1, timestamp=1409122354918, value=sku188\n user1|ts3                   column=sf:s1, timestamp=1409122354954, value=sku123 </code></pre><p><strong>10.从user1|ts2开始,找到所有的到rowkey以user2开头</strong></p>\n<pre><code>scan &#39;test1&#39;, {STARTROW=&gt;&#39;user1|ts2&#39;, STOPROW=&gt;&#39;user2&#39;}</code></pre><p>**#查询结果</p>\n<pre><code> ROW                          COLUMN+CELL\n user1|ts2                   column=sf:c1, timestamp=1409122354918, value=sku188\n user1|ts3                   column=sf:s1, timestamp=1409122354954, value=sku123</code></pre><p><strong>11.查询rowkey里面包含ts3的</strong></p>\n<pre><code>import org.apache.hadoop.hbase.filter.CompareFilter\nimport org.apache.hadoop.hbase.filter.SubstringComparator\nimport org.apache.hadoop.hbase.filter.RowFilter\nscan &#39;test1&#39;, {FILTER =&gt; RowFilter.new(CompareFilter::CompareOp.valueOf(&#39;EQUAL&#39;), SubstringComparator.new(&#39;ts3&#39;))}</code></pre><p>**#查询结果</p>\n<pre><code> ROW                          COLUMN+CELL\n user1|ts3                   column=sf:s1, timestamp=1409122354954, value=sku123 </code></pre><p><strong>12.查询rowkey里面包含ts的</strong></p>\n<pre><code>import org.apache.hadoop.hbase.filter.CompareFilter\nimport org.apache.hadoop.hbase.filter.SubstringComparator\nimport org.apache.hadoop.hbase.filter.RowFilter\nscan &#39;test1&#39;, {FILTER =&gt; RowFilter.new(CompareFilter::CompareOp.valueOf(&#39;EQUAL&#39;), SubstringComparator.new(&#39;ts&#39;))}</code></pre><p>**#查询结果</p>\n<pre><code> ROW                         COLUMN+CELL\n user1|ts1                   column=sf:c1, timestamp=1409122354868, value=sku1\n user1|ts2                   column=sf:c1, timestamp=1409122354918, value=sku188\n user1|ts3                   column=sf:s1, timestamp=1409122354954, value=sku123\n user2|ts4                   column=sf:c1, timestamp=1409122354998, value=sku2\n user2|ts5                   column=sf:c2, timestamp=1409122355030, value=sku288\n user2|ts6                   column=sf:s1, timestamp=1409122355970, value=sku222</code></pre><p><strong>13.加入一条测试数据</strong></p>\n<pre><code>put &#39;test1&#39;, &#39;user2|err&#39;, &#39;sf:s1&#39;, &#39;sku999&#39;</code></pre><p><strong>14.查询rowkey里面以user开头的，新加入的测试数据并不符合正则表达式的规则，故查询不出来</strong></p>\n<pre><code>import org.apache.hadoop.hbase.filter.RegexStringComparator\nimport org.apache.hadoop.hbase.filter.CompareFilter\nimport org.apache.hadoop.hbase.filter.SubstringComparator\nimport org.apache.hadoop.hbase.filter.RowFilter\nscan &#39;test1&#39;, {FILTER =&gt; RowFilter.new(CompareFilter::CompareOp.valueOf(&#39;EQUAL&#39;),RegexStringComparator.new(&#39;^user\\d+\\|ts\\d+$&#39;))}</code></pre><p>**#查询结果</p>\n<pre><code> ROW                         COLUMN+CELL\n user1|ts1                   column=sf:c1, timestamp=1409122354868, value=sku1\n user1|ts2                   column=sf:c1, timestamp=1409122354918, value=sku188\n user1|ts3                   column=sf:s1, timestamp=1409122354954, value=sku123\n user2|ts4                   column=sf:c1, timestamp=1409122354998, value=sku2\n user2|ts5                   column=sf:c2, timestamp=1409122355030, value=sku288\n user2|ts6                   column=sf:s1, timestamp=1409122355970, value=sku222</code></pre><p><strong>15.加入测试数据</strong></p>\n<pre><code>put &#39;test1&#39;, &#39;user1|ts9&#39;, &#39;sf:b1&#39;, &#39;sku1&#39;</code></pre><p><strong>16.b1开头的列中并且值为sku1的</strong></p>\n<pre><code>scan &#39;test1&#39;, FILTER=&gt;&quot;ColumnPrefixFilter(&#39;b1&#39;) AND ValueFilter(=,&#39;binary:sku1&#39;)&quot;</code></pre><p>**#查询结果</p>\n<pre><code> ROW                          COLUMN+CELL                                                   user1|ts9                   column=sf:b1, timestamp=1409124908668, value=sku1</code></pre><p><strong>17.SingleColumnValueFilter的使用，b1开头的列中并且值为sku1的</strong></p>\n<pre><code>import org.apache.hadoop.hbase.filter.CompareFilter\nimport org.apache.hadoop.hbase.filter.SingleColumnValueFilter\nimport org.apache.hadoop.hbase.filter.SubstringComparator\nscan &#39;test1&#39;, {COLUMNS =&gt; &#39;sf:b1&#39;, FILTER =&gt; SingleColumnValueFilter.new(Bytes.toBytes(&#39;sf&#39;), Bytes.toBytes(&#39;b1&#39;), CompareFilter::CompareOp.valueOf(&#39;EQUAL&#39;), Bytes.toBytes(&#39;sku1&#39;))}</code></pre><p>**#查询结果</p>\n<pre><code> ROW                         COLUMN+CELL\n user1|ts9                   column=sf:b1, timestamp=1409124908668, value=sku1</code></pre><p><strong>18.KeyOnlyFilter: 只要key,不要value</strong></p>\n<pre><code>scan &#39;test1&#39;, FILTER=&gt;&quot;FirstKeyOnlyFilter() AND ValueFilter(=,&#39;binary:sku188&#39;) AND KeyOnlyFilter()&quot;</code></pre><p>**#查询结果</p>\n<pre><code> ROW                         COLUMN+CELL\n user1|ts2                   column=sf:c1, timestamp=1409122354918, value=</code></pre><p>FirstKeyOnlyFilter: 一个rowkey可以有多个version,同一个rowkey的同一个column也会有多个的值, 只拿出key中的第一个column的第一个version</p>\n<h2 id=\"五-hbase的java操作-maven构建\"><a href=\"#五-hbase的java操作-maven构建\" class=\"headerlink\" title=\"五.hbase的java操作 maven构建\"></a>五.hbase的java操作 maven构建</h2><p><strong>1.pom.xml文件添加hbase依赖</strong></p>\n<pre><code>&lt;properties&gt;\n    &lt;hbase.version&gt;2.0.2&lt;/hbase.version&gt;\n&lt;/properties&gt;\n\n&lt;dependencies&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt;\n        &lt;artifactId&gt;hbase-server&lt;/artifactId&gt;\n        &lt;version&gt;${hbase.version}&lt;/version&gt;\n    &lt;/dependency&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt;\n        &lt;artifactId&gt;hbase-client&lt;/artifactId&gt;\n        &lt;version&gt;${hbase.version}&lt;/version&gt;\n    &lt;/dependency&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt;\n        &lt;artifactId&gt;hbase-common&lt;/artifactId&gt;\n        &lt;version&gt;${hbase.version}&lt;/version&gt;\n    &lt;/dependency&gt;\n&lt;/dependencies&gt;</code></pre><p><strong>2.初始化静态方法</strong></p>\n<pre><code>static {\n    Configuration configuration = HBaseConfiguration.create();\n    try {\n        connection = ConnectionFactory.createConnection(configuration);\n        admin = connection.getAdmin();\n    } catch (Exception e) {\n        e.printStackTrace();\n    }\n}</code></pre><p><strong>3.判断表是否存在</strong></p>\n<pre><code>public static boolean isExist(String tableName) throws Exception {\n    return admin.tableExists(TableName.valueOf(tableName));\n}</code></pre><p><strong>4.创建表</strong></p>\n<pre><code>public static void createTable(String tableName,String ... column) throws Exception {\n    if(isExist(tableName)){\n        System.out.println(tableName+&quot;已经存在&quot;);\n        return;\n    }\n    HTableDescriptor tableDescriptor = new HTableDescriptor(TableName.valueOf(tableName));\n    for (String c : column) {\n        HColumnDescriptor hColumnDescriptor = new HColumnDescriptor(c);\n        tableDescriptor.addFamily(hColumnDescriptor);\n    }\n    admin.createTable(tableDescriptor);\n    System.out.println(tableName+&quot;创建成功&quot;);\n    getAllTable();\n}</code></pre><p><strong>5.删除表</strong></p>\n<pre><code>public static void deleteTable(String tableName) throws Exception {\n    if(isExist(tableName)){\n        admin.disableTable(TableName.valueOf(tableName));\n        admin.deleteTable(TableName.valueOf(tableName));\n    }\n    System.out.println(tableName+&quot;已被删除&quot;);\n    getAllTable();\n }</code></pre><p><strong>6.获取所有表</strong></p>\n<pre><code>public static void getAllTable() throws Exception {\n    TableName[] tableNames = admin.listTableNames();\n    for (TableName tableName : tableNames) {\n        System.out.println(Bytes.toString(tableName.getName()));\n    }\n}</code></pre><p><strong>7.添加一行数据</strong></p>\n<pre><code>public static void add1Row(String tableName,String rowkey,String cf,String column,String val) throws Exception {\n    Table table = connection.getTable(TableName.valueOf(tableName));\n    Put put = new Put(Bytes.toBytes(rowkey));\n    put.addColumn(Bytes.toBytes(cf),Bytes.toBytes(column),Bytes.toBytes(val));\n    table.put(put);\n}</code></pre><p><strong>8.删除一行数据</strong></p>\n<pre><code>public static void del1Row(String tableName,String rowkey) throws Exception {\n    Table table = connection.getTable(TableName.valueOf(tableName));\n    Delete delete = new Delete(Bytes.toBytes(rowkey));\n    table.delete(delete);\n}</code></pre><p><strong>9.删除多行数据</strong></p>\n<pre><code>public static void delMulRow(String tableName,String... rowkeys) throws Exception {\n    Table table = connection.getTable(TableName.valueOf(tableName));\n    List&lt;Delete&gt; deletes = new ArrayList&lt;Delete&gt;();\n    for (String rowkey : rowkeys) {\n        Delete delete = new Delete(Bytes.toBytes(rowkey));\n        deletes.add(delete);\n    }\n    table.delete(deletes);\n}</code></pre><p><strong>10.获取多行数据</strong></p>\n<pre><code>public static void getAllrows(String tableName) throws Exception {\n    Table table = connection.getTable(TableName.valueOf(tableName));\n    Scan scan = new Scan();\n    scan.setMaxVersions();\n    ResultScanner resultScanner = table.getScanner(scan);\n    for (Result result : resultScanner) {\n        Cell[] cells = result.rawCells();\n        for (Cell cell : cells) {\n            System.out.print(Bytes.toString(CellUtil.cloneFamily(cell))+&quot; &quot;);\n            System.out.print(Bytes.toString(CellUtil.cloneQualifier(cell))+&quot; &quot;);\n            System.out.print(Bytes.toString(CellUtil.cloneRow(cell))+&quot; &quot;);\n            System.out.println(Bytes.toString(CellUtil.cloneValue(cell)));\n        }\n    }\n}</code></pre><p><strong>11.获取一行数据</strong></p>\n<pre><code>public static void getrow(String tableName,String rowkey) throws Exception {\n    Table table = connection.getTable(TableName.valueOf(tableName));\n    Get get = new Get(Bytes.toBytes(rowkey));\n    Result result = table.get(get);\n    Cell[] cells = result.rawCells();\n    for (Cell cell : cells) {\n        System.out.print(Bytes.toString(CellUtil.cloneFamily(cell))+&quot; &quot;);\n        System.out.print(Bytes.toString(CellUtil.cloneQualifier(cell))+&quot; &quot;);\n        System.out.print(Bytes.toString(CellUtil.cloneRow(cell))+&quot; &quot;);\n        System.out.println(Bytes.toString(CellUtil.cloneValue(cell)));\n    }\n}</code></pre><p><strong>hbase的demo</strong></p>\n<pre><code>package com.chen;\n\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.hbase.*;\nimport org.apache.hadoop.hbase.client.*;\nimport org.apache.hadoop.hbase.util.Bytes;\n\nimport java.io.IOException;\nimport java.util.ArrayList;\nimport java.util.List;\n\npublic class App {\n    static Admin admin = null;\n    static Connection connection = null;\n\n    /**\n     * 静态初始化\n     */\n    static {\n        Configuration configuration = HBaseConfiguration.create();\n        try {\n            connection = ConnectionFactory.createConnection(configuration);\n            admin = connection.getAdmin();\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n\n    /**\n     * 判断表是否存在\n     * @param tableName\n     * @return\n     * @throws Exception\n     */\n    public static boolean isExist(String tableName) throws Exception {\n        return admin.tableExists(TableName.valueOf(tableName));\n    }\n\n    /**\n     * 创建表\n     * @param tableName\n     * @param column\n     * @throws Exception\n     */\n    public static void createTable(String tableName,String ... column) throws Exception {\n        if(isExist(tableName)){\n            System.out.println(tableName+&quot;已经存在&quot;);\n            return;\n        }\n        HTableDescriptor tableDescriptor = new HTableDescriptor(TableName.valueOf(tableName));\n        for (String c : column) {\n            HColumnDescriptor hColumnDescriptor = new HColumnDescriptor(c);\n            tableDescriptor.addFamily(hColumnDescriptor);\n        }\n        admin.createTable(tableDescriptor);\n        System.out.println(tableName+&quot;创建成功&quot;);\n        getAllTable();\n    }\n\n    /**\n     * 删除表\n     * @param tableName\n     * @throws Exception\n     */\n    public static void deleteTable(String tableName) throws Exception {\n        if(isExist(tableName)){\n            admin.disableTable(TableName.valueOf(tableName));\n            admin.deleteTable(TableName.valueOf(tableName));\n        }\n        System.out.println(tableName+&quot;已被删除&quot;);\n        getAllTable();\n    }\n\n    /**\n     * 获取所有表\n     * @throws Exception\n     */\n    public static void getAllTable() throws Exception {\n        TableName[] tableNames = admin.listTableNames();\n        for (TableName tableName : tableNames) {\n            System.out.println(Bytes.toString(tableName.getName()));\n        }\n    }\n\n\n    /**\n     * 添加一行数据\n     * @param tableName\n     * @param rowkey\n     * @param cf\n     * @param column\n     * @param val\n     * @throws Exception\n     */\n    public static void add1Row(String tableName,String rowkey,String cf,String column,String val) throws Exception {\n        Table table = connection.getTable(TableName.valueOf(tableName));\n        Put put = new Put(Bytes.toBytes(rowkey));\n        put.addColumn(Bytes.toBytes(cf),Bytes.toBytes(column),Bytes.toBytes(val));\n        table.put(put);\n    }\n\n\n    /**\n     * 删除一行数据\n     * @param tableName\n     * @param rowkey\n     * @throws Exception\n     */\n    public static void del1Row(String tableName,String rowkey) throws Exception {\n        Table table = connection.getTable(TableName.valueOf(tableName));\n        Delete delete = new Delete(Bytes.toBytes(rowkey));\n        table.delete(delete);\n    }\n\n    /**\n     * 删除多行数据\n     * @param tableName\n     * @param rowkeys\n     * @throws Exception\n     */\n    public static void delMulRow(String tableName,String... rowkeys) throws Exception {\n        Table table = connection.getTable(TableName.valueOf(tableName));\n        List&amp;lt;Delete&amp;gt; deletes = new ArrayList&amp;lt;Delete&amp;gt;();\n        for (String rowkey : rowkeys) {\n            Delete delete = new Delete(Bytes.toBytes(rowkey));\n            deletes.add(delete);\n        }\n        table.delete(deletes);\n    }\n\n    /**\n     * 获取多行数据\n     * @param tableName\n     * @throws Exception\n     */\n    public static void getAllrows(String tableName) throws Exception {\n        Table table = connection.getTable(TableName.valueOf(tableName));\n        Scan scan = new Scan();\n        scan.setMaxVersions();\n        ResultScanner resultScanner = table.getScanner(scan);\n        for (Result result : resultScanner) {\n            Cell[] cells = result.rawCells();\n            for (Cell cell : cells) {\n                System.out.print(Bytes.toString(CellUtil.cloneFamily(cell))+&quot; &quot;);\n                System.out.print(Bytes.toString(CellUtil.cloneQualifier(cell))+&quot; &quot;);\n                System.out.print(Bytes.toString(CellUtil.cloneRow(cell))+&quot; &quot;);\n                System.out.println(Bytes.toString(CellUtil.cloneValue(cell)));\n            }\n        }\n    }\n\n    public static void main(String[] args) throws Exception {\n        /*String table=&quot;t3&quot;;\n        System.out.println(isExist(table));*/\n        //createTable(&quot;test1&quot;,&quot;info&quot;,&quot;extra&quot;);\n        //deleteTable(&quot;test1&quot;);\n        add1Row(&quot;test1&quot;,&quot;r2&quot;,&quot;extra&quot;,&quot;age&quot;,&quot;11&quot;);\n        //del1Row(&quot;test1&quot;,&quot;r1&quot;);\n        getAllrows(&quot;test1&quot;);\n    }\n}\n</code></pre><h1 id=\"flume\"><a href=\"#flume\" class=\"headerlink\" title=\"flume\"></a>flume</h1><h2 id=\"一-flume的搭建\"><a href=\"#一-flume的搭建\" class=\"headerlink\" title=\"一.flume的搭建\"></a>一.flume的搭建</h2><p>1.将在qq939598604的百度网盘中的路径，我的软件/apache-flume-1.8.0-bin.tar.gz下载并上传到/soft/elk目录下<br>2.解压</p>\n<pre><code>cd /soft/elk\ntar –zxvf apache-flume-1.8.0-bin.tar.gz</code></pre><p>3.配置java_home<br>cp flume-env.sh.template flume-env.sh<br>vim flume-env.sh</p>\n<pre><code>export JAVA_HOME=/soft/jdk1.8.0_161</code></pre><p>4.编辑配置文件<br>vim  spool1.conf </p>\n<pre><code>a1.sources = r1\na1.sinks = k1\na1.channels = c1\n\n# Describe/configure the source\na1.sources.r1.type = netcat\na1.sources.r1.bind = localhost\na1.sources.r1.port = 44444\n\n# Describe the sink\na1.sinks.k1.type = logger\n\n# Use a channel which buffers events in memory\na1.channels.c1.type = memory\na1.channels.c1.capacity = 1000\na1.channels.c1.transactionCapacity = 100\n\n# Bind the source and sink to the channel\na1.sources.r1.channels = c1\na1.sinks.k1.channel = c1</code></pre><p>5.启动flume</p>\n<pre><code>/soft/elk/apache-flume-1.8.0-bin/bin/flume-ng agent -c /soft/elk/apache-flume-1.8.0-bin/conf -f /soft/elk/apache-flume-1.8.0-bin/conf/spool1.conf --name a1 -Dflume.root.logger=INFO,console</code></pre><p>6.安装telnet工具</p>\n<pre><code>yum install telnet -y\ntelnet localhost 4444</code></pre><p>7.在telnet终端发送数据到flume中并查看是否有接收到</p>\n<h1 id=\"zookpeer\"><a href=\"#zookpeer\" class=\"headerlink\" title=\"zookpeer\"></a>zookpeer</h1><h2 id=\"一-Zookeeper集群搭建\"><a href=\"#一-Zookeeper集群搭建\" class=\"headerlink\" title=\"一.Zookeeper集群搭建\"></a>一.Zookeeper集群搭建</h2><p>（一）先把Java环境配好，三台机器，配置Zookeeper<br>（二）下载zookeeper-3.4.10.tar.gz，并且上传到/soft/目录下，直接解压zookeeper-3.4.10.tar.gz<br> tar -zxvf zookeeper-3.4.10.tar.gz<br>（三）修改配置文件名称</p>\n<pre><code>mv /soft/zookeeper-3.4.10/conf/zoo_simple.cfg /soft/zookeeper-3.4.10/conf/zoo.cfg</code></pre><p>（四）编辑配置文件</p>\n<pre><code>vim /soft/zookeeper-3.4.10/conf/zoo.cfg</code></pre><p>修改<strong>dataDir=/soft/zookeeper-3.4.10/data</strong><br>同时增加</p>\n<pre><code>server.1=192.168.197.231:2888:3888\nserver.2=192.168.197.232:2888:3888\nserver.3=192.168.197.233:2888:3888</code></pre><p><strong>server.X=A:B:C</strong>  X-代表服务器编号 A-代表ip  B和C-代表端口，这个端口用来系统之间通信</p>\n<p>（五）编辑配置myid文件</p>\n<p>vim /soft/zookeeper-3.4.10/data/myid<br>之后会产生一个新文件，直接在里面写X即可，比如我配置的三个server，当前服务器的ip是多少，myid里面写的X就是server.X=ip:2888:3888 中ip所对应的X</p>\n<pre><code>server.1=192.168.197.231:2888:3888【192.168.197.231服务器上面的myid填写1】\nserver.2=192.168.197.232:2888:3888【192.168.197.232服务器上面的myid填写2】\nserver.3=192.168.197.233:2888:3888【192.168.197.233服务器上面的myid填写3】</code></pre><p>（六）修改环境</p>\n<p>​    vim /etc/profile<br>　　在export PATH语句前添加两行：</p>\n<pre><code>ZOOKEEPER=/soft/zookeeper-3.4.10\nPATH=PATH:ZOOKEEPER/bin</code></pre><p>（六）并执行 source /etc/profile<br>（七）启动zookeeper<br>分别在3台机器启动 zookeeper</p>\n<h1 id=\"kafka\"><a href=\"#kafka\" class=\"headerlink\" title=\"kafka\"></a>kafka</h1><h2 id=\"一-认识\"><a href=\"#一-认识\" class=\"headerlink\" title=\"一.认识\"></a>一.认识</h2><p><strong>首先几个概念：</strong></p>\n<ol>\n<li><strong>kafka作为一个集群运</strong>行在一个或多个服务器上。</li>\n<li>kafka集群存储的消息是以topic为类别记录的。</li>\n<li>每个消息（也叫记录record，我习惯叫消息）是由一个key，一个value和时间戳构成。</li>\n<li>kafka是基于点对点的拉取（pull）模式（看到尚硅谷视频讲到，便记下来）</li>\n</ol>\n<p><strong>kafka有四个核心API：</strong></p>\n<ul>\n<li><p>应用程序使用 <code>Producer API</code> 发布消息到1个或多个topic（主题）。</p>\n</li>\n<li><p>应用程序使用 <code>Consumer API</code> 来订阅一个或多个topic，并处理产生的消息。</p>\n</li>\n<li><p>应用程序使用 <code>Streams API</code> 充当一个流处理器，从1个或多个topic消费输入流，并生产一个输出流到1个或多个输出topic，有效地将输入流转换到输出流。</p>\n</li>\n<li><p><code>Connector API</code>允许构建或运行可重复使用的生产者或消费者，将topic连接到现有的应用程序或数据系统。例如，一个关系数据库的连接器可捕获每一个变化。</p>\n<p><img src=\"C:%5CUsers%5CAdministrator%5CDesktop%5CMd%E7%AC%94%E8%AE%B0%5Cpic%5Cproduct.png\" alt=\"1565660315040\"></p>\n</li>\n</ul>\n<p><strong>基本术语：</strong></p>\n<p><strong>Topic</strong></p>\n<p>Kafka将消息种子(Feed)分门别类，每一类的消息称之为一个主题(Topic).</p>\n<ul>\n<li><p>Topic是Kafka数据写入操作的基本单元，可以指定副本</p>\n</li>\n<li><p>一个Topic包含一个或多个Partition，建Topic时可手动指定Partition个数，个数必须少于服务器个数</p>\n</li>\n<li><p>每条消息属于且仅属于一个Topic</p>\n</li>\n<li><p>Producer发布数据时，必须指定将该消息发布到哪个Topic</p>\n</li>\n<li><p>Consumer订阅消息时，也必须指定订阅哪个Topic的信息</p>\n<p><strong>Partition</strong></p>\n</li>\n<li><p>每个Partition只会在一个Broker上，物理上每个Partition对应的是一个文件夹</p>\n</li>\n<li><p>Kafka默认使用的是hash进行分区，所以会出现不同的分区数据不一样的情况，但是partitioner是可以override的</p>\n</li>\n<li><p>Partition包含多个Segment，每个Segment对应一个文件，Segment可以手动指定大小，当Segment达到阈值时，将不再写数据，每个Segment都是大小相同的</p>\n</li>\n<li><p>Segment由多个不可变的记录组成，记录只会被append到Segment中，不会被单独删除或者修改，每个Segment中的Message数量不一定相等</p>\n<p><strong>Producer</strong></p>\n</li>\n</ul>\n<p>发布消息的对象称之为主题生产者(Kafka topic producer)，写数据只会找leader</p>\n<p><strong>Consumer</strong></p>\n<p>订阅消息并处理发布的消息的对象称之为主题消费者(consumers)</p>\n<p> <strong>Broker</strong></p>\n<p>已发布的消息保存在一组服务器中，称之为Kafka集群。集群中的每一个服务器都是一个代理(Broker). 消费者可以订阅一个或多个主题（topic），并从Broker拉数据，从而消费这些已发布的消息。</p>\n<p> <strong>主题</strong></p>\n<p> Topic是发布的消息的类别或者种子Feed名。对于每一个Topic，Kafka集群维护这一个分区的log，就像下图中的示例： </p>\n<p><img src=\"C:%5CUsers%5CAdministrator%5CDesktop%5CMd%E7%AC%94%E8%AE%B0%5Cpic%5C1565660685648.png\" alt=\"1565660685648\"></p>\n<p> 每一个分区都是一个顺序的、不可变的消息队列， 并且可以持续的添加。分区中的消息都被分了一个序列号，称之为偏移量(offset)，在每个分区中此偏移量都是唯一的。 </p>\n<p>Kafka集群保持所有的消息，直到它们过期， 无论消息是否被消费了。 实际上消费者所持有的仅有的元数据就是这个偏移量，也就是消费者在这个log中的位置。 这个偏移量由消费者控制：正常情况当消费者消费消息的时候，偏移量也线性的的增加。但是实际偏移量由消费者控制，消费者可以将偏移量重置为更老的一个偏移量，重新读取消息。 可以看到这种设计对消费者来说操作自如， 一个消费者的操作不会影响其它消费者对此log的处理。 再说说分区。Kafka中采用分区的设计有几个目的。一是可以处理更多的消息，不受单台服务器的限制。Topic拥有多个分区意味着它可以不受限的处理更多的数据。第二，分区可以作为并行处理的单元，稍后会谈到这一点。</p>\n<p>kafka存储数据有2个地方：broker里面的patition下的log文件，broker的存储策略是文件的大小和存储时间，zookpeer里面的元数据</p>\n<h2 id=\"二-window安装kafka\"><a href=\"#二-window安装kafka\" class=\"headerlink\" title=\"二.window安装kafka\"></a>二.window安装kafka</h2><p><strong>（一）zookeeper在Windows下的安装</strong></p>\n<p>1.把下载的zookeeper的文件解压到指定目录：D:\\zookeeper-3.4.14</p>\n<p>2.复制conf目录下的zoo_sample.cfg文件为zoo.cfg</p>\n<p>3.修改内容如下：</p>\n<pre><code>dataDir=D:\\data\\zookeeper</code></pre><p>4.进入到bin目录，双击启动zkServer.cmd</p>\n<p>5.启动后jps可以看到QuorumPeerMain的进程</p>\n<pre><code>D:\\zookeeper-3.4.14\\bin &gt;jps</code></pre><p>6.启动客户端运行查看一下</p>\n<pre><code>D:\\zookeeper-3.4.14\\bin&gt;zkCli.cmd -server 127.0.0.1:2181</code></pre><p><strong>（二）kafka在Windows下的安装</strong></p>\n<p>1.下载kafka</p>\n<p>下载kafka，必须scala的版本对应kafka_2.11-2.3.0，其中前面的是2.12是scala的 版本号</p>\n<p><a href=\"https://www.apache.org/dyn/closer.cgi?path=/kafka/2.3.0/kafka_2.11-2.3.0.tgz\" target=\"_blank\" rel=\"noopener\">https://www.apache.org/dyn/closer.cgi?path=/kafka/2.3.0/kafka_2.11-2.3.0.tgz</a></p>\n<p>2.解压文件（我的目录是D:\\kafka_2.11-2.3.0  【这里不要在Program Files等文件名之间有空格的目录下，不然一会执行会不识别路径】）</p>\n<p>3.修改D:\\kafka_2.11-2.3.0\\config下server.properties文件</p>\n<pre><code>log.dirs=D:\\kafka_2.11-2.3.0\\kafka-logs\nbroker.id=0\nport=9092\nzookeeper.connect=localhost:2181</code></pre><p>4.进入kafka文件目录D:\\kafka_2.11-2.3.0，执行以下命令，启动kafka通讯的服务器broker</p>\n<pre><code>.\\bin\\windows\\kafka-server-start.bat .\\config\\server.properties</code></pre><p>5.进入kafka文件目录D:\\kafka_2.11-2.3.0\\bin\\windows，创建kafka的消息topics</p>\n<pre><code>kafka-topics.bat --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test</code></pre><p> 6.分别打开两个cmd窗口，进入目录D:\\kafka_2.11-2.3.0\\bin\\windows，创建Producer和Consumer</p>\n<p>（1）Producer</p>\n<p>进入目录D:\\kafka_2.11-2.3.0\\bin\\windows输入如下命令</p>\n<pre><code>kafka-console-producer.bat --broker-list localhost:9092 --topic test</code></pre><p>（2）Consumer</p>\n<p>进入目录D:\\kafka_2.11-2.3.0\\bin\\windows输入如下命令</p>\n<pre><code>kafka-console-consumer.bat --zookeeper localhost:2181 --topic testDemo</code></pre><p>然后就可以在Producer中发信息，在Consumer中收信息了</p>\n<p><strong>（三）kafka集群在Windows下的安装</strong></p>\n<p>1.复制上面的kafka单机版文件夹</p>\n<p>修改文件名为：kafka_2.11-2.3.0–1和 kafka_2.11-2.3.0–2</p>\n<p><img src=\"C:%5CUsers%5CAdministrator%5CDesktop%5CMd%E7%AC%94%E8%AE%B0%5Cpic%5C1565773682533.png\" alt=\"1565773682533\"></p>\n<p>2.修改D:\\kafka_2.11-2.3.0–1\\config下server.properties文件</p>\n<pre><code>log.dirs=D:\\kafka_2.11-2.3.0--1\\kafka-logs\nbroker.id=1\nport=9093\nzookeeper.connect=localhost:2181</code></pre><p>3.修改D:\\kafka_2.11-2.3.0–2\\config下server.properties文件</p>\n<pre><code>log.dirs=D:\\kafka_2.11-2.3.0--2\\kafka-logs\nbroker.id=2\nport=9094\nzookeeper.connect=localhost:2181</code></pre><p>4.分别进入kafka文件目录D:\\kafka_2.11-2.3.0和kafka_2.11-2.3.0–1和 kafka_2.11-2.3.0–2三个文件夹，执行以下命令，启动kafka通讯的服务器broker</p>\n<pre><code>.\\bin\\windows\\kafka-server-start.bat .\\config\\server.properties</code></pre><p>  5.查看kafka集群中所有broker节点</p>\n<p>broker的配置文件中有zookeeper的地址,也有自己的broker ID </p>\n<p>当broker启动后,会在zookeeper中新建一个znode,访问zk并执行ls /brokers/ids 就可以看到zk中存的所有的broker id list，然后确认你增加的broker的ID是否在list里面 </p>\n<pre><code>D:\\zookeeper-3.4.14\\bin&gt;zkCli.cmd -server 127.0.0.1:2181\n[zk: 127.0.0.1:2181(CONNECTED) 2] ls /\n[cluster, controller_epoch, controller, brokers, zookeeper, admin, isr_change_no\ntification, consumers, log_dir_event_notification, latest_producer_id_block, config]\n[zk: 127.0.0.1:2181(CONNECTED) 3] ls /brokers\n[ids, topics, seqid]\n[zk: 127.0.0.1:2181(CONNECTED) 4] ls /brokers/ids\n[0, 1, 2]</code></pre><p>上面可以看到/brokers/ids有[0, 1, 2]，说明是一个集群了</p>\n<p>6.windows下kafka集群的批处理启动脚本</p>\n<pre><code>start d:\\windows_install\\zookeeper-3.4.14\\bin\\zkServer.cmd\nstart d:\\windows_install\\kafka_2.11-2.3.0\\bin\\windows\\kafka-server-start.bat d:\\windows_install\\kafka_2.11-2.3.0\\config\\server.properties\nstart d:\\windows_install\\kafka_2.11-2.3.0--1\\bin\\windows\\kafka-server-start.bat d:\\windows_install\\kafka_2.11-2.3.0--1\\config\\server.properties\nstart d:\\windows_install\\kafka_2.11-2.3.0--2\\bin\\windows\\kafka-server-start.bat d:\\windows_install\\kafka_2.11-2.3.0--2\\config\\server.properties</code></pre><h2 id=\"三-消费者组案例测试\"><a href=\"#三-消费者组案例测试\" class=\"headerlink\" title=\"三.消费者组案例测试\"></a>三.<strong>消费者组案例测试</strong></h2><p><strong>案例一</strong></p>\n<p>生产者：如果topicA只有一个patition，即patition0，启动一个生产者实例</p>\n<p>消费者组中有A和B，其中消费者A先启动，A会绑定topicA中的patition0，然后再启动消费者B，启动的时候会提示，没有patition被绑定，则topicA中的生产数据的时候只有消费者A消费。</p>\n<p><strong>案例二</strong></p>\n<p>在前面的kafka集群3台机器中，连接测试192.168.197.30测试，以下测试是在windows的D:\\windows_install\\kafka_2.11-2.3.0\\bin\\windows&gt;目录下进行</p>\n<p>1.新建一个topic，指定复制因子为3，分区为3</p>\n<pre><code>kafka-topics.bat --create --zookeeper 192.168.197.30:2181 --replication-factor 3 --partitions 3 --topic test\nCreated topic test.</code></pre><p>2.启动一个生产者</p>\n<pre><code>kafka-console-producer.bat --broker-list 192.168.197.30:9092 --topic test</code></pre><p>3.启动消费者A，并指定组id为t</p>\n<pre><code>kafka-console-consumer.bat --bootstrap-server 192.168.197.30:9092 --topic test --group t</code></pre><p>4.启动消费者B，并指定组id为t</p>\n<pre><code>kafka-console-consumer.bat --bootstrap-server 192.168.197.30:9092 --topic test --group t</code></pre><p>5.在生产者端输入消息</p>\n<pre><code>D:\\windows_install\\kafka_2.11-2.3.0\\bin\\windows&gt;kafka-console-producer.bat --broker-list 192.168.197.30:9092 --topic test\n&gt;dafads\n&gt;sdfa\n&gt;fadsads\n&gt;dfads</code></pre><p>6.可以观察到，同个消费者组的消费者，消费消息只能由一个完成，并且只有一次</p>\n<p>消费者A获取到的消息如下：</p>\n<pre><code>D:\\windows_install\\kafka_2.11-2.3.0\\bin\\windows&gt;kafka-console-consumer.bat --botstrap-server 192.168.197.30:9092 --topic test --group t\ndafads\nfadsads</code></pre><p>消费者B获取到的消息如下：</p>\n<pre><code>D:\\windows_install\\kafka_2.11-2.3.0\\bin\\windows&gt;kafka-console-consumer.bat --bootstrap-server 192.168.197.30:9092 --topic test --group t\nsdfa\ndfads</code></pre><p><strong>同个消费者组的消费者，消费消息只能由一个完成，并且只有一次</strong></p>\n<h2 id=\"四-消费者连接集群只需一个broker\"><a href=\"#四-消费者连接集群只需一个broker\" class=\"headerlink\" title=\"四.消费者连接集群只需一个broker\"></a>四.消费者连接集群只需一个broker</h2><p>在前面的kafka集群3台机器中，连接测试192.168.197.30测试，以下测试是在windows的D:\\windows_install\\kafka_2.11-2.3.0\\bin\\windows&gt;目录下进行</p>\n<p>1.新建一个topic，指定复制因子为3，分区为3</p>\n<pre><code>kafka-topics.bat --create --zookeeper 192.168.197.30:2181 --replication-factor 3 --partitions 3 --topic test\nCreated topic test.</code></pre><p>2.启动一个生产者</p>\n<pre><code>kafka-console-producer.bat --broker-list 192.168.197.30:9092 --topic test</code></pre><p>3.启动消费者A，连接的bootstrap-server,参数指定为 <code>--bootstrap-server 192.168.197.30:9092</code>并指定组id为t</p>\n<pre><code>kafka-console-consumer.bat --bootstrap-server 192.168.197.30:9092 --topic test --group t</code></pre><p>4.启动消费者B，连接的bootstrap-server和消费者A不一样,参数指定为 <code>--bootstrap-server 192.168.197.30:9093</code>并指定组id为t</p>\n<pre><code>kafka-console-consumer.bat --bootstrap-server 192.168.197.30:9092 --topic test --group t</code></pre><p>5.在生产者端输入消息</p>\n<pre><code>D:\\windows_install\\kafka_2.11-2.3.0\\bin\\windows&gt;kafka-console-producer.bat --broker-list 192.168.197.30:9092 --topic test\n&gt;ghjhh67\n&gt;ljgty\n&gt;tyetw\n&gt;uioqw</code></pre><p>6.可以观察到，消费者连接集群只需一个broker，即可获取到整个集群的消息</p>\n<p>消费者A获取到的消息如下：</p>\n<pre><code>D:\\windows_install\\kafka_2.11-2.3.0\\bin\\windows&gt;kafka-console-consumer.bat --botstrap-server 192.168.197.30:9092 --topic test --group t\nghjhh67\ntyetw</code></pre><p>消费者B获取到的消息如下：</p>\n<pre><code>D:\\windows_install\\kafka_2.11-2.3.0\\bin\\windows&gt;kafka-console-consumer.bat --bootstrap-server 192.168.197.30:9093 --topic test --group t\nljgty\nuioqw</code></pre><p><strong>消费者连接集群只需一个broker，即可获取到整个集群的消息</strong></p>\n<h2 id=\"五-生产者的java版本代码编写\"><a href=\"#五-生产者的java版本代码编写\" class=\"headerlink\" title=\"五.生产者的java版本代码编写\"></a>五.生产者的java版本代码编写</h2><p><strong>(一)最简单的调用方式</strong></p>\n<p>1.新建一个MyProduce.java，发送消息到test的topic</p>\n<pre><code class=\"java\">public class MyProduce {\n    public static void main(String[] args) {\n        Properties props = new Properties();\n        props.put(&quot;bootstrap.servers&quot;,&quot;192.168.197.30:9092&quot;);\n        props.put(&quot;acks&quot;,&quot;all&quot;);\n        props.put(&quot;retries&quot;,0);\n        props.put(&quot;batch.size&quot;,16384);\n        props.put(&quot;linger.ms&quot;,1);\n        props.put(&quot;buffer.memory&quot;,33554432);\n        props.put(&quot;key.serializer&quot;,&quot;org.apache.kafka.common.serialization.StringSerializer&quot;);\n        props.put(&quot;value.serializer&quot;,&quot;org.apache.kafka.common.serialization.StringSerializer&quot;);\n        Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props);\n        for(int i=0;i&lt;10;i++){\n          producer.send(new ProducerRecord&lt;&gt;(&quot;test&quot;, Integer.toString(i), Integer.toString(i)));\n        }\n        producer.close();\n    }\n}</code></pre>\n<p><strong>(二)有回调的生产者</strong></p>\n<pre><code>package com.gzstrong.TestKafka;\n\nimport org.apache.kafka.clients.producer.*;\n\nimport java.util.Properties;\n\n/**\n * @author 陈锦华\n * @version V1.0\n * @Title:\n * @Description: create by Intellij Idea\n * @date 2019/8/15 0015 上午 9:08\n **/\npublic class MyProduce {\n    public static void main(String[] args) {\n        Properties props = new Properties();\n        props.put(&quot;bootstrap.servers&quot;,&quot;192.168.197.30:9092&quot;);\n        props.put(&quot;acks&quot;,&quot;all&quot;);\n        props.put(&quot;retries&quot;,0);\n        props.put(&quot;batch.size&quot;,16384);\n        props.put(&quot;linger.ms&quot;,1);\n        props.put(&quot;buffer.memory&quot;,33554432);\n        props.put(&quot;key.serializer&quot;,&quot;org.apache.kafka.common.serialization.StringSerializer&quot;);\n        props.put(&quot;value.serializer&quot;,&quot;org.apache.kafka.common.serialization.StringSerializer&quot;);\n        Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props);\n        for(int i=0;i&lt;10;i++){\n            producer.send(new ProducerRecord&lt;&gt;(&quot;test&quot;, Integer.toString(i), Integer.toString(i)), new Callback() {\n                @Override\n                public void onCompletion(RecordMetadata metadata, Exception exception) {\n                    System.out.println(metadata.partition()+&quot;---&quot;+metadata.offset());\n                }\n            });\n\n        }\n        producer.close();\n    }\n}</code></pre><p><strong>(二)指定分区发送，且有回调的生产者</strong></p>\n<p>1.新建ProducePatition.java实现Partitioner接口</p>\n<pre><code>public class ProducePatition implements Partitioner {\n\n    @Override\n    public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {\n        return 0;\n    }\n\n    @Override\n    public void close() {\n\n    }\n\n    @Override\n    public void configure(Map&lt;String, ?&gt; configs) {\n\n    }\n}</code></pre><p>2.在生产者里面设置参数<code>props.put(&quot;partitioner.class&quot;,&quot;com.gzstrong.TestKafka.ProducePatition&quot;);</code></p>\n<pre><code>public class MyProduce {\n    public static void main(String[] args) {\n        Properties props = new Properties();\n        props.put(&quot;bootstrap.servers&quot;,&quot;192.168.197.30:9092&quot;);\n        props.put(&quot;acks&quot;,&quot;all&quot;);\n        props.put(&quot;retries&quot;,0);\n        props.put(&quot;batch.size&quot;,16384);\n        props.put(&quot;linger.ms&quot;,1);\n        props.put(&quot;buffer.memory&quot;,33554432);\n        props.put(&quot;partitioner.class&quot;,&quot;com.gzstrong.TestKafka.ProducePatition&quot;);\n        props.put(&quot;key.serializer&quot;,&quot;org.apache.kafka.common.serialization.StringSerializer&quot;);\n        props.put(&quot;value.serializer&quot;,&quot;org.apache.kafka.common.serialization.StringSerializer&quot;);\n        Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props);\n        for(int i=0;i&lt;10;i++){\n            producer.send(new ProducerRecord&lt;&gt;(&quot;test&quot;, Integer.toString(i), Integer.toString(i)), (metadata, exception) -&gt; System.out.println(metadata.partition()+&quot;---&quot;+metadata.offset()));\n        }\n        producer.close();\n    }\n}</code></pre><h2 id=\"六-消费者java编码\"><a href=\"#六-消费者java编码\" class=\"headerlink\" title=\"六.消费者java编码\"></a>六.消费者java编码</h2><p>（一）高级消费者</p>\n<pre><code>public class MyComSumer {\n    public static void main(String[] args){\n        Properties props = new Properties();\n        props.put(&quot;bootstrap.servers&quot;, &quot;192.168.197.30:9092&quot;);\n        props.put(&quot;group.id&quot;, &quot;test&quot;);\n        props.put(&quot;enable.auto.commit&quot;, &quot;false&quot;);\n        props.put(&quot;auto.commit.interval.ms&quot;, &quot;1000&quot;);\n        props.put(&quot;session.timeout.ms&quot;, &quot;30000&quot;);\n        props.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);\n        props.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);\n        KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(props);\n        consumer.subscribe(Arrays.asList(&quot;test&quot;, &quot;bar&quot;));\n        final int minBatchSize = 200;\n        List&lt;ConsumerRecord&lt;String, String&gt;&gt; buffer = new ArrayList&lt;&gt;();\n        while (true) {\n            ConsumerRecords&lt;String, String&gt; records = consumer.poll(100);\n            for (ConsumerRecord&lt;String, String&gt; record : records) {\n                System.out.println(&quot;offset:&quot;+record.offset()+&quot; partition: &quot;+record.partition()+&quot; record: &quot;+ record);\n            }\n        }\n    }\n}</code></pre><h1 id=\"spark\"><a href=\"#spark\" class=\"headerlink\" title=\"spark\"></a>spark</h1><h2 id=\"一-spark集群搭建\"><a href=\"#一-spark集群搭建\" class=\"headerlink\" title=\"一.spark集群搭建\"></a>一.spark集群搭建</h2><p><strong>（一）.安装基础环境（JAVA和SCALA环境）</strong></p>\n<p><strong>1.安装JDK</strong></p>\n<p>(1)下载jdk1.8.0_161<br>(2)在/etc/profile中添加如下配置<br> vim /etc/profile</p>\n<pre><code>    export JAVA_HOME=/soft/jdk1.8.0_161\n    export JRE_HOME=${JAVA_HOME}/jre\n    export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib\n    export PATH=${JAVA_HOME}/bin:$PATH</code></pre><p>(3)使环境变量生效，source /etc/profile<br>(4)安装验证# java -version </p>\n<p><strong>2.安装SCALA</strong></p>\n<p>(1)到<a href=\"http://www.scala-lang.org/download/2.11.8.html下载scala2.11.8.tar.gz\" target=\"_blank\" rel=\"noopener\">http://www.scala-lang.org/download/2.11.8.html下载scala2.11.8.tar.gz</a><br>将下载的文件上传到/soft目录下</p>\n<pre><code>tar -zxvf /soft/scala-2.11.8.tgz -C /soft/</code></pre><p>(2)在/etc/profile中添加如下配置<br>  vim /etc/profile</p>\n<pre><code>  export SCALA_HOME=/soft/scala-2.11.8\n  export PATH=$SCALA_HOME/bin:$PATH</code></pre><p>(3)使环境变量生效，source /etc/profile<br>(4)安装验证# java -version </p>\n<p><strong>（二）Hadoop2.7.4完全分布式搭建</strong></p>\n<p>*<em>（三）Spark2.1.0完全分布式环境搭建 *</em></p>\n<p>以下操作都在Master节点进行。<br>1.下载二进制包spark-2.1.0-bin-hadoop2.7.tgz<br>2.解压并移动到相应目录，命令如下：</p>\n<pre><code>tar -zxvf spark-2.2.1-bin-hadoop2.7.tgz -C /soft/</code></pre><p>3.修改相应的配置文件。<br>　　在/etc/profile中添加如下配置<br>          vim /etc/profile</p>\n<pre><code>  export SPARK_HOME=/soft/spark-2.2.1-bin-hadoop2.7/\n  export PATH=$PATH:$SPARK_HOME/bin</code></pre><pre><code>使环境变量生效，source /etc/profile</code></pre><p>4.复制spark-env.sh.template成spark-env.sh<br>　  　cp /soft/spark-2.2.1-bin-hadoop2.7/conf/spark-env.sh.template /soft/spark-2.2.1-bin-        hadoop2.7/conf/spark-env.sh<br>5.修改$SPARK_HOME/conf/spark-env.sh，添加如下内容：</p>\n<pre><code>export JAVA_HOME=/soft/jdk1.8.0_161/\nexport SCALA_HOME=/soft/scala-2.11.8\nexport HADOOP_HOME=/soft/hadoop-2.7.4\nexport HADOOP_CONF_DIR=/soft/hadoop-2.7.4/etc/hadoop\nexport SPARK_MASTER_IP=master\nexport SPARK_MASTER_HOST=master\nexport SPARK_WORKER_MEMORY=512m\nexport SPARK_HOME=/soft/spark-2.2.1-bin-hadoop2.7\nexport SPARK_DIST_CLASSPATH=$(/soft/hadoop-2.7.4/bin/hadoop classpath)</code></pre><p>6.复制slaves.template成slaves<br>7.cp /soft/spark-2.2.1-bin-hadoop2.7/conf/slaves.template /soft/spark-2.2.1-bin-hadoop2.7/conf/slaves<br>8.修改$SPARK_HOME/conf/slaves，添加如下内容：</p>\n<pre><code>master\nslave1\nslave2</code></pre><p>9.将配置好的spark文件复制到Slave1和Slave2节点。<br>    scp /opt/spark-2.1.0-bin-hadoop2.7 root@Slave1:/opt<br>          scp /opt/spark-2.1.0-bin-hadoop2.7 root@Slave2:/opt<br>10.修改Slave1和Slave2配置。<br>　　在slave1和slave2上分别修改/etc/profile，增加Spark的配置，过程同Master一样。<br>　　在slave1和slave2修改$SPARK_HOME/conf/spark-env.sh，将export SPARK_LOCAL_IP=114.55.246.88改成slave1和slave2对应节点的IP。<br>11.在master节点启动集群。<br>　　/opt/spark-2.1.0-bin-hadoop2.7/sbin/start-all.sh<br>12.查看集群是否启动成功：<br>　　jps<br>　　master在Hadoop的基础上新增了：<br>　　master<br>　　slave在Hadoop的基础上新增了：<br>　　Worker</p>\n<h2 id=\"二-spark的maven项目构建（基于idea-和maven）\"><a href=\"#二-spark的maven项目构建（基于idea-和maven）\" class=\"headerlink\" title=\"二.spark的maven项目构建（基于idea 和maven）\"></a>二.spark的maven项目构建（基于idea 和maven）</h2><p>首先idea安装scala插件<br><img src=\"https://images.gitee.com/uploads/images/2019/0521/154430_f3a9b447_429848.png\" alt=\"输入图片说明\" title=\"QQ截图20190521154225.png\"></p>\n<p>新建一个maven项目<br>开始创建项目体系结构<br>File –&gt; Project<br><img src=\"https://static.oschina.net/uploads/img/201802/11153035_Ac2b.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"><br><img src=\"https://static.oschina.net/uploads/img/201802/11153132_Ijqk.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"><br><img src=\"https://static.oschina.net/uploads/img/201802/11153403_6Rrj.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"><br><img src=\"https://static.oschina.net/uploads/img/201802/11153427_h2XW.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"></p>\n<p>pom.xml</p>\n<pre><code>&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\n         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt;\n    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\n    &lt;groupId&gt;com.chen&lt;/groupId&gt;\n    &lt;artifactId&gt;Spark_Test&lt;/artifactId&gt;\n    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;\n    &lt;inceptionYear&gt;2008&lt;/inceptionYear&gt;\n    &lt;properties&gt;\n        &lt;scala.version&gt;2.11.0&lt;/scala.version&gt;\n        &lt;spark.version&gt;2.0.2&lt;/spark.version&gt;\n        &lt;scala&gt;2.11&lt;/scala&gt;\n    &lt;/properties&gt;\n\n    &lt;repositories&gt;\n        &lt;repository&gt;\n            &lt;id&gt;scala-tools.org&lt;/id&gt;\n            &lt;name&gt;Scala-Tools Maven2 Repository&lt;/name&gt;\n            &lt;url&gt;http://scala-tools.org/repo-releases&lt;/url&gt;\n        &lt;/repository&gt;\n    &lt;/repositories&gt;\n\n    &lt;pluginRepositories&gt;\n        &lt;pluginRepository&gt;\n            &lt;id&gt;scala-tools.org&lt;/id&gt;\n            &lt;name&gt;Scala-Tools Maven2 Repository&lt;/name&gt;\n            &lt;url&gt;http://scala-tools.org/repo-releases&lt;/url&gt;\n        &lt;/pluginRepository&gt;\n    &lt;/pluginRepositories&gt;\n\n    &lt;dependencies&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.scala-lang&lt;/groupId&gt;\n            &lt;artifactId&gt;scala-library&lt;/artifactId&gt;\n            &lt;version&gt;${scala.version}&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;junit&lt;/groupId&gt;\n            &lt;artifactId&gt;junit&lt;/artifactId&gt;\n            &lt;version&gt;4.4&lt;/version&gt;\n            &lt;scope&gt;test&lt;/scope&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.specs&lt;/groupId&gt;\n            &lt;artifactId&gt;specs&lt;/artifactId&gt;\n            &lt;version&gt;1.2.5&lt;/version&gt;\n            &lt;scope&gt;test&lt;/scope&gt;\n        &lt;/dependency&gt;\n\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;\n            &lt;artifactId&gt;spark-core_${scala}&lt;/artifactId&gt;\n            &lt;version&gt;${spark.version}&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;\n            &lt;artifactId&gt;spark-streaming_${scala}&lt;/artifactId&gt;\n            &lt;version&gt;${spark.version}&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;\n            &lt;artifactId&gt;spark-sql_${scala}&lt;/artifactId&gt;\n            &lt;version&gt;${spark.version}&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;\n            &lt;artifactId&gt;spark-hive_${scala}&lt;/artifactId&gt;\n            &lt;version&gt;${spark.version}&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;\n            &lt;artifactId&gt;spark-mllib_${scala}&lt;/artifactId&gt;\n            &lt;version&gt;${spark.version}&lt;/version&gt;\n        &lt;/dependency&gt;\n    &lt;/dependencies&gt;\n\n    &lt;build&gt;\n        &lt;sourceDirectory&gt;src/main/scala&lt;/sourceDirectory&gt;\n        &lt;testSourceDirectory&gt;src/test/scala&lt;/testSourceDirectory&gt;\n        &lt;plugins&gt;\n            &lt;plugin&gt;\n                &lt;groupId&gt;org.scala-tools&lt;/groupId&gt;\n                &lt;artifactId&gt;maven-scala-plugin&lt;/artifactId&gt;\n                &lt;executions&gt;\n                    &lt;execution&gt;\n                        &lt;goals&gt;\n                            &lt;goal&gt;compile&lt;/goal&gt;\n                            &lt;goal&gt;testCompile&lt;/goal&gt;\n                        &lt;/goals&gt;\n                    &lt;/execution&gt;\n                &lt;/executions&gt;\n                &lt;configuration&gt;\n                    &lt;scalaVersion&gt;2.11&lt;/scalaVersion&gt;\n                    &lt;args&gt;\n                        &lt;arg&gt;-target:jvm-1.5&lt;/arg&gt;\n                    &lt;/args&gt;\n                &lt;/configuration&gt;\n            &lt;/plugin&gt;\n            &lt;plugin&gt;\n                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n                &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;\n                &lt;version&gt;2.19&lt;/version&gt;\n                &lt;configuration&gt;\n                    &lt;skip&gt;true&lt;/skip&gt;\n                &lt;/configuration&gt;\n            &lt;/plugin&gt;\n\n            &lt;plugin&gt;\n                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;\n                &lt;version&gt;3.6.0&lt;/version&gt;\n                &lt;configuration&gt;\n                    &lt;source&gt;1.8&lt;/source&gt;\n                    &lt;target&gt;1.8&lt;/target&gt;\n                    &lt;excludes&gt;\n                        &lt;exclude&gt;**/*.java&lt;/exclude&gt;\n                    &lt;/excludes&gt;\n                &lt;/configuration&gt;\n            &lt;/plugin&gt;\n            &lt;plugin&gt;\n                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n                &lt;artifactId&gt;maven-eclipse-plugin&lt;/artifactId&gt;\n                &lt;configuration&gt;\n                    &lt;downloadSources&gt;true&lt;/downloadSources&gt;\n                    &lt;buildcommands&gt;\n                        &lt;buildcommand&gt;ch.epfl.lamp.sdt.core.scalabuilder&lt;/buildcommand&gt;\n                    &lt;/buildcommands&gt;\n                    &lt;additionalProjectnatures&gt;\n                        &lt;projectnature&gt;ch.epfl.lamp.sdt.core.scalanature&lt;/projectnature&gt;\n                    &lt;/additionalProjectnatures&gt;\n                    &lt;classpathContainers&gt;\n                        &lt;classpathContainer&gt;org.eclipse.jdt.launching.JRE_CONTAINER&lt;/classpathContainer&gt;\n                        &lt;classpathContainer&gt;ch.epfl.lamp.sdt.launching.SCALA_CONTAINER&lt;/classpathContainer&gt;\n                    &lt;/classpathContainers&gt;\n                &lt;/configuration&gt;\n            &lt;/plugin&gt;\n        &lt;/plugins&gt;\n    &lt;/build&gt;\n    &lt;reporting&gt;\n        &lt;plugins&gt;\n            &lt;plugin&gt;\n                &lt;groupId&gt;org.scala-tools&lt;/groupId&gt;\n                &lt;artifactId&gt;maven-scala-plugin&lt;/artifactId&gt;\n                &lt;configuration&gt;\n                    &lt;scalaVersion&gt;${scala.version}&lt;/scalaVersion&gt;\n                &lt;/configuration&gt;\n            &lt;/plugin&gt;\n        &lt;/plugins&gt;\n    &lt;/reporting&gt;\n&lt;/project&gt;\n</code></pre><p>目录结构如下:<br><img src=\"https://static.oschina.net/uploads/img/201803/29141709_MjWs.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"><br>在src的main目录下新建java和scala文件夹<br><img src=\"https://static.oschina.net/uploads/img/201803/29142045_fhmF.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"><br>同时修改java和scala文件夹为源码文件夹<br><img src=\"https://static.oschina.net/uploads/img/201803/29142301_rELw.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"><br><img src=\"https://static.oschina.net/uploads/img/201803/29142317_bdXa.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"><br>在src的test目录下新建java和scala文件夹<br><img src=\"https://static.oschina.net/uploads/img/201803/29142115_RNRo.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"><br>同时修改java和scala文件夹为测试文件夹<br><img src=\"https://static.oschina.net/uploads/img/201803/29142409_KwUu.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"></p>\n<p>然后设置scal为项目的sdk</p>\n<h2 id=\"三-spark的java7代码编写\"><a href=\"#三-spark的java7代码编写\" class=\"headerlink\" title=\"三.spark的java7代码编写\"></a>三.spark的java7代码编写</h2><p>新建package名称为<br><img src=\"https://static.oschina.net/uploads/img/201803/29142627_StWH.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"><br>新建Java7WordCount.java的文件</p>\n<p>Java7WordCount.java</p>\n<pre><code>package com.chen;\n\nimport org.apache.spark.SparkConf;\nimport org.apache.spark.api.java.JavaPairRDD;\nimport org.apache.spark.api.java.JavaRDD;\nimport org.apache.spark.api.java.JavaSparkContext;\nimport org.apache.spark.api.java.function.FlatMapFunction;\nimport org.apache.spark.api.java.function.Function2;\nimport org.apache.spark.api.java.function.PairFunction;\nimport org.apache.spark.api.java.function.VoidFunction;\nimport scala.Tuple2;\n\nimport java.util.Arrays;\nimport java.util.Iterator;\n\n/**\n * @author 陈锦华\n * @version V1.0\n * @Title:\n * @Description: create by Intellij Idea\n * @date 2018/3/29 0029 上午 10:57\n **/\npublic class Java7WordCount {\n\n    /**\n     * 使用Java的方式开发进行本地测试Spark的WordCount程序\n     *\n     */\n        public static void main(String[] args) {\n            /**\n             * * setAppName：设置应用名字，此名字会在Spark web UI显示\n             * setMaster：设置主节点URL，本例使用“local”是指本机单线程，另外还有以下选项：\n             * local[K]：本机K线程\n             * local[*]：本机多线程，线程数与服务器核数相同\n             * spark://HOST:PORT：Spark集群地址和端口，默认端口为7077\n             * mesos://HOST:PORT：Mesos集群地址和端口，默认端口为5050\n             * yarn：YARN集群\n             * 第1步：创建Spark的配置对象SparkConf，设置Spark程序的运行时的配置信息，\n             * 例如说通过setMaster来设置程序要链接的Spark集群的Master的URL,如果设置\n             * 为local，则代表Spark程序在本地运行，特别适合于机器配置条件非常差（例如 只有1G的内存）的初学者 *\n             */\n            SparkConf conf = new SparkConf().setAppName(&quot;Spark WordCount written by Java&quot;).setMaster(&quot;local&quot;);\n            /**\n             * 第2步：创建SparkContext对象\n             * SparkContext是Spark程序所有功能的唯一入口，无论是采用Scala、Java、Python\n             * 、R等都必须有一个SparkContext(不同的语言具体的类名称不同，如果是Java的话则为JavaSparkContext)\n             * SparkContext核心作用：初始化Spark应用程序运行所需要的核心组件，包括DAGScheduler、TaskScheduler、\n             * SchedulerBackend 同时还会负责Spark程序往Master注册程序等\n             * SparkContext是整个Spark应用程序中最为至关重要的一个对象\n             */\n            JavaSparkContext sc = new JavaSparkContext(conf); // 其底层实际上就是Scala的SparkContext\n            /**\n             * 第3步：根据具体的数据来源（HDFS、HBase、Local FS、DB、S3等）通过JavaSparkContext来创建JavaRDD\n             * JavaRDD的创建基本有三种方式：根据外部的数据来源（例如HDFS）、根据Scala集合、由其它的RDD操作\n             * 数据会被RDD划分成为一系列的Partitions，分配到每个Partition的数据属于一个Task的处理范畴\n             * 注意：文件路径不能直接用Windows路径中的反斜扛\\，要改成Linux下的斜扛/\n             */\n            JavaRDD&lt;String&gt; lines = sc.textFile(&quot;C:\\\\offline_FtnInfo.txt&quot;);\n            /**\n             * 第4步：对初始的JavaRDD进行Transformation级别的处理，例如map、filter等高阶函数等的编程，来进行具体的数据计算\n             * 第4.1步：讲每一行的字符串拆分成单个的单词\n             */\n            JavaRDD&lt;String&gt; words = lines.flatMap(new FlatMapFunction&lt;String, String&gt;() {\n                        @Override\n                        public Iterator&lt;String&gt; call(String line) throws Exception {\n                            return Arrays.asList(line.split(&quot; &quot;)).iterator();\n                        }\n                    });\n            /**\n             * 第4步：对初始的JavaRDD进行Transformation级别的处理，例如map、filter等高阶函数等的编程，来进行具体的数据计算\n             * 第4.2步：在单词拆分的基础上对每个单词实例计数为1，也就是word =&gt; (word, 1)\n             */\n            JavaPairRDD&lt;String, Integer&gt; pairs = words.mapToPair(new PairFunction&lt;String, String, Integer&gt;() {\n                        public Tuple2&lt;String, Integer&gt; call(String word) throws Exception {\n                            return new Tuple2&lt;String, Integer&gt;(word, 1);\n                        }\n                    });\n            /**\n             * 第4步：对初始的RDD进行Transformation级别的处理，例如map、filter等高阶函数等的编程，来进行具体的数据计算\n             * 第4.3步：在每个单词实例计数为1基础之上统计每个单词在文件中出现的总次数\n             */\n            JavaPairRDD&lt;String, Integer&gt; wordsCount = pairs.reduceByKey(new Function2&lt;Integer, Integer, Integer&gt;() { // 对相同的Key，进行Value的累计（包括Local和Reducer级别同时Reduce）\n                        public Integer call(Integer v1, Integer v2) throws Exception {\n                            return v1 + v2;\n                        }\n                    });\n            wordsCount.foreach(new VoidFunction&lt;Tuple2&lt;String, Integer&gt;&gt;() {\n                public void call(Tuple2&lt;String, Integer&gt; pairs) throws Exception {\n                    System.out.println(pairs._1 + &quot; : &quot; + pairs._2);\n                }\n            });\n            sc.close();\n        }\n    }</code></pre><h2 id=\"四-spark的java8代码编写\"><a href=\"#四-spark的java8代码编写\" class=\"headerlink\" title=\"四.spark的java8代码编写\"></a>四.spark的java8代码编写</h2><p>新建package名称为com.chen</p>\n<p>新建Java8WordCount.java的文件</p>\n<p>Java8WordCount.java</p>\n<pre><code>package com.chen;\n\nimport org.apache.spark.SparkConf;\nimport org.apache.spark.api.java.JavaPairRDD;\nimport org.apache.spark.api.java.JavaRDD;\nimport org.apache.spark.api.java.JavaSparkContext;\nimport scala.Tuple2;\n\nimport java.util.Arrays;\nimport java.util.List;\n\n/**\n * @author 陈锦华\n * @version V1.0\n * @Title:\n * @Description: create by Intellij Idea\n * @date 2018/3/29 0029 上午 10:57\n **/\npublic class Java8WordCount {\n    /**\n     * 使用Java的方式开发进行本地测试Spark的WordCount程序\n     */\n    public static void main(String[] args) {\n        WordCount2();\n    }\n\n    public static void WordCount1(){\n        /**\n         * 第4步：对初始的JavaRDD进行Transformation级别的处理，例如map、filter等高阶函数等的编程，来进行具体的数据计算\n         * 第4.2步：在单词拆分的基础上对每个单词实例计数为1，也就是word =&gt; (word, 1)\n         * 第4步：对初始的RDD进行Transformation级别的处理，例如map、filter等高阶函数等的编程，来进行具体的数据计算\n         * 第4.3步：在每个单词实例计数为1基础之上统计每个单词在文件中出现的总次数\n         */\n        SparkConf conf = new SparkConf().setAppName(&quot;Spark WordCount written by Java&quot;).setMaster(&quot;local&quot;);\n        JavaSparkContext sc = new JavaSparkContext(conf); // 其底层实际上就是Scala的SparkContext\n        JavaRDD&lt;String&gt; lines = sc.textFile(&quot;C:\\\\offline_FtnInfo.txt&quot;);\n        JavaRDD&lt;String&gt; words = lines.flatMap((line) -&gt;Arrays.asList(line.split(&quot; &quot;)).iterator());\n        JavaPairRDD&lt;String, Integer&gt; pairs = words.mapToPair((word)-&gt;new Tuple2&lt;&gt;(word, 1));\n        JavaPairRDD&lt;String, Integer&gt; wordsCount = pairs.reduceByKey((Integer v1, Integer v2) -&gt;v1 + v2);\n        wordsCount.foreach((Tuple2&lt;String, Integer&gt; pair)-&gt;System.out.println(pair._1 + &quot; : &quot; + pair._2));\n        sc.close();\n    }\n\n    public static void WordCount2(){\n        SparkConf conf = new SparkConf().setAppName(&quot;Spark WordCount written by Java&quot;).setMaster(&quot;local&quot;);\n        JavaSparkContext sc = new JavaSparkContext(conf); // 其底层实际上就是Scala的SparkContext\n        JavaRDD&lt;String&gt; lines = sc.textFile(&quot;C:\\\\offline_FtnInfo.txt&quot;);\n        JavaRDD&lt;String&gt; words = lines.flatMap(line -&gt; Arrays.asList(line.split(&quot; &quot;)).iterator());\n        JavaPairRDD&lt;String, Integer&gt; counts = words.mapToPair(w -&gt; new Tuple2&lt;String, Integer&gt;(w, 1))\n            .reduceByKey((x, y) -&gt; x + y);\n        List&lt;Tuple2&lt;String, Integer&gt;&gt; output = counts.collect();\n            for (Tuple2&lt;?, ?&gt; tuple : output) {\n                System.out.println(tuple._1() + &quot;:== &quot; + tuple._2());\n            }\n        sc.close();\n    }\n}    </code></pre><h2 id=\"五-spark的scalar代码编写\"><a href=\"#五-spark的scalar代码编写\" class=\"headerlink\" title=\"五.spark的scalar代码编写\"></a>五.spark的scalar代码编写</h2><p>1.新建package名称为</p>\n<p>com.chen</p>\n<p>2.新建scalaWordCount.scala的文件</p>\n<p>scalaWordCount.scala</p>\n<pre><code>package com.chen\n\nimport org.apache.spark.{SparkConf, SparkContext}\n\n    object scalaWordCount{\n        def main(args: Array[String]) {\n            //setMaster(&quot;local&quot;) 本机的spark就用local，远端的就写ip\n            //如果是打成jar包运行则需要去掉 setMaster(&quot;local&quot;)因为在参数中会指定。\n            val conf = new SparkConf().setAppName(&quot;local Application&quot;).setMaster(&quot;local&quot;)\n            val sc = new SparkContext(conf)\n            val rdd = sc.textFile(&quot;C:\\\\offline_FtnInfo.txt&quot;)\n            val wordcount = rdd\n                    .flatMap(_.split(&quot; &quot;))\n                    .map((_,1))\n                    .reduceByKey(_ + _)\n                    .map(x =&gt; (x._2,x._1))\n                    .sortByKey(false)\n                    .map(x =&gt; (x._2,x._1)\n                )\n            wordcount.foreach(x=&gt;println(x._1+&quot;的数量是:&quot;+x._2))\n            sc.stop()\n        }\n    }</code></pre><h2 id=\"六-RDD\"><a href=\"#六-RDD\" class=\"headerlink\" title=\"六.RDD\"></a>六.RDD</h2><h3 id=\"（一）rdd的创建方式\"><a href=\"#（一）rdd的创建方式\" class=\"headerlink\" title=\"（一）rdd的创建方式\"></a>（一）rdd的创建方式</h3><p><strong>1.parallelize从集合创建</strong></p>\n<pre><code>var rdd = sc.parallelize(1 to 10)</code></pre><p><strong>2.makeRdd创建</strong></p>\n<pre><code>val seq = List((1, List(&quot;iteblog.com&quot;, &quot;sparkhost1.com&quot;, &quot;sparkhost2.com&quot;)),(2, List(&quot;iteblog.com&quot;, &quot;sparkhost2.com&quot;)))\nval rdd = sc.makeRDD(seq)</code></pre><p><strong>3.从外部存储创建RDD</strong></p>\n<pre><code>var rdd = sc.textFile(&quot;hdfs:///tmp/lxw1234/1.txt&quot;)</code></pre><p><strong>4.从其他HDFS文件格式创建</strong></p>\n<p>hadoopFile</p>\n<p>sequenceFile</p>\n<p>objectFile</p>\n<p>newAPIHadoopFile</p>\n<p>从Hadoop接口API创建</p>\n<p>hadoopRDD</p>\n<p>newAPIHadoopRDD</p>\n<p><strong>5.从HBase创建RDD</strong> </p>\n<pre><code class=\"scala\">import org.apache.hadoop.hbase.{HBaseConfiguration, HTableDescriptor, TableName}\nimport org.apache.hadoop.hbase.{HBaseConfiguration, HTableDescriptor, TableName}\nimport org.apache.hadoop.hbase.mapreduce.TableInputFormat\nimport org.apache.hadoop.hbase.mapreduce.TableInputFormat\nimport org.apache.hadoop.hbase.client.HBaseAdmin\nimport org.apache.hadoop.hbase.client.HBaseAdmin\nval conf = HBaseConfiguration.create()\nconf.set(TableInputFormat.INPUT_TABLE,&quot;lxw1234&quot;)\nvar hbaseRDD = sc.newAPIHadoopRDD(conf,classOf[org.apache.hadoop.hbase.mapreduce.TableInputFormat],classOf[org.apache.hadoop.hbase.io.ImmutableBytesWritable],classOf[org.apache.hadoop.hbase.client.Result])</code></pre>\n<h2 id=\"七-spark-Sql\"><a href=\"#七-spark-Sql\" class=\"headerlink\" title=\"七.spark Sql\"></a>七.spark Sql</h2><h3 id=\"（一）-spark-sql的join\"><a href=\"#（一）-spark-sql的join\" class=\"headerlink\" title=\"（一）.spark sql的join\"></a>（一）.spark sql的join</h3><p>1.spark直接传入List列表用createDataset方法进行创建dataset，然后转DataFrame</p>\n<pre><code>package com.chen\nimport org.apache.spark.sql.{DataFrame, Dataset, SparkSession}\n\nobject TestSpark{\n    def main(args: Array[String]): Unit = {\n        val spark: SparkSession = SparkSession.builder().master(&quot;local[*]&quot;).appName(&quot;sparkTest&quot;).getOrCreate()\n        import spark.implicits._\n        val lines: Dataset[(String)] = spark.createDataset(List(&quot;1,chenjinhua,cn&quot;,&quot;2,Lisi,usa&quot;,&quot;3,jony,usa&quot;))\n        val empDataset: Dataset[(String, String, String)] = lines.map(line =&gt; {\n            val field: Array[String] = line.split(&quot;,&quot;)\n            var id = field(0)\n            var empName = field(1)\n            var code = field(2)\n            (id, empName, code)\n        })\n        val empDataFrame: DataFrame = empDataset.toDF(&quot;id&quot;, &quot;empName&quot;, &quot;code&quot;)\n        empDataFrame.createTempView(&quot;emp&quot;)\n\n        val nations: Dataset[(String)] = spark.createDataset(List(&quot;cn,中国&quot;,&quot;usa,美国&quot;))\n        val nationDataset: Dataset[(String, String)] = nations.map(line =&gt; {\n            val field: Array[String] = line.split(&quot;,&quot;)\n            val code = field(0)\n            val name = field(1)\n            (code, name)\n        })\n        val nationDataFrame: DataFrame = nationDataset.toDF(&quot;code&quot;,&quot;name&quot;)\n        nationDataFrame.createTempView(&quot;nation&quot;)\n        val dframe: DataFrame = spark.sql(&quot;select * from emp left join nation on emp.code=nation.code&quot;)\n        dframe.show()\n        spark.stop()\n    }\n}</code></pre><p>执行之后展示结果如下</p>\n<pre><code>+---+----------+----+----+----+\n| id|   empName|code|code|name|\n+---+----------+----+----+----+\n|  1|chenjinhua|  cn|  cn|  中国|\n|  2|      Lisi| usa| usa|  美国|\n|  3|      jony| usa| usa|  美国|\n+---+----------+----+----+----+</code></pre><h3 id=\"（二）spark-Sql计算nginx的日志\"><a href=\"#（二）spark-Sql计算nginx的日志\" class=\"headerlink\" title=\"（二）spark Sql计算nginx的日志\"></a>（二）spark Sql计算nginx的日志</h3><p>1.access.log</p>\n<pre><code>192.168.197.50 - - [20/Dec/2018:15:46:15 +0800] &quot;GET /api/rep/scRepairBusHouse/datagrid?pageNum=1&amp;pageRow=10&amp;busHouseCode=&amp;orgId= HTTP/1.1&quot; 200 1745 &quot;http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg&quot; &quot;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36&quot;\n192.168.197.50 - - [20/Dec/2018:15:46:15 +0800] &quot;GET /api/sys/coreDepart/showCompsTreeByUser HTTP/1.1&quot; 200 809 &quot;http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg&quot; &quot;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36&quot;\n192.168.197.50 - - [20/Dec/2018:15:46:15 +0800] &quot;GET /api/sys/coreDepart/showCompsTreeByUser HTTP/1.1&quot; 200 809 &quot;http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg&quot; &quot;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36&quot;\n192.168.197.50 - - [20/Dec/2018:15:46:26 +0800] &quot;GET /api/rep/scRepairBusHouse/datagrid?pageNum=1&amp;pageRow=10&amp;busHouseCode=&amp;orgId=1 HTTP/1.1&quot; 200 1745 &quot;http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg&quot; &quot;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36&quot;\n192.168.197.50 - - [20/Dec/2018:15:46:28 +0800] &quot;GET /api/rep/scRepairBusHouse/datagrid?pageNum=1&amp;pageRow=10&amp;busHouseCode=&amp;orgId=6 HTTP/1.1&quot; 200 1340 &quot;http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg&quot; &quot;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36&quot;\n192.168.197.50 - - [20/Dec/2018:15:46:29 +0800] &quot;GET /api/rep/scRepairBusHouse/datagrid?pageNum=1&amp;pageRow=10&amp;busHouseCode=&amp;orgId=7 HTTP/1.1&quot; 200 483 &quot;http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg&quot; &quot;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36&quot;\n192.168.197.50 - - [20/Dec/2018:15:46:30 +0800] &quot;GET /api/rep/scRepairBusHouse/datagrid?pageNum=1&amp;pageRow=10&amp;busHouseCode=&amp;orgId=6 HTTP/1.1&quot; 200 1340 &quot;http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg&quot; &quot;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36&quot;\n192.168.197.50 - - [20/Dec/2018:15:46:30 +0800] &quot;GET /api/rep/scRepairBusHouse/datagrid?pageNum=1&amp;pageRow=10&amp;busHouseCode=&amp;orgId=1 HTTP/1.1&quot; 200 1745 &quot;http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg&quot; &quot;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36&quot;\n192.168.197.145 - - [20/Dec/2018:15:46:30 +0800] &quot;GET /static/js/13.c5de91a3a5351c406417.js HTTP/1.1&quot; 304 0 &quot;http://192.168.197.28:9090/&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299&quot;\n192.168.197.145 - - [20/Dec/2018:15:46:31 +0800] &quot;GET /api/rep/scRepairFixPlace/datagrid?pageNum=1&amp;pageRow=10&amp;positionCode=&amp;orgId= HTTP/1.1&quot; 200 1559 &quot;http://192.168.197.28:9090/&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299&quot;\n192.168.197.145 - - [20/Dec/2018:15:46:31 +0800] &quot;GET /api/sys/coreDepart/showCompsTreeByUser HTTP/1.1&quot; 200 809 &quot;http://192.168.197.28:9090/&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299&quot;\n192.168.197.145 - - [20/Dec/2018:15:46:31 +0800] &quot;GET /api/sys/coreDepart/showCompsTreeByUser HTTP/1.1&quot; 200 809 &quot;http://192.168.197.28:9090/&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299&quot;\n192.168.197.50 - - [20/Dec/2018:15:46:31 +0800] &quot;GET /api/rep/scRepairBusHouse/datagrid?pageNum=1&amp;pageRow=10&amp;busHouseCode=&amp;orgId=1 HTTP/1.1&quot; 200 1745 &quot;http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg&quot; &quot;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36&quot;\n192.168.197.145 - - [20/Dec/2018:15:46:33 +0800] &quot;GET /api/rep/scRepairFixitemInfo/datagrid?pageNum=1&amp;pageRow=10&amp;lineCode=&amp;fixItemTypeId= HTTP/1.1&quot; 200 906 &quot;http://192.168.197.28:9090/&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299&quot;\n192.168.197.145 - - [20/Dec/2018:15:46:33 +0800] &quot;GET /api/rep/scRepairFixitemType/datagrid?fixItemTypeCode= HTTP/1.1&quot; 200 861 &quot;http://192.168.197.28:9090/&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299&quot;\n192.168.197.145 - - [20/Dec/2018:15:46:33 +0800] &quot;GET /api/rep/scRepairFixitemType/selectTreeData HTTP/1.1&quot; 200 861 &quot;http://192.168.197.28:9090/&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299&quot;\n192.168.197.145 - - [20/Dec/2018:15:46:34 +0800] &quot;GET /api/rep/scRepairFaultInfo/datagrid?pageNum=1&amp;pageRow=10&amp;lineCode=&amp;faultTypeId= HTTP/1.1&quot; 200 816 &quot;http://192.168.197.28:9090/&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299&quot;\n192.168.197.145 - - [20/Dec/2018:15:46:34 +0800] &quot;GET /api/rep/scRepairFaultType/selectTreeData HTTP/1.1&quot; 200 992 &quot;http://192.168.197.28:9090/&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299&quot;\n192.168.197.145 - - [20/Dec/2018:15:46:34 +0800] &quot;GET /api/rep/scRepairFaultType/datagrid?faultTypeCode= HTTP/1.1&quot; 200 992 &quot;http://192.168.197.28:9090/&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299&quot;\n192.168.197.50 - - [20/Dec/2018:15:46:37 +0800] &quot;GET /static/js/45.f9d68fececdbd4771c9f.js HTTP/1.1&quot; 200 14268 &quot;http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg&quot; &quot;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36&quot;\n192.168.197.50 - - [20/Dec/2018:15:46:37 +0800] &quot;GET /api/mat/scClRelationClient/datagrid?pageNum=1&amp;pageRow=10&amp;clientName= HTTP/1.1&quot; 200 1815 &quot;http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg&quot; &quot;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36&quot;</code></pre><p>2.计算每个ip访问的次数，并保存到mysql数据库中</p>\n<pre><code>import org.apache.spark.sql.{DataFrame, Dataset, SparkSession}\nobject SparkSqlTest2{\n    def main(args: Array[String]): Unit = {\n        val spark: SparkSession = SparkSession.builder().master(&quot;local[*]&quot;).appName(&quot;sparkTest&quot;).getOrCreate()\n        import spark.implicits._\n        val lines: Dataset[String] = spark.read.textFile(&quot;file:///C:/Users/Administrator/Desktop/access.log&quot;)\n        val data = lines.map(line =&gt; {\n            val fields: Array[String] = line.split(&quot; &quot;)\n            var ip = fields(0)\n            var method = fields(5)\n            var path = fields(6)\n            var HTTPmethod = fields(7)\n            var status = fields(8)\n            var server = fields(10)\n            (ip, method, path, HTTPmethod,status,server)\n        }).toDF(&quot;ip&quot;, &quot;method&quot;, &quot;path&quot;, &quot;HTTPmethod&quot;,&quot;status&quot;, &quot;server&quot;)\n        data.createTempView(&quot;logs&quot;)\n        val frame: DataFrame = spark.sql(&quot;select ip,count(ip) from  logs group by ip&quot;)\n\n        val url=&quot;jdbc:mysql://localhost:3306/anfu&quot;\n        val table=&quot;logs&quot;\n        val prop=new java.util.Properties()\n        prop.put(&quot;driver&quot;,&quot;com.mysql.jdbc.Driver&quot;)\n        prop.put(&quot;user&quot;,&quot;root&quot;)\n        prop.put(&quot;password&quot;,&quot;root&quot;)\n\n        //表自动创建\n        frame.write.jdbc(url,table,prop)\n        spark.stop()\n    }\n}</code></pre><h3 id=\"（三）dataset创建方式\"><a href=\"#（三）dataset创建方式\" class=\"headerlink\" title=\"（三）dataset创建方式\"></a>（三）dataset创建方式</h3><p><strong>1.spark读取text文件</strong></p>\n<pre><code>val lines=spark.read.textFile(&quot;file:///c:/text&quot;)</code></pre><p><strong>2.spark传入list创建</strong></p>\n<pre><code class=\"scala\">val lines = spark.createDataset(List(&quot;1,chenjinhua,cn&quot;,&quot;2,Lisi,usa&quot;,&quot;3,jony,usa&quot;))</code></pre>\n<p><strong>3.spark传入Seq创建</strong></p>\n<pre><code>val dataset = Seq(\n  (1, &quot;zhangyuhang&quot;, java.sql.Date.valueOf(&quot;2018-05-15&quot;)),\n  (2, &quot;zhangqiuyue&quot;, java.sql.Date.valueOf(&quot;2018-05-15&quot;))\n)</code></pre><p><strong>4.spark传入Rdd创建</strong></p>\n<pre><code>val dataset = spark.createDataset(spark.sparkContext.parallelize(1 to 10))</code></pre><h3 id=\"（四）dataFrame创建方式\"><a href=\"#（四）dataFrame创建方式\" class=\"headerlink\" title=\"（四）dataFrame创建方式\"></a>（四）dataFrame创建方式</h3><p><strong>1.使用toDF函数创建DataFrame</strong> </p>\n<pre><code>import spark.implicits._\nval df = Seq(\n  (1, &quot;zhangyuhang&quot;, java.sql.Date.valueOf(&quot;2018-05-15&quot;)),\n  (2, &quot;zhangqiuyue&quot;, java.sql.Date.valueOf(&quot;2018-05-15&quot;))\n).toDF(&quot;id&quot;, &quot;name&quot;, &quot;created_time&quot;)</code></pre><p><strong>2.使用createDataFrame函数创建DataFrame</strong> ，<strong>通过schema + row 来创建</strong> </p>\n<p>可以理解为schema为表的表头，row为表的数据记录 </p>\n<pre><code>import org.apache.spark.sql.types._\n//定义dataframe的结构的schema\nval schema = StructType(List(\n    StructField(&quot;id&quot;, IntegerType, nullable = false),\n    StructField(&quot;name&quot;, StringType, nullable = true),\n    StructField(&quot;create_time&quot;, DateType, nullable = true)\n))\n\n//定义dataframe内容的rdd\nval rdd = sc.parallelize(Seq(\n  Row(1, &quot;zhangyuhang&quot;, java.sql.Date.valueOf(&quot;2018-05-15&quot;)),\n  Row(2, &quot;zhangqiuyue&quot;, java.sql.Date.valueOf(&quot;2018-05-15&quot;))\n))\n//创建dataframe\nval df = spark.createDataFrame(rdd, schema)</code></pre><p>或者</p>\n<pre><code>import org.apache.spark.sql.types._\n//传入属性参数\nval schemaString = &quot; id name create_time&quot;\n//解析参数变成StructField\nval fields = schemaString.split(&quot; &quot;).map(fieldName =&gt; StructField(fieldname, StringType, nullable = true))\n//定义dataframe的结构的schema\nval schema = StructType(fields)\n//定义dataframe内容的rdd\nval lines = sc.textFile(&quot;file:///people.txt&quot;)\nval rdd = lines.spilt(_.split(&quot;,&quot;)).map(field=&gt;ROW(field(0),field(1).trim) )\n//创建dataframe\nval df = spark.createDataFrame(rdd, schema) </code></pre><p><strong>3.通过反射机制创建DataFrame</strong></p>\n<p> 首先要定义一个case class，因为只有case class才能被Spark隐式转化为DataFrame</p>\n<pre><code>import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\nimport org.apache.spark.sql.Encoder\nimport spark.implicits._\n//创建匹配类\ncase class Person(id:Int,name:String,age:Long)\n//读取文件生成rdd\nval rdd = sc.textFile(&quot;file:///&quot;)\n//通过匹配类把rdd转化成dataframe\nval df = rdd.map(_.split(&quot;,&quot;)).map(attributes =&gt; Person(attributes(0),attributes(1),attributes(2).trim.toInt)).toDF()　</code></pre><h3 id=\"（五）spark-sql设置分区数量\"><a href=\"#（五）spark-sql设置分区数量\" class=\"headerlink\" title=\"（五）spark sql设置分区数量\"></a>（五）spark sql设置分区数量</h3><p>保存文件时可以设置分区为一个，文件数量就会是一个</p>\n<pre><code>spark.sqlContext.setConf(&quot;spark.sql.shuffle.partitions&quot;,&quot;1&quot;)</code></pre><h3 id=\"（六）spark-sql数据读取数据\"><a href=\"#（六）spark-sql数据读取数据\" class=\"headerlink\" title=\"（六）spark sql数据读取数据\"></a>（六）spark sql数据读取数据</h3><p><strong>1.读取parquet文件</strong> </p>\n<pre><code>val df = spark.read.parquet(&quot;hdfs:/path/to/file&quot;)</code></pre><p>*<em>2.读取json文件 *</em></p>\n<pre><code>val df = spark.read.json(&quot;examples/src/main/resources/people.json&quot;)</code></pre><p><strong>3.读取csv</strong></p>\n<pre><code>val df = spark.read.format(&quot;com.databricks.spark.csv&quot;)\n        .option(&quot;header&quot;, &quot;true&quot;) //reading the headers\n        .option(&quot;mode&quot;, &quot;DROPMALFORMED&quot;)\n        .load(&quot;csv/file/path&quot;)</code></pre><p><strong>4.读取Hive表</strong></p>\n<pre><code>spark.table(&quot;test.person&quot;) // 库名.表名 的格式\n     .registerTempTable(&quot;person&quot;)  // 注册成临时表\nspark.sql(\n      &quot;&quot;&quot;\n        | select *\n        | from person\n        | limit 10\n      &quot;&quot;&quot;.stripMargin).show()</code></pre><h3 id=\"（七）spark-sql数据保存\"><a href=\"#（七）spark-sql数据保存\" class=\"headerlink\" title=\"（七）spark sql数据保存\"></a>（七）spark sql数据保存</h3><p><strong>1.通过df.write.format().save(“file:///“)保存</strong> </p>\n<p>write.format()支持输出的格式有parquet、 JSON、csv、JDBC、text等文件格式,save()定义保存的位置</p>\n<p>当我们保存成功后可以在保存位置的目录下看到文件，但是这个文件并不是一个文件而是一个目录。</p>\n<p><strong>（1）parquet格式</strong></p>\n<pre><code>df.write.mode(SaveMode.Append).format(&quot;parquet&quot;).save(&quot;file:///C:/Users/Administrator/Desktop/parquet&quot;)\ndf.write.mode(SaveMode.Append).parquet(&quot;file:///C:/Users/Administrator/Desktop/parquet2&quot;)</code></pre><p><strong>（2）json格式</strong></p>\n<pre><code>df.write.format(&quot;json&quot;).save(&quot;file:///C:/Users/Administrator/Desktop/myjson&quot;)</code></pre><p><strong>（3）csv格式</strong></p>\n<pre><code>df.write.format(&quot;csv&quot;).save(&quot;file:///C:/Users/Administrator/Desktop/mycsv&quot;)</code></pre><p><strong>（4）jdbc格式，保存到mysql数据库</strong></p>\n<pre><code class=\"scala\">val url=&quot;jdbc:mysql://localhost:3306/anfu&quot;\nval table=&quot;logs&quot;\nval prop=new java.util.Properties()\nprop.put(&quot;driver&quot;,&quot;com.mysql.jdbc.Driver&quot;)\nprop.put(&quot;user&quot;,&quot;root&quot;)\nprop.put(&quot;password&quot;,&quot;root&quot;)\n//表自动创建\nframe.write.jdbc(url,table,prop)</code></pre>\n<p><strong>（5）text格式，保存的时候必须是一列，否则报错</strong></p>\n<pre><code>df.write.format(&quot;text&quot;).save(&quot;file:///C:/Users/Administrator/Desktop/mytext&quot;)</code></pre><p><strong>2.通过df.rdd.saveAsTextFile(“file:///“)转化成rdd再保存</strong></p>\n<p><strong>我们对于不同格式的文件读写来说，我们一般使用两套对应方式</strong></p>\n<h2 id=\"八-spark-Stream\"><a href=\"#八-spark-Stream\" class=\"headerlink\" title=\"八.spark Stream\"></a>八.spark Stream</h2><h3 id=\"（一）netcat运用\"><a href=\"#（一）netcat运用\" class=\"headerlink\" title=\"（一）netcat运用\"></a>（一）netcat运用</h3><p><strong>1.netcat在windows下使用</strong></p>\n<p>Windows间传输：</p>\n<p>1、安装NetCat</p>\n<p>2、开启服务端：nc -l -p 9999</p>\n<p>3、开启客户端：nc localhost 9999</p>\n<p>4、客户端和服务端间通信</p>\n<p><strong>2.netcat在linux下使用</strong></p>\n<p><strong>（1）netcat的安装</strong></p>\n<pre><code>yum install nc -y</code></pre><p><strong>（2）netcat使用</strong></p>\n<pre><code>nc -lk 9000</code></pre><h3 id=\"（二）spark-Stream的socketTextStream\"><a href=\"#（二）spark-Stream的socketTextStream\" class=\"headerlink\" title=\"（二）spark Stream的socketTextStream\"></a>（二）spark Stream的socketTextStream</h3><p><strong>（1）代码编写</strong></p>\n<pre><code>import org.apache.spark.SparkContext\nimport org.apache.spark.sql.{DataFrame, Dataset, SparkSession}\nimport org.apache.spark.streaming.dstream.{DStream, ReceiverInputDStream}\nimport org.apache.spark.streaming.{Duration, StreamingContext}\n\nobject SparkStreamTest1{\n    def main(args: Array[String]): Unit = {\n        val spark: SparkSession = SparkSession.builder().master(&quot;local[*]&quot;).appName(&quot;sparkTest&quot;).getOrCreate()\n        val sc= spark.sparkContext\n        val ssc = new StreamingContext(sc,Duration(5000))\n        val line: ReceiverInputDStream[String] = ssc.socketTextStream(&quot;192.168.232.140&quot;,9000)\n        val ds: DStream[(String, Int)] = line.flatMap(_.split(&quot; &quot;)).map((_,1)).reduceByKey(_+_)\n        ds.print()\n        ssc.start()\n        ssc.awaitTermination()\n    }\n}</code></pre><p><strong>（2）在192.168.232.140的netcat下输入数据</strong></p>\n<pre><code>[root@master ~]# nc -lk 9000\ndsfadsfad\nl1l\nkj\nhjhj</code></pre><p><strong>（3）输出结果</strong></p>\n<pre><code>(dsfadsfad,1)\n(hjhj,1)\n(l1l,1)\n(kj,1)</code></pre><h3 id=\"（三）spark-Stream的结果集保存到数据库\"><a href=\"#（三）spark-Stream的结果集保存到数据库\" class=\"headerlink\" title=\"（三）spark Stream的结果集保存到数据库\"></a>（三）spark Stream的结果集保存到数据库</h3><p><strong>（1）获取socketTextStream中的数据进行计算之后保存mysql</strong></p>\n<pre><code>package com.chen\nimport java.sql.{Connection, DriverManager, Statement}\nimport org.apache.log4j.{Level, Logger}\nimport org.apache.spark.sql.SparkSession\nimport org.apache.spark.streaming.dstream.{DStream, ReceiverInputDStream}\nimport org.apache.spark.streaming.{Duration, StreamingContext}\n\nobject SparkStream2MysqlTest1{\n    def main(args: Array[String]): Unit = {\n        Logger.getLogger(&quot;com.chen&quot;).setLevel(Level.OFF)\n        val spark: SparkSession = SparkSession.builder().master(&quot;local[*]&quot;).appName(&quot;sparkTest&quot;).getOrCreate()\n        val sc= spark.sparkContext\n        val ssc = new StreamingContext(sc,Duration(5000))\n        val line: ReceiverInputDStream[String] = ssc.socketTextStream(&quot;192.168.232.140&quot;,9000)\n        val ds: DStream[(String, Int)] = line.flatMap(_.split(&quot; &quot;)).map((_,1)).reduceByKey(_+_)\n\n        ds.foreachRDD(rdd=&gt;rdd.foreachPartition(line=&gt;{\n                Class.forName(&quot;com.mysql.jdbc.Driver&quot;)\n                val connection: Connection = DriverManager.getConnection(&quot;jdbc:mysql://192.168.197.28:3306/sys&quot;,&quot;dev&quot;,&quot;dev@gzstrong&quot;)\n                try{\n                    for (row&lt;-line){\n                        val statement: Statement = connection.createStatement()\n                        val sql=&quot;INSERT INTO `sys`.`test` (`value`, `valueCount`) VALUES (&#39;&quot;+row._1+&quot;&#39;,&#39;&quot;+row._2+&quot;&#39;);&quot;\n                        statement.execute(sql)\n                    }\n                }finally {\n                    connection.close()\n                }\n            })\n        )\n        ssc.start()\n        ssc.awaitTermination()\n    }\n}</code></pre><p><strong>（2）在192.168.232.140的netcat下输入数据</strong></p>\n<pre><code>[root@master ~]# nc -lk 9000\ntest\nsichuang\ngzstrong</code></pre><p><strong>（3）查看数据库中的结果</strong></p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">value</th>\n<th align=\"center\">valuecount</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">test</td>\n<td align=\"center\">1</td>\n</tr>\n<tr>\n<td align=\"center\">sichuang</td>\n<td align=\"center\">1</td>\n</tr>\n<tr>\n<td align=\"center\">gzstrong</td>\n<td align=\"center\">1</td>\n</tr>\n</tbody></table>\n<h3 id=\"（四）spark-Stream与kafka的集成\"><a href=\"#（四）spark-Stream与kafka的集成\" class=\"headerlink\" title=\"（四）spark Stream与kafka的集成\"></a>（四）spark Stream与kafka的集成</h3><h2 id=\"九-Structured-Streaming\"><a href=\"#九-Structured-Streaming\" class=\"headerlink\" title=\"九.Structured Streaming\"></a>九.Structured Streaming</h2><h2 id=\"十-spark案例分析与编程实现\"><a href=\"#十-spark案例分析与编程实现\" class=\"headerlink\" title=\"十.spark案例分析与编程实现\"></a>十.spark案例分析与编程实现</h2><p>案例一</p>\n<p>a. 案例描述</p>\n<p>提起 Word Count(词频数统计)，相信大家都不陌生，就是统计一个或者多个文件中单词出现的次数。本文将此作为一个入门级案例，由浅入深的开启使用 Scala 编写 Spark 大数据处理程序的大门。</p>\n<p>b．案例分析</p>\n<p>对于词频数统计，用 Spark 提供的算子来实现，我们首先需要将文本文件中的每一行转化成一个个的单词, 其次是对每一个出现的单词进行记一次数，最后就是把所有相同单词的计数相加得到最终的结果。</p>\n<p>对于第一步我们自然的想到使用 flatMap 算子把一行文本 split 成多个单词，然后对于第二步我们需要使用 map 算子把单个的单词转化成一个有计数的 Key-Value 对，即 word -&gt; (word,1). 对于最后一步统计相同单词的出现次数，我们需要使用 reduceByKey 算子把相同单词的计数相加得到最终结果。</p>\n<p>c. 编程实现</p>\n<p>清单 1.SparkWordCount 类源码</p>\n<p>SparkWordCount.scala</p>\n<pre><code>import org.apache.spark.SparkConf\nimport org.apache.spark.SparkContext\nimport org.apache.spark.SparkContext._\n\nobject SparkWordCount {\n def FILE_NAME:String = &quot;word_count_results_&quot;;\n def main(args:Array[String]) {\n if (args.length &lt; 1) {\n println(&quot;Usage:SparkWordCount FileName&quot;);\n System.exit(1);\n }\n val conf = new SparkConf().setAppName(&quot;Spark Exercise: Spark Version Word Count Program&quot;);\n val sc = new SparkContext(conf);\n val textFile = sc.textFile(args(0));\n val wordCounts = textFile.flatMap(line =&gt; line.split(&quot; &quot;)).map(\n                                        word =&gt; (word, 1)).reduceByKey((a, b) =&gt; a + b)\n //print the results,for debug use.\n //println(&quot;Word Count program running results:&quot;);\n //wordCounts.collect().foreach(e =&gt; {\n //val (k,v) = e\n //println(k+&quot;=&quot;+v)\n //});\n wordCounts.saveAsTextFile(FILE_NAME+System.currentTimeMillis());\n println(&quot;Word Count program running results are successfully saved.&quot;);\n }\n}</code></pre><p>d. 提交到集群执行</p>\n<p>本实例中, 我们将统计 HDFS 文件系统中/user/fams 目录下所有 txt 文件中词频数。其中 spark-exercise.jar 是 Spark 工程打包后的 jar 包，这个 jar 包执行时会被上传到目标服务器的/home/fams 目录下。运行此实例的具体命令如下：</p>\n<pre><code>./spark-submit \\\n--class com.ibm.spark.exercise.basic.SparkWordCount \\\n--master spark://hadoop036166:7077 \\\n--num-executors 3 \\\n--driver-memory 6g --executor-memory 2g \\\n--executor-cores 2 \\\n/home/fams/sparkexercise.jar \\\nhdfs://hadoop036166:9000/user/fams/*.txt</code></pre><p><strong>案例二</strong></p>\n<p>a. 案例描述</p>\n<p>该案例中，我们将假设我们需要统计一个 1000 万人口的所有人的平均年龄，当然如果您想测试 Spark 对于大数据的处理能力，您可以把人口数放的更大，比如 1 亿人口，当然这个取决于测试所用集群的存储容量。假设这些年龄信息都存储在一个文件里，并且该文件的格式如下，第一列是 ID，第二列是年龄。</p>\n<p>案例二age.txt测试数据格式预览</p>\n<p><img src=\"https://static.oschina.net/uploads/img/201803/29143845_eRx4.jpg\" alt=\"è¾å¥å¾çè¯´æ\"> </p>\n<p>现在我们需要用 Scala 写一个生成 1000 万人口年龄数据的文件，源程序如下：</p>\n<p>清单 3. 年龄信息文件生成类源码</p>\n<pre><code>import java.io.FileWriter\nimport java.io.File\nimport scala.util.Random\n\nobject SampleDataFileGenerator {\n\ndef main(args:Array[String]) {\nval writer = new FileWriter(new File(&quot;C: \\\\sample_age_data.txt&quot;),false)\nval rand = new Random()\nfor ( i &lt;- 1 to 10000000) {\nwriter.write( i + &quot; &quot; + rand.nextInt(100))\nwriter.write(System.getProperty(&quot;line.separator&quot;))\n}\nwriter.flush()\nwriter.close()\n}\n}</code></pre><p>b. 案例分析</p>\n<p>要计算平均年龄，那么首先需要对源文件对应的 RDD 进行处理，也就是将它转化成一个只包含年龄信息的 RDD，其次是计算元素个数即为总人数，然后是把所有年龄数加起来，最后平均年龄=总年龄/人数。</p>\n<p>对于第一步我们需要使用 map 算子把源文件对应的 RDD 映射成一个新的只包含年龄数据的 RDD，很显然需要对在 map 算子的传入函数中使用 split 方法，得到数组后只取第二个元素即为年龄信息；第二步计算数据元素总数需要对于第一步映射的结果 RDD 使用 count 算子；第三步则是使用 reduce 算子对只包含年龄信息的 RDD 的所有元素用加法求和；最后使用除法计算平均年龄即可。</p>\n<p>由于本例输出结果很简单，所以只打印在控制台即可。</p>\n<p>c. 编程实现</p>\n<p>清单 4.AvgAgeCalculator 类源码</p>\n<pre><code>import org.apache.spark.SparkConf\nimport org.apache.spark.SparkContext\nobject AvgAgeCalculator {\n def main(args:Array[String]) {\n if (args.length &lt; 1){\n println(&quot;Usage:AvgAgeCalculator datafile&quot;)\n System.exit(1)\n }\n val conf = new SparkConf().setAppName(&quot;Spark Exercise:Average Age Calculator&quot;)\n val sc = new SparkContext(conf)\n val dataFile = sc.textFile(args(0), 5);\n val count = dataFile.count()\n val ageData = dataFile.map(line =&gt; line.split(&quot; &quot;)(1))\n val totalAge = ageData.map(age =&gt; Integer.parseInt(\n                                String.valueOf(age))).collect().reduce((a,b) =&gt; a+b)\n println(&quot;Total Age:&quot; + totalAge + &quot;;Number of People:&quot; + count )\n val avgAge : Double = totalAge.toDouble / count.toDouble\n println(&quot;Average Age is &quot; + avgAge)\n }\n}</code></pre><p>案例三</p>\n<p>a. 案例描述</p>\n<p>本案例假设我们需要对某个省的人口 (1 亿) 性别还有身高进行统计，需要计算出男女人数，男性中的最高和最低身高，以及女性中的最高和最低身高。本案例中用到的源文件有以下格式, 三列分别是 ID，性别，身高 (cm)。</p>\n<p>案例三测试数据格式预览</p>\n<p>我们将用以下 Scala 程序生成这个文件，源码如下：</p>\n<p>清单 7. 人口信息生成类源码</p>\n<pre><code>import java.io.FileWriter\nimport java.io.File\nimport scala.util.Random\n\nobject PeopleInfoFileGenerator {\n def main(args:Array[String]) {\n val writer = new FileWriter(new File(&quot;C:\\\\LOCAL_DISK_D\\\\sample_people_info.txt&quot;),false)\n val rand = new Random()\n for ( i &lt;- 1 to 100000000) {\n var height = rand.nextInt(220)\n if (height &lt; 50) {\n height = height + 50\n }\n var gender = getRandomGender\n if (height &lt; 100 &amp;&amp; gender == &quot;M&quot;)\n height = height + 100\n if (height &lt; 100 &amp;&amp; gender == &quot;F&quot;)\n height = height + 50\n writer.write( i + &quot; &quot; + getRandomGender + &quot; &quot; + height)\n writer.write(System.getProperty(&quot;line.separator&quot;))\n }\n writer.flush()\n writer.close()\n println(&quot;People Information File generated successfully.&quot;)\n }\n\n def getRandomGender() :String = {\n val rand = new Random()\n val randNum = rand.nextInt(2) + 1\n if (randNum % 2 == 0) {\n &quot;M&quot;\n } else {\n &quot;F&quot;\n }\n }\n}</code></pre><p>b. 案例分析</p>\n<p>对于这个案例，我们要分别统计男女的信息，那么很自然的想到首先需要对于男女信息从源文件的对应的 RDD 中进行分离，这样会产生两个新的 RDD，分别包含男女信息；其次是分别对男女信息对应的 RDD 的数据进行进一步映射，使其只包含身高数据，这样我们又得到两个 RDD，分别对应男性身高和女性身高；最后需要对这两个 RDD 进行排序，进而得到最高和最低的男性或女性身高。</p>\n<p>对于第一步，也就是分离男女信息，我们需要使用 filter 算子，过滤条件就是包含”M” 的行是男性，包含”F”的行是女性；第二步我们需要使用 map 算子把男女各自的身高数据从 RDD 中分离出来；第三步我们需要使用 sortBy 算子对男女身高数据进行排序。</p>\n<p>c. 编程实现</p>\n<p>在实现上，有一个需要注意的点是在 RDD 转化的过程中需要把身高数据转换成整数，否则 sortBy 算子会把它视为字符串，那么排序结果就会受到影响，例如 身高数据如果是：123,110,84,72,100，那么升序排序结果将会是 100,110,123,72,84，显然这是不对的。</p>\n<p>清单 8.PeopleInfoCalculator 类源码</p>\n<pre><code>object PeopleInfoCalculator {\n def main(args:Array[String]) {\n if (args.length &lt; 1){\n println(&quot;Usage:PeopleInfoCalculator datafile&quot;)\n System.exit(1)\n }\n val conf = new SparkConf().setAppName(&quot;Spark Exercise:People Info(Gender &amp; Height) Calculator&quot;)\n val sc = new SparkContext(conf)\n val dataFile = sc.textFile(args(0), 5);\n val maleData = dataFile.filter(line =&gt; line.contains(&quot;M&quot;)).map(\n                              line =&gt; (line.split(&quot; &quot;)(1) + &quot; &quot; + line.split(&quot; &quot;)(2)))\n val femaleData = dataFile.filter(line =&gt; line.contains(&quot;F&quot;)).map(\n                              line =&gt; (line.split(&quot; &quot;)(1) + &quot; &quot; + line.split(&quot; &quot;)(2)))\n //for debug use\n //maleData.collect().foreach { x =&gt; println(x)}\n //femaleData.collect().foreach { x =&gt; println(x)}\n val maleHeightData = maleData.map(line =&gt; line.split(&quot; &quot;)(1).toInt)\n val femaleHeightData = femaleData.map(line =&gt; line.split(&quot; &quot;)(1).toInt)\n //for debug use\n //maleHeightData.collect().foreach { x =&gt; println(x)}\n //femaleHeightData.collect().foreach { x =&gt; println(x)}\n val lowestMale = maleHeightData.sortBy(x =&gt; x,true).first()\n val lowestFemale = femaleHeightData.sortBy(x =&gt; x,true).first()\n //for debug use\n //maleHeightData.collect().sortBy(x =&gt; x).foreach { x =&gt; println(x)}\n //femaleHeightData.collect().sortBy(x =&gt; x).foreach { x =&gt; println(x)}\n val highestMale = maleHeightData.sortBy(x =&gt; x, false).first()\n val highestFemale = femaleHeightData.sortBy(x =&gt; x, false).first()\n println(&quot;Number of Male Peole:&quot; + maleData.count())\n println(&quot;Number of Female Peole:&quot; + femaleData.count())\n println(&quot;Lowest Male:&quot; + lowestMale)\n println(&quot;Lowest Female:&quot; + lowestFemale)\n println(&quot;Highest Male:&quot; + highestMale)\n println(&quot;Highest Female:&quot; + highestFemale)\n }\n}</code></pre><p>案例四</p>\n<p>a. 案例描述</p>\n<p>该案例中我们假设某搜索引擎公司要统计过去一年搜索频率最高的 K 个科技关键词或词组，为了简化问题，我们假设关键词组已经被整理到一个或者多个文本文件中，并且文档具有以下格式。</p>\n<p>图 13. 案例四测试数据格式预览</p>\n<p>我们可以看到一个关键词或者词组可能出现多次，并且大小写格式可能不一致。</p>\n<p>b. 案例分析</p>\n<p>要解决这个问题，首先我们需要对每个关键词出现的次数进行计算，在这个过程中需要识别不同大小写的相同单词或者词组，如”Spark”和“spark” 需要被认定为一个单词。对于出现次数统计的过程和 word count 案例类似；其次我们需要对关键词或者词组按照出现的次数进行降序排序，在排序前需要把 RDD 数据元素从 (k,v) 转化成 (v,k)；最后取排在最前面的 K 个单词或者词组。</p>\n<p>对于第一步，我们需要使用 map 算子对源数据对应的 RDD 数据进行全小写转化并且给词组记一次数，然后调用 reduceByKey 算子计算相同词组的出现次数；第二步我们需要对第一步产生的 RDD 的数据元素用 sortByKey 算子进行降序排序；第三步再对排好序的 RDD 数据使用 take 算子获取前 K 个数据元素。</p>\n<p>c. 编程实现</p>\n<p>清单 10.TopKSearchKeyWords 类源码</p>\n<pre><code>import org.apache.spark.SparkConf\nimport org.apache.spark.SparkContext\n\nobject TopKSearchKeyWords {\n def main(args:Array[String]){\n if (args.length &lt; 2) {\n println(&quot;Usage:TopKSearchKeyWords KeyWordsFile K&quot;);\n System.exit(1)\n }\n val conf = new SparkConf().setAppName(&quot;Spark Exercise:Top K Searching Key Words&quot;)\n val sc = new SparkContext(conf)\n val srcData = sc.textFile(args(0))\n val countedData = srcData.map(line =&gt; (line.toLowerCase(),1)).reduceByKey((a,b) =&gt; a+b)\n //for debug use\n //countedData.foreach(x =&gt; println(x))\n val sortedData = countedData.map{ case (k,v) =&gt; (v,k) }.sortByKey(false)\n val topKData = sortedData.take(args(1).toInt).map{ case (v,k) =&gt; (k,v) }\n topKData.foreach(println)\n }\n}</code></pre><p><strong>案例二的age.txt文件</strong></p>\n<p>1 16</p>\n<p>2 73</p>\n<p>3 74</p>\n<p>4 76 </p>\n<p>5 75</p>\n<p>6 78</p>\n<p>7 66</p>\n<p>8 55</p>\n<p>9 85</p>\n<p>11 25</p>\n<p>12 43</p>\n<p>13 45</p>\n<p>14 61</p>\n<p>15 35</p>\n<p>16 38</p>\n<p>17 69</p>\n<p>18 45</p>\n<p>19 55</p>\n<p>20 45</p>\n<p>21 16</p>\n<p>22 73</p>\n<p>23 74</p>\n<p>24 76 </p>\n<p>25 75</p>\n<p>26 78</p>\n<p>27 66</p>\n<p>28 55</p>\n<p>29 85</p>\n<p>30 85</p>\n<p>31 25</p>\n<p>32 43</p>\n<p>33 45</p>\n<p>34 61</p>\n<p>35 35</p>\n<p>36 38</p>\n<p>37 69</p>\n<p>38 45</p>\n<p>39 55</p>\n<p>40 45</p>\n<p>七.算子reduceByKey和groupByKey，sortByKey和sortBy区别</p>\n<ol>\n<li><p>Spark算子reduceByKey深度解析<br>那么这就基本奠定了reduceByKey的作用域是key-value类型的键值对，并且是只对每个key的value进行处理，如果含有多个key的话，那么就对多个values进行处理。这里的函数是我们自己传入的，也就是说是可人为控制的【其实这是废话，人为控制不了这算子一点用没有】。那么举个例子：</p>\n<p> scala&gt; val x = sc.parallelize(Array((“a”, 1), (“b”, 1), (“a”, 1),</p>\n<pre><code>  | (&quot;a&quot;, 1), (&quot;b&quot;, 1), (&quot;b&quot;, 1),\n  | (&quot;b&quot;, 1), (&quot;b&quot;, 1)), 3)</code></pre></li>\n</ol>\n<p>我们创建了一个Array的字符串，并把其存入spark的集群上，设置了三个分区【这里我们不关注分区，只关注操作】。那么我们调用reduceByKey并且传入函数进行相应操作【本处我们对相同key的value进行相加操作，类似于统计单词出现次数】：</p>\n<pre><code>scala&gt; val y = x.reduceByKey((pre, after) =&gt; (pre + after))</code></pre><p>这里两个参数我们逻辑上让他分别代表同一个key的两个不同values，那么结果想必大家应该猜到了： </p>\n<pre><code>scala&gt; y.collect\nres0: Array[(String, Int)] = Array((a,3), (b,5))</code></pre><ol>\n<li>reduceByKey和groupByKey区别与用法<br>首先，看一看spark官网[1]是怎么解释的：<br>reduceByKey(func, numPartitions=None)<br>reduceByKey用于对每个key对应的多个value进行merge操作，最重要的是它能够在本地先进行merge操作，并且merge操作可以通过函数自定义。</li>\n</ol>\n<p>groupByKey(numPartitions=None)</p>\n<p>也就是，groupByKey也是对每个key进行操作，但只生成一个sequence。需要特别注意“Note”中的话，它告诉我们：如果需要对sequence进行aggregation操作（注意，groupByKey本身不能自定义操作函数），那么，选择reduceByKey/aggregateByKey更好。这是因为groupByKey不能自定义函数，我们需要先用groupByKey生成RDD，然后才能对此RDD通过map进行自定义函数操作。 </p>\n<pre><code>val words = Array(&quot;one&quot;, &quot;two&quot;, &quot;two&quot;, &quot;three&quot;, &quot;three&quot;, &quot;three&quot;)\nval wordPairsRDD = sc.parallelize(words).map(word =&gt; (word, 1))\nval wordCountsWithReduce = wordPairsRDD.reduceByKey(_ + _)\nval wordCountsWithGroup = wordPairsRDD.groupByKey().map(t =&gt; (t._1, t._2.sum))</code></pre><p>上面得到的wordCountsWithReduce和wordCountsWithGroup是完全一样的，但是，它们的内部运算过程是不同的。 </p>\n<p>（1）当采用reduceByKeyt时，Spark可以在每个分区移动数据之前将待输出数据与一个共用的key结合。借助下图可以理解在reduceByKey里究竟发生了什么。 注意在数据对被搬移前同一机器上同样的key是怎样被组合的(reduceByKey中的lamdba函数)。然后lamdba函数在每个区上被再次调用来将所有值reduce成一个最终结果。整个过程如下：</p>\n<p>（2）当采用groupByKey时，由于它不接收函数，spark只能先将所有的键值对(key-value pair)都移动，这样的后果是集群节点之间的开销很大，导致传输延时。整个过程如下：</p>\n<p>因此，在对大数据进行复杂计算时，reduceByKey优于groupByKey。</p>\n<p>另外，如果仅仅是group处理，那么以下函数应该优先于 groupByKey ：</p>\n<p> 　　（1）、combineByKey 组合数据，但是组合之后的数据类型与输入时值的类型不一样。</p>\n<p> 　　（2）、foldByKey合并每一个 key 的所有值，在级联函数和“零值”中使用。</p>\n<ol>\n<li>sortByKey和sortBy区别<br>SortByKey()函数</li>\n</ol>\n<p>sortBy函数是在org.apache.spark.rdd.RDD类中实现的，它的实现如下：</p>\n<pre><code>def sortBy[K](f: (T) =&gt; K,ascending: Boolean = true,\n    numPartitions: Int = this.partitions.size)\n    (implicit ord: Ordering[K], ctag: ClassTag[K]): RDD[T] =\n    this.keyBy[K](f).sortByKey(ascending, numPartitions).values</code></pre><p>　该函数最多可以传三个参数：</p>\n<p>　　第一个参数是一个函数，该函数的也有一个带T泛型的参数，返回类型和RDD中元素的类型是一致的；</p>\n<p>　　第二个参数是ascending，从字面的意思大家应该可以猜到，是的，这参数决定排序后RDD中的元素是升序还是降序，默认是true，也就是升序；</p>\n<p>　　第三个参数是numPartitions，该参数决定排序后的RDD的分区个数，默认排序后的分区个数和排序之前的个数相等，即为this.partitions.size。</p>\n<p>　　从sortBy函数的实现可以看出，第一个参数是必须传入的，而后面的两个参数可以不传入。而且sortBy函数函数的实现依赖于sortByKey函数，关于sortByKey函数后面会进行说明。</p>\n<p>   那么，如何使用sortBy函数呢？</p>\n<pre><code>scala&gt; val data = List(3,1,90,3,5,12)\ndata: List[Int] = List(3, 1, 90, 3, 5, 12)\n\nscala&gt; val rdd = sc.parallelize(data)\nrdd: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[0] at parallelize at &lt;console&gt;:14\n\nscala&gt; rdd.collect\nres0: Array[Int] = Array(3, 1, 90, 3, 5, 12)\n\nscala&gt; rdd.sortBy(x =&gt; x).collect\nres1: Array[Int] = Array(1, 3, 3, 5, 12, 90)\n\nscala&gt; rdd.sortBy(x =&gt; x, false).collect\nres3: Array[Int] = Array(90, 12, 5, 3, 3, 1)\n\nscala&gt; val result = rdd.sortBy(x =&gt; x, false)\nresult: org.apache.spark.rdd.RDD[Int] = MappedRDD[23] at sortBy at &lt;console&gt;:16\n\nscala&gt; result.partitions.size\nres9: Int = 2\n\nscala&gt; val result = rdd.sortBy(x =&gt; x, false, 1)\nresult: org.apache.spark.rdd.RDD[Int] = MappedRDD[26] at sortBy at &lt;console&gt;:16\n\nscala&gt; result.partitions.size\nres10: Int = 1</code></pre><p>上面的实例对rdd中的元素进行升序排序。并对排序后的RDD的分区个数进行了修改，上面的result就是排序后的RDD，默认的分区个数是2，而我们对它进行了修改，所以最后变成了1。</p>\n<pre><code>val data = sc.parallelize(Array((&quot;cc&quot;,12),(&quot;bb&quot;,32),(&quot;cc&quot;,22),(&quot;aa&quot;,18),(&quot;bb&quot;,16),(&quot;dd&quot;,16),(&quot;ee&quot;,54),(&quot;cc&quot;,1),(&quot;ff&quot;,13),(&quot;gg&quot;,68),(&quot;bb&quot;,4)))\nvar sortbykey=data.sortByKey(false).collect\nsortbykey.foreach(x=&gt;(println(x._1+&quot; &quot;+x._2)))</code></pre><p>结果如下</p>\n<p>测到的测试结果如上图所示，显然是根据Key进行了排序。</p>\n<p>SortBy()函数</p>\n<p>sortByKey函数作用于Key-Value形式的RDD，并对Key进行排序。它是在org.apache.spark.rdd.OrderedRDDFunctions中实现的，实现如下</p>\n<pre><code>def sortByKey(ascending: Boolean = true, numPartitions: Int = self.partitions.size)\n    : RDD[(K, V)] =\n{\n  val part = new RangePartitioner(numPartitions, self, ascending)\n  new ShuffledRDD[K, V, V](self, part)\n    .setKeyOrdering(if (ascending) ordering else ordering.reverse)\n}</code></pre><p>从函数的实现可以看出，它主要接受两个函数，含义和sortBy一样，这里就不进行解释了。该函数返回的RDD一定是ShuffledRDD类型的，因为对源RDD进行排序，必须进行Shuffle操作，而Shuffle操作的结果RDD就是ShuffledRDD。其实这个函数的实现很优雅，里面用到了RangePartitioner，它可以使得相应的范围Key数据分到同一个partition中，然后内部用到了mapPartitions对每个partition中的数据进行排序，而每个partition中数据的排序用到了标准的sort机制，避免了大量数据的shuffle。下面对sortByKey的使用进行说明：</p>\n<pre><code>scala&gt; val a = sc.parallelize(List(&quot;wyp&quot;, &quot;iteblog&quot;, &quot;com&quot;, &quot;397090770&quot;, &quot;test&quot;), 2)\na: org.apache.spark.rdd.RDD[String] =ParallelCollectionRDD[30] at parallelize at &lt;console&gt;:12\n\nscala&gt; val b = sc. parallelize (1 to a.count.toInt , 2)\nb: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[31] at parallelize at &lt;console&gt;:14\n\nscala&gt; val c = a.zip(b)\nc: org.apache.spark.rdd.RDD[(String, Int)] = ZippedPartitionsRDD2[32] at zip at &lt;console&gt;:16\n\nscala&gt; c.sortByKey().collect\nres11: Array[(String, Int)] = Array((397090770,4), (com,3), (iteblog,2), (test,5), (wyp,1))\n\n\nval data = sc.parallelize(Array((&quot;cc&quot;,12),(&quot;bb&quot;,32),(&quot;cc&quot;,22),(&quot;aa&quot;,18),(&quot;bb&quot;,16),(&quot;dd&quot;,16),(&quot;ee&quot;,54),(&quot;cc&quot;,1),(&quot;ff&quot;,13),(&quot;gg&quot;,68),(&quot;bb&quot;,4)))\nvar sort=data.reduceByKey(_+_).sortBy(_._2,false).collect()\nsort.foreach(x=&gt;(println(x._1+&quot; &quot;+x._2)))</code></pre><p>结果如下</p>\n<p> 显然，上图显示的结果是根据Value中的数据进行的排序。</p>\n<h1 id=\"海量数据算法\"><a href=\"#海量数据算法\" class=\"headerlink\" title=\"海量数据算法\"></a>海量数据算法</h1><p><strong>数据倾斜的算子</strong></p>\n<p>数据倾斜只会发生在shuffle过程中。这里给大家罗列一些常用的并且可能会触发shuffle操作的算子：distinct、groupByKey、reduceByKey、aggregateByKey、join、cogroup、repartition等。出现数据倾斜时，可能就是你的代码中使用了这些算子中的某一个所导致的。</p>\n<h2 id=\"（一）mapjoin解析\"><a href=\"#（一）mapjoin解析\" class=\"headerlink\" title=\"（一）mapjoin解析\"></a>（一）mapjoin解析</h2><p>利用hive进行join连接操作，相较于MR有两种执行方案，一种为common join，另一种为map join ，map join是相对于common join的一种优化，省去shullfe和reduce的过程，大大的降低的作业运行的时间。 </p>\n<p>select f.a,f.b from A t join B f  on ( f.a=t.a and f.ftime=20110802)  </p>\n<p>该语句中B表有30亿行记录，A表只有100行记录，而且B表中数据倾斜特别严重，有一个key上有15亿行记录，在运行过程中特别的慢，而且在reduece的过程中遇有内存不够而报错。</p>\n<p>为了解决用户的这个问题，考虑使用mapjoin,mapjoin的原理： </p>\n<blockquote>\n<p><strong>MAPJION会把小表全部读入内存中，在map阶段直接拿另外一个表的数据和内存中表数据做匹配，由于在map是进行了join操作，省去了reduce运行的效率也会高很多</strong> </p>\n</blockquote>\n<p>这样就不会由于数据倾斜导致某个reduce上落数据太多而失败。于是原来的sql可以通过使用hint的方式指定join时使用mapjoin。 </p>\n<blockquote>\n<p>select /<em>+ mapjoin(A)</em>/ f.a,f.b from A t join B f  on ( f.a=t.a and f.ftime=20110802)  </p>\n</blockquote>\n<p>再运行发现执行的效率比以前的写法高了好多。 </p>\n<p>mapjoin还有一个很大的好处是能够进行不等连接的join操作，如果将不等条件写在where中，那么mapreduce过程中会进行笛卡尔积，运行效率特别低，如果使用mapjoin操作，在map的过程中就完成了不等值的join操作，效率会高很多。 </p>\n<p>例子： </p>\n<p>select A.a ,A.b from A join B where A.a&gt;B.a </p>\n<p><strong>简单总结一下，mapjoin的使用场景：</strong></p>\n<p>1.关联操作中有一张表非常小</p>\n<p> 2.不等值的链接操作</p>\n<p> <strong>MapJoin原理</strong></p>\n<p><img src=\"C:%5CUsers%5CAdministrator%5CDesktop%5CMd%E7%AC%94%E8%AE%B0%5Cpic%5C1565833762509.png\" alt=\"1565833762509\"></p>\n<p>MapJoin简单说就是在Map阶段将小表读入内存，顺序扫描大表完成Join。</p>\n<p>上图是Hive MapJoin的原理图，出自Facebook工程师Liyin Tang的一篇介绍Join优化的slice，从图中可以看出MapJoin分为两个阶段：</p>\n<ol>\n<li>通过MapReduce Local Task，将小表读入内存，生成HashTableFiles上传至Distributed Cache中，这里会对HashTableFiles进行压缩。</li>\n<li>MapReduce Job在Map阶段，每个Mapper从Distributed Cache读取HashTableFiles到内存中，顺序扫描大表，在Map阶段直接进行Join，将数据传递给下一个MapReduce任务。</li>\n</ol>\n<h2 id=\"（二）美团网的spark调优\"><a href=\"#（二）美团网的spark调优\" class=\"headerlink\" title=\"（二）美团网的spark调优\"></a>（二）美团网的spark调优</h2><p>基础版  <a href=\"https://tech.meituan.com/2016/04/29/spark-tuning-basic.html\" target=\"_blank\" rel=\"noopener\">https://tech.meituan.com/2016/04/29/spark-tuning-basic.html</a></p>\n<p>高级版  <a href=\"https://tech.meituan.com/2016/05/12/spark-tuning-pro.html\" target=\"_blank\" rel=\"noopener\">https://tech.meituan.com/2016/05/12/spark-tuning-pro.html</a></p>\n<h2 id=\"（三）-两阶段聚合（局部聚合-全局聚合）\"><a href=\"#（三）-两阶段聚合（局部聚合-全局聚合）\" class=\"headerlink\" title=\"（三） 两阶段聚合（局部聚合+全局聚合）\"></a>（三） 两阶段聚合（局部聚合+全局聚合）</h2><p><strong>方案适用场景：</strong>对RDD执行reduceByKey等聚合类shuffle算子或者在Spark SQL中使用group by语句进行分组聚合时，比较适用这种方案。</p>\n<p><strong>方案实现思路：</strong>这个方案的核心实现思路就是进行两阶段聚合。第一次是局部聚合，先给每个key都打上一个随机数，比如10以内的随机数，此时原先一样的key就变成不一样的了，比如(hello, 1) (hello, 1) (hello, 1) (hello, 1)，就会变成(1_hello, 1) (1_hello, 1) (2_hello, 1) (2_hello, 1)。接着对打上随机数后的数据，执行reduceByKey等聚合操作，进行局部聚合，那么局部聚合结果，就会变成了(1_hello, 2) (2_hello, 2)。然后将各个key的前缀给去掉，就会变成(hello,2)(hello,2)，再次进行全局聚合操作，就可以得到最终结果了，比如(hello, 4)。</p>\n<p><strong>方案实现原理：</strong>将原本相同的key通过附加随机前缀的方式，变成多个不同的key，就可以让原本被一个task处理的数据分散到多个task上去做局部聚合，进而解决单个task处理数据量过多的问题。接着去除掉随机前缀，再次进行全局聚合，就可以得到最终的结果。具体原理见下图。</p>\n<p><strong>方案优点：</strong>对于聚合类的shuffle操作导致的数据倾斜，效果是非常不错的。通常都可以解决掉数据倾斜，或者至少是大幅度缓解数据倾斜，将Spark作业的性能提升数倍以上。</p>\n<p><strong>方案缺点：</strong>仅仅适用于聚合类的shuffle操作，适用范围相对较窄。如果是join类的shuffle操作，还得用其他的解决方案。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"scala\"><a href=\"#scala\" class=\"headerlink\" title=\"scala\"></a>scala</h1><h2 id=\"一-scala的maven在IDE中的搭建\"><a href=\"#一-scala的maven在IDE中的搭建\" class=\"headerlink\" title=\"一.scala的maven在IDE中的搭建\"></a>一.scala的maven在IDE中的搭建</h2><p>1.开始创建项目体系结构<br>File –&gt; Project </p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904175253.png\" alt></p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904175319.png\" alt></p>\n<p><img src=\"https://gitee.com/chenjinhua_939598604/resources/raw/master/static/20190904175417.png\" alt></p>\n<p><img src=\"https://static.oschina.net/uploads/img/201802/11153427_h2XW.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"></p>\n<p>2.修改pom.xml</p>\n<pre><code>&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt;\n  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\n  &lt;groupId&gt;scala_maven&lt;/groupId&gt;\n  &lt;artifactId&gt;com.chen&lt;/artifactId&gt;\n  &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;\n  &lt;inceptionYear&gt;2008&lt;/inceptionYear&gt;\n  &lt;properties&gt;\n    &lt;scala.version&gt;2.11.7&lt;/scala.version&gt;\n  &lt;/properties&gt;\n\n  &lt;dependencies&gt;\n    &lt;dependency&gt;\n      &lt;groupId&gt;org.scala-lang&lt;/groupId&gt;\n      &lt;artifactId&gt;scala-library&lt;/artifactId&gt;\n      &lt;version&gt;${scala.version}&lt;/version&gt;\n    &lt;/dependency&gt;\n\n    &lt;dependency&gt;\n      &lt;groupId&gt;com.typesafe.akka&lt;/groupId&gt;\n      &lt;artifactId&gt;akka-actor_2.11&lt;/artifactId&gt;\n      &lt;version&gt;2.5.3&lt;/version&gt;\n    &lt;/dependency&gt;\n    &lt;dependency&gt;\n      &lt;groupId&gt;org.specs&lt;/groupId&gt;\n      &lt;artifactId&gt;specs&lt;/artifactId&gt;\n      &lt;version&gt;1.2.5&lt;/version&gt;\n      &lt;scope&gt;test&lt;/scope&gt;\n    &lt;/dependency&gt;\n  &lt;/dependencies&gt;\n\n  &lt;build&gt;\n    &lt;sourceDirectory&gt;src/main/scala&lt;/sourceDirectory&gt;\n    &lt;testSourceDirectory&gt;src/test/scala&lt;/testSourceDirectory&gt;\n    &lt;plugins&gt;\n      &lt;plugin&gt;\n        &lt;groupId&gt;org.scala-tools&lt;/groupId&gt;\n        &lt;artifactId&gt;maven-scala-plugin&lt;/artifactId&gt;\n        &lt;executions&gt;\n          &lt;execution&gt;\n            &lt;goals&gt;\n              &lt;goal&gt;compile&lt;/goal&gt;\n              &lt;goal&gt;testCompile&lt;/goal&gt;\n            &lt;/goals&gt;\n          &lt;/execution&gt;\n        &lt;/executions&gt;\n        &lt;configuration&gt;\n          &lt;scalaVersion&gt;${scala.version}&lt;/scalaVersion&gt;\n          &lt;args&gt;\n            &lt;arg&gt;-target:jvm-1.5&lt;/arg&gt;\n          &lt;/args&gt;\n        &lt;/configuration&gt;\n      &lt;/plugin&gt;\n      &lt;plugin&gt;\n        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n        &lt;artifactId&gt;maven-eclipse-plugin&lt;/artifactId&gt;\n        &lt;configuration&gt;\n          &lt;downloadSources&gt;true&lt;/downloadSources&gt;\n          &lt;buildcommands&gt;\n            &lt;buildcommand&gt;ch.epfl.lamp.sdt.core.scalabuilder&lt;/buildcommand&gt;\n          &lt;/buildcommands&gt;\n          &lt;additionalProjectnatures&gt;\n            &lt;projectnature&gt;ch.epfl.lamp.sdt.core.scalanature&lt;/projectnature&gt;\n          &lt;/additionalProjectnatures&gt;\n          &lt;classpathContainers&gt;\n            &lt;classpathContainer&gt;org.eclipse.jdt.launching.JRE_CONTAINER&lt;/classpathContainer&gt;\n            &lt;classpathContainer&gt;ch.epfl.lamp.sdt.launching.SCALA_CONTAINER&lt;/classpathContainer&gt;\n          &lt;/classpathContainers&gt;\n        &lt;/configuration&gt;\n      &lt;/plugin&gt;\n    &lt;/plugins&gt;\n  &lt;/build&gt;\n  &lt;reporting&gt;\n    &lt;plugins&gt;\n      &lt;plugin&gt;\n        &lt;groupId&gt;org.scala-tools&lt;/groupId&gt;\n        &lt;artifactId&gt;maven-scala-plugin&lt;/artifactId&gt;\n        &lt;configuration&gt;\n          &lt;scalaVersion&gt;${scala.version}&lt;/scalaVersion&gt;\n        &lt;/configuration&gt;\n      &lt;/plugin&gt;\n    &lt;/plugins&gt;\n  &lt;/reporting&gt;\n&lt;/project&gt;\n</code></pre><blockquote>\n<p><strong>注意：如果有akka-actor的话  要和scala的版本相对应</strong></p>\n</blockquote>\n<p><img src=\"https://static.oschina.net/uploads/space/2018/0211/155017_Suab_3005534.png\" alt></p>\n<h2 id=\"二-scala的单词拆分\"><a href=\"#二-scala的单词拆分\" class=\"headerlink\" title=\"二.scala的单词拆分\"></a>二.scala的单词拆分</h2><pre><code>var word=Array(&quot;hello tom hello jelly&quot;,&quot;tom jelly&quot;,&quot;hello world hello tom&quot;,&quot;hello jelly&quot;,&quot;hello tom&quot;)\nvar b=word.flatMap(_.split(&quot; &quot;)).map((_,1)).groupBy(_._1).map(m=&gt;(m._1,m._2.map(x=&gt;x._2).sum)).toArray\nb.sortWith(_._2 &gt; _._2).toMap\nres33: scala.collection.immutable.Map[String,Int] = Map(hello -&gt; 6, tom -&gt; 4, jelly -&gt; 3, world -&gt; 1)</code></pre><p>或者</p>\n<pre><code>scala&gt; b.toSeq.sortWith(_._2&gt;_._2).toMap\nres32: scala.collection.immutable.Map[String,Int] = Map(hello -&gt; 6, tom -&gt; 4, jelly -&gt; 3, world -&gt; 1)</code></pre><p>扩展：</p>\n<pre><code>a=Map()//数据清空使用再次new\nprintln(a.size)\na.toSeq.sortBy(_._1)//升序排序 key\na.toSeq.sortBy(_._2)//升序排序 value\na.toSeq.sortWith(_._1&gt;_._1) //降序排序 key\na.toSeq.sortWith(_._2&gt;_._2) //降序排序 value</code></pre><pre><code>scala&gt; var word=Array(&quot;hello tom hello jelly&quot;,&quot;tom jelly&quot;,&quot;hello world hello tom&quot;,&quot;hello jelly&quot;,&quot;hello tom&quot;)\n\nscala&gt; word.flatMap(_.split(&quot; &quot;))  //将数组中每个元素，按照空格切分并且扁平化\nres34: Array[String] = Array(hello, tom, hello, jelly, tom, jelly, hello, world, hello, tom, hello, jelly, hello, tom)\n\nscala&gt; word.flatMap(_.split(&quot; &quot;)).map((_,1))  //将数组中每个单词，转成元组，并标记1\nres35: Array[(String, Int)] = Array((hello,1), (tom,1), (hello,1), (jelly,1), (tom,1), (jelly,1), (hello,1), (world,1), (hello,1), (tom,1), (hello,1), (jelly,1), (hello,1), (tom,1))\n\nscala&gt; word.flatMap(_.split(&quot; &quot;)).map((_,1)).groupBy(_._1)//将元组的数组中按照元组的第一个元素排序\nres36: scala.collection.immutable.Map[String,Array[(String, Int)]] = Map(world -&gt; Array((world,1)), tom -&gt; Array((tom,1), (tom,1), (tom,1), (tom,1)), hello -&gt; Array((hello,1), (hello,1), (hello,1), (hello,1), (hello,1), (hello,1)), jelly -&gt; Array((jelly,1), (jelly,1), (jelly,1)))\n\nscala&gt; word.flatMap(_.split(&quot; &quot;)).map((_,1)).groupBy(_._1).map(m=&gt;(m._1,m._2.map(x=&gt;x._2).sum)) //将排序后的元组进行数值求和\nres37: scala.collection.immutable.Map[String,Int] = Map(world -&gt; 1, tom -&gt; 4, hello -&gt; 6, jelly -&gt; 3)\n\nscala&gt; word.flatMap(_.split(&quot; &quot;)).map((_,1)).groupBy(_._1).map(m=&gt;(m._1,m._2.map(x=&gt;x._2).sum)).toArray\n//将排序求和后的map转化成元组方便排序\nres38: Array[(String, Int)] = Array((world,1), (tom,4), (hello,6), (jelly,3))\n\nscala&gt; word.flatMap(_.split(&quot; &quot;)).map((_,1)).groupBy(_._1).map(m=&gt;(m._1,m._2.map(x=&gt;x._2).sum)).toArray.sortWith(_._2 &gt; _._2) //将排序求和后的map转化成元组排序\nres39: Array[(String, Int)] = Array((hello,6), (tom,4), (jelly,3), (world,1))\n\nscala&gt; word.flatMap(_.split(&quot; &quot;)).map((_,1)).groupBy(_._1).map(m=&gt;(m._1,m._2.map(x=&gt;x._2).sum)).toArray.sortWith(_._2 &gt; _._2).toMap //转化回来map\nres40: scala.collection.immutable.Map[String,Int] = Map(hello -&gt; 6, tom -&gt; 4, jelly -&gt; 3, world -&gt; 1)\n\n\n</code></pre><h2 id=\"三-数组常见方法汇总\"><a href=\"#三-数组常见方法汇总\" class=\"headerlink\" title=\"三.数组常见方法汇总\"></a>三.数组常见方法汇总</h2><p><strong>array学习笔记</strong></p>\n<p>数组要点<br>1.若长度固定则使用Array，若长度可能有变化则使用ArrayBuffer<br>2.提供初始值时不要使用new<br>3.用()来访问元素<br>4.用for(elem &lt;- arr) 来遍历元素<br>5.用for(elem &lt;- array if …) … yield 来将原数组转型为新数组<br>6.Scala数组和Java数组可以互操作，用ArrayBuffer，使用scala.collection.JavaConversions中的转换函数。<br>定长数组 如果数组长度不变，则可使用scala中的Array，例如：</p>\n<pre><code>val nums = new Array[Int](10)    //10个整数的数组，所有元素初始化为0\nval string = new Array[String](10) //10个元素的字符串数组，所有元素被初始化为null\nval s = Array(&quot;hello&quot;,&quot;scala&quot;)  //长度为2的Array[String]——类型是推断出来的。已提供初始值，不需要new</code></pre><p>变长数组<br>对于那种长度按需要变化的数组，Java有ArrayList，C++有vector。Scalable中有等效的数据结构为：ArrayBuffer</p>\n<pre><code>import scala.collection.mutable.ArrayBuffer\nval b = ArrayBuffer[Int]()\n//或者new ArrayBuffer[Int]\n//一个空的数组缓冲，准备存放整数\nb += 1   //ArrayBuffer(1),用+=在尾部添加元素\nb += (1,2,3,4)     //在尾部添加多个元素\n\nb ++= Array(8,12,13)   //可以用++=操作符追加任何集合\nb.trimEnd(5)  //移除最后5个元素\n\n//在任意 位置添加元素\nb.insert(2,6)   //在下标2之前插入\nb.insert(2,6,7,8)   //在下标2之前插入6,7,8\n\nb.remove(2)   //移除下标为2的位置开始移除元素\nb.remove(2,3)  //从下标为2开始移除3个元素；第二个参数是表示移除元素的个数</code></pre><p>在使用时，有时不确定数组需要装元素的个数。此时，可以先构建一个数组缓冲，然后调用</p>\n<pre><code>b.toArray   //将缓冲数组转换为定长数组</code></pre><p>定长数组也可以转换为缓冲数组</p>\n<pre><code>a.toBuffer</code></pre><p>遍历数组和数组缓冲</p>\n<p>使用for循环遍历数组和数组缓冲<br>使用下标的方式</p>\n<pre><code>for (i &lt;- 0 until a.length){\n    println( i + &quot;:&quot; + a(i))\n}</code></pre><p>until用法扩展：这只步长–&gt; 0 until (a.length,2)  从数组尾部开始–&gt;(0 until a.length).reverse<br>不使用下标访问数组元素</p>\n<pre><code>for (elem &lt;- arrName) {println(elem)}</code></pre><p>数组转换</p>\n<pre><code>val a = Array(2,3,4)\nval result = for (elem &lt;- a) yield 2 * elem\nfor (elem &lt;-  a if elem %2==0) yield 2 * elem</code></pre><p>常用算法</p>\n<pre><code>sum: Array(1,2,3).sum\nmax/min : Array(1,2,3).max/min\nsorted : Array(1,2,3).sorted(_ &lt; ) ; Array(1,2,3).sorted( &gt; _) //不能对缓冲数组排序\nquickSort方法排序：scala.util.Sorting.quickSort(a)\n显示数组内容：mkString; a.mkString(&quot; and &quot;) //可以设置分隔符</code></pre><p>1、定长数组定义：</p>\n<pre><code>//定义一个长度为10的数值数组\nscala&gt; val numberArray = new Array[int](10)\nnumberArray:Array[Int] = Array(0,0,0,0,0,0,0,0,0,0)\n//定义一个长度为10的String类数组\nscala&gt; val strArray = new Array[String](10)\nstrArray:Array[String] = Array(null, null, null, null, null, null, null, null, null, null)\n\n//由上可以看出，复杂对象类型在数组定义时被初始化为null，数值型呗初始化为0，并且上面复杂类型定义的时候必须加new，否则会报错\n\n//提供初始值的定义数组\nscala&gt; val strArray2 = Array(&quot;First&quot;, &quot;Second&quot;)  //这里说明已提供初始值就不需要new\nstrArray2:Array[String] = Array(First, Second)\n\nscala&gt; strArray2(0) = &quot;Goodbye&quot;\nstrArray2:Array[String] = Array(Goodbye, Second)\n</code></pre><p>2、变长数组定义</p>\n<pre><code>对于长度需要变化的数组，Java有ArrayList,C++有vector。Scala中的等效数据结构为ArrayBuffer\n\n//导入可变包，Scala中的可变集合都是放在mutable中，使用时要导入\nscala&gt; import scala.collection.mutable.ArrayBuffer\nimport scala.collection.mutable.ArrayBuffer\n\nscala&gt; val arrayBuffer = ArrayBuffer[Int]()\narrayBuffer: scala.collection.mutable.ArrayBuffer[Int] = ArrayBuffer()\n\n//在尾部添加一个值\nscala&gt; arrayBuffer += 1\nres17: arrayBuffer.type = ArrayBuffer(1)\n\n//在尾部添加多个元素\nscala&gt; arrayBuffer += (2, 3, 4, 5)\nres19: arrayBuffer.type = ArrayBuffer(1, 2, 3, 4, 5)\n\n//在尾部添加一个集合\nscala&gt; arrayBuffer ++= Array(6, 7, 8, 9)\nres20: arrayBuffer.type = ArrayBuffer(1, 2, 3, 4, 5, 6, 7, 8, 9)\n\n//移除最后2个元素\nscala&gt; arrayBuffer.trimEnd(2)\n\n//在开头移除1一个元素\nscala&gt; arrayBuffer.trimStart(2)\n\nscala&gt; arrayBuffer\nres23: scala.collection.mutable.ArrayBuffer[Int] = ArrayBuffer(2, 3, 4, 5, 6, 7)\n\n\n//在任意位置插入或者删除元素\nscala&gt; arrayBuffer.insert(2, 6)\n//ArrayBuffer(2, 3, 6, 4, 5, 6, 7)\n\nscala&gt; arrayBuffer.insert(1, 2, 3, 4)\n//ArrayBuffer(2, 1, 2, 3, 4, 3, 6, 4, 5, 6, 7)\n\nscala&gt; arrayBuffer.remove(2)\n//ArrayBuffer(2, 1, 3, 4, 3, 6, 4, 5, 6, 7)\n\nscala&gt; arrayBuffer.remover(1, 8)\n//ArrayBuffer(2, 7)\n</code></pre><p>3、变长数组和定长数组转换</p>\n<pre><code>//变长转换长定长\nscala &gt; arrayBuffer.toArray\n//Array(2, 7)\n\n//定长转换成变长\nscala&gt;res7.toBuffer\n//ArrayBuffer(2, 7)\n</code></pre><p>4、遍历定长和变长数组</p>\n<pre><code>for(i &lt;- 0 until.arrayBuffer.length)\n    println(i + &quot;: &quot; + a(i))\n0 until.arrayBuffer.length实际上是一个方法调用，返回的是一个区间Range： 0.until(arrayBuffer.length)\nfor(i &lt;- 区间)会让变量i遍历该区间的所有值\n如果想要在区间中步长不为1，则：0 until (arrayBuffer.length, 2)\n如果想要数组从尾端开始，则遍历的写法为:(0 until (arrayBuffer.length, 2)).reverse\n\nScala也提供了一个和Java增强for循环类似的for\n\n//增强for\nfor(i &lt;- arrayBuffer)\n    println(i + &quot;: &quot; + a(i))\n</code></pre><p>5、数组转换</p>\n<p>在《Scala入门学习笔记二-基本数据类型、程序控制结构》提到在for循环推导式，可以利用原来的数组产生一个新的数组。</p>\n<pre><code>scala&gt; val a = Array(2, 3, 5, 7, 11)\na: Array[Int] = Array(2, 3, 5, 7, 11)\n//这里产生了一个新的数组，原来的数组也在\nscala&gt; val result = for(elem &lt;- a) yield 2 * elem\nresult: Array[Int] = Array(4, 6, 10, 14, 22)\n如果for中使用的是定长数组，则for(...)...yield之后得到的是定长数组;如果使用的是变长数组，则会得到变长数组\n\nScala也提供了另外一种做法\nscala&gt; a.filter(_ % 2 == 0).map(2 * _)\n\n甚至\nscala&gt;a.filter(_ % 2 == 0).map{2 * _}\n例子：\n给定一个整数的缓冲数组，我们想要移除第一个负数之外的所有负数。有几种做法\n\n//第一种做法：\nvar first = true\nvar n = a.length\nvar i = 0\nwhile(i &lt; n){\n    if(a(i) &gt; 0) i += 1\n    else{\n        if(first) {first = false; i += 1}\n        else {a.remove(i); n-= 1}\n    }\n}\n\n//第二种做法：\n//首先使用一个新数组用于记录满足条件的数组的下标\nval first = true\nval indexes = for(i &lt;- 0 until a.length if first || a(i) &gt; 0) yield {\n    if(a(i) &lt; 0) first = false; i\n}\n//然后将元素移动到该去的位置，截断尾端\nfor(j &lt;- o until indexes.length) a(j) = a(indexes(j))\na.trimEnd(a.length-indexes.length)</code></pre><p>6、常用算法<br>Scala针对数组提供了一个常用的函数</p>\n<pre><code>//定义一个整型数组\nscala&gt; val intArr=Array(1,2,3,4,5,6,7,8,9,10)\nintArr: Array[Int] = Array(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n\n//求和\nscala&gt; intArr.sum\nres87: Int = 55\n\n//求最大值\nscala&gt; intArr.max\nres88: Int = 10\n\nscala&gt; ArrayBuffer(&quot;Hello&quot;,&quot;Hell&quot;,&quot;Hey&quot;,&quot;Happy&quot;).max\nres90: String = Hey\n\n//求最小值\nscala&gt; intArr.min\nres89: Int = 1\n\n//排序\n//sorted方法将数组或数组缓冲排序并返回经过排序的数组或数组缓冲，原始数组被保留\nscala&gt;val b = ArrayBuffer(1, 7, 2, 9)\nb:ArrayBuffer[Int] = ArrayBuffer(1, 7, 2, 9)\nscala&gt;val bSorted = b.sorted(_&lt;_) \nbSorted: ArrayBuffer[Int] = ArrayBuffer(1, 2, 7, 9)\n\n//toString()方法\nscala&gt; intArr.toString()\nres94: String = [I@141aba8\n\n//mkString()方法\nscala&gt; intArr.mkString(&quot;,&quot;)\nres96: String = 1,2,3,4,5,6,7,8,9,10\n\nscala&gt; intArr.mkString(&quot;&lt;&quot;,&quot;,&quot;,&quot;&gt;&quot;)\nres97: String = &lt;1,2,3,4,5,6,7,8,9,10&gt;</code></pre><p>7、ArrayBuffer Scaladoc解析</p>\n<pre><code>初学者在查看sacaladoc时常常会感到困惑，不用担心，随着学习的深入，api文档中的内容将逐渐清晰\n下面给出两个示例：\n++=方法传入的参数类型是TraversableOnce Trait的子类，它返回的是更新好的ArrayBuffer\n\n++=方法解析\n\ndropWhile传入的是一个函数，该函数返回值是布尔类型，dropWhile反回的是操作后的ArrayBuffer\n\ndropWith方法解析</code></pre><p>8、多维数组<br>和Java一样，多维数组是通过数组的数组来实现的。</p>\n<pre><code>//第一种构造方式\nval metrix = Array.ofDim[Double](3, 4) //3行 4列\n\n//访问其中的元素\nmetrix(row)(column)  =42\n\n//可以创建不规则的数组，每一行的长度不相同\nval triangle = new Array[Array[Int]](10)\nfor(i &lt;- 0 until triangle.length)\n    trianglr(i) = new Array[Int](i+1)\n\n//在创建的时候赋值\nscala&gt; val metrix = Array(Array(1, 2, 3), Array(2.3, 3.4), Array(&quot;asdf&quot;, &quot;asdfas&quot;))\nmetrix: Array[Array[_ &gt;: String with Double with Int]] = Array(Array(1, 2, 3), Array(2.3, 3.4), Arra\ny(asdf, asdfas))\n\n//打印输出数组\nscala&gt; for(i &lt;- metrix) println(i.mkString(&quot; &quot;))\n1 2 3\n2.3 3.4\nasdf asdfas\n\n//输出二维数组的每个值\nscala&gt; for(i &lt;- metrix; from = i; j &lt;- from) println(j)\n1\n2\n3\n2.3\n3.4\nasdf\nasdfas</code></pre><h2 id=\"四-数组操作-二\"><a href=\"#四-数组操作-二\" class=\"headerlink\" title=\"四.数组操作(二)\"></a>四.数组操作(二)</h2><p>Scala数组操作：</p>\n<p>1.定长数组<br> 长度不变的数组的声明：</p>\n<pre><code>//长度为10的整数数组，所有元素初始化为0\n val numArr = new Array[Int](10)\n\n//长度为10的字符串数组，所有元素初始化为null\nval numArr = new Array[String](10)\n\n//长度为2的数组，数据类型自动推断出来，已经提供初始值就不需要new关键字\nval s = Array(&quot;cai&quot;,&quot;yong&quot;)\n\n//通过ArrayName(index)访问数组元素和更改数组元素\nval s = Array(&quot;cai&quot;,&quot;yong&quot;)\n println(s(0))\ns(0) = &quot;haha&quot;\nprintln(s(0))\n输出：\n cai\n haha\n</code></pre><p>2.变长数组：数组缓冲<br> Scala也支持长度变化的数组，支持的数据结构是ArrayBuffer</p>\n<pre><code>//一个空的数组缓冲，准备存放整数\n val ab = ArrayBuffer[Int]()\n val ab2 = new ArrayBuffer[Int]\n\n//用+=在尾部添加元素\nab += 2\n\n//在尾部添加多个元素\nab += (1,2,3,4,5)\n\n//通过++=往数组缓冲后面追加集合\n ab ++= Array(6,7,8,9)\n\n//使用trimEnd(n)移除尾部n个元素\nab.trimEnd(3)\n\n//在下标3之前插入元素\nab.insert(3, 33)\n\n//插入多个元素，第一个值为index，后面所有的值为要插入的值\nab.insert(3,3,4,5,6)\n\n//移除某个位置的元素\nab.remove(3)\n\n//移除从下标为n开始（包括n）的count个元素\nab.remove(n, count)</code></pre><p> 有时候需要构造一个Array，但是不知道具体要存放多少元素，可以先构造ArrayBuffer,再调用toArray方法转化成Array，同样，对Array调用toBuffer方法可以转成ArrayBuffer.</p>\n<p> 注：在数组缓冲的尾部进行元素添加移除操作的效率很高，但是在任意位置插入或移除元素的效率并不太高效，因为涉及到数组元素的移动。</p>\n<p>3.遍历数组</p>\n<pre><code>//for循环遍历\nfor(i &lt;- 0 until ab.length){\n print(ab(i) + &quot;, &quot;)\n }\n\n//根据特定步长遍历数组\nfor(i &lt;- 0 until (ab.length, 2)){\n print(ab(i) + &quot;, &quot;)\n }\n\n//从数组的尾部开始向前遍历数组\nfor(i &lt;- (0 until ab.length).reverse){\n print(ab(i) + &quot;, &quot;)\n}\n\n//类似于Java中的foreach遍历数组\n for(elem &lt;- ab){\n print(elem + &quot;, &quot;)\n}</code></pre><p>4.数组转换</p>\n<pre><code>//进行数组转换会生成一个新的数组，而不会修改原始数组\n val change = for(elem &lt;- ab) yield elem * 2\nfor(elem &lt;- change){\nprint(elem + &quot;, &quot;)\n }\n\n//添加一个守卫的数组转换\nval change = for(elem &lt;- ab if elem%2 == 0) yield elem * 2</code></pre><p>5.数组操作常用算法</p>\n<pre><code>//sum求和(数组与阿奴必须是数值型数据)\nprintln(change.sum)\n\n//min max 输出数组中最小和最大元素\nprintln(change.min)\nprintln(change.max)\n\n//使用sorted方法对数组或数组缓冲进行升序排序，这个过程不会修改原始数组\n val sortArr = ab.sorted \n for(elem &lt;- sortArr)\n print(elem + &quot;, &quot;)\n\n//使用比较函数sortWith进行排序\nval sortArr = ab.sortWith(_&gt;_)\n\n//数组显示\n println(sortArr.mkString(&quot;|&quot;))\n println(sortArr.mkString(&quot;startFlag&quot;,&quot;|&quot;,&quot;endFlag&quot;))</code></pre><p>6.多维数组</p>\n<pre><code>//构造一个2行3列的数组\nval arr = Array.ofDim[Int](2,3)\nprintln(arr.length)\nprintln(arr(0).length)\narr(0)(0) = 20\nprintln(arr(0)(0))\n\n//创建长度不规则的数组\nval arr = new Array[Array[Int]](3)\n\n for(i &lt;- 0 until arr.length){\narr(i) = new Array[Int](i + 2)\n}\n\nfor(i &lt;- 0 until arr.length){\nprintln(arr(i).length)\n}</code></pre><h2 id=\"五-Tuple常见方法汇总\"><a href=\"#五-Tuple常见方法汇总\" class=\"headerlink\" title=\"五.Tuple常见方法汇总\"></a>五.Tuple常见方法汇总</h2><pre><code>tuple的定义\n\n对偶是元组(tuple)的最简单形态——元组是不同类型的值的聚集。\n元组的值是通过将单个值包含在圆括号中构成。Example：（1，1.3415，“Fred”)\ntuple的访问\n\n可以通过_1,_2,_3访问元组的元素\nval first = tuple._1 //元组的位置从1开始，而非从0开始</code></pre><p>与列表一样，元组也是不可变的，但与列表不同的是元组可以包含不同类型的元素。<br>元组的值是通过将单个的值包含在圆括号中构成的。例如：</p>\n<pre><code>val t = (1, 3.14, &quot;Fred&quot;)  </code></pre><p>以上实例在元组中定义了三个元素，对应的类型分别为[Int, Double, java.lang.String]。<br>此外我们也可以使用以上方式来定义：</p>\n<pre><code>val t = new Tuple3(1, 3.14, &quot;Fred&quot;)</code></pre><p>元组的实际类型取决于它的元素的类型，比如 (99, “runoob”) 是 Tuple2[Int, String]。 (‘u’, ‘r’, “the”, 1, 4, “me”) 为 Tuple6[Char, Char, String, Int, Int, String]。<br>目前 Scala 支持的元组最大长度为 22。对于更大长度你可以使用集合，或者扩展元组。<br>访问元组的元素可以通过数字索引，如下一个元组：</p>\n<pre><code>val t = (4,3,2,1)\nval sum = t._1 + t._2 + t._3 + t._4\nprintln( &quot;元素之和为: &quot;  + sum )//10</code></pre><p>迭代元组</p>\n<pre><code>val t = (4,3,2,1)\nt.productIterator.foreach{ i =&gt;println(&quot;Value = &quot; + i )}\nValue = 4\nValue = 3\nValue = 2\nValue = 1</code></pre><p>元组转为字符串<br>你可以使用 Tuple.toString() 方法将元组的所有元素组合成一个字符串，实例如下：</p>\n<pre><code>val t = new Tuple3(1, &quot;hello&quot;, Console)\nprintln(&quot;连接后的字符串为: &quot; + t.toString() )\n连接后的字符串为: (1,hello,scala.Console$@4dd8dc3)</code></pre><h2 id=\"六-List常见方法汇总\"><a href=\"#六-List常见方法汇总\" class=\"headerlink\" title=\"六.List常见方法汇总\"></a>六.List常见方法汇总</h2><p>List的4种操作符的区别和联</p>\n<p>(1):+和+: 两者的区别在于:+方法用于在尾部追加元素，+:方法用于在头部追加元素，和::很类似，但是::可以用于pattern match ，而+:则不行. 关于+:和:+,只要记住冒号永远靠近集合类型就OK了。</p>\n<pre><code>scala&gt; a\nres23: List[Int] = List(1, 2, 3, 4)\n\nscala&gt; var b=a:+9\nb: List[Int] = List(1, 2, 3, 4, 9)\n\nscala&gt; var c=9:+a\n&lt;console&gt;:15: error: value :+ is not a member of Int\n       var c=9:+a\n              ^\nscala&gt; var c=9+:a\nc: List[Int] = List(9, 1, 2, 3, 4)\n\nscala&gt; var r1=&quot;A&quot;+:&quot;B&quot;+:Nil\nr1: List[String] = List(A, B)\n\nscala&gt;var r2=Nil:+&quot;A&quot;:+&quot;B&quot;\nr2: List[String] = List(A, B)</code></pre><p>(2):: 该方法被称为cons，意为构造，向队列的头部追加数据，创造新的列表。用法为 x::list,其中x为加入到头部的元素，无论x是列表与否，它都只将成为新生成列表的第一个元素，也就是说新生成的列表长度为list的长度＋1(btw, x::list等价于list.::(x))</p>\n<pre><code>scala&gt;&quot;A&quot;::&quot;B&quot;::Nil\nres0: List[String] = List(A, B)\n\nscala&gt;List(&quot;A&quot;,&quot;B&quot;)::List(&quot;C&quot;,&quot;D&quot;)\nres1: List[java.io.Serializable] = List(List(A, B), C, D)</code></pre><p>(3) ++ 该方法用于连接两个集合，list1++list2</p>\n<pre><code>scala&gt;List(&quot;A&quot;,&quot;B&quot;) ++ List(&quot;C&quot;,&quot;D&quot;)\nres2: List[String] = List(A, B, C, D)</code></pre><p>(4)::: 该方法只能用于连接两个List类型的集合</p>\n<pre><code>scala&gt;List(&quot;A&quot;,&quot;B&quot;) ::: List(&quot;C&quot;,&quot;D&quot;)\nres3: List[String] = List(A, B, C, D)</code></pre><p><strong>List常用用法</strong></p>\n<p>1）List类型定义以及List的特点：</p>\n<pre><code>//字符串类型List\nscala&gt; val fruit=List(&quot;Apple&quot;,&quot;Banana&quot;,&quot;Orange&quot;)\nfruit: List[String] = List(Apple, Banana, Orange)\n\n//前一个语句与下面语句等同\nscala&gt; val fruit=List.apply(&quot;Apple&quot;,&quot;Banana&quot;,&quot;Orange&quot;)\nfruit: List[String] = List(Apple, Banana, Orange)\n\n//数值类型List\nscala&gt; val nums=List(1,2,3,4,5)\nnums: List[Int] = List(1, 2, 3, 4, 5)\n\n//多重List，List的子元素为List\nscala&gt; val list = List(List(1, 2, 3), List(&quot;adfa&quot;, &quot;asdfa&quot;, &quot;asdf&quot;))\nlist: List[List[Any]] = List(List(1, 2, 3), List(adfa, asdfa, asdf))\n\n//遍历List\nscala&gt; for(i &lt;- list; from=i; j&lt;-from)println(j)\n1\n2\n3\nadfa\nasdfa\nasdf</code></pre><p>（2）List与Array的区别：</p>\n<pre><code>1、List一旦创建，已有元素的值不能改变，可以使用添加元素或删除元素生成一个新的集合返回。\n如前面的nums，改变其值的话，编译器就会报错。而Array就可以成功\n\nscala&gt;nums(3)=4\n&lt;console&gt;:10: error: value update is not a member of List[Int]\n              nums(3)=4\n              ^\n2、List具有递归结构(Recursive Structure),例如链表结构\nList类型和气他类型集合一样，它具有协变性(Covariant),即对于类型S和T，如果S是T的子类型，则List[S]也是List[T]的子类型。\n例如:\n\nscala&gt;var listStr:List[Object] = List(&quot;This&quot;, &quot;Is&quot;, &quot;Covariant&quot;, &quot;Example&quot;)\nlistStr:List[Object] = List(This, Is, Covariant, Example)\n\n//空的List,其类行为Nothing,Nothing在Scala的继承层次中的最底层\n//,即Nothing是任何Scala其它类型如String,Object等的子类\nscala&gt; var listStr = List()\nlistStr:List[Nothing] = List()\n\nscala&gt;var listStr:List[String] = List()\nlistStr:List[String] = List()</code></pre><p>（3）List常用构造方法</p>\n<pre><code>//1、常用::及Nil进行列表构建\nscala&gt; val nums = 1 :: (2:: (3:: (4 :: Nil)))\nnums: List[Int] = List(1, 2, 3, 4)\n\n\n//由于::操作符的优先级是从右向左的，因此上一条语句等同于下面这条语句\nscala&gt; val nums = 1::2::3::4::Nil\nnums:List[Int] = List(1, 2, 3, 4)\n至于::操作符的使用将在下面介绍</code></pre><p>（4）List常用操作</p>\n<pre><code>//判断是否为空\nscala&gt; nums.isEmpty\nres5: Boolean = false\n\n//取第一个元素\nscala&gt; nums.head\nres6: Int = 1\n\n//取列表第二个元素\nscala&gt;nums.tail.head\nres7: Int = 2\n\n//取第三个元素\nscala&gt;nums.tail.tail.head\nres8: Int = 3\n\n//插入操作\n//在第二个位置插入一个元素\nscala&gt;nums.head::(3::nums.tail)\nres11: List[Int] = List(1, 3, 2, 3, 4)\n\nscala&gt; nums.head::(nums.tail.head::(4::nums.tail.tail))\nres12: List[Int] = List(1, 2, 4, 3, 4)\n\n//插入排序算法实现\ndef isort(xs: List[Int]):List[Int] = {\n    if(xs.isEmpty) Nil\n    else insert(xs.head, issort(xs.tail))\n}\n\ndef insert(x:Int, xs:List[Int]):List[Int] = {\n    if(xs.isEmpty || x &lt;= xs.head) x::xs\n    else xs.head :: insert(x, xs.tail)\n}\n\n//连接操作\nscala&gt;List(1, 2, 3):::List(4, 5, 6)\nres13: List[Int] = List(1, 2, 3, 4, 5, 6)\n\n//去除最后一个元素外的元素，返回的是列表\nscala&gt; nums.init\nres13: List[Int] = List(1, 2, 3)\n\n//取出列表最后一个元素\nscala&gt;nums.last\nres14: Int = 4\n\n//列表元素倒置\nscala&gt; nums.reverse\nres15: List[Int] = List(4, 3, 2, 1)\n\n//一些好玩的方法调用\nscala&gt; nums.reverse.reverse == nums\n\n\n//丢弃前面n个元素\nscala&gt;nums drop 3\nres16: List[Int] = List(4)\n\n//获取前面n个元素\nscala&gt;nums take 1\nres17: List[Int] = List[1]\n\n//将列表进行分割\nscala&gt; nums.splitAt(2)\nres18: (List[Int], List[Int]) = (List(1, 2),List(3, 4))\n\n//前一个操作与下列语句等同\nscala&gt; (nums.take(2),nums.drop(2))\nres19: (List[Int], List[Int]) = (List(1, 2),List(3, 4))\n\n//Zip操作\nscala&gt; val nums=List(1,2,3,4)\nnums: List[Int] = List(1, 2, 3, 4)\n\nscala&gt; val chars=List(&#39;1&#39;,&#39;2&#39;,&#39;3&#39;,&#39;4&#39;)\nchars: List[Char] = List(1, 2, 3, 4)\n\n//返回的是List类型的元组(Tuple），返回的元素个数与最小的List集合的元素个数一样\nscala&gt; nums zip chars\nres20: List[(Int, Char)] = List((1,1), (2,2), (3,3), (4,4))\n\n//List toString方法\nscala&gt; nums.toString\nres21: String = List(1, 2, 3, 4)\n\n//List mkString方法\nscala&gt; nums.mkString\nres22: String = 1234\n\n//转换成数组\nscala&gt; nums.toArray\nres23: Array[Int] = Array(1, 2, 3, 4)</code></pre><p>（5）List伴生对象方法</p>\n<pre><code>//apply方法\nscala&gt;  List.apply(1, 2, 3)\nres24: List[Int] = List(1, 2, 3)\n\n//range方法，构建某一值范围内的List\nscala&gt;  List.range(2, 6)\nres25: List[Int] = List(2, 3, 4, 5)\n\n//步长为2\nscala&gt;  List.range(2, 6,2)\nres26: List[Int] = List(2, 4)\n\n//步长为-1\nscala&gt;  List.range(2, 6,-1)\nres27: List[Int] = List()\n\nscala&gt;  List.range(6,2 ,-1)\nres28: List[Int] = List(6, 5, 4, 3)\n\n//构建相同元素的List\nscala&gt; List.make(5, &quot;hey&quot;)\nres29: List[String] = List(hey, hey, hey, hey, hey)\n\n//unzip方法\nscala&gt; List.unzip(res20)\nres30: (List[Int], List[Char]) = (List(1, 2, 3, 4),List(1, 2, 3, 4))\n\n//list.flatten，将列表平滑成第一个无素\nscala&gt; val xss =\n     | List(List(&#39;a&#39;, &#39;b&#39;), List(&#39;c&#39;), List(&#39;d&#39;, &#39;e&#39;))\nxss: List[List[Char]] = List(List(a, b), List(c), List(d, e))\nscala&gt; xss.flatten\nres31: List[Char] = List(a, b, c, d, e)\n\n//列表连接\nscala&gt; List.concat(List(&#39;a&#39;, &#39;b&#39;), List(&#39;c&#39;))\nres32: List[Char] = List(a\n, b, c)</code></pre><p>（6）::和:::操作符介绍</p>\n<pre><code>List中常用&#39;::&#39;,发音为&quot;cons&quot;。Cons把一个新元素组合到已有元素的最前端，然后返回结果List。\n\nscala&gt; val twoThree = List(2, 3)\nscala&gt; val oneTwoThree = 1 :: twoThree\nscala&gt; oneTwoThree\noneTwoThree: List[Int] = List(1, 2, 3)\n上面表达式&quot;1::twoThree&quot;中，::是右操作数，列表twoThree的方法。可能会有疑惑。表达式怎么是右边参数的方法，这是Scala语言的一个例外的情况:如果一个方法操作符标注，如a * b,那么方法被左操作数调用，就像a.* (b)--除非方法名以冒号结尾。这种情况下，方法被右操作数调用。\nList有个方法叫&quot;:::&quot;，用于实现叠加两个列表。\n\nscala&gt; val one = List(&#39;A&#39;, &#39;B&#39;)\nval one = List(&#39;A&#39;, &#39;B&#39;)\nscala&gt; val two = List(&#39;C&#39;, &#39;D&#39;)\n\nscala&gt; one:::two\nres1: List[Char] = List(A, B, C, D)</code></pre><p>创建列表</p>\n<pre><code>scala&gt; val days = List(&quot;Sunday&quot;, &quot;Monday&quot;, &quot;Tuesday&quot;, &quot;Wednesday&quot;, &quot;Thursday&quot;, &quot;Friday&quot;, &quot;Saturday&quot;)\ndays: List[String] = List(Sunday, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday)</code></pre><p>创建空列表</p>\n<pre><code>scala&gt; val l = Nil //scala.collection.immutable.Nil继承了List[Nothing]  这是空列表\nl: scala.collection.immutable.Nil.type = List()\n\nscala&gt; val l = List()\nl: List[Nothing] = List()</code></pre><p>用字符串创建列表</p>\n<pre><code>scala&gt; val l = &quot;Hello&quot; :: &quot;Hi&quot; :: &quot;Hah&quot; :: &quot;WOW&quot; :: &quot;WOOW&quot; :: Nil\nl: List[String] = List(Hello, Hi, Hah, WOW, WOOW)</code></pre><p>用“:::”叠加创建新列表</p>\n<pre><code>scala&gt; val wow = l ::: List(&quot;WOOOW&quot;, &quot;WOOOOW&quot;)\nwow: List[String] = List(Hello, Hi, Hah, WOW, WOOW, WOOOW, WOOOOW)</code></pre><p>通过索引获取列表值</p>\n<pre><code>scala&gt; l(3)\nres0: String = WOW</code></pre><p>获取值长度为3的元素数目</p>\n<pre><code>scala&gt; l.count(s =&gt; s.length == 3)\nres1: Int = 2</code></pre><p>返回去掉l头两个元素的新列表</p>\n<pre><code>scala&gt; l.drop(2)\nres2: List[String] = List(Hah, WOW, WOOW)\n\nscala&gt; l\nres3: List[String] = List(Hello, Hi, Hah, WOW, WOOW)</code></pre><p>返回去掉l后两个元素的新列表</p>\n<pre><code>scala&gt; l.dropRight(2)\nres5: List[String] = List(Hello, Hi, Hah)\n\nscala&gt; l\nres6: List[String] = List(Hello, Hi, Hah, WOW, WOOW)</code></pre><p>判断l是否存在某个元素</p>\n<pre><code>scala&gt; l.exists(s =&gt; s == &quot;Hah&quot;)\nres7: Boolean = true</code></pre><p>滤出长度为3的元素</p>\n<pre><code>scala&gt; l.filter(s =&gt; s.length == 3)\nres8: List[String] = List(Hah, WOW)</code></pre><p>判断所有元素是否以“H”打头</p>\n<pre><code>scala&gt; l.forall(s =&gt; s.startsWith(&quot;H&quot;))\nres10: Boolean = false</code></pre><p>判断所有元素是否以“H”结尾</p>\n<pre><code>scala&gt; l.forall(s =&gt; s.endsWith(&quot;W&quot;))\nres11: Boolean = false</code></pre><p>打印每个元素</p>\n<pre><code>scala&gt; l.foreach(s =&gt; print(s + &#39; &#39;))\nHello Hi Hah WOW WOOW</code></pre><p>取出第一个元素</p>\n<pre><code>scala&gt; l.head\nres17: String = Hello</code></pre><p>取出最后一个元素</p>\n<pre><code>scala&gt; l.last\nres20: String = WOOW</code></pre><p>剔除最后一个元素，生成新列表</p>\n<pre><code>scala&gt; l.init\nres18: List[String] = List(Hello, Hi, Hah, WOW)</code></pre><p>剔除第一个元素，生成新列表</p>\n<pre><code>scala&gt; l.tail\nres49: List[String] = List(Hi, Hah, WOW, WOOW)</code></pre><p>判断列表是否为空</p>\n<pre><code>scala&gt; l.isEmpty\nres19: Boolean = false</code></pre><p>获得列表长度</p>\n<pre><code>scala&gt; l.length\nres21: Int = 5</code></pre><p>修改每个元素，再反转每个元素形成新列表</p>\n<pre><code>scala&gt; l.map(s =&gt; {val s1 = s + &quot; - 01&quot;; s1.reverse})\nres29: List[String] = List(10 - olleH, 10 - iH, 10 - haH, 10 - WOW, 10 - WOOW)</code></pre><p>生成用逗号隔开的字符串</p>\n<pre><code>scala&gt; l.mkString(&quot;, &quot;)\nres30: String = Hello, Hi, Hah, WOW, WOOW</code></pre><p>反序生成新列表</p>\n<pre><code>scala&gt; l.reverse\nres41: List[String] = List(WOOW, WOW, Hah, Hi, Hello)</code></pre><p>按字母递增排序</p>\n<pre><code>scala&gt; l.sortWith(_.compareTo(_) &lt; 0)\nres48: List[String] = List(Hah, Hello, Hi, WOOW, WOW)</code></pre><p><strong>List定义的方法</strong></p>\n<pre><code>def  ++[B &gt;: A, That](that: GenTraversableOnce[B])(implicit bf: CanBuildFrom[List[A], B, That]): That\nReturns a new list containing the elements from the left hand operand followed by the elements from the right hand operand.</code></pre><pre><code>def  ++:[B &gt;: A, That](that: collection.Traversable[B])(implicit bf: CanBuildFrom[List[A], B, That]): That\nAs with ++, returns a new collection containing the elements from the left operand followed by the elements from the right operand.</code></pre><pre><code>def  ++:[B](that: TraversableOnce[B]): List[B]\n[use case] As with ++, returns a new collection containing the elements from the left operand followed by the elements from the right operand.</code></pre><pre><code>def  +:(elem: A): List[A]\n[use case]\nA copy of the list with an element prepended.\n\nNote that :-ending operators are right associative (see example). A mnemonic for +: vs. :+ is: the COLon goes on the COLlection side.\n\nAlso, the original list is not modified, so you will want to capture the result.\n\nExample:\n\nscala&gt; val x = List(1)\nx: List[Int] = List(1)\n\nscala&gt; val y = 2 +: x\ny: List[Int] = List(2, 1)\n\nscala&gt; println(x)\nList(1)\nelem\nthe prepended element\nreturns\na new list consisting of elem followed by all elements of this list.</code></pre><pre><code>def inition Classes\nList → SeqLike → GenSeqLike\n Full Signature</code></pre><pre><code>def  /:[B](z: B)(op: (B, A) ⇒ B): B\nApplies a binary operator to a start value and all elements of this traversable or iterator, going left to right.</code></pre><pre><code>def  :+(elem: A): List[A]\n[use case] A copy of this list with an element appended.</code></pre><pre><code>def  ::(x: A): List[A]\n[use case] Adds an element at the beginning of this list.</code></pre><pre><code>def  :::(prefix: List[A]): List[A]\n[use case] Adds the elements of a given list in front of this list.</code></pre><pre><code>def  :\\[B](z: B)(op: (A, B) ⇒ B): B\nApplies a binary operator to all elements of this traversable or iterator and a start value, going right to left.</code></pre><pre><code>def  addString(b: StringBuilder): StringBuilder\nAppends all elements of this traversable or iterator to a string builder.</code></pre><pre><code>def  addString(b: StringBuilder, sep: String): StringBuilder\nAppends all elements of this traversable or iterator to a string builder using a separator string.</code></pre><pre><code>def  addString(b: StringBuilder, start: String, sep: String, end: String): StringBuilder\nAppends all elements of this traversable or iterator to a string builder using start, end, and separator strings.</code></pre><pre><code>def  aggregate[B](z: ⇒ B)(seqop: (B, A) ⇒ B, combop: (B, B) ⇒ B): B\nAggregates the results of applying an operator to subsequent elements.</code></pre><pre><code>def  andThen[C](k: (A) ⇒ C): PartialFunction[Int, C]\nComposes this partial function with a transformation function that gets applied to results of this partial function.</code></pre><pre><code>def  apply(n: Int): A\nSelects an element by its index in the sequence.</code></pre><pre><code>def  applyOrElse[A1 &lt;: Int, B1 &gt;: A](x: A1, ```</code></pre><p>def ault: (A1) ⇒ B1): B1<br>Applies this partial function to the given argument when it is contained in the function domain.</p>\n<pre><code></code></pre><p>def  canEqual(that: Any): Boolean<br>Method called from equality methods, so that user-```</p>\n<pre><code>def ined subclasses can refuse to be equal to other collections of the same kind.\nfinal ```</code></pre><p>def  collect[B](pf: PartialFunction[A, B]): List[B]<br>[use case] Builds a new collection by applying a partial function to all elements of this list on which the function is ```</p>\n<pre><code>def ined.</code></pre><pre><code>def  collectFirst[B](pf: PartialFunction[A, B]): Option[B]\nFinds the first element of the traversable or iterator for which the given partial function is ```</code></pre><p>def ined, and applies the partial function to it.</p>\n<pre><code></code></pre><p>def  combinations(n: Int): Iterator[List[A]]<br>Iterates over combinations.</p>\n<pre><code></code></pre><p>def  companion: GenericCompanion[List]<br>The factory companion object that builds instances of class List.</p>\n<pre><code></code></pre><p>def  compose[A](g: (A) ⇒ Int): (A) ⇒ A<br>Composes two instances of Function1 in a new Function1, with this function applied last.</p>\n<pre><code></code></pre><p>def  contains[A1 &gt;: A](elem: A1): Boolean<br>Tests whether this sequence contains a given value as an element.</p>\n<pre><code></code></pre><p>def  containsSlice[B](that: GenSeq[B]): Boolean<br>Tests whether this sequence contains a given sequence as a slice.</p>\n<pre><code></code></pre><p>def  copyToArray(xs: Array[A], start: Int, len: Int): Unit<br>[use case] Copies the elements of this list to an array.</p>\n<pre><code></code></pre><p>def  copyToArray(xs: Array[A]): Unit<br>[use case] Copies the elements of this list to an array.</p>\n<pre><code></code></pre><p>def  copyToArray(xs: Array[A], start: Int): Unit<br>[use case] Copies the elements of this list to an array.</p>\n<pre><code></code></pre><p>def  copyToBuffer[B &gt;: A](dest: Buffer[B]): Unit<br>Copies all elements of this traversable or iterator to a buffer.<br>final ```</p>\n<pre><code>def  corresponds[B](that: GenSeq[B])(p: (A, B) ⇒ Boolean): Boolean\nTests whether every element of this sequence relates to the corresponding element of another sequence by satisfying a test predicate.</code></pre><pre><code>def  count(p: (A) ⇒ Boolean): Int\nCounts the number of elements in the traversable or iterator which satisfy a predicate.</code></pre><pre><code>def  diff(that: collection.Seq[A]): List[A]\n[use case] Computes the multiset difference between this list and another sequence.</code></pre><pre><code>def  distinct: List[A]\nBuilds a new sequence from this sequence without any duplicate elements.</code></pre><pre><code>def  drop(n: Int): List[A]\nSelects all elements except first n ones.</code></pre><pre><code>def  dropRight(n: Int): List[A]\nSelects all elements except last n ones.\nfinal ```</code></pre><p>def  dropWhile(p: (A) ⇒ Boolean): List[A]<br>Drops longest prefix of elements that satisfy a predicate.</p>\n<pre><code></code></pre><p>def  endsWith[B](that: GenSeq[B]): Boolean<br>Tests whether this sequence ends with the given sequence.</p>\n<pre><code></code></pre><p>def  equals(that: Any): Boolean<br>The equals method for arbitrary sequences.</p>\n<pre><code></code></pre><p>def  exists(p: (A) ⇒ Boolean): Boolean<br>Tests whether a predicate holds for at least one element of this sequence.</p>\n<pre><code></code></pre><p>def  filter(p: (A) ⇒ Boolean): List[A]<br>Selects all elements of this traversable collection which satisfy a predicate.</p>\n<pre><code></code></pre><p>def  filterNot(p: (A) ⇒ Boolean): List[A]<br>Selects all elements of this traversable collection which do not satisfy a predicate.</p>\n<pre><code></code></pre><p>def  find(p: (A) ⇒ Boolean): Option[A]<br>Finds the first element of the sequence satisfying a predicate, if any.<br>final ```</p>\n<pre><code>def  flatMap[B](f: (A) ⇒ GenTraversableOnce[B]): List[B]\n[use case] Builds a new collection by applying a function to all elements of this list and using the elements of the resulting collections.</code></pre><pre><code>def  flatten[B]: List[B]\n[use case] Converts this list of traversable collections into a list formed by the elements of these traversable collections.</code></pre><pre><code>def  fold[A1 &gt;: A](z: A1)(op: (A1, A1) ⇒ A1): A1\nFolds the elements of this traversable or iterator using the specified associative binary operator.</code></pre><pre><code>def  foldLeft[B](z: B)(op: (B, A) ⇒ B): B\nApplies a binary operator to a start value and all elements of this sequence, going left to right.</code></pre><pre><code>def  foldRight[B](z: B)(op: (A, B) ⇒ B): B\nApplies a binary operator to all elements of this list and a start value, going right to left.</code></pre><pre><code>def  forall(p: (A) ⇒ Boolean): Boolean\nTests whether a predicate holds for all elements of this sequence.\nfinal ```</code></pre><p>def  foreach(f: (A) ⇒ Unit): Unit<br>[use case] Applies a function f to all elements of this list.</p>\n<pre><code></code></pre><p>def  genericBuilder[B]: Builder[B, List[B]]<br>The generic builder that builds instances of Traversable at arbitrary element types.</p>\n<pre><code></code></pre><p>def  groupBy[K](f: (A) ⇒ K): Map[K, List[A]]<br>Partitions this traversable collection into a map of traversable collections according to some discriminator function.</p>\n<pre><code></code></pre><p>def  grouped(size: Int): Iterator[List[A]]<br>Partitions elements in fixed size iterable collections.</p>\n<pre><code></code></pre><p>def  has```</p>\n<pre><code>def initeSize: Boolean\nTests whether this traversable collection is known to have a finite size.</code></pre><pre><code>def  hashCode(): Int\nHashcodes for Seq produce a value from the hashcodes of all the elements of the sequence.</code></pre><pre><code>def  head: A\nSelects the first element of this iterable collection.</code></pre><pre><code>def  headOption: Option[A]\nOptionally selects the first element.</code></pre><pre><code>def  indexOf(elem: A, from: Int): Int\n[use case] Finds index of first occurrence of some value in this list after or at some start index.</code></pre><pre><code>def  indexOf(elem: A): Int\n[use case] Finds index of first occurrence of some value in this list.</code></pre><pre><code>def  indexOfSlice[B &gt;: A](that: GenSeq[B], from: Int): Int\nFinds first index after or at a start index where this sequence contains a given sequence as a slice.</code></pre><pre><code>def  indexOfSlice[B &gt;: A](that: GenSeq[B]): Int\nFinds first index where this sequence contains a given sequence as a slice.</code></pre><pre><code>def  indexWhere(p: (A) ⇒ Boolean, from: Int): Int\nFinds index of the first element satisfying some predicate after or at some start index.</code></pre><pre><code>def  indexWhere(p: (A) ⇒ Boolean): Int\nFinds index of first element satisfying some predicate.</code></pre><pre><code>def  indices: Range\nProduces the range of all indices of this sequence.</code></pre><pre><code>def  init: List[A]\nSelects all elements except the last.</code></pre><pre><code>def  inits: Iterator[List[A]]\nIterates over the inits of this traversable collection.</code></pre><pre><code>def  intersect(that: collection.Seq[A]): List[A]\n[use case] Computes the multiset intersection between this list and another sequence.</code></pre><pre><code>def  is```</code></pre><p>def inedAt(x: Int): Boolean<br>Tests whether this sequence contains given index.</p>\n<pre><code></code></pre><p>def  isEmpty: Boolean<br>Tests whether this sequence is empty.<br>final ```</p>\n<pre><code>def  isTraversableAgain: Boolean\nTests whether this traversable collection can be repeatedly traversed.</code></pre><pre><code>def  iterator: Iterator[A]\nCreates a new iterator over all elements contained in this iterable object.</code></pre><pre><code>def  last: A\nSelects the last element.</code></pre><pre><code>def  lastIndexOf(elem: A, end: Int): Int\n[use case] Finds index of last occurrence of some value in this list before or at a given end index.</code></pre><pre><code>def  lastIndexOf(elem: A): Int\n[use case] Finds index of last occurrence of some value in this list.</code></pre><pre><code>def  lastIndexOfSlice[B &gt;: A](that: GenSeq[B], end: Int): Int\nFinds last index before or at a given end index where this sequence contains a given sequence as a slice.</code></pre><pre><code>def  lastIndexOfSlice[B &gt;: A](that: GenSeq[B]): Int\nFinds last index where this sequence contains a given sequence as a slice.</code></pre><pre><code>def  lastIndexWhere(p: (A) ⇒ Boolean, end: Int): Int\nFinds index of last element satisfying some predicate before or at given end index.</code></pre><pre><code>def  lastIndexWhere(p: (A) ⇒ Boolean): Int\nFinds index of last element satisfying some predicate.</code></pre><pre><code>def  lastOption: Option[A]\nOptionally selects the last element.</code></pre><pre><code>def  length: Int\nThe length of the sequence.</code></pre><pre><code>def  lengthCompare(len: Int): Int\nCompares the length of this sequence to a test value.</code></pre><pre><code>def  lift: (Int) ⇒ Option[A]\nTurns this partial function into a plain function returning an Option result.\nfinal ```</code></pre><p>def  map[B](f: (A) ⇒ B): List[B]<br>[use case] Builds a new collection by applying a function to all elements of this list.<br>final ```</p>\n<pre><code>def  mapConserve(f: (A) ⇒ A): List[A]\n[use case] Builds a new list by applying a function to all elements of this list.</code></pre><pre><code>def  max: A\n[use case] Finds the largest element.</code></pre><pre><code>def  maxBy[B](f: (A) ⇒ B): A\n[use case] Finds the first element which yields the largest value measured by function f.</code></pre><pre><code>def  min: A\n[use case] Finds the smallest element.</code></pre><pre><code>def  minBy[B](f: (A) ⇒ B): A\n[use case] Finds the first element which yields the smallest value measured by function f.</code></pre><pre><code>def  mkString: String\nDisplays all elements of this traversable or iterator in a string.</code></pre><pre><code>def  mkString(sep: String): String\nDisplays all elements of this traversable or iterator in a string using a separator string.</code></pre><pre><code>def  mkString(start: String, sep: String, end: String): String\nDisplays all elements of this traversable or iterator in a string using start, end, and separator strings.</code></pre><pre><code>def  nonEmpty: Boolean\nTests whether the traversable or iterator is not empty.</code></pre><pre><code>def  orElse[A1 &lt;: Int, B1 &gt;: A](that: PartialFunction[A1, B1]): PartialFunction[A1, B1]\nComposes this partial function with a fallback partial function which gets applied where this partial function is not ```</code></pre><p>def ined.</p>\n<pre><code></code></pre><p>def  padTo(len: Int, elem: A): List[A]<br>[use case] A copy of this list with an element value appended until a given target length is reached.</p>\n<pre><code></code></pre><p>def  par: ParSeq[A]<br>Returns a parallel implementation of this collection.</p>\n<pre><code></code></pre><p>def  partition(p: (A) ⇒ Boolean): (List[A], List[A])<br>Partitions this traversable collection in two traversable collections according to a predicate.</p>\n<pre><code></code></pre><p>def  patch(from: Int, that: GenSeq[A], replaced: Int): List[A]<br>[use case] Produces a new list where a slice of elements in this list is replaced by another sequence.</p>\n<pre><code></code></pre><p>def  permutations: Iterator[List[A]]<br>Iterates over distinct permutations.</p>\n<pre><code></code></pre><p>def  prefixLength(p: (A) ⇒ Boolean): Int<br>Returns the length of the longest prefix whose elements all satisfy some predicate.</p>\n<pre><code></code></pre><p>def  product: A<br>[use case] Multiplies up the elements of this collection.</p>\n<pre><code></code></pre><p>def  productIterator: scala.Iterator[Any]<br>An iterator over all the elements of this product.</p>\n<pre><code></code></pre><p>def  productPrefix: String<br>A string used in the toString methods of derived classes.</p>\n<pre><code></code></pre><p>def  reduce[A1 &gt;: A](op: (A1, A1) ⇒ A1): A1<br>Reduces the elements of this traversable or iterator using the specified associative binary operator.</p>\n<pre><code></code></pre><p>def  reduceLeft[B &gt;: A](op: (B, A) ⇒ B): B<br>Applies a binary operator to all elements of this sequence, going left to right.</p>\n<pre><code></code></pre><p>def  reduceLeftOption[B &gt;: A](op: (B, A) ⇒ B): Option[B]<br>Optionally applies a binary operator to all elements of this traversable or iterator, going left to right.</p>\n<pre><code></code></pre><p>def  reduceOption[A1 &gt;: A](op: (A1, A1) ⇒ A1): Option[A1]<br>Reduces the elements of this traversable or iterator, if any, using the specified associative binary operator.</p>\n<pre><code></code></pre><p>def  reduceRight[B &gt;: A](op: (A, B) ⇒ B): B<br>Applies a binary operator to all elements of this sequence, going right to left.</p>\n<pre><code></code></pre><p>def  reduceRightOption[B &gt;: A](op: (A, B) ⇒ B): Option[B]<br>Optionally applies a binary operator to all elements of this traversable or iterator, going right to left.</p>\n<pre><code></code></pre><p>def  repr: List[A]<br>The collection of type traversable collection underlying this TraversableLike object.</p>\n<pre><code></code></pre><p>def  reverse: List[A]<br>Returns new list with elements in reversed order.</p>\n<pre><code></code></pre><p>def  reverseIterator: Iterator[A]<br>An iterator yielding elements in reversed order.</p>\n<pre><code></code></pre><p>def  reverseMap[B](f: (A) ⇒ B): List[B]<br>[use case] Builds a new collection by applying a function to all elements of this list and collecting the results in reversed order.</p>\n<pre><code></code></pre><p>def  reverse_:::(prefix: List[A]): List[A]<br>[use case] Adds the elements of a given list in reverse order in front of this list.</p>\n<pre><code></code></pre><p>def  runWith[U](action: (A) ⇒ U): (Int) ⇒ Boolean<br>Composes this partial function with an action function which gets applied to results of this partial function.</p>\n<pre><code></code></pre><p>def  sameElements(that: GenIterable[A]): Boolean<br>[use case] Checks if the other iterable collection contains the same elements in the same order as this list.</p>\n<pre><code></code></pre><p>def  scan[B &gt;: A, That](z: B)(op: (B, B) ⇒ B)(implicit cbf: CanBuildFrom[List[A], B, That]): That<br>Computes a prefix scan of the elements of the collection.</p>\n<pre><code></code></pre><p>def  scanLeft[B, That](z: B)(op: (B, A) ⇒ B)(implicit bf: CanBuildFrom[List[A], B, That]): That<br>Produces a collection containing cumulative results of applying the operator going left to right.</p>\n<pre><code></code></pre><p>def  scanRight[B, That](z: B)(op: (A, B) ⇒ B)(implicit bf: CanBuildFrom[List[A], B, That]): That<br>Produces a collection containing cumulative results of applying the operator going right to left.</p>\n<pre><code></code></pre><p>def  segmentLength(p: (A) ⇒ Boolean, from: Int): Int<br>Computes length of longest segment whose elements all satisfy some predicate.</p>\n<pre><code></code></pre><p>def  seq: LinearSeq[A]<br>A version of this collection with all of the operations implemented sequentially (i.e., in a single-threaded manner).</p>\n<pre><code></code></pre><p>def  size: Int<br>The size of this sequence, equivalent to length.</p>\n<pre><code></code></pre><p>def  slice(from: Int, until: Int): List[A]</p>\n<pre><code></code></pre><p>def  sliding(size: Int, step: Int): Iterator[List[A]]<br>Groups elements in fixed size blocks by passing a “sliding window” over them (as opposed to partitioning them, as is done in grouped.)</p>\n<pre><code></code></pre><p>def  sliding(size: Int): Iterator[List[A]]<br>Groups elements in fixed size blocks by passing a “sliding window” over them (as opposed to partitioning them, as is done in grouped.) The “sliding window” step is set to one.</p>\n<pre><code></code></pre><p>def  sortBy[B](f: (A) ⇒ B)(implicit ord: math.Ordering[B]): List[A]<br>Sorts this Seq according to the Ordering which results from transforming an implicitly given Ordering with a transformation function.</p>\n<pre><code></code></pre><p>def  sortWith(lt: (A, A) ⇒ Boolean): List[A]<br>Sorts this sequence according to a comparison function.</p>\n<pre><code></code></pre><p>def  sorted[B &gt;: A](implicit ord: math.Ordering[B]): List[A]<br>Sorts this sequence according to an Ordering.<br>final ```</p>\n<pre><code>def  span(p: (A) ⇒ Boolean): (List[A], List[A])\nSplits this list into a prefix/suffix pair according to a predicate.</code></pre><pre><code>def  splitAt(n: Int): (List[A], List[A])\nSplits this list into two at a given position.</code></pre><pre><code>def  startsWith[B](that: GenSeq[B], offset: Int): Boolean\nTests whether this sequence contains the given sequence at a given index.</code></pre><pre><code>def  startsWith[B](that: GenSeq[B]): Boolean\nTests whether this general sequence starts with the given sequence.</code></pre><pre><code>def  stringPrefix: String</code></pre><pre><code>def ines the prefix of this object&#39;s toString representation.</code></pre><pre><code>def  sum: A\n[use case] Sums up the elements of this collection.</code></pre><pre><code>def  tail: List[A]\nSelects all elements except the first.</code></pre><pre><code>def  tails: Iterator[List[A]]\nIterates over the tails of this traversable collection.</code></pre><pre><code>def  take(n: Int): List[A]\nSelects first n elements.</code></pre><pre><code>def  takeRight(n: Int): List[A]\nSelects last n elements.\nfinal ```</code></pre><p>def  takeWhile(p: (A) ⇒ Boolean): List[A]<br>Takes longest prefix of elements that satisfy a predicate.</p>\n<pre><code></code></pre><p>def  to[Col[_]]: Col[A]<br>[use case] Converts this list into another by copying all elements.</p>\n<pre><code></code></pre><p>def  toArray: Array[A]<br>[use case] Converts this list to an array.</p>\n<pre><code></code></pre><p>def  toBuffer[B &gt;: A]: Buffer[B]<br>Uses the contents of this traversable or iterator to create a new mutable buffer.</p>\n<pre><code></code></pre><p>def  toIndexedSeq: IndexedSeq[A]<br>Converts this traversable or iterator to an indexed sequence.</p>\n<pre><code></code></pre><p>def  toIterable: collection.Iterable[A]<br>Returns this iterable collection as an iterable collection.</p>\n<pre><code></code></pre><p>def  toIterator: Iterator[A]<br>Returns an Iterator over the elements in this iterable collection.</p>\n<pre><code></code></pre><p>def  toList: List[A]<br>Converts this list to a list.</p>\n<pre><code></code></pre><p>def  toMap[T, U]: collection.Map[T, U]<br>[use case] Converts this list to a map.</p>\n<pre><code></code></pre><p>def  toParArray: ParArray[T]</p>\n<pre><code></code></pre><p>def  toSeq: Seq[A]<br>Converts this immutable sequence to a sequence.</p>\n<pre><code></code></pre><p>def  toSet[B &gt;: A]: Set[B]<br>Converts this traversable or iterator to a set.</p>\n<pre><code></code></pre><p>def  toStream: Stream[A]<br>Converts this list to a stream.</p>\n<pre><code></code></pre><p>def  toString(): String<br>Converts this sequence to a string.</p>\n<pre><code></code></pre><p>def  toTraversable: collection.Traversable[A]<br>Converts this traversable collection to an unspecified Traversable.</p>\n<pre><code></code></pre><p>def  toVector: scala.Vector[A]<br>Converts this traversable or iterator to a Vector.</p>\n<pre><code></code></pre><p>def  transpose[B](implicit asTraversable: (A) ⇒ GenTraversableOnce[B]): List[List[B]]<br>Transposes this collection of traversable collections into a collection of collections.</p>\n<pre><code></code></pre><p>def  union(that: collection.Seq[A]): List[A]<br>[use case] Produces a new sequence which contains all elements of this list and also all elements of a given sequence.</p>\n<pre><code></code></pre><p>def  unzip[A1, A2](implicit asPair: (A) ⇒ (A1, A2)): (List[A1], List[A2])<br>Converts this collection of pairs into two collections of the first and second half of each pair.</p>\n<pre><code></code></pre><p>def  unzip3[A1, A2, A3](implicit asTriple: (A) ⇒ (A1, A2, A3)): (List[A1], List[A2], List[A3])<br>Converts this collection of triples into three collections of the first, second, and third element of each triple.</p>\n<pre><code></code></pre><p>def  updated(index: Int, elem: A): List[A]<br>[use case] A copy of this list with one single replaced element.</p>\n<pre><code></code></pre><p>def  view(from: Int, until: Int): SeqView[A, List[A]]<br>Creates a non-strict view of a slice of this sequence.</p>\n<pre><code></code></pre><p>def  view: SeqView[A, List[A]]<br>Creates a non-strict view of this sequence.</p>\n<pre><code></code></pre><p>def  withFilter(p: (A) ⇒ Boolean): FilterMonadic[A, List[A]]<br>Creates a non-strict filter of this traversable collection.</p>\n<pre><code></code></pre><p>def  zip[B](that: GenIterable[B]): List[(A, B)]<br>[use case] Returns a list formed from this list and another iterable collection by combining corresponding elements in pairs.</p>\n<pre><code></code></pre><p>def  zipAll[B](that: collection.Iterable[B], thisElem: A, thatElem: B): List[(A, B)]<br>[use case] Returns a list formed from this list and another iterable collection by combining corresponding elements in pairs.</p>\n<pre><code></code></pre><p>def  zipWithIndex: List[(A, Int)]<br>[use case] Zips this list with its indices.</p>\n<pre><code>\n</code></pre><h2 id=\"七-Map的常见方法汇总\"><a href=\"#七-Map的常见方法汇总\" class=\"headerlink\" title=\"七.Map的常见方法汇总\"></a>七.Map的常见方法汇总</h2><p>（1）不可变Map</p>\n<pre><code>var a:Map[String,Int]=Map(&quot;k1&quot;-&gt;1,&quot;k2&quot;-&gt;2)//初始化构造函数\na += (&quot;k3&quot;-&gt;3)//添加元素\na += (&quot;k4&quot;-&gt;4)//添加元素\na += (&quot;k1&quot;-&gt;100)//已经存在添加元素会覆盖\na -= (&quot;k2&quot;,&quot;k1&quot;)//删除元素    //a(&quot;k1&quot;) = &quot;foo&quot;//不支持\nprintln(a.contains(&quot;k6&quot;))//是否包含某元素\nprintln(a.size)//打印大小\nprintln(a.get(&quot;k1&quot;).getOrElse(&quot;default&quot;)) //根据key读取元素，不存在就替换成默认值\na.foreach{case (e,i) =&gt; println(e,i)} //遍历打印1\nfor( (k,v)&lt;-a ) println(k,v) //遍历打印2\nprintln(a.isEmpty)//判断是否为空\na.keys.foreach(println)//只打印key\na.values.foreach(println)//只打印value\n\na=Map()//数据清空使用再次new\nprintln(a.size)\na.toSeq.sortBy(_._1)//升序排序 key\na.toSeq.sortBy(_._2)//升序排序 value\na.toSeq.sortWith(_._1&gt;_._1) //降序排序 key\na.toSeq.sortWith(_._2&gt;_._2) //降序排序 value\n\n//下面自定义按英文字母或数字排序\nimplicit  val KeyOrdering=new Ordering[String] {\n      override def compare(x: String, y: String): Int = {\n        x.compareTo(y)\n      }\n}\nprintln(a.toSeq.sorted)</code></pre><p>2）可变Map例子</p>\n<pre><code>var a:scala.collection.mutable.Map[String,Int]=scala.collection.mutable.Map(&quot;k1&quot;-&gt;1,&quot;k2&quot;-&gt;2)//初始化构造函数\n  a += (&quot;k3&quot;-&gt;3)//添加元素\n  a += (&quot;k4&quot;-&gt;4)//添加元素\n  a += (&quot;k1&quot;-&gt;100)//已经存在添加元素会覆盖\n  a += (&quot;k1&quot;-&gt;100,&quot;k9&quot;-&gt;9)//添加多个元素\n  a -= (&quot;k2&quot;,&quot;k1&quot;)//删除元素\n  a ++= List(&quot;CA&quot; -&gt; 23, &quot;CO&quot; -&gt; 25)//追加集合\n  a --= List(&quot;AL&quot;, &quot;AZ&quot;)//删除集合\n\n  a.retain((k,v)=&gt; k==&quot;k1&quot;)//只保留等于k1元素，其他的删除\n  a.put(&quot;put1&quot;,200)//put\n  a.remove(&quot;k2&quot;)//remove\n  a.clear()//清空\n  a(&quot;k3&quot;)=100//支持\n\n  println(a.contains(&quot;k6&quot;))//是否包含某元素\n  println(a.size)//打印大小\n  println(a.get(&quot;k1&quot;).getOrElse(&quot;default&quot;)) //根据key读取元素，不存在就替换成默认值\n  a.foreach{case (e,i) =&gt; println(e,i)} //遍历打印1\n  for( (k,v)&lt;-a ) println(k,v) //遍历打印2\n  println(a.isEmpty)//判断是否为空\n  a.keys.foreach(println)//只打印key\n  a.values.foreach(println)//只打印value\n  a=scala.collection.mutable.Map()//引用能变\n  println(a.size)\n  a.toSeq.sortBy(_._1)//排序 key\n  a.toSeq.sortBy(_._2)//排序 value\n  a.toSeq.sortWith(_._1&gt;_._1) //降序排序 key\n  a.toSeq.sortWith(_._2&gt;_._2) //降序排序 value\n\n//下面自定义按英文字母或数字排序\n  implicit  val KeyOrdering=new Ordering[String] {\n    override def compare(x: String, y: String): Int = {\n      x.compareTo(y)\n    }\n  }\n  println(a.toSeq.sorted)\n}</code></pre><p>默认情况下，Scala使用不可变映射(Map)。如果要使用可变集合(Set)，则必须明确导入scala.collection.mutable.Map类。如果想同时使用可变的和不可变映射(Map)，那么可以继续引用不可变映射(Map)，但是可以将mutable集合引用mutable.Map。<br>以下是声明不可变映射(Map)的示例声明<br>集合基本操作</p>\n<pre><code>scala&gt; val colors = Map(&quot;red&quot; -&gt; &quot;#FF0000&quot;, &quot;azure&quot; -&gt; &quot;#F0FFFF&quot;, &quot;peru&quot; -&gt; &quot;#CD853F&quot;)\ncolors: scala.collection.immutable.Map[String,String] = Map(red -&gt; #FF0000, azure -&gt; #F0FFFF, peru -&gt; #CD853F)\n\nscala&gt; val nums: Map[Int, Int] = Map()\nnums: Map[Int,Int] = Map()\n\nscala&gt;println( &quot;Keys in colors : &quot; + colors.keys )\nKeys in colors : Set(red, azure, peru)\n\nscala&gt;println( &quot;Values in colors : &quot; + colors.values )\nValues in colors : MapLike(#FF0000, #F0FFFF, #CD853F)\n\nscala&gt;println( &quot;Check if colors is empty : &quot; + colors.isEmpty )\nCheck if colors is empty : false\n\nscala&gt;println( &quot;Check if nums is empty : &quot; + nums.isEmpty )\nCheck if nums is empty : true</code></pre><p>连接映射</p>\n<pre><code>scala&gt;val colors1 = Map(&quot;red&quot; -&gt; &quot;#FF0000&quot;, &quot;azure&quot; -&gt; &quot;#F0FFFF&quot;, &quot;peru&quot; -&gt; &quot;#CD853F&quot;)\ncolors1: scala.collection.immutable.Map[String,String] = Map(red -&gt; #FF0000, azure -&gt; #F0FFFF, peru -&gt; #CD853F)\n\nscala&gt;val colors2 = Map(&quot;blue&quot; -&gt; &quot;#0033FF&quot;, &quot;yellow&quot; -&gt; &quot;#FFFF00&quot;, &quot;red&quot; -&gt; &quot;#FF0000&quot;)\ncolors2: scala.collection.immutable.Map[String,String] = Map(blue -&gt; #0033FF, yellow -&gt; #FFFF00, red -&gt; #FF0000)\n\nscala&gt;var colors = colors1 ++ colors2\ncolors: scala.collection.immutable.Map[String,String] = Map(blue -&gt; #0033FF, azure -&gt; #F0FFFF, peru -&gt; #CD853F, yellow -&gt; #FFFF00, red -&gt; #FF0000)\n\nscala&gt;println( &quot;colors1 ++ colors2 : &quot; + colors )\ncolors1 ++ colors2 : Map(blue -&gt; #0033FF, azure -&gt; #F0FFFF, peru -&gt; #CD853F, yellow -&gt; #FFFF00, red -&gt; #FF0000)\n\nscala&gt;colors = colors1.++(colors2)\ncolors: scala.collection.immutable.Map[String,String] = Map(blue -&gt; #0033FF, azure -&gt; #F0FFFF, peru -&gt; #CD853F, yellow -&gt; #FFFF00, red -&gt; #FF0000)\n\nscala&gt;println( &quot;colors1.++(colors2)) : &quot; + colors )\ncolors1.++(colors2)) : Map(blue -&gt; #0033FF, azure -&gt; #F0FFFF, peru -&gt; #CD853F, yellow -&gt; #FFFF00, red -&gt; #FF0000)\n</code></pre><p>打印映射的键和值</p>\n<pre><code>val colors = Map(&quot;red&quot; -&gt; &quot;#FF0000&quot;, &quot;azure&quot; -&gt; &quot;#F0FFFF&quot;,&quot;peru&quot; -&gt; &quot;#CD853F&quot;)\ncolors.keys.foreach{ i =&gt;  \n    print( &quot;Key = &quot; + i )\n    println(&quot; Value = &quot; + colors(i) )}\n}\n\nKey = red Value = #FF0000\nKey = azure Value = #F0FFFF\nKey = peru Value = #CD853F</code></pre><p>查找检查映射中的键</p>\n<pre><code>val colors = Map(&quot;red&quot; -&gt; &quot;#FF0000&quot;, &quot;azure&quot; -&gt; &quot;#F0FFFF&quot;, &quot;peru&quot; -&gt; &quot;#CD853F&quot;)\nif( colors.contains( &quot;red&quot; )) {\n    println(&quot;Red key exists with value :&quot;  + colors(&quot;red&quot;))\n} else {\n    println(&quot;Red key does not exist&quot;)\n}\nif( colors.contains( &quot;maroon&quot; )) {\n    println(&quot;Maroon key exists with value :&quot;  + colors(&quot;maroon&quot;))\n} else {\n    println(&quot;Maroon key does not exist&quot;)\n}</code></pre><p>scala - Map基础<br>构造Map:不可变：</p>\n<pre><code>val map = Map(&quot;sa&quot; -&gt; 1, &quot;s&quot; -&gt; 2)\nmap(&quot;sa&quot;) = 3 // error\nval emptyMap = new scala.collection.immutable.HashMap[String, Int]</code></pre><p>可变：</p>\n<pre><code>val map2 = scala.collection.mutable.Map(&quot;sa&quot; -&gt; 2)\nmap2(&quot;sa&quot;) = 3\nval emptyMap = new scala.collection.mutable.HashMap[String, Int]</code></pre><p>注：-&gt;用来创建元组， “sa” -&gt; 1即(“sa”, 1) 初始化完全可以 val map = Map((“sa”, 1), (“s”, 2))<br>获取Map中的值：</p>\n<pre><code>如果map中不包含请求中使用的key值，则抛异常。NoSuchElementException\nmap(&quot;sa&quot;) // 类似于java中的map.get(&quot;sa&quot;)</code></pre><p>要检查map中是否包含某个key，使用contains方法。</p>\n<pre><code>val sa = if (map2.contains(&quot;sa3&quot;)) map2(&quot;sa3&quot;) else 0;\n快捷的方式：\nval sa2 = map.getOrElse(&quot;sa2&quot;, 0)\n一次得到是否包含key，并获取值：\nval sa3 = map.get(&quot;sa3&quot;); // Option类型，\nprintln(sa3.isEmpty)</code></pre><p>更新Map中的值：</p>\n<pre><code>添加或更新：map(&quot;sa&quot;) = 3\n添加或更新多个：map += (&quot;aa&quot; -&gt; 4, &quot;bb&quot; -&gt; 5)</code></pre><p>移除某个key和对应的值：</p>\n<pre><code>map -= &quot;aa&quot;\n不可变的map也可以使用+和-操作，但是会生成新的map\nvar map = Map(&quot;aa&quot; -&gt; 1)\nmap = map + (&quot;bb&quot; -&gt; 2)\nmap += (&quot;cc&quot; -&gt; 2)\nmap -= &quot;aa&quot;</code></pre><p>迭代map：</p>\n<pre><code>for ((k, v) &lt;- map) {\n\n}\n所有key：map.keySet\n所有值：map.values\n反转：map2 = for((k, v) &lt;- map) yield (v, k)</code></pre><p>已排序Map：<br>按key排序：SortedMap<br>按添加顺序：LinkedHashMap<br>Map与Java互操作：<br>Java Properties转为scala.collection.Map：</p>\n<pre><code>import scala.collection.JavaConversions.propertiesAsScalaMap\nval prop: scala.collection.Map[String, String] = System.getProperties();</code></pre><p>Java Map转为scala.collection.mutable.Map[String, Int]：</p>\n<pre><code>import scala.collection.JavaConversions.mapAsScalaMap\nval map: scala.collection.mutable.Map[String, Int] = new TreeMap[String, Int]</code></pre><p>Scala Map转为Java Map:</p>\n<pre><code>import scala.collection.JavaConversions.mapAsJavaMap\nimport java.awt.font.TextAttribute._\nvar fs = Map(FAMILY -&gt; &quot;Serif&quot;, SIZE -&gt; 12)\nvar fonts = new Font(fs)</code></pre><p><strong>Map的操作方法</strong></p>\n<pre><code>def ++(xs: Map[(A, B)]): Map[A, B]\n返回一个新的 Map，新的 Map xs 组成</code></pre><pre><code>def -(elem1: A, elem2: A, elems: A*): Map[A, B]\n返回一个新的 Map, 移除 key 为 elem1, elem2 或其他 elems。</code></pre><pre><code>def --(xs: GTO[A]): Map[A, B]\n返回一个新的 Map, 移除 xs 对象中对应的 key</code></pre><pre><code>def get(key: A): Option[B]\n返回指定 key 的值</code></pre><pre><code>def iterator: Iterator[(A, B)]\n创建新的迭代器，并输出 key/value 对</code></pre><pre><code>def addString(b: StringBuilder): StringBuilder\n将 Map 中的所有元素附加到StringBuilder，可加入分隔符</code></pre><pre><code>def addString(b: StringBuilder, sep: String): StringBuilder\n将 Map 中的所有元素附加到StringBuilder，可加入分隔符</code></pre><pre><code>def apply(key: A): B\n返回指定键的值，如果不存在返回 Map 的默认方法</code></pre><pre><code>def clear(): Unit\n清空 Map</code></pre><pre><code>def clone(): Map[A, B]\n从一个 Map 复制到另一个 Map</code></pre><pre><code>def contains(key: A): Boolean\n如果 Map 中存在指定 key，返回 true，否则返回 false。</code></pre><pre><code>def copyToArray(xs: Array[(A, B)]): Unit\n复制集合到数组</code></pre><pre><code>def count(p: ((A, B)) =&gt; Boolean): Int\n计算满足指定条件的集合元素数量</code></pre><pre><code>def default(key: A): B\n定义 Map 的默认值，在 key 不存在时返回。</code></pre><pre><code>def drop(n: Int): Map[A, B]\n返回丢弃前n个元素新集合</code></pre><pre><code>def dropRight(n: Int): Map[A, B]\n返回丢弃最后n个元素新集合</code></pre><pre><code>def dropWhile(p: ((A, B)) =&gt; Boolean): Map[A, B]\n从左向右丢弃元素，直到条件p不成立</code></pre><pre><code>def empty: Map[A, B]\n返回相同类型的空 Map</code></pre><pre><code>def equals(that: Any): Boolean\n如果两个 Map 相等(key/value 均相等)，返回true，否则返回false</code></pre><pre><code>def exists(p: ((A, B)) =&gt; Boolean): Boolean\n判断集合中指定条件的元素是否存在</code></pre><pre><code>def filter(p: ((A, B))=&gt; Boolean): Map[A, B]\n返回满足指定条件的所有集合</code></pre><pre><code>def filterKeys(p: (A) =&gt; Boolean): Map[A, B]\n返回符合指定条件的的不可变 Map</code></pre><pre><code>def find(p: ((A, B)) =&gt; Boolean): Option[(A, B)]\n查找集合中满足指定条件的第一个元素</code></pre><pre><code>def foreach(f: ((A, B)) =&gt; Unit): Unit\n将函数应用到集合的所有元素</code></pre><pre><code>def init: Map[A, B]\n返回所有元素，除了最后一个</code></pre><pre><code>def isEmpty: Boolean\n检测 Map 是否为空</code></pre><pre><code>def keys: Iterable[A]\n返回所有的key/p&gt;</code></pre><pre><code>def last: (A, B)\n返回最后一个元素</code></pre><pre><code>def max: (A, B)\n查找最大元素</code></pre><pre><code>def min: (A, B)\n查找最小元素</code></pre><pre><code>def mkString: String\n集合所有元素作为字符串显示</code></pre><pre><code>def product: (A, B)\n返回集合中数字元素的积。</code></pre><pre><code>def remove(key: A): Option[B]\n移除指定 key</code></pre><pre><code>def retain(p: (A, B) =&gt; Boolean): Map.this.type\n如果符合满足条件的返回 true</code></pre><pre><code>def size: Int\n返回 Map 元素的个数</code></pre><pre><code>def sum: (A, B)\n返回集合中所有数字元素之和</code></pre><pre><code>def tail: Map[A, B]\n返回一个集合中除了第一元素之外的其他元素</code></pre><pre><code>def take(n: Int): Map[A, B]\n返回前 n 个元素</code></pre><pre><code>def takeRight(n: Int): Map[A, B]\n返回后 n 个元素</code></pre><pre><code>def takeWhile(p: ((A, B)) =&gt; Boolean): Map[A, B]\n返回满足指定条件的元素</code></pre><pre><code>def toArray: Array[(A, B)]\n集合转数组</code></pre><pre><code>def toBuffer[B &gt;: A]: Buffer[B]\n返回缓冲区，包含了 Map 的所有元素</code></pre><pre><code>def toList: List[A]\n返回 List，包含了 Map 的所有元素</code></pre><pre><code>def toSeq: Seq[A]\n返回 Seq，包含了 Map 的所有元素</code></pre><pre><code>def toSet: Set[A]\n返回 Set，包含了 Map 的所有元素</code></pre><pre><code>def toString(): String\n返回字符串对象</code></pre><h2 id=\"八-类的定义及构造器\"><a href=\"#八-类的定义及构造器\" class=\"headerlink\" title=\"八.类的定义及构造器\"></a>八.类的定义及构造器</h2><p><strong>类和对象之基础</strong></p>\n<p><strong>定义</strong></p>\n<p>Scala 中以 class 来作为类的声明，在类中可以定义成员和方法，成员和方法可以有不同的可见性（这个会在后文详述）</p>\n<pre><code>scala&gt; class Company {\n     |   private var employeeCount = 0\n     |   def getEmployeeCount(): Int = employeeCount\n     |   def setEmployeeCount( count: Int)= {\n     |     employeeCount = count\n     |   }\n     |\n     |   def m( i: Int ) {}\n     |   def m( str: String ) {}\n     | }\ndefined class Company</code></pre><p><strong>构造器</strong></p>\n<p>Scala 中，类有一个主构造器，主构造器必须包含所需的所有参数。除了一个主构造器，还可以有0个或多个辅助构造器，辅助构造器又称次构造器。辅助构造器命名为 this，其第一条语句必须调用主构造器或其他辅助构造器，来看下面的例子：</p>\n<pre><code>scala&gt; class T ( x1: Int, y1: String, z1: Double ) {\n     |   private val xx1 = x1\n     |   private val yy1 = y1\n     |   private val zz1 = z1\n     |\n     |   def this ( x1: Int, y1: String ) {\n     |     this( x1, y1, 1.0 )\n     |   }\n     |\n     |   def this ( x1: Int ) {\n     |     this( x1, &quot;&quot; )\n     |   }\n     | }\ndefined class T</code></pre><p>还有一点需要注意的是，被调用的辅助构造函数的定义必须放在主动调用的辅助构造函数前面，不然会报错：</p>\n<pre><code>scala&gt; class T ( x1: Int, y1: String, z1: Double ) {\n     |   private val xx1 = x1\n     |   private val yy1 = y1\n     |   private val zz1 = z1\n     |\n     |   def this ( x1: Int ) {\n     |     this( x1, &quot;&quot; )\n     |   }\n     |\n     |   def this ( x1: Int, y1: String ) {\n     |     this( x1, y1, 1.0 )\n     |   }\n     | }\n&lt;console&gt;:13: error: called constructor&#39;s definition must precede calling constructor&#39;s definition\n           this( x1, &quot;&quot; )\n           ^</code></pre><p>不管辅助函数调来调去，最终都还是要调用到主构造函数，这确保了新实例的初始化逻辑一致。</p>\n<p>如果在主构造函数的参数前加 var 或 val，该参数就成为实例的一个成员，这部分知识在Scala case class那些你不知道的知识有更详细的介绍</p>\n<p><strong>重载</strong></p>\n<p>Scala 类方法允许重载，如类 Company 中的 m 方法。重载要求参数列表和返回类型不完全相同，但参数名可相同，这是因为编译后是通过方法名、参数列表、返回类型综合来区分各个方法的。</p>\n<p>在方法重载时，有一点需要注意：对于『高级类型』，存在类型擦除机制，所谓的高级类型就是包含类型参数的类型，比如 List[A]，下面这个例子可以展示了类型擦除：</p>\n<pre><code>scala&gt; class Tmp {\n     |   def m( data: List[Int] ) {}\n     |   def m( data: List[String] ) {}\n     | }\n&lt;console&gt;:9: error: double definition:\nmethod m:(data: List[String])Unit and\nmethod m:(data: List[Int])Unit at line 8\nhave same type after erasure: (data: List)Unit\n         def m( data: List[String] ) {}\n             ^</code></pre><p>报了有相同类型的参数的错误。</p>\n<p><strong>类型成员</strong></p>\n<p>Scala 允许你在类内部定义类型成员，在构造类实例的时候指定该类型成员对应的具体类型。类型成员可用于类内部的成员或函数，提供了更好的泛华能力，从下面这个简单的例子可以看出：</p>\n<pre><code>scala&gt; class T {\n     |   type X\n     |\n     |   def getClassName( x: X): String = {\n     |     x.getClass.getTypeName\n     |   }\n     | }\ndefined class T\n\nscala&gt; val x1 = new T{ type X = Int }\nx1: T{type X = Int} = $anon$1@515f550a\n\nscala&gt; x1.getClassName(10)\nres0: String = java.lang.Integer\n\nscala&gt; val x2 = new T{ type X = String }\nx2: T{type X = String} = $anon$1@61a52fbd\n\nscala&gt; x2.getClassName(&quot;string&quot;)\nres1: String = java.lang.String</code></pre><p>当然，也可以在类外部定义类型变量，如：</p>\n<pre><code>scala&gt; type L = List[Int]\ndefined type alias L</code></pre><p><strong>方法与成员同名</strong></p>\n<p>与 JAVA 不同，如果方法参数列表不为空，该方法可以与成员同名，如：</p>\n<pre><code>scala&gt; class T {\n     |   private val m = 0\n     |\n     |   def m( i: Int ): Int = m + i\n     | }\ndefined class T\n</code></pre><h2 id=\"九-类和对象之进阶（一）\"><a href=\"#九-类和对象之进阶（一）\" class=\"headerlink\" title=\"九.类和对象之进阶（一）\"></a>九.类和对象之进阶（一）</h2><p> 1、Scala中的类是公有可见性的，且多个类可以包含在同一个源文件中；</p>\n<pre><code>class Counter{\n    private var value = 0　　//类成员变量必须初始化，否则报错\n    def increment(){    //类中的方法默认是公有可见性\n        value += 1\n    }\n    def current() = value //对于类中的“取值方法”，在定义时可省略掉括号，直接 def current = value\n}</code></pre><p>继承</p>\n<p>只能有一个父类</p>\n<p>与其他支持面向对象的语言一样，Scala 也支持继承，并且子类只能有一个父类，不能继承于多个父类，如果希望实现类似继承多个父类的功能，应该考虑引入 trait。虽然只支持一个父类，但是父类还可以有父类，也就是爷爷类，对于类继承的层数是没有具体要求的，这几点在下面这个例子中都有体现：</p>\n<pre><code>scala&gt; class A {\n     | }\ndefined class A\n\nscala&gt; class B {\n     | }\ndefined class B\n\nscala&gt; class AA extends A {\n     | }\ndefined class AA\n\nscala&gt; class AB extends A with B {\n     | }\n&lt;console&gt;:9: error: class B needs to be a trait to be mixed in\n       class AB extends A with B {\n                               ^\n\nscala&gt; class AAA extends AA {\n     | }\ndefined class AAA\n\nscala&gt; class AAAA extends AAA {\n     | }\ndefined class AAAA</code></pre><p>都继承了什么</p>\n<p>子类继承父类时都会继承些什么呢，这里结合可见性（可见性的详细内容会在下文介绍）进行分析，先定义这样一组父子类：</p>\n<pre><code>scala&gt; class Parent ( x: Int, y: String, z: Double ) {\n     |   val xx = x\n     |   protected val yy = y\n     |   private val zz = z\n     |\n     |   def getXX = xx\n     |   protected def getYY = yy\n     |   private def getZZ = zz\n     |\n     |   def testYY = yy\n     |   def testZZ = zz\n     |   def testGetYY = getYY\n     |   def testGetZZ = getZZ\n     | }\ndefined class Parent</code></pre><p>在 Scala 类继承中，允许在子类内部直接访问父类的 public 及 protected 成员及方法，但不允许子类直接访问父类的 private 成员及方法，如下例：</p>\n<pre><code>scala&gt; class Child1 ( x: Int, y: String, z: Double ) extends Parent(x, y, z ) {\n     |   println( xx )\n     |   println( yy )\n     |   println( getXX )\n     |   println( getYY )\n     | }\ndefined class Child1\n\nscala&gt; class Child2 ( x: Int, y: String, z: Double ) extends Parent(x, y, z ) {\n     |   println( zz )\n     |   println( getZZ )\n     | }\n&lt;console&gt;:9: error: value zz in class Parent cannot be accessed in Child2\n         println( zz )\n                  ^\n&lt;console&gt;:10: error: method getZZ in class Parent cannot be accessed in Child2\n         println( getZZ )\n                  ^</code></pre><p>在类外部，只有 public 的方法和成员能被直接访问，protected 及 private 均不予许：</p>\n<pre><code>scala&gt; class Child3 ( x: Int, y: String, z: Double ) extends Parent(x, y, z ) {\n     | }\ndefined class Child3\n\nscala&gt; val child = new Child3( 1, &quot;hello&quot;, 3.1415926 )\nchild: Child3 = Child3@39529185\n\nscala&gt; child.xx\nres6: Int = 1\n\nscala&gt; child.yy\n&lt;console&gt;:11: error: value yy in class Parent cannot be accessed in Child3\n Access to protected value yy not permitted because\n enclosing object $iw is not a subclass of\n class Parent where target is defined\n              child.yy\n                    ^\n\nscala&gt; child.zz\n&lt;console&gt;:11: error: value zz in class Parent cannot be accessed in Child3\n              child.zz\n                    ^\n\nscala&gt;\n\nscala&gt; child.getXX\nres9: Int = 1\n\nscala&gt; child.getYY\n&lt;console&gt;:11: error: method getYY in class Parent cannot be accessed in Child3\n Access to protected method getYY not permitted because\n enclosing object $iw is not a subclass of\n class Parent where target is defined\n              child.getYY\n                    ^\n\nscala&gt; child.getZZ\n&lt;console&gt;:11: error: method getZZ in class Parent cannot be accessed in Child3\n              child.getZZ\n                    ^</code></pre><p>但我们可以通过父类提供的方法来间接访问 protected 和 private 的成员和方法：</p>\n<pre><code>scala&gt; child.testYY\nres20: String = hello\n\nscala&gt; child.testZZ\nres21: Double = 3.1415926\n\nscala&gt; child.testGetYY\nres22: String = hello\n\nscala&gt; child.testGetZZ\nres23: Double = 3.1415926</code></pre><p>单例对象</p>\n<p>在 Scala 中，使用关键字 object 来定义单例对象：</p>\n<pre><code>scala&gt; object T {}\ndefined module T</code></pre><p>单例对象将在其首次被调用时初始化，且没有参数。单例对象一旦定义完毕，它的名字就代表了该单例对象的唯一实例。</p>\n<p>当单例对象与某个类的名字相同且两者定义在同一文件中，就形成了特殊的单例对象-伴生对象，对应的类称为伴生类，若单例没有相同名字的类的话成为孤立对象（好惨）。我们经常使用在伴生对象中对应 apply 方法来创建新的伴生类实例并且将半身列的可见性设置为 private，以便能方便的创建伴生类实例，更重要的是可以在伴生类对象中管理所有伴生类实例，例子如下：</p>\n<pre><code>class Q ( qParam: String ) {\n  private val q = qParam\n}\n\nobject Q {\n  private val qList = ListBuffer[ Q ]()\n\n  def apply( qParam: String ) {\n    val qInstance = new Q( qParam )\n    qList.append( qInstance )\n    qInstance\n  }\n\n  def qListSize = qList.size\n}\n\nobject Test {\n  def main (args: Array[String]) {\n    val qIns1 = Q( &quot;q1&quot; )\n    val qIns2 = Q( &quot;q2&quot; )\n    println( Q.qListSize )\n  }\n}</code></pre><p>输出：</p>\n<pre><code>2</code></pre><p>另外伴生对象与伴生类可以互相访问 private 成员和方法，object 也可以继承父类或混入特质</p>\n<h2 id=\"十-类和对象之进阶（二）\"><a href=\"#十-类和对象之进阶（二）\" class=\"headerlink\" title=\"十.类和对象之进阶（二）\"></a>十.类和对象之进阶（二）</h2><p>Scala 中的可见性非常灵活且复杂，这篇文章希望通过大量的示例来说清楚各种情况下的可见性是怎么样的。<br>默认可见性<br>Scala 中的默认可见性为 public，所谓默认即你没有在类或者成员前显示加 private 或 protected 可见性关键字。虽然默认可见性为 public，但这是逻辑上的，实际上 Scala 中并没有 public 这个关键字，如果你用 public 来声明一个类或成员，编译器会报错。<br>可见性作用域<br>在 Scala 中，可以在类型的 class 或 trait 关键字之前、字段的 val 或 var 之前，方法定义的 def 关键字之前指定可见性。<br>公有可见性<br>对于公有可见性，任何作用域内都可以访问公有成员或公有类型。<br>Protected 可见性<br>对于受保护可见性，用 protected 声明，受保护成员对本类型、继承类型可见。而受保护的类型则只对包含该类的包内可见。<br>下面例子是关于 protected 成员的：</p>\n<pre><code>package P1 {\n  class C1 {\n    protected val c = 0\n\n    //&lt; 受保护可见性中,嵌套类可访问 protected 成员\n    class C11 {\n      println( c )\n    }\n  }\n\n  package P11 {\n    //&lt; 继承类客房为父类 protected 成员\n    class C1Child extends C1 {\n      println( c )\n    }\n  }\n\n}\n\npackage P2 {\n  //&lt; 继承类客房为父类 protected 成员\n  class C2Child extends P1.C1 {\n    println( c )\n  }\n}</code></pre><p>接下来是 protected 类型的：</p>\n<pre><code>package P1 {\n  protected class C1 {\n  }\n\n  //&lt; 对于 protected 类型,相同包内可见\n  class C1Child extends C1 {\n  }\n\n  package P11 {\n    //&lt; 对于 protected 类型,子包内可见\n    class C11Child extends C1 {\n    }\n  }\n}\n\npackage P2 {\n//&lt; 对于 protected 类型,外部包不可见\n  class C2Child extends P1.C1 {\n  }\n}</code></pre><p>编译报错如下，这是因为 protected 类型只在包含该类的包内可见</p>\n<pre><code>Error:(22, 28) class C1 in package P1 cannot be accessed in package P1\n Access to protected class C1 not permitted because\n enclosing package P2 is not a subclass of \n package P1 where target is defined\n  class C2Child extends P1.C1 {</code></pre><p>私有可见性</p>\n<p>私有可见性将实现细节完全隐藏起来，即便是继承类也无法访问这些细节。声明中包含了 private 关键字的所有成员只对该类可见，该类型的其他实例也能访问这些成员。如果类型被声明为私有可见性类型，那么该类型的可见性将仅限于包含该类型的包内</p>\n<pre><code>package P1 {\n  class C1 {\n    private val c = 0\n  }\n\n  //&lt; 对于 private 类型,相同包内的子类都不可见\n  class C1Child extends C1 {\n    println( c )\n  }\n}\n\npackage P2 {\n  //&lt; 对于 private 类型,外部包内的子类也不可见\n  class C2Child extends P1.C1 {\n    println( c )\n  }\n}</code></pre><p>编译报错：</p>\n<pre><code>Error:(12, 14) value c in class C1 cannot be accessed in P1.C1Child\n    println( c )\n             ^\n\nError:(19, 14) value c in class C1 cannot be accessed in P2.C2Child\n    println( c )\n             ^</code></pre><p>另外，嵌套类中的私有成员也是无法访问的。在私有可见性中，私有类型只在包含该类型的包中可见，在子包或外部包中均不可见。我们用下面的例子进一步说明，具体说明见代码中的注释：</p>\n<pre><code>package P1 {\n  private class C1\n\n  class C11 extends C1            //&lt; 错误,这样相当于变相改变了C1的可见性,子包和外部包都能访问C11,也就间接能访问C1\n  protected class C12 extends C1  //&lt; 错误这样相当于变相改变了C1的可见性,子包能访问C11,也就间接能访问C1\n  private class C13 extends C1    //&lt; 正确,由于C13也为 private,是的C1的 private 可见性不会\n\n  class C14 {\n    val c14_1 = new C1            //&lt; 正确,私有类型在其所在包内可见\n  }\n}\n\npackage P2 {\n\n  //&lt; 对于私有类型,外部包内不可见\n  class C2 {\n    val c1 = new P1.C1\n  }\n}</code></pre><p>编译报错：</p>\n<pre><code>Error:(8, 21) private class C1 escapes its defining scope as part of type P1.C1\n  class C11 extends C1            //&lt; 错误\n                    ^\n\nError:(9, 31) private class C1 escapes its defining scope as part of type P1.C1\n  protected class C12 extends C1  //&lt; 错误\n                              ^\n\nError:(22, 21) class C1 in package P1 cannot be accessed in package P1\n    val c1 = new P1.C1\n                    ^</code></pre><p>作用域内私有和作用域内受保护可见性</p>\n<p>所谓作用域内私有/受保护可见性，就是你可以更细粒度指定某个类或某个成员在某个作用域（可以是包或类）私有或受保护可见性</p>\n<p>成员在类和包中的 private/protected 可见性<br>该可见性可以有16种组合，下面的例子列举除了这些组合</p>\n<pre><code>package P1 {\n  class C1 {\n    private[C1] val m1 = 1\n    private[this] val m2 = 2\n    private[P1] val m3 = 3\n    private[P2] val m4 = 4\n\n    protected[C1] val n1 = 1\n    protected[this] val n2 = 2\n    protected[P1] val n3 = 3\n    protected[P2] val n4 = 4\n\n    //&lt; 不管什么样的作用域内 private 或 protected,在自身类中都是可见的\n    println( m1 )\n    println( m2 )\n    println( m3 )\n    println( m4 )\n\n    println( n1 )\n    println( n2 )\n    println( n3 )\n    println( n4 )\n  }\n\n  class C11 extends C1 {\n    println( m1 )   //&lt; 1, 错误\n    println( m2 )   //&lt; 2, 错误\n    println( m3 )   //&lt; 3, 正确\n    println( m4 )   //&lt; 4, 正确\n\n    println( n1 )   //&lt; 5, 正确\n    println( n2 )   //&lt; 6, 正确\n    println( n3 )   //&lt; 7, 正确\n    println( n4 )   //&lt; 8, 正确\n  }\n}\n\npackage P2 {\n  class C21 extends P1.C1 {\n    println( m1 )   //&lt; 9, 错误\n    println( m2 )   //&lt; 10, 错误\n    println( m3 )   //&lt; 11, 错误\n    println( m4 )   //&lt; 12, 正确\n\n    println( n1 )   //&lt; 13, 正确\n    println( n2 )   //&lt; 14, 正确\n    println( n3 )   //&lt; 15, 正确\n    println( n4 )   //&lt; 16, 正确\n  }\n}</code></pre><p>下面我们对每一项进行解释，并穿插介绍一些规则：</p>\n<p>private[C1]指定成员在自身类作用域 private，在该类所在的包内和包外均不可见（9也是这个道理）<br>private[this]比 private[C1]更加严格，前者只对相同实例可见，相同类的不同实例都不可见；而后者对相同类的不同实例也可见<br>private[P1]指定在包 P1 内 private，则在 P1 包中的类中均可见，而在 P1外的包均不可见<br>private[P2]指定在包 P2 内 private，则在包 P2 及该类所在包内均可见<br>protected[C1]指定在 C1 中 protected，则在 C1 所在包内的继承类及外部包内所在的继承类均可见</p>\n<p>类型在类和包中的 private/protected 可见性<br>类型的情况就会少一点：</p>\n<pre><code>package P1 {\n\n  private[P1] class C1\n  protected[P1] class C2\n\n  package P11 {\n    private[P1] class C3\n    protected[P1] class C4\n    private[P11] class C5\n    protected[P11] class C6\n  }\n\n\n  class C11 extends C1  //&lt; 1, 正确\n  class C12 extends C2  //&lt; 2, 正确\n\n  import P11._\n  class C13 extends C3  //&lt; 3, 正确\n  class C14 extends C4  //&lt; 4, 正确\n  class C15 extends C5  //&lt; 5, 错误\n  class C16 extends C6  //&lt; 6, 正确\n}\n\npackage P2 {\n  import P1._\n  import P1.P11._\n\n\n  class C21 extends C1  //&lt; 7, 错误\n  class C22 extends C2  //&lt; 8, 正确\n\n  class C23 extends C3  //&lt; 9, 错误\n  class C24 extends C4  //&lt; 10, 正确\n  class C25 extends C5  //&lt; 11, 错误\n  class C26 extends C6  //&lt; 12, 正确\n}</code></pre><p>从上面的例子我们可以得出以下结论：</p>\n<p>对于 private[package] 声明的类型，在 package 包内及 package 子包内可见；在外部包内不可见<br>对于 protected[package] 声明的类型，在 package 包内、package 子包内及外部包均可见<br>有包 package 的子包为 package1，对于 private[package1]，在 package1 包内、package1 子包及其父包即 package 内可见，在外部包不可见<br>有包 package 的子包为 package1，对于 protected[package1]，在 package1包内、package1子包、package1父包及外部包可见</p>\n<h2 id=\"十一-trait\"><a href=\"#十一-trait\" class=\"headerlink\" title=\"十一.trait\"></a>十一.trait</h2><p>这是我以前在知乎上看到关于类继承作用的回答，虽不完全正确，却十分明确的表达出了好的代码应避免类继承而尽量使用类组合。Scala 显然也非常赞同这一点，以至于有了 trait，又叫做特质。当我们定义特质时，应该要遵循这样的原则：一个 trait 只干一件事，如果要干多件事，就定义多个 trait，然后使用一个类来 extends 这些 traits</p>\n<p><strong>定义 trait</strong></p>\n<p>trait 的定义与 class 类似:</p>\n<pre><code>scala&gt; trait T {\n     | }\ndefined trait T</code></pre><p>当然，trait 可以包含成员和方法，并且：</p>\n<p>trait 中的成员可以仅声明，也可以声明并指定值<br>trait 中的方法可以有实现，也可以只有声明而没有实现</p>\n<pre><code>scala&gt; trait T {\n     |   val a: Int\n     |   val b: Int = 1\n     |\n     |   def getA(): Int\n     |   def getB() = b\n     | }\ndefined trait T</code></pre><p>对比而言，类一旦包含未定义的方法就必须声明为 abstract；而 Java 的接口中的方法是不能实现的，必须是抽象方法。如果 trait 既为实现它所声明的方法，也没有定义或声明其他成员，那么在字节码级别，该 trait 其实是接口是相同的</p>\n<p>另一个与类不同的是，trait 主构造函数不允许有参数列表，并且不允许为 trait 定义辅助构造函数</p>\n<p>混入多个 trait</p>\n<p>Scala 类只能有一个父类，但可以混入多个 trait，当要混入多个 traits 或已经继承了某个父类时，需要使用关键字 with，如下例：</p>\n<pre><code>scala&gt; trait T {\n     |   val a: Int\n     |   val b: Int = 1\n     |\n     |   def getA(): Int\n     |   def getB() = b\n     | }\ndefined trait T\n\nscala&gt;\n\nscala&gt; trait Q {\n     |   def currentTime: String = System.currentTimeMillis().toString\n     | }\ndefined trait Q\n\nscala&gt;\n\nscala&gt; class X extends T with Q {\n     |   override val a = 1\n     |   override def getA(): Int = a\n     | }\ndefined class X</code></pre><p>当类混入 trait 时，需要实现 trait 中为实现的成员和方法。要混入多个 trait 是为了保证『高内聚』，通俗说就是一个 trait 只干一件事，如果要干多件事，就定义多个 trait 然后混入它们</p>\n<p>当你继承的父类和混入的特质或混入的不同特质之间有同名方法时可能会有冲突，分为以下几种情况：</p>\n<p>trait 中的方法未实现：不会冲突</p>\n<pre><code>scala&gt; class C {\n     |   def a: String = &quot;a&quot;\n     | }\ndefined class C\n\nscala&gt;\n\nscala&gt; trait T {\n     |   def a: String\n     | }\ndefined trait T\n\nscala&gt;\n\nscala&gt; trait Q extends C with T {}\ndefined trait Q</code></pre><p>trait 中的方法实现了且与父类中的方法参数列表及返回类型相同：会冲突</p>\n<pre><code>scala&gt; class C {\n     |   def a: String = &quot;a&quot;\n     | }\ndefined class C\n\nscala&gt;\n\nscala&gt; trait T {\n     |   def a: String = &quot;&quot;\n     | }\ndefined trait T\n\nscala&gt;\n\nscala&gt; trait Q extends C with T {}\n&lt;console&gt;:9: error: trait Q inherits conflicting members:\n  method a in class C of type =&gt; String  and\n  method a in trait T of type =&gt; String\n(Note: this can be resolved by declaring an override in trait Q.)\n       trait Q extends C with T {}\n             ^</code></pre><p>trait 中的方法实现了且与父类中的参数列表相同，返回类型不同：会冲突</p>\n<pre><code>scala&gt; class C {\n     |   def a: String = &quot;a&quot;\n     | }\ndefined class C\n\nscala&gt;\n\nscala&gt; trait T {\n     |   def a: Int = 1\n     | }\ndefined trait T\n\nscala&gt;\n\nscala&gt; trait Q extends C with T {}\n&lt;console&gt;:9: error: trait Q inherits conflicting members:\n  method a in class C of type =&gt; String  and\n  method a in trait T of type =&gt; Int\n(Note: this can be resolved by declaring an override in trait Q.)\n       trait Q extends C with T {}\n             ^</code></pre><p>trait 中的方法实现了且与父类的参数列表不同，返回类型相同：不会冲突</p>\n<pre><code>scala&gt; class C {\n     |   def a: String = &quot;a&quot;\n     | }\ndefined class C\n\nscala&gt;\n\nscala&gt; trait T {\n     |   def a( i: Int ): String = i.toString\n     | }\ndefined trait T\n\nscala&gt;\n\nscala&gt; trait Q extends C with T {}\ndefined trait Q</code></pre><p><strong>trait 的继承</strong></p>\n<p>一个 trait 同样可以混入其他 trait 或继承类：</p>\n<pre><code>scala&gt; class C {\n     |   def currentTime: String = System.currentTimeMillis().toString\n     | }\ndefined class C\n\nscala&gt;\n\nscala&gt; trait T {\n     |   def random: Int\n     | }\ndefined trait T\n\nscala&gt;\n\nscala&gt; trait Q extends C with T {}\ndefined trait Q</code></pre><h2 id=\"十二-case-class样例类\"><a href=\"#十二-case-class样例类\" class=\"headerlink\" title=\"十二.case class样例类\"></a>十二.case class样例类</h2><p>当你声明了一个 case class，Scala 编译器为你做了这些：<br>创建 case class 和它的伴生 object<br>实现了 apply 方法让你不需要通过 new 来创建类实例</p>\n<pre><code>scala&gt; case class Person(lastname: String, firstname: String, birthYear: Int)\ndefined class Person\n\nscala&gt; val p = Person(&quot;Lacava&quot;, &quot;Alessandro&quot;, 1976)\np: Person = Person(Lacava,Alessandro,1976)</code></pre><p>默认为主构造函数参数列表的所有参数前加 val</p>\n<pre><code>scala&gt; println( p.lastname )\nLacava\n\nscala&gt; p.lastname = &quot;jhon&quot;\n&lt;console&gt;:10: error: reassignment to val\n   p.lastname = &quot;jhon&quot;\n              ^</code></pre><p>添加天然的 hashCode、equals 和 toString 方法。由于 == 在 Scala 中总是代表 equals，所以 case class 实例总是可比较的</p>\n<pre><code>scala&gt; val p_1 = new Person( &quot;Brown&quot;, &quot;John&quot;, 1969 )\np_1: Person = Person(Brown,John,1969)\n\nscala&gt;val p_2 = new Person( &quot;Lacave&quot;, &quot;Alessandro&quot;, 1976)\np_2: Person = Person(Lacave,Alessandro,1976)\n\nscala&gt; p_1.hashCode\nres1: Int = -1362628729\n\nscala&gt; p_1.toString\nres2: String = Person(Brown,John,1969)\n\nscala&gt; p_1.equals(p_2)\nres3: Boolean = false\n\nscala&gt; p_1 == p_2\nres4: Boolean = false</code></pre><p>生成一个 copy 方法以支持从实例 a 生成另一个实例 b，实例 b 可以指定构造函数参数与 a 一致或不一致</p>\n<pre><code>//&lt; 保留 lastname 一致，修改 firstname 和 birthYear\nscala&gt; val p_3 = p.copy(firstname = &quot;Michele&quot;, birthYear = 1972)\np_3: Person = Person(Lacava,Michele,1972)</code></pre><p>由于编译器实现了 unapply 方法，一个 case class 支持模式匹配</p>\n<pre><code>scala&gt; case class A( a: Int )\ndefined class A\n\nscala&gt; case class B( b: String )\ndefined class B\n\nscala&gt; def classMath( x: AnyRef ): Unit = {\n     |   x match {\n     |     case A(a) =&gt; println( &quot;A:&quot; + a )\n     |     case B(b) =&gt; println( &quot;B:&quot; + b )\n     |     case A =&gt; println( A.apply(100) )\n     |   }\n     | }\nclassMath: (x: AnyRef)Unit\n\nscala&gt; val a = A( 1 )\na: A = A(1)\n\nscala&gt; val b = B( &quot;b&quot; )\nb: B = B(b)\n\nscala&gt; classMath( a )\nA:1\n\nscala&gt; classMath( b )\nB:b</code></pre><p>也许你已经知道，在模式匹配中，当你的 case class 没有参数的时候，你是在使用 case object 而不是一个空参数列表的 case class</p>\n<pre><code>scala&gt; classMath( A )\nA(100)</code></pre><p>除了在模式匹配中使用之外，unapply 方法可以让你结构 case class 来提取它的字段，如：</p>\n<pre><code>scala&gt; val Person(lastname, _, _) = p\nlastname: String = Lacava</code></pre><p>case class 接收一个 tuple 作为参数，该 tuple 的元素类型与个数与某 case class 相同，那么可以将该tuple 作为 case class 的 tuple 方法参数来构造 case class 实例</p>\n<pre><code>scala&gt; val meAsTuple: (String, String, Int) = (&quot;Lacava&quot;, &quot;Alessandro&quot;, 1976)\nmeAsTuple: (String, String, Int) = (Lacava,Alessandro,1976)\n\nscala&gt; Person.tupled( meAsTuple )\nres2: Person = Person(Lacava,Alessandro,1976)</code></pre><p>相对用 tuple 来创建 case class 实例，还可以从 case class 实例中解构并提取出 tuple 对象</p>\n<pre><code>scala&gt; val transform: Person =&gt; Option[ (String, String, Int) ] = {\n |   Person.unapply _\n | }\ntransform: Person =&gt; Option[(String, String, Int)] = &lt;function1&gt;\n\nscala&gt; transform( p )\nres0: Option[(String, String, Int)] = Some((Lacava,Alessandro,1976))\n</code></pre><p><strong>另一种定义 case class 的方式</strong></p>\n<p>还有另一种很少人知道的定义 case class 的方式，如：</p>\n<pre><code>case class Person( lastname: String )( firstname: String, birthYear: Int )</code></pre><p>这种方式有点像偏函数，有两个参数列表，要注意的是，对这两个参数列表是区别对待的。上文提到的所有 case class 的特性在这种定义方式下只作用于第一个参数列表中的参数（比如在参数前自动加 val，模式匹配，copy 支持等等），第二个及之后的参数列表中的参数和普通的 class 参数列表参数无异。</p>\n<p>firstname和birthYear前不再自动添加 val，不再是类的成员</p>\n<pre><code>scala&gt; val p = Person(&quot;Lacava&quot;)(&quot;Alessandro&quot;, 1976)\np: Person = Person(Lacava)\n\nscala&gt; p.lastname\nres0: String = Lacava\n\nscala&gt; p.firstname\n&lt;console&gt;:11: error: value firstname is not a member of Person\n              p.firstname\n                ^\n\nscala&gt; p.birthYear\n&lt;console&gt;:11: error: value birthYear is not a member of Person\n              p.birthYear\n                ^</code></pre><p>copy 时，当不指定birthYear的值时，不会使用 p 中的birthYear，因为根本没这个值，会报错</p>\n<pre><code>scala&gt; p.copy()(firstname = &quot;Jhon&quot;)\n&lt;console&gt;:11: error: not enough arguments for method copy: (firstname: String, birthYear: Int)Person.\nUnspecified value parameter birthYear.\n              p.copy()(firstname = &quot;Jhon&quot;)</code></pre><p>equals 和 toString 方法也发生了改变：</p>\n<pre><code>scala&gt; val p_1 = Person(&quot;Lacava&quot;)(&quot;Jhon&quot;, 2001)\np_1: Person = Person(Lacava)\n\nscala&gt; p.equals(p_1)\nres9: Boolean = true\n\nscala&gt; p == p_1\nres10: Boolean = true\n\nscala&gt; println ( p.toString )\nPerson(Lacava)</code></pre><h2 id=\"十三-对象\"><a href=\"#十三-对象\" class=\"headerlink\" title=\"十三.对象\"></a>十三.对象</h2><p> 1、Scala中没有静态方法和静态字段，但是可以用object语法来实现类似的功能。对象定义了某个类的单个实例。</p>\n<p>Scala的object中可以用来实现类似的功能，用来存放工具函数或常量等。如</p>\n<pre><code>object Sequence{\n    private var next_num = 0\n    val threshold = 100\n\n    def getSequence() = {\n        next_num += 1\n        next_num\n    }\n}</code></pre><h2 id=\"十四-常用操作符\"><a href=\"#十四-常用操作符\" class=\"headerlink\" title=\"十四.常用操作符\"></a>十四.常用操作符</h2><p>一、常用操作符（操作符其实也是函数）</p>\n<p>++ ++[B](that: GenTraversableOnce[B]): List[B] 从列表的尾部添加另外一个列表<br>++: ++:[B &gt;: A, That](that: collection.Traversable[B])(implicit bf: CanBuildFrom[List[A], B, That]): That 在列表的头部添加一个列表<br>+: +:(elem: A): List[A] 在列表的头部添加一个元素<br>:+ :+(elem: A): List[A] 在列表的尾部添加一个元素<br>:: ::(x: A): List[A] 在列表的头部添加一个元素<br>::: :::(prefix: List[A]): List[A] 在列表的头部添加另外一个列表<br>:\\ :[B](z: B)(op: (A, B) ⇒ B): B 与foldRight等价</p>\n<p>val left = List(1,2,3)<br>val right = List(4,5,6)</p>\n<p>//以下操作等价<br>left ++ right   // List(1,2,3,4,5,6)<br>left ++: right  // List(1,2,3,4,5,6)<br>right.++:(left)    // Listval left = List(1,2,3)(1,2,3,4,5,6)<br>right.:::(left)  // List(1,2,3,4,5,6)</p>\n<p>//以下操作等价<br>0 +: left    //List(0,1,2,3)<br>left.+:(0)   //List(0,1,2,3)</p>\n<p>//以下操作等价<br>left :+ 4    //List(1,2,3,4)<br>left.:+(4)   //List(1,2,3,4)</p>\n<p>//以下操作等价<br>0 :: left      //List(0,1,2,3)<br>left.::(0)     //List(0,1,2,3)</p>\n<p>看到这里大家应该跟我一样有一点晕吧，怎么这么多奇怪的操作符，这里给大家一个提示，任何以冒号结果的操作符，都是右绑定的，即 0 :: List(1,2,3) = List(1,2,3).::(0) = List(0,1,2,3) 从这里可以看出操作::其实是右边List的操作符，而非左边Int类型的操作符</p>\n<p>二、常用变换操作<br>1.map<br>map[B](f: (A) ⇒ B): List[B]<br>定义一个变换,把该变换应用到列表的每个元素中,原列表不变，返回一个新的列表数据<br>Example1 平方变换</p>\n<pre><code>val nums = List(1,2,3)\nval square = (x: Int) =&gt; x*x   \nval squareNums1 = nums.map(num =&gt; num*num)    //List(1,4,9)\nval squareNums2 = nums.map(math.pow(_,2))    //List(1,4,9)\nval squareNums3 = nums.map(square)            //List(1,4,9)1</code></pre><p>Example2 保存文本数据中的某几列</p>\n<pre><code>val text = List(&quot;Homeway,25,Male&quot;,&quot;XSDYM,23,Female&quot;)\nval usersList = text.map(_.split(&quot;,&quot;)(0))    \nval usersWithAgeList = text.map(line =&gt; {\n    val fields = line.split(&quot;,&quot;)\n    val user = fields(0)\n    val age = fields(1).toInt\n    (user,age)\n})</code></pre><p>2.flatMap, flatten<br>flatten: flatten[B]: List[B] 对列表的列表进行平坦化操作 flatMap: flatMap[B](f: (A) ⇒ GenTraversableOnce[B]): List[B] map之后对结果进行flatten</p>\n<p>定义一个变换f, 把f应用列表的每个元素中，每个f返回一个列表，最终把所有列表连结起来。</p>\n<pre><code>val text = List(&quot;A,B,C&quot;,&quot;D,E,F&quot;)\nval textMapped = text.map(_.split(&quot;,&quot;).toList) // List(List(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;),List(&quot;D&quot;,&quot;E&quot;,&quot;F&quot;))\nval textFlattened = textMapped.flatten          // List(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;,&quot;E&quot;,&quot;F&quot;)\nval textFlatMapped = text.flatMap(_.split(&quot;,&quot;).toList) // List(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;,&quot;E&quot;,&quot;F&quot;)</code></pre><p>3.reduce<br>reduce[A1 &gt;: A](op: (A1, A1) ⇒ A1): A1<br>定义一个变换f, f把两个列表的元素合成一个，遍历列表，最终把列表合并成单一元素<br>Example 列表求和</p>\n<pre><code>val nums = List(1,2,3)\nval sum1 = nums.reduce((a,b) =&gt; a+b)   //6\nval sum2 = nums.reduce(_+_)            //6\nval sum3 = nums.sum                 //6</code></pre><p>4.reduceLeft,reduceRight<br>reduceLeft: reduceLeft[B &gt;: A](f: (B, A) ⇒ B): B<br>reduceRight: reduceRight[B &gt;: A](op: (A, B) ⇒ B): B<br>reduceLeft从列表的左边往右边应用reduce函数，reduceRight从列表的右边往左边应用reduce函数<br>Example</p>\n<pre><code>val nums = List(2.0,2.0,3.0)\nval resultLeftReduce = nums.reduceLeft(math.pow)  // = pow( pow(2.0,2.0) , 3.0) = 64.0\nval resultRightReduce = nums.reduceRight(math.pow) // = pow(2.0, pow(2.0,3.0)) = 256.0</code></pre><p>5.fold,foldLeft,foldRight<br>fold: fold[A1 &gt;: A](z: A1)(op: (A1, A1) ⇒ A1): A1 带有初始值的reduce,从一个初始值开始，从左向右将两个元素合并成一个，最终把列表合并成单一元素。<br>foldLeft: foldLeft[B](z: B)(f: (B, A) ⇒ B): B 带有初始值的reduceLeft<br>foldRight: foldRight[B](z: B)(op: (A, B) ⇒ B): B 带有初始值的reduceRight</p>\n<pre><code>val nums = List(2,3,4)\nval sum = nums.fold(1)(_+_)  // = 1+2+3+4 = 9\n\nval nums = List(2.0,3.0)\nval result1 = nums.foldLeft(4.0)(math.pow) // = pow(pow(4.0,2.0),3.0) = 4096\nval result2 = nums.foldRight(1.0)(math.pow) // = pow(1.0,pow(2.0,3.0)) = 8.0</code></pre><p>6.sortBy,sortWith,sorted<br>sortBy: sortBy[B](f: (A) ⇒ B)(implicit ord: math.Ordering[B]): List[A] 按照应用函数f之后产生的元素进行排序<br>sorted： sorted[B &gt;: A](implicit ord: math.Ordering[B]): List[A] 按照元素自身进行排序<br>sortWith： sortWith(lt: (A, A) ⇒ Boolean): List[A] 使用自定义的比较函数进行排序</p>\n<pre><code>val nums = List(1,3,2,4)\nval sorted = nums.sorted  //List(1,2,3,4)\n\nval users = List((&quot;HomeWay&quot;,25),(&quot;XSDYM&quot;,23))\nval sortedByAge = users.sortBy{case(user,age) =&gt; age}  //List((&quot;XSDYM&quot;,23),(&quot;HomeWay&quot;,25))\nval sortedWith = users.sortWith{case(user1,user2) =&gt; user1._2 &lt; user2._2} //List((&quot;XSDYM&quot;,23),(&quot;HomeWay&quot;,25))</code></pre><p>7.filter, filterNot<br>filter: filter(p: (A) ⇒ Boolean): List[A]<br>filterNot: filterNot(p: (A) ⇒ Boolean): List[A]<br>filter 保留列表中符合条件p的列表元素 ， filterNot，保留列表中不符合条件p的列表元素</p>\n<pre><code>val nums = List(1,2,3,4)\nval odd = nums.filter( _ % 2 != 0) // List(1,3)\nval even = nums.filterNot( _ % 2 != 0) // List(2,4)</code></pre><p>8.count<br>count(p: (A) ⇒ Boolean): Int<br>计算列表中所有满足条件p的元素的个数，等价于 filter(p).length</p>\n<pre><code>val nums = List(-1,-2,0,1,2) \nval plusCnt1 = nums.count(_&gt; 0) \nval plusCnt2 = nums.filter(_&gt; 0).length </code></pre><ol start=\"9\">\n<li>diff, union, intersect<br>diff:diff(that: collection.Seq[A]): List[A] 保存列表中那些不在另外一个列表中的元素，即从集合中减去与另外一个集合的交集<br>union : union(that: collection.Seq[A]): List[A] 与另外一个列表进行连结<br>intersect: intersect(that: collection.Seq[A]): List[A] 与另外一个集合的交集<pre><code>val nums1 = List(1,2,3)\nval nums2 = List(2,3,4)\nval diff1 = nums1 diff nums2   // List(1)\nval diff2 = nums2.diff(num1)   // List(4)\nval union1 = nums1 union nums2  // List(1,2,3,2,3,4)\nval union2 = nums2 ++ nums1        // List(2,3,4,1,2,3)\nval intersection = nums1 intersect nums2  //List(2,3)</code></pre></li>\n<li>distinct</li>\n</ol>\n<p>distinct: List[A] 保留列表中非重复的元素，相同的元素只会被保留一次</p>\n<pre><code>val list = List(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;A&quot;,&quot;B&quot;) val distincted = list.distinct // List(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;)1</code></pre><p>11.groupBy, grouped<br>groupBy : groupBy[K](f: (A) ⇒ K): Map[K, List[A]] 将列表进行分组，分组的依据是应用f在元素上后产生的新元素<br>grouped: grouped(size: Int): Iterator[List[A]] 按列表按照固定的大小进行分组</p>\n<pre><code>val data = List((&quot;HomeWay&quot;,&quot;Male&quot;),(&quot;XSDYM&quot;,&quot;Femail&quot;),(&quot;Mr.Wang&quot;,&quot;Male&quot;))\nval group1 = data.groupBy(_._2) // = Map(&quot;Male&quot; -&gt; List((&quot;HomeWay&quot;,&quot;Male&quot;),(&quot;Mr.Wang&quot;,&quot;Male&quot;)),&quot;Female&quot; -&gt; List((&quot;XSDYM&quot;,&quot;Femail&quot;)))\nval group2 = data.groupBy{case (name,sex) =&gt; sex} // = Map(&quot;Male&quot; -&gt; List((&quot;HomeWay&quot;,&quot;Male&quot;),(&quot;Mr.Wang&quot;,&quot;Male&quot;)),&quot;Female&quot; -&gt; List((&quot;XSDYM&quot;,&quot;Femail&quot;)))\nval fixSizeGroup = data.grouped(2).toList // = Map(&quot;Male&quot; -&gt; List((&quot;HomeWay&quot;,&quot;Male&quot;),(&quot;XSDYM&quot;,&quot;Femail&quot;)),&quot;Female&quot; -&gt; List((&quot;Mr.Wang&quot;,&quot;Male&quot;)))</code></pre><p>12.scan<br>scan[B &gt;: A, That](z: B)(op: (B, B) ⇒ B)(implicit cbf: CanBuildFrom[List[A], B, That]): That<br>由一个初始值开始，从左向右，进行积累的op操作，这个比较难解释，具体的看例子吧。</p>\n<pre><code>val nums = List(1,2,3)\nval result = nums.scan(10)(_+_)   // List(10,10+1,10+1+2,10+1+2+3) = List(10,11,13,16)</code></pre><p>13.scanLeft,scanRight<br>scanLeft: scanLeft[B, That](z: B)(op: (B, A) ⇒ B)(implicit bf: CanBuildFrom[List[A], B, That]): That<br>scanRight: scanRight[B, That](z: B)(op: (A, B) ⇒ B)(implicit bf: CanBuildFrom[List[A], B, That]): That<br>scanLeft: 从左向右进行scan函数的操作，scanRight：从右向左进行scan函数的操作</p>\n<pre><code>val nums = List(1.0,2.0,3.0)\nval result = nums.scanLeft(2.0)(math.pow)   // List(2.0,pow(2.0,1.0), pow(pow(2.0,1.0),2.0),pow(pow(pow(2.0,1.0),2.0),3.0) = List(2.0,2.0,4.0,64.0)\nval result = nums.scanRight(2.0)(math.pow)  // List(2.0,pow(3.0,2.0), pow(2.0,pow(3.0,2.0)), pow(1.0,pow(2.0,pow(3.0,2.0))) = List(1.0,512.0,9.0,2.0)</code></pre><p>14.take,takeRight,takeWhile<br>take : takeRight(n: Int): List[A] 提取列表的前n个元素 takeRight: takeRight(n: Int): List[A] 提取列表的最后n个元素 takeWhile: takeWhile(p: (A) ⇒ Boolean): List[A] 从左向右提取列表的元素，直到条件p不成立</p>\n<pre><code>val nums = List(1,1,1,1,4,4,4,4)\nval left = nums.take(4)   // List(1,1,1,1)\nval right = nums.takeRight(4) // List(4,4,4,4)\nval headNums = nums.takeWhile( _ == nums.head)  // List(1,1,1,1)</code></pre><p>15.drop,dropRight,dropWhile<br>drop: drop(n: Int): List[A] 丢弃前n个元素，返回剩下的元素 dropRight: dropRight(n: Int): List[A] 丢弃最后n个元素，返回剩下的元素 dropWhile: dropWhile(p: (A) ⇒ Boolean): List[A] 从左向右丢弃元素，直到条件p不成立</p>\n<pre><code>val nums = List(1,1,1,1,4,4,4,4)\nval left = nums.drop(4)   // List(4,4,4,4)\nval right = nums.dropRight(4) // List(1,1,1,1)\nval tailNums = nums.dropWhile( _ == nums.head)  // List(4,4,4,4)</code></pre><p>16.span, splitAt, partition<br>span : span(p: (A) ⇒ Boolean): (List[A], List[A]) 从左向右应用条件p进行判断，直到条件p不成立，此时将列表分为两个列表<br>splitAt: splitAt(n: Int): (List[A], List[A]) 将列表分为前n个，与，剩下的部分<br>partition: partition(p: (A) ⇒ Boolean): (List[A], List[A]) 将列表分为两部分，第一部分为满足条件p的元素，第二部分为不满足条件p的元素</p>\n<pre><code>val nums = List(1,1,1,2,3,2,1)\nval (prefix,suffix) = nums.span( _ == 1) // prefix = List(1,1,1), suffix = List(2,3,2,1)\nval (prefix,suffix) = nums.splitAt(3)  // prefix = List(1,1,1), suffix = List(2,3,2,1)\nval (prefix,suffix) = nums.partition( _ == 1) // prefix = List(1,1,1,1), suffix = List(2,3,2)</code></pre><p>17.padTo</p>\n<pre><code>padTo(len: Int, elem: A): List[A]\n将列表扩展到指定长度，长度不够的时候，使用elem进行填充，否则不做任何操作。\n val nums = List(1,1,1)\n val padded = nums.padTo(6,2)   // List(1,1,1,2,2,2)</code></pre><p>18.combinations,permutations</p>\n<pre><code>combinations: combinations(n: Int): Iterator[List[A]] 取列表中的n个元素进行组合，返回不重复的组合列表，结果一个迭代器\npermutations: permutations: Iterator[List[A]] 对列表中的元素进行排列，返回不重得的排列列表，结果是一个迭代器\nval nums = List(1,1,3)\nval combinations = nums.combinations(2).toList //List(List(1,1),List(1,3))\nval permutations = nums.permutations.toList        // List(List(1,1,3),List(1,3,1),List(3,1,1))</code></pre><p>19.zip, zipAll, zipWithIndex, unzip,unzip3<br>zip: zip[B](that: GenIterable[B]): List[(A, B)] 与另外一个列表进行拉链操作，将对应位置的元素组成一个pair，返回的列表长度为两个列表中短的那个<br>zipAll: zipAll[B](that: collection.Iterable[B], thisElem: A, thatElem: B): List[(A, B)] 与另外一个列表进行拉链操作，将对应位置的元素组成一个pair，若列表长度不一致，自身列表比较短的话使用thisElem进行填充，对方列表较短的话使用thatElem进行填充<br>zipWithIndex：zipWithIndex: List[(A, Int)] 将列表元素与其索引进行拉链操作，组成一个pair<br>unzip: unzip[A1, A2](implicit asPair: (A) ⇒ (A1, A2)): (List[A1], List[A2]) 解开拉链操作<br>unzip3: unzip3[A1, A2, A3](implicit asTriple: (A) ⇒ (A1, A2, A3)): (List[A1], List[A2], List[A3]) 3个元素的解拉链操作</p>\n<pre><code>val alphabet = List(&quot;A&quot;,B&quot;,&quot;C&quot;)\nval nums = List(1,2)\nval zipped = alphabet zip nums   // List((&quot;A&quot;,1),(&quot;B&quot;,2))\nval zippedAll = alphabet.zipAll(nums,&quot;*&quot;,-1)   // List((&quot;A&quot;,1),(&quot;B&quot;,2),(&quot;C&quot;,-1))\nval zippedIndex = alphabet.zipWithIndex  // List((&quot;A&quot;,0),(&quot;B&quot;,1),(&quot;C&quot;,3))\nval (list1,list2) = zipped.unzip        // list1 = List(&quot;A&quot;,&quot;B&quot;), list2 = List(1,2)\nval (l1,l2,l3) = List((1, &quot;one&quot;, &#39;1&#39;),(2, &quot;two&quot;, &#39;2&#39;),(3, &quot;three&quot;, &#39;3&#39;)).unzip3   // l1=List(1,2,3),l2=List(&quot;one&quot;,&quot;two&quot;,&quot;three&quot;),l3=List(&#39;1&#39;,&#39;2&#39;,&#39;3&#39;)</code></pre><p>20.slice<br>slice(from: Int, until: Int): List[A] 提取列表中从位置from到位置until(不含该位置)的元素列表</p>\n<pre><code>val nums = List(1,2,3,4,5)\nval sliced = nums.slice(2,4)  //List(3,4)</code></pre><p>21.sliding<br>sliding(size: Int, step: Int): Iterator[List[A]] 将列表按照固定大小size进行分组，步进为step，step默认为1,返回结果为迭代器</p>\n<pre><code>val nums = List(1,1,2,2,3,3,4,4)\nval groupStep2 = nums.sliding(2,2).toList  //List(List(1,1),List(2,2),List(3,3),List(4,4))\nval groupStep1 = nums.sliding(2).toList //List(List(1,1),List(1,2),List(2,2),List(2,3),List(3,3),List(3,4),List(4,4)) </code></pre><p>22.updated<br>updated(index: Int, elem: A): List[A] 对列表中的某个元素进行更新操作</p>\n<pre><code>val nums = List(1,2,3,3)\nval fixed = nums.updated(3,4)  // List(1,2,3,4)</code></pre><h2 id=\"十五-快学scala练习题\"><a href=\"#十五-快学scala练习题\" class=\"headerlink\" title=\"十五.快学scala练习题\"></a>十五.快学scala练习题</h2><p>练习：</p>\n<p>1.设置一个映射,其中包含你想要的一些装备，以及它们的价格。然后构建另一个映射，采用同一组键，但是价格上打9折</p>\n<pre><code>scala&gt; val price = Map(&quot;ipad&quot; -&gt; 4000,&quot;iPhone&quot; -&gt; 6000, &quot;iWatch&quot; -&gt; 3000)\nprice: scala.collection.immutable.Map[String,Int] = Map(ipad -&gt; 4000, iPhone -&gt;\n6000, iWatch -&gt; 3000)\n\nscala&gt; val newprice = for((k,v) &lt;- price) yield (k, v * 0.9)\nnewprice: scala.collection.immutable.Map[String,Double] = Map(ipad -&gt; 3600.0, iP\nhone -&gt; 5400.0, iWatch -&gt; 2700.0)</code></pre><p>2.编写一段程序，从文件中读取单词。用一个可变映射来清点每个单词出现的频率。读取这些单词的操作可以使用java.util.Scanner:<br>val in = new java.util.Scanner(new java.io.File(“myfile.txt”)) while(in.hasNext()) 处理 in.next()最后，打印出所有单词和它们出现的次数。</p>\n<pre><code>import scala.io.Source\nimport scala.collection.mutable.HashMap\nobject Pract {\n   def main(args: Array[String])  = {\n      val source = Source.fromFile(&quot;file.txt&quot;).mkString\n      val tokens = source.split(&quot;\\s+&quot;)\n      val map = new HashMap[String,Int]\n  for(key &lt;- tokens){\n    map(key) = map.getOrElse(key, 0) + 1\n  }\n  println(map.mkString(&quot;,&quot;))      \n   }\n}</code></pre><p>3.重复前一个练习，这次用不可变的映射<br>不可变映射与可变映射的区别就是每次添加新的元素时都会返回一个新的映射。</p>\n<pre><code>import scala.io.Source\nobject Pract {\n   def main(args: Array[String])  = {\n      val source = Source.fromFile(&quot;file.txt&quot;).mkString\n      val tokens = source.split(&quot;\\s+&quot;)\n      var map = MapString,Int //注意这里用的 var 了\n\n  for(key &lt;- tokens){\n      map += (key -&gt; (map.getOrElse(key, 0) + 1))\n  }\n  println(map.mkString(&quot;,&quot;))      \n   }\n}</code></pre><p>4.重复前一个练习，这次使用已排序的映射，以便单词可以按顺序打印出来</p>\n<pre><code>import scala.io.Source\nimport scala.collection.SortedMap\n\nobject Pract {\n   def main(args: Array[String])  = {\n      val source = Source.fromFile(&quot;file.txt&quot;).mkString\n      val tokens = source.split(&quot;\\s+&quot;)\n      var sortedmap = SortedMapString,Int //注意这里用的 var 了\n\n  for(key &lt;- tokens){\n      sortedmap += (key -&gt; (sortedmap.getOrElse(key, 0) + 1))\n  }\n  println(sortedmap.mkString(&quot;,&quot;))      \n   }\n}</code></pre><p>5.重复前一个练习，这次使用java.util.TreeMap并使之适用于Scala API</p>\n<pre><code>import scala.io.Source\nimport scala.collection.mutable.Map\nimport scala.collection.JavaConversions.mapAsScalaMap\nimport java.util.TreeMap\n\nobject Pract {\n   def main(args: Array[String])  = {\n      val source = Source.fromFile(&quot;file.txt&quot;).mkString\n      val tokens = source.split(&quot;\\s+&quot;)\n      val map:Map[String,Int] = new TreeMap[String,Int]\n\n  for(key &lt;- tokens){\n     map(key) = map.getOrElse(key, 0) + 1\n  }\n  println(map.mkString(&quot;,&quot;))   \n   }\n}</code></pre><p>6.定义一个链式哈希映射,将”Monday”映射到java.util.Calendar.MONDAY,依次类推加入其他日期。展示元素是以插入的顺序被访问的</p>\n<pre><code>import scala.collection.mutable.LinkedHashMap\nimport java.util.Calendar\n\nobject Pract {\n   def main(args: Array[String])  = {\n      val map = new LinkedHashMap[String, Int]\n      map += (&quot;MONDAY&quot; -&gt; Calendar.MONDAY)\n      map += (&quot;TUESDAY&quot; -&gt; Calendar.TUESDAY)\n      map += (&quot;WENDSDAY&quot; -&gt; Calendar.WEDNESDAY)\n      map += (&quot;THURSDAY&quot; -&gt; Calendar.THURSDAY)\n      map += (&quot;FRIDAY&quot; -&gt; Calendar.FRIDAY)\n      map += (&quot;SATURDAY&quot; -&gt; Calendar.SATURDAY)\n      map += (&quot;SUNDAY&quot; -&gt; Calendar.SUNDAY)\n      println(map.mkString(&quot;,&quot;))\n   }\n}</code></pre><p>7.打印出所有Java系统属性的表格</p>\n<p>JAVA系统属性转scala map的使用</p>\n<pre><code>import scala.collection.JavaConversions.propertiesAsScalaMap\nimport scala.collection.Map\n\nobject Pract {\n   def main(args: Array[String])  = {\n      val props: Map[String,String] = System.getProperties\n      val keys = props.keySet\n      val keylength = for( key &lt;- keys) yield key.length\n      val maxlength = keylength.max\n      for( key &lt;- keys) {\n        print(key)\n        print(&quot; &quot; * (maxlength - key.length))\n        print(&quot;| &quot;)\n        println(props(key))\n      }\n\n   }\n}</code></pre><p>8.编写一个函数minmax(values:Array[Int]),返回数组中最小值和最大值的对偶</p>\n<pre><code>def minmax(values:Array[Int])  = {\n     (values.max,values.min)\n   }</code></pre><p>9.编写一个函数Iteqgt(values:Array[int],v:Int),返回数组中小于v,等于v和大于v的数量，要求三个值一起返回</p>\n<pre><code>def Iteqgt(values:Array[Int],v:Int) = {\n     var a,b,c=0\n     for(value &lt;- values){\n       if(value &gt; v) a += 1\n       else if(value == v) b += 1\n       else c += 1\n     }\n     (a,b,c)\n   }\n\n   def Iteqgt1(values:Array[Int],v:Int) = {\n     (values.count( &gt; v),values.count( == v), values.count(_ &lt; v))\n   }</code></pre><p>10.当你将两个字符串拉链在一起，比如”Hello”.zip(“World”)，会是什么结果？想出一个讲得通的用例</p>\n<pre><code>scala&gt; &quot;Hello&quot;.zip(&quot;world&quot;)\nres0: scala.collection.immutable.IndexedSeq[(Char, Char)] = Vector((H,w), (e,o),\n (l,r), (l,l), (o,d))\n</code></pre><h2 id=\"十六-构造器\"><a href=\"#十六-构造器\" class=\"headerlink\" title=\"十六.构造器\"></a>十六.构造器</h2><p>Scala的类可以有一个主构造器和多个辅助构造器。每个辅助构造器的名称为this，每一个辅助构造器都必须以调用已经定义的辅助构造器或主构造器开始定义</p>\n<ul>\n<li>主构造器</li>\n</ul>\n<blockquote>\n<p>如果一个类没有显示定义主构造器，则有一个默认的无参主构造器     如定义一个Student类</p>\n</blockquote>\n<pre><code>class Student(val name:String, var age:Int = 0, address:String = &quot;&quot;, private var school:String = &quot;&quot;){\n    var grade:Int = if( age&gt;7 ) age -7 else 0\n    println(&quot; I&#39;m in main constructor. &quot;)\n    def info() = &quot; name is &quot;+name+&quot;, age is &quot;+age+&quot;, address is &quot;+address\n}</code></pre><p>　　对于Scala类，主构造器的参数放置在类名后，由括号括起来。且对于主构造器中var、val、private 等标注的参数，都会成为类的对应字段，并生成对应的默认getter、setter方法。如Student类中的name、age、school等。对于主构造器中的未用var、val标注的参数，如果在类的任何一个方法用用到该参数，该参数将会转换为类的字段，否则不会，如Student类的address属性。</p>\n<p>　　由于在Student类中的info方法中用到了参数address，所以Student共有name、age、address、school、grade等5个属性，且Scala根据对应属性的特点生成了默认的getter和setter方法。</p>\n<p>　　对于主构造器的参数，也可以提供参数默认值。通过为主构造器提供默认值可减少辅助构造器的个数<br>　　主构造器的函数体，是类中除了方法定义以外的其他语句，如在Student类的主构造器中，包含grade属性的初始化和prinln这两行语句。</p>\n<p><img src=\"https://static.oschina.net/uploads/space/2018/1116/110347_10HB_3005534.png\" alt></p>\n<ul>\n<li>辅助构造器<blockquote>\n<p> 辅助构造器通过this来定义，且必须首先调用主构造器或者其他已经定义的辅助构造器。</p>\n</blockquote>\n</li>\n</ul>\n<pre><code>class Person(val name:String){\n    var age = 0\n    var sex:Char = &#39;f&#39;\n    println(&quot;main constructor...&quot;)\n\n    def this(name:String,  age:Int){\n        this(name)        //调用主构造器\n        this.age = age     //使用this关键字\n        println(&quot; auxiliary constructor1 &quot;)\n    }\n\n    def this(name:String, age:Int, sex:Char){\n        this(name, age)\n        this.sex = sex\n        println(&quot; auxiliary constructor2 &quot;)\n    }\n}</code></pre><blockquote>\n<p>【注：辅助构造器的参数前不能添加val、var标志，否则会报错。】</p>\n</blockquote>\n<p><img src=\"https://static.oschina.net/uploads/space/2018/1116/110550_hUV6_3005534.png\" alt></p>\n<ul>\n<li>私有主构造器</li>\n</ul>\n<pre><code>class Person private(val name:String){\n    var age:Int = 1\n    def this(name: String, age:Int){\n        this(name)\n        this.age = age\n    }\n}</code></pre><h1 id=\"hadoop\"><a href=\"#hadoop\" class=\"headerlink\" title=\"hadoop\"></a>hadoop</h1><h2 id=\"一-Nodepad远程linux插件NppFTP\"><a href=\"#一-Nodepad远程linux插件NppFTP\" class=\"headerlink\" title=\"一.Nodepad远程linux插件NppFTP\"></a>一.Nodepad远程linux插件NppFTP</h2><p><strong>1.在该github上下载自己notepad++对应版本位数的插件</strong><br><a href=\"https://github.com/ashkulz/NppFTP/releases/tag/v0.27.6\" target=\"_blank\" rel=\"noopener\">NppFTP下载地址</a>：<a href=\"https://github.com/ashkulz/NppFTP/releases/tag/v0.27.6\" target=\"_blank\" rel=\"noopener\">https://github.com/ashkulz/NppFTP/releases/tag/v0.27.6</a></p>\n<blockquote>\n<p>下载时可以因为被墙的原因下载不了，如果有跨网服务器，直接wget 实际下载地址<br><img src=\"https://static.oschina.net/uploads/img/201901/11105326_7IeQ.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"></p>\n</blockquote>\n<blockquote>\n<p>软件如果下载不了 可以到百度网盘qq939598604/我的软件/NppFTP目录下下载</p>\n</blockquote>\n<p><strong>2.下载之后进行解压，然后将bin目录下的dll文件拷贝到notepad++的安装目录下的插件目录</strong><br>notepad++的安装目录可以右键notepad++的快捷方式，找到安装目录<br><img src=\"https://static.oschina.net/uploads/img/201901/11105635_bvCw.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"><br><img src=\"https://static.oschina.net/uploads/img/201901/11105728_rL2U.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"> </p>\n<p><strong>3.重启notepad++</strong></p>\n<p><strong>4.重启后，在插件菜单中会显示该插件</strong><br><img src=\"https://static.oschina.net/uploads/img/201901/11105829_SBf5.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"></p>\n<p><strong>5.NppFTP使用</strong><br><img src=\"https://static.oschina.net/uploads/img/201901/11110929_I4h9.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"><br><img src=\"https://static.oschina.net/uploads/img/201901/11110936_ZoEY.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"><br><img src=\"https://static.oschina.net/uploads/img/201901/11110948_7ATB.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"><br><img src=\"https://static.oschina.net/uploads/img/201901/11110955_AfYH.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"></p>\n<p><img src=\"https://static.oschina.net/uploads/img/201901/11112540_Mc1p.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"></p>\n<h2 id=\"二-实现linux集群所有机器免密钥登录\"><a href=\"#二-实现linux集群所有机器免密钥登录\" class=\"headerlink\" title=\"二.实现linux集群所有机器免密钥登录\"></a>二.实现linux集群所有机器免密钥登录</h2><p><strong>1.先安装expect</strong> </p>\n<pre><code>yum install expect</code></pre><p>*<em>2.生成密钥 *</em></p>\n<pre><code>ssh-keygen(注,一路回车,不用管)</code></pre><p><strong>3.修改host文件 /etc/hosts</strong></p>\n<pre><code>192.168.197.21 master\n192.168.197.25 slave1\n192.168.197.27 slave2 </code></pre><p><strong>4.编写shell脚本 vim.ssh_copy_id_to_all.sh</strong></p>\n<pre><code>#!/bin/bash\nSERVERS=&quot;master slave1 slave2&quot;\nPASSWORD=root\nauto_ssh_copy_id() {\n    expect -c &quot;set timeout -1;\n        spawn ssh-copy-id $1;\n        expect {\n            *(yes/no)* {send -- yes\\r;exp_continue;}\n            *assword:* {send -- $2\\r;exp_continue;}\n            eof        {exit 0;}\n        }&quot;;\n}\n\nssh_copy_id_to_all() {\n    for SERVER in $SERVERS\n    do\n        auto_ssh_copy_id $SERVER $PASSWORD\n    done\n}\n\nssh_copy_id_to_all</code></pre><p><strong>5.chomd +x ssh_copy_id_to_all.sh</strong><br><strong>6.执行脚本</strong><br>./ssh_copy_id_to_all.sh</p>\n<h2 id=\"三-Windows安装部署hadoop-2-7-5\"><a href=\"#三-Windows安装部署hadoop-2-7-5\" class=\"headerlink\" title=\"三.Windows安装部署hadoop-2.7.5\"></a>三.Windows安装部署hadoop-2.7.5</h2><p><strong>(1).编辑“M:\\soft\\hadoop-2.7.5\\etc\\hadoop”下的core-site.xml文件，将下列文本粘贴进去，并保存；</strong></p>\n<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;\n&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;\n        &lt;value&gt;/M:/soft/hadoop-2.7.5/tmp&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.name.dir&lt;/name&gt;\n        &lt;value&gt;/M:/soft/hadoop-2.7.5/name&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;fs.default.name&lt;/name&gt;\n        &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;</code></pre><p><strong>(2).编辑“M:\\soft\\hadoop-2.7.5\\etc\\hadoop”目录下的mapred-site.xml(没有就将mapred-site.xml.template重命名为mapred-site.xml)文件，粘贴一下内容并保存:</strong></p>\n<pre><code>&lt;?xml version=&quot;1.0&quot;?&gt;\n&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;\n&lt;configuration&gt;\n    &lt;property&gt;\n       &lt;name&gt;mapreduce.framework.name&lt;/name&gt;\n       &lt;value&gt;yarn&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n       &lt;name&gt;mapred.job.tracker&lt;/name&gt;\n       &lt;value&gt;hdfs://localhost:9001&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;</code></pre><p><strong>(3).编辑“M:\\soft\\hadoop-2.7.5\\etc\\hadoop”目录下的hdfs-site.xml文件，粘贴以下内容并保存。请自行创建data目录，在这里我是在HADOOP_HOME目录下创建了data目录:</strong></p>\n<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;\n&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;\n&lt;configuration&gt;\n    &lt;!-- 这个参数设置为1，因为是单机版hadoop --&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.replication&lt;/name&gt;\n        &lt;value&gt;1&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.data.dir&lt;/name&gt;\n        &lt;value&gt;/M:/soft/hadoop-2.7.5/data&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;</code></pre><p><strong>(4).编辑“M:\\soft\\hadoop-2.7.5\\etc\\hadoop”目录下的yarn-site.xml文件，粘贴以下内容并保存；</strong></p>\n<pre><code>&lt;?xml version=&quot;1.0&quot;?&gt;\n&lt;configuration&gt;\n    &lt;property&gt;\n       &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;\n       &lt;value&gt;mapreduce_shuffle&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n       &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;\n       &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;</code></pre><p><strong>(5).编辑“M:\\soft\\hadoop-2.7.5\\etc\\hadoop”目录下的hadoop-env.cmd文件，将JAVA_HOME用 @rem注释掉，编辑为JAVA_HOME的路径，然后保存:</strong></p>\n<pre><code>@rem set JAVA_HOME=%JAVA_HOME%\nset JAVA_HOME=M:\\soft\\Java\\jdk1.8.0_101</code></pre><p><strong>替换文件</strong> 将下载好的hadooponwindows-master.zip（笔记第一步有下载地址，不知道可以去笔记开头的需求栏目查看）解压，将解压后的<strong>*bin目录下的所有文件直接覆盖Hadoop的bin目录*</strong>。</p>\n<h2 id=\"四-hadoop集群安装\"><a href=\"#四-hadoop集群安装\" class=\"headerlink\" title=\"四.hadoop集群安装\"></a>四.hadoop集群安装</h2><p><strong>（一）.安装环境 ：所有的软件安装在根目录下的/soft目录</strong></p>\n<p>java—/soft/jdk1.0.8<br>hadoop–/soft/hadoop2.7.4<br>固定hadoop配置变量(JAVA_HOME,主机名称,hadoop的固定目录)可以不用安装那么多<br>hadoop-env.sh 文件:</p>\n<pre><code>export JAVA_HOME=/soft/jdk1.0.8</code></pre><p>core-site.xml文件: </p>\n<pre><code>&lt;name&gt;fs.defaultFS&lt;/name&gt;\n&lt;value&gt;hdfs://node1:9000&lt;/value&gt;</code></pre><p>hdfs-site.xml文件：</p>\n<pre><code>&lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;\n&lt;value&gt;file:/soft/hadoop-2.7.4/tmp/dfs/name&lt;/value&gt;</code></pre><p>slaves文件</p>\n<pre><code>slave1   slave2 </code></pre><p>集群规划<br>主机名           ip          安装的软件         进程<br>master   192.168.197.255  jdk、hadoop  namenode ressourcemanager<br>slave1   192.168.197.256  jdk、hadoop  datanode secondnamenode<br>slave2   192.168.197.257  jdk、hadoop  datanade</p>\n<p><strong>（二）.安装JDK</strong> </p>\n<p>1.下载jdk1.8.0_161<br>2.在/etc/profile中添加如下配置<br>sudo vim /etc/profile</p>\n<pre><code>export JAVA_HOME=/soft/jdk1.8.0_161\nexport JRE_HOME=${JAVA_HOME}/jre\nexport CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib\nexport PATH=${JAVA_HOME}/bin:$PATH</code></pre><p>3.使环境变量生效，source /etc/profile<br>4.安装验证# java -version </p>\n<p><strong>（三）.准备host文件和修改主机名称</strong><br>1.vim /etc/hosts</p>\n<pre><code>192.168.197.225 master\n192.168.197.226 slave1\n192.168.197.227 slave2</code></pre><p>2.拷贝/etc/hosts到其它主机<br>   scp /etc/hosts slave1:/etc/<br>   scp /etc/hosts slave2:/etc/</p>\n<p>3.修改主机名<br>   vim /etc/hosts<br>   master slave1 slave2 </p>\n<p><strong>（四）.免登录</strong><br>1.注意将防火墙关掉<br>CentOS7 </p>\n<pre><code> (1)关闭防火墙：sudo systemctl stop firewalld.service\n (2)关闭开机启动：sudo systemctl disable firewalld.service\n (3)安装iptables防火墙：sudo yum install iptables-services\n (4)设置iptables防火墙开机启动：sudo systemctl enable iptables</code></pre><p>ubuntu</p>\n<pre><code>(1)关闭ubuntu的防火墙 ufw disable\n(2)开启防火墙 ufw enable\n(3)卸载了iptables apt-get remove iptables \n(4)关闭ubuntu中的防火墙的其余命令\n    iptables -P INPUT ACCEPT\n    iptables -P FORWARD ACCEPT\n    iptables -P OUTPUT ACCEPT\n    iptables -F</code></pre><p>2.ssh无密登录,<br>(1)在集群/etc/ssh/sshd_config 文件去掉以下选项的注释<br>sudo vim /etc/ssh/sshd_config</p>\n<pre><code>Port 22\nProtocol 2\nRSAAuthentication yes      #开启私钥验证\nPubkeyAuthentication yes   #开启公钥验证</code></pre><p>3.生成秘钥<br>(1)在主从节点(集群的每一个节点节点)输入命令 ，生成 key，一律回车<br>   ssh-keygen -t rsa -P ‘’<br>(2)将从节点(集群的每一个节点节点)公钥收集到一个文件中authorized_keys，并发送到各个节点<br>从节点配置：<br>      在slave1的机器：scp /home/chen/.ssh/id_rsa.pub master:/home/chen/.ssh/id_rsa.pub.s1<br>      在slave2的机器：scp /home/chen/.ssh/id_rsa.pub master:/home/chen/.ssh/id_rsa.pub.s2<br>主节点配置：<br>(3)将所有机器的id_rsa.pub文件收集到authorized_keys，并发送到各个节点<br>   sudo cat /home/chen/.ssh/id_rsa.pub &gt;&gt; /home/chen/.ssh/authorized_keys<br>   sudo cat /home/chen/.ssh/id_rsa.pub.s1 &gt;&gt; /home/chen/.ssh/authorized_keys<br>   sudo cat /home/chen/.ssh/id_rsa.pub.s2 &gt;&gt; /home/chen/.ssh/authorized_keys<br>(4)最后将生成的包含三个节点的秘钥的authorized_keys 复制到s1和s2的.ssh目录下（<br>   scp /home/chen/.ssh/authorized_keys slave1:/home/chen/.ssh/<br>   scp /home/chen/.ssh/authorized_keys slave2:/home/chen/.ssh/</p>\n<p>验证ssh免密码登录<br>1.输入命令ssh  localhost(主机名) 根据提示输入“yes”<br>2.输入命令exit注销（Logout）<br>3.再次输入命令ssh localhost即可直接登录</p>\n<p><strong>（五）hadoop的配置</strong><br>(1)编辑 hadoop-env.sh 文件,找到 JAVA_HOME 改为 JDK 的安装目录<br>   sudo vim /soft/hadoop-2.7.4/etc/hadoop/hadoop-env.sh<br>   export JAVA_HOME=/soft/jdk1.8.0_161<br>(2)修改 core-site.xml<br>   sudo vim core-site.xml</p>\n<pre><code>&lt;configuration&gt;\n       &lt;property&gt;\n           &lt;name&gt;fs.defaultFS&lt;/name&gt;\n           &lt;value&gt;hdfs://master:9000&lt;/value&gt;\n       &lt;/property&gt;\n       &lt;property&gt;\n           &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;\n           &lt;value&gt;file:/soft/hadoop-2.7.4/tmp&lt;/value&gt;\n       &lt;/property&gt;\n   &lt;/configuration&gt;</code></pre><p>(2)修改 hdfs-site.xml<br>   sudo vim hdfs-site.xml</p>\n<pre><code>&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;\n        &lt;value&gt;master:50090&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.replication&lt;/name&gt;\n        &lt;value&gt;2&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;\n        &lt;value&gt;file:/soft/hadoop-2.7.4/tmp/dfs/name&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;\n        &lt;value&gt;file:/soft/hadoop-2.7.4/tmp/dfs/data&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;</code></pre><p>(3)修改 mapred-site.xml<br>目录下么没有这个文件,这有一个模板,我们需要先拷贝一份<br> cp mapred-site.xml.template mapred-site.xml<br> vim  mapred-site.xml</p>\n<pre><code>&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;\n        &lt;value&gt;yarn&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;\n        &lt;value&gt;master:10020&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;\n        &lt;value&gt;master:19888&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;</code></pre><p>(4)修改 yarn-site.xml<br>vi yarn-site.xml</p>\n<pre><code>&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;\n        &lt;value&gt;master&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;\n        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;</code></pre><p><strong>（六）配置集群</strong><br>(1)复制节点,将hadoop-2.7.4 文件夹重打包后复制到其他子节点</p>\n<pre><code>scp /soft/hadoop-2.7.4/ chen@slave1:/soft\nscp /soft/hadoop-2.7.4/ chen@slave2:/soft</code></pre><p>(2)配置slaves文件<br>修改（Master主机）/soft/hadoop-2.7.4/etc/hadoop/slaves该文件指定哪些服务器节点是datanode节点。删除locahost，添加所有datanode节点的主机名<br>sudo vim /soft/hadoop-2.7.4/etc/hadoop/slaves</p>\n<pre><code>slave1\nslave2</code></pre><p>(3)格式化namenode和datanode并启动，（在master上执行就可以了 不需要在slave上执行）</p>\n<pre><code>cd /soft/hadoop-2.7.4/bin\n./hadoop namenode -format\n./hadoop datanode -format</code></pre><p><strong>（七）启动 hadoop</strong></p>\n<p>cd /soft/hadoop-2.7.4/sbin<br>./start-dfs.sh<br>./start-yarn.sh<br>./mr-jobhistory-daemon.sh start historyserver<br>或者<br>./start-all.sh<br>./mr-jobhistory-daemon.sh start historyserver</p>\n<p><strong>（八）查看进程服务</strong><br>查看启动进程,缺少以下任一进程都表示出错<br>$ jps<br>2528 NameNode<br>2720 SecondaryNameNode<br>2872 ResourceManager<br>3151 JobHistoryServer<br>查看端口占用情况<br>netstat -tnlp | grep java<br>访问master<br><a href=\"http://192.168.197.255:50070\" target=\"_blank\" rel=\"noopener\">http://192.168.197.255:50070</a><br><a href=\"http://192.168.197.255:8088\" target=\"_blank\" rel=\"noopener\">http://192.168.197.255:8088</a></p>\n<p><strong>（九）停止 hadoop</strong><br>cd /soft/hadoop-2.7.4/sbin<br>./stop-all.sh</p>\n<h1 id><a href=\"#\" class=\"headerlink\" title=\" \"></a> </h1><h1 id=\"hbase\"><a href=\"#hbase\" class=\"headerlink\" title=\"hbase\"></a>hbase</h1><h2 id=\"一-hbase在linux系统本地模式\"><a href=\"#一-hbase在linux系统本地模式\" class=\"headerlink\" title=\"一.hbase在linux系统本地模式\"></a>一.hbase在linux系统本地模式</h2><p>1.安装好jdk<br>2.下载hbase hbase 下载地址：<a href=\"http://hbase.apache.org/\" target=\"_blank\" rel=\"noopener\">http://hbase.apache.org/</a></p>\n<pre><code>hbase-2.0.2-bin.tar.gz</code></pre><p>3.上传到linux服务的/soft目录下<br>4.tar 开hbase压缩包</p>\n<pre><code>tar -zxvf /soft/hbase-2.0.2-bin.tar.gz -C /soft/</code></pre><p>5.修改conf/hbase-env.sh<br>vim /soft/hbase-2.0.2/conf/hbase-env.sh</p>\n<pre><code>export JAVA_HOME=/soft/jdk1.8.0_161</code></pre><p>6.编辑hbase-site.xml </p>\n<pre><code>&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;hbase.rootdir&lt;/name&gt;\n        &lt;value&gt;file:///soft/hbase-2.0.2/data&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>7.新建hbase数据存放目录</p>\n<pre><code>mkdir /soft/hbase-2.0.2/data</code></pre><p>8.启动hbase</p>\n<pre><code>cd /soft/hbase-2.0.2/bin\n./bin/start-hbase.sh</code></pre><p>9.jps 查看后 出现Hmaster就是启动成功 然后就可以进入shell进行对hbase的操作</p>\n<pre><code>[root@master hbase-2.0.2]# jps\n4359 Main\n5532 Jps\n4829 HMaster</code></pre><p>10.进入hbase shell</p>\n<pre><code>./bin/hbase shell</code></pre><p>11.访问web</p>\n<pre><code>http://192.168.197.21:16010/master-status</code></pre><p><strong>shell环境测试</strong><br>创建表</p>\n<pre><code>hbase(main):016:0&gt; create &#39;t1&#39;, {NAME =&gt; &#39;f1&#39;, VERSIONS =&gt; 1}</code></pre><p>查看表</p>\n<pre><code>hbase(main):017:0&gt; list\nTABLE\nt1\n1 row(s)\nTook 0.0053 seconds                                                                   \n=&gt; [&quot;t1&quot;]</code></pre><p>插入一条数据</p>\n<pre><code>hbase(main):019:0&gt; put &#39;t1&#39;, &#39;r1&#39;, &#39;f1&#39;, &#39;v1&#39;</code></pre><p>扫描t1表的全数据</p>\n<pre><code>hbase(main):018:0&gt;  scan &#39;t1&#39;\nROW                       COLUMN+CELL                                                 \nr1                       column=f1:, timestamp=1540885480142, value=v1                \n1 row(s)</code></pre><h2 id=\"二-Hbase在linux集群搭建\"><a href=\"#二-Hbase在linux集群搭建\" class=\"headerlink\" title=\"二.Hbase在linux集群搭建\"></a>二.Hbase在linux集群搭建</h2><p>软件放置路径为初级配置的路径/soft/hbase-1.3.1<br>1.解压已经安装整理过的压缩包hbase-1.3.1-install.tar.gz</p>\n<pre><code>tar -zxvf /soft/hbase-1.3.1-install.tar.gz -C /soft/</code></pre><p>2.修改hbase-env环境变量<br>vim /soft/hbase-1.3.1/conf/hbase-env.sh</p>\n<pre><code>export JAVA_HOME=/soft/jdk1.8.0_161\nexport HBASE_CLASSPATH=/soft/hadoop-2.7.4\nexport HBASE_MANAGES_ZK=false          # 不使用自带的zk，使用独立的zookeeper</code></pre><p>3.修改hbase-site.xml<br>vim /soft/hbase-1.3.1/conf/hbase-site.xml    # 配置站点信息</p>\n<pre><code>&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;hbase.rootdir&lt;/name&gt;\n        &lt;value&gt;hdfs://master:9000/hbase&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;hbase.master&lt;/name&gt;\n        &lt;value&gt;master&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;\n        &lt;value&gt;true&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt;\n        &lt;value&gt;2181&lt;/value&gt;                                     # 这里指的是zook的端口\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;                     # 主机名一定要对应上\n        &lt;value&gt;master,slave1,slave2&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;zookeeper.session.timeout&lt;/name&gt;                  # zook的session超时时长\n        &lt;value&gt;60000000&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.support.append&lt;/name&gt;\n        &lt;value&gt;true&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;</code></pre><p>4.指定添加regionservers<br>vim /soft/hbase-1.3.1/conf/regionservers# 配置从节点 一定要对应上</p>\n<pre><code>master\nslave1\nslave2</code></pre><p>5.复制/soft/hbase-1.3.1到各个从的机器</p>\n<pre><code>scp /soft/hbase-1.3.1 root@slave1:/soft/\nscp /soft/hbase-1.3.1 root@slave2:/soft/</code></pre><p>6.在各个节点添加hbase的环境变量<br>vim /etc/profile</p>\n<pre><code>export HBASE_HOME=/soft/hbase-1.3.1\nexport PATH=$HBASE_HOME/bin:$PATH</code></pre><p>7.在master启动hbase</p>\n<pre><code>/soft/hbase-1.3.1/bin/start-hbase.sh</code></pre><p>8.浏览器检查打开master机器的端口16010<br><a href=\"http://192.168.197.231:16010/master-status\" target=\"_blank\" rel=\"noopener\">http://192.168.197.231:16010/master-status</a></p>\n<h2 id=\"三-hbase在window环境下安装\"><a href=\"#三-hbase在window环境下安装\" class=\"headerlink\" title=\"三.hbase在window环境下安装\"></a>三.hbase在window环境下安装</h2><p>1.安装jdk</p>\n<pre><code>默认JDK已安装并配置好环境变量，本处用的jdk1.8.0_101 </code></pre><p>2、下载hbase-2.0.2-bin.tar.gz</p>\n<pre><code>解压到C:\\hbase-2.0.2\\目录下</code></pre><p>3、下载hadoop-common-2.2.0-bin-master</p>\n<pre><code>hadoop-common-2.2.0-bin-master(包含windows端开发Hadoop2.2需要的winutils.exe)，HBase在Windows下部署需要使用到。    \n地址：https://github.com/srccodes/hadoop-common-2.2.0-bin，下载hadoop-common-2.2.0-bin-master.zip，解压缩到D:\\hadoop\\hadoop-common-2.2.0-bin-master。</code></pre><p>4、修改HBase下的conf/hbase-env.cmd</p>\n<pre><code>set JAVA_HOME=M:\\soft\\Java\\jdk1.8.0_101\nset HBASE_MANAGES_ZK=true</code></pre><p>5.修改HBase下的hbase-site.xml</p>\n<pre><code>&lt;?xml version=&quot;1.0&quot;?&gt;\n&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;\n&lt;configuration&gt;\n    &lt;property&gt;  \n        &lt;name&gt;hbase.rootdir&lt;/name&gt;  \n        &lt;value&gt;file:///C:/hbase-2.0.2/data&lt;/value&gt;  \n    &lt;/property&gt;  \n    &lt;property&gt;  \n        &lt;name&gt;hbase.tmp.dir&lt;/name&gt;  \n        &lt;value&gt;C:/hbase-2.0.2/tmp&lt;/value&gt;  \n    &lt;/property&gt;  \n    &lt;property&gt;  \n        &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;  \n        &lt;value&gt;127.0.0.1&lt;/value&gt;  \n    &lt;/property&gt;  \n    &lt;property&gt;  \n        &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;  \n        &lt;value&gt;C:/hbase-2.0.2/tmp/zoo&lt;/value&gt;  \n    &lt;/property&gt;  \n    &lt;property&gt;  \n        &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;  \n        &lt;value&gt;false&lt;/value&gt;  \n    &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre><p>6.配置用户变量HADOOP_HOME</p>\n<pre><code>新建环境变量HADOOP_HOME，值为C:\\hadoop-common-2.2.0-bin-master\n在path后添加：%HADOOP_HOME%\\bin\n</code></pre><p>7.启动HBase</p>\n<pre><code>在C:\\hbase-2.0.2\\bin下打开命令行，输入start-hbase.cmd，启动HBase。</code></pre><p>8.测试Shell</p>\n<pre><code> HBase启动后，在命令行输入hbase shell，打卡HBase的shell命令行</code></pre><p>9.打开HBase主页，网址：<a href=\"http://127.0.0.1:16010/master-status\" target=\"_blank\" rel=\"noopener\">http://127.0.0.1:16010/master-status</a><br>10.可以通过测试命令建表测试等等</p>\n<h2 id=\"四-hbase的filter操作\"><a href=\"#四-hbase的filter操作\" class=\"headerlink\" title=\"四.hbase的filter操作\"></a>四.hbase的filter操作</h2><p><strong>1.创建表</strong></p>\n<pre><code>create &#39;test1&#39;, &#39;lf&#39;, &#39;sf&#39;</code></pre><p><strong>2.导入数据</strong></p>\n<pre><code>put &#39;test1&#39;, &#39;user1|ts1&#39;, &#39;sf:c1&#39;, &#39;sku1&#39;\nput &#39;test1&#39;, &#39;user1|ts2&#39;, &#39;sf:c1&#39;, &#39;sku188&#39;\nput &#39;test1&#39;, &#39;user1|ts3&#39;, &#39;sf:s1&#39;, &#39;sku123&#39;\nput &#39;test1&#39;, &#39;user2|ts4&#39;, &#39;sf:c1&#39;, &#39;sku2&#39;\nput &#39;test1&#39;, &#39;user2|ts5&#39;, &#39;sf:c2&#39;, &#39;sku288&#39;\nput &#39;test1&#39;, &#39;user2|ts6&#39;, &#39;sf:s1&#39;, &#39;sku222&#39;</code></pre><p><strong>3.查询案例：谁的值=sku188</strong></p>\n<pre><code>scan &#39;test1&#39;, FILTER=&gt;&quot;ValueFilter(=,&#39;binary:sku188&#39;)&quot;</code></pre><p>**#查询结果</p>\n<pre><code>ROW                         COLUMN+CELL                    \nuser1|ts2                   column=sf:c1, timestamp=1409122354918, value=sku188</code></pre><p><strong>4.查询案例：谁的值包含88</strong></p>\n<pre><code>scan &#39;test1&#39;, FILTER=&gt;&quot;ValueFilter(=,&#39;substring:88&#39;)&quot;</code></pre><p>**#查询结果</p>\n<pre><code> ROW                         COLUMN+CELL    \n user1|ts2                   column=sf:c1, timestamp=1409122354918, value=sku188\n user2|ts5                   column=sf:c2, timestamp=1409122355030, value=sku288</code></pre><p><strong>5.查询案例：谁的值包含88</strong></p>\n<pre><code>scan &#39;test1&#39;, FILTER=&gt;&quot;ValueFilter(=,&#39;substring:88&#39;)&quot;</code></pre><p>**#查询结果</p>\n<pre><code> ROW                         COLUMN+CELL    \n user1|ts2                   column=sf:c1, timestamp=1409122354918, value=sku188\n user2|ts5                   column=sf:c2, timestamp=1409122355030, value=sku288</code></pre><p><strong>6.通过广告点击进来的(column为c2)值包含88的用户</strong></p>\n<pre><code>scan &#39;test1&#39;, FILTER=&gt;&quot;ColumnPrefixFilter(&#39;c2&#39;) AND ValueFilter(=,&#39;substring:88&#39;)&quot;</code></pre><p>**#查询结果</p>\n<pre><code> ROW                         COLUMN+CELL\n user2|ts5                   column=sf:c2, timestamp=1409122355030, value=sku288</code></pre><p><strong>7.通过搜索进来的(column为s)值包含123或者222的用户</strong></p>\n<pre><code>scan &#39;test1&#39;, FILTER=&gt;&quot;ColumnPrefixFilter(&#39;s&#39;) AND ( ValueFilter(=,&#39;substring:123&#39;) OR ValueFilter(=,&#39;substring:222&#39;) )&quot;</code></pre><p>**#查询结果</p>\n<pre><code> ROW                         COLUMN+CELL\n user1|ts3                   column=sf:s1, timestamp=1409122354954, value=sku123\n user2|ts6                   column=sf:s1, timestamp=1409122355970, value=sku222</code></pre><p><strong>8.rowkey为user1开头的</strong></p>\n<pre><code>scan &#39;test1&#39;, FILTER =&gt; &quot;PrefixFilter (&#39;user1&#39;)&quot;</code></pre><p>**#查询结果</p>\n<pre><code> ROW                        COLUMN+CELL\n user1|ts1                   column=sf:c1, timestamp=1409122354868, value=sku1\n user1|ts2                   column=sf:c1, timestamp=1409122354918, value=sku188\n user1|ts3                   column=sf:s1, timestamp=1409122354954, value=sku123</code></pre><p><strong>9.从user1|ts2开始,找到所有的rowkey以user1开头的</strong></p>\n<pre><code>scan &#39;test1&#39;, {STARTROW=&gt;&#39;user1|ts2&#39;, FILTER =&gt; &quot;PrefixFilter (&#39;user1&#39;)&quot;}</code></pre><p>**#查询结果</p>\n<pre><code> ROW                         COLUMN+CELL\n user1|ts2                   column=sf:c1, timestamp=1409122354918, value=sku188\n user1|ts3                   column=sf:s1, timestamp=1409122354954, value=sku123 </code></pre><p><strong>10.从user1|ts2开始,找到所有的到rowkey以user2开头</strong></p>\n<pre><code>scan &#39;test1&#39;, {STARTROW=&gt;&#39;user1|ts2&#39;, STOPROW=&gt;&#39;user2&#39;}</code></pre><p>**#查询结果</p>\n<pre><code> ROW                          COLUMN+CELL\n user1|ts2                   column=sf:c1, timestamp=1409122354918, value=sku188\n user1|ts3                   column=sf:s1, timestamp=1409122354954, value=sku123</code></pre><p><strong>11.查询rowkey里面包含ts3的</strong></p>\n<pre><code>import org.apache.hadoop.hbase.filter.CompareFilter\nimport org.apache.hadoop.hbase.filter.SubstringComparator\nimport org.apache.hadoop.hbase.filter.RowFilter\nscan &#39;test1&#39;, {FILTER =&gt; RowFilter.new(CompareFilter::CompareOp.valueOf(&#39;EQUAL&#39;), SubstringComparator.new(&#39;ts3&#39;))}</code></pre><p>**#查询结果</p>\n<pre><code> ROW                          COLUMN+CELL\n user1|ts3                   column=sf:s1, timestamp=1409122354954, value=sku123 </code></pre><p><strong>12.查询rowkey里面包含ts的</strong></p>\n<pre><code>import org.apache.hadoop.hbase.filter.CompareFilter\nimport org.apache.hadoop.hbase.filter.SubstringComparator\nimport org.apache.hadoop.hbase.filter.RowFilter\nscan &#39;test1&#39;, {FILTER =&gt; RowFilter.new(CompareFilter::CompareOp.valueOf(&#39;EQUAL&#39;), SubstringComparator.new(&#39;ts&#39;))}</code></pre><p>**#查询结果</p>\n<pre><code> ROW                         COLUMN+CELL\n user1|ts1                   column=sf:c1, timestamp=1409122354868, value=sku1\n user1|ts2                   column=sf:c1, timestamp=1409122354918, value=sku188\n user1|ts3                   column=sf:s1, timestamp=1409122354954, value=sku123\n user2|ts4                   column=sf:c1, timestamp=1409122354998, value=sku2\n user2|ts5                   column=sf:c2, timestamp=1409122355030, value=sku288\n user2|ts6                   column=sf:s1, timestamp=1409122355970, value=sku222</code></pre><p><strong>13.加入一条测试数据</strong></p>\n<pre><code>put &#39;test1&#39;, &#39;user2|err&#39;, &#39;sf:s1&#39;, &#39;sku999&#39;</code></pre><p><strong>14.查询rowkey里面以user开头的，新加入的测试数据并不符合正则表达式的规则，故查询不出来</strong></p>\n<pre><code>import org.apache.hadoop.hbase.filter.RegexStringComparator\nimport org.apache.hadoop.hbase.filter.CompareFilter\nimport org.apache.hadoop.hbase.filter.SubstringComparator\nimport org.apache.hadoop.hbase.filter.RowFilter\nscan &#39;test1&#39;, {FILTER =&gt; RowFilter.new(CompareFilter::CompareOp.valueOf(&#39;EQUAL&#39;),RegexStringComparator.new(&#39;^user\\d+\\|ts\\d+$&#39;))}</code></pre><p>**#查询结果</p>\n<pre><code> ROW                         COLUMN+CELL\n user1|ts1                   column=sf:c1, timestamp=1409122354868, value=sku1\n user1|ts2                   column=sf:c1, timestamp=1409122354918, value=sku188\n user1|ts3                   column=sf:s1, timestamp=1409122354954, value=sku123\n user2|ts4                   column=sf:c1, timestamp=1409122354998, value=sku2\n user2|ts5                   column=sf:c2, timestamp=1409122355030, value=sku288\n user2|ts6                   column=sf:s1, timestamp=1409122355970, value=sku222</code></pre><p><strong>15.加入测试数据</strong></p>\n<pre><code>put &#39;test1&#39;, &#39;user1|ts9&#39;, &#39;sf:b1&#39;, &#39;sku1&#39;</code></pre><p><strong>16.b1开头的列中并且值为sku1的</strong></p>\n<pre><code>scan &#39;test1&#39;, FILTER=&gt;&quot;ColumnPrefixFilter(&#39;b1&#39;) AND ValueFilter(=,&#39;binary:sku1&#39;)&quot;</code></pre><p>**#查询结果</p>\n<pre><code> ROW                          COLUMN+CELL                                                   user1|ts9                   column=sf:b1, timestamp=1409124908668, value=sku1</code></pre><p><strong>17.SingleColumnValueFilter的使用，b1开头的列中并且值为sku1的</strong></p>\n<pre><code>import org.apache.hadoop.hbase.filter.CompareFilter\nimport org.apache.hadoop.hbase.filter.SingleColumnValueFilter\nimport org.apache.hadoop.hbase.filter.SubstringComparator\nscan &#39;test1&#39;, {COLUMNS =&gt; &#39;sf:b1&#39;, FILTER =&gt; SingleColumnValueFilter.new(Bytes.toBytes(&#39;sf&#39;), Bytes.toBytes(&#39;b1&#39;), CompareFilter::CompareOp.valueOf(&#39;EQUAL&#39;), Bytes.toBytes(&#39;sku1&#39;))}</code></pre><p>**#查询结果</p>\n<pre><code> ROW                         COLUMN+CELL\n user1|ts9                   column=sf:b1, timestamp=1409124908668, value=sku1</code></pre><p><strong>18.KeyOnlyFilter: 只要key,不要value</strong></p>\n<pre><code>scan &#39;test1&#39;, FILTER=&gt;&quot;FirstKeyOnlyFilter() AND ValueFilter(=,&#39;binary:sku188&#39;) AND KeyOnlyFilter()&quot;</code></pre><p>**#查询结果</p>\n<pre><code> ROW                         COLUMN+CELL\n user1|ts2                   column=sf:c1, timestamp=1409122354918, value=</code></pre><p>FirstKeyOnlyFilter: 一个rowkey可以有多个version,同一个rowkey的同一个column也会有多个的值, 只拿出key中的第一个column的第一个version</p>\n<h2 id=\"五-hbase的java操作-maven构建\"><a href=\"#五-hbase的java操作-maven构建\" class=\"headerlink\" title=\"五.hbase的java操作 maven构建\"></a>五.hbase的java操作 maven构建</h2><p><strong>1.pom.xml文件添加hbase依赖</strong></p>\n<pre><code>&lt;properties&gt;\n    &lt;hbase.version&gt;2.0.2&lt;/hbase.version&gt;\n&lt;/properties&gt;\n\n&lt;dependencies&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt;\n        &lt;artifactId&gt;hbase-server&lt;/artifactId&gt;\n        &lt;version&gt;${hbase.version}&lt;/version&gt;\n    &lt;/dependency&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt;\n        &lt;artifactId&gt;hbase-client&lt;/artifactId&gt;\n        &lt;version&gt;${hbase.version}&lt;/version&gt;\n    &lt;/dependency&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt;\n        &lt;artifactId&gt;hbase-common&lt;/artifactId&gt;\n        &lt;version&gt;${hbase.version}&lt;/version&gt;\n    &lt;/dependency&gt;\n&lt;/dependencies&gt;</code></pre><p><strong>2.初始化静态方法</strong></p>\n<pre><code>static {\n    Configuration configuration = HBaseConfiguration.create();\n    try {\n        connection = ConnectionFactory.createConnection(configuration);\n        admin = connection.getAdmin();\n    } catch (Exception e) {\n        e.printStackTrace();\n    }\n}</code></pre><p><strong>3.判断表是否存在</strong></p>\n<pre><code>public static boolean isExist(String tableName) throws Exception {\n    return admin.tableExists(TableName.valueOf(tableName));\n}</code></pre><p><strong>4.创建表</strong></p>\n<pre><code>public static void createTable(String tableName,String ... column) throws Exception {\n    if(isExist(tableName)){\n        System.out.println(tableName+&quot;已经存在&quot;);\n        return;\n    }\n    HTableDescriptor tableDescriptor = new HTableDescriptor(TableName.valueOf(tableName));\n    for (String c : column) {\n        HColumnDescriptor hColumnDescriptor = new HColumnDescriptor(c);\n        tableDescriptor.addFamily(hColumnDescriptor);\n    }\n    admin.createTable(tableDescriptor);\n    System.out.println(tableName+&quot;创建成功&quot;);\n    getAllTable();\n}</code></pre><p><strong>5.删除表</strong></p>\n<pre><code>public static void deleteTable(String tableName) throws Exception {\n    if(isExist(tableName)){\n        admin.disableTable(TableName.valueOf(tableName));\n        admin.deleteTable(TableName.valueOf(tableName));\n    }\n    System.out.println(tableName+&quot;已被删除&quot;);\n    getAllTable();\n }</code></pre><p><strong>6.获取所有表</strong></p>\n<pre><code>public static void getAllTable() throws Exception {\n    TableName[] tableNames = admin.listTableNames();\n    for (TableName tableName : tableNames) {\n        System.out.println(Bytes.toString(tableName.getName()));\n    }\n}</code></pre><p><strong>7.添加一行数据</strong></p>\n<pre><code>public static void add1Row(String tableName,String rowkey,String cf,String column,String val) throws Exception {\n    Table table = connection.getTable(TableName.valueOf(tableName));\n    Put put = new Put(Bytes.toBytes(rowkey));\n    put.addColumn(Bytes.toBytes(cf),Bytes.toBytes(column),Bytes.toBytes(val));\n    table.put(put);\n}</code></pre><p><strong>8.删除一行数据</strong></p>\n<pre><code>public static void del1Row(String tableName,String rowkey) throws Exception {\n    Table table = connection.getTable(TableName.valueOf(tableName));\n    Delete delete = new Delete(Bytes.toBytes(rowkey));\n    table.delete(delete);\n}</code></pre><p><strong>9.删除多行数据</strong></p>\n<pre><code>public static void delMulRow(String tableName,String... rowkeys) throws Exception {\n    Table table = connection.getTable(TableName.valueOf(tableName));\n    List&lt;Delete&gt; deletes = new ArrayList&lt;Delete&gt;();\n    for (String rowkey : rowkeys) {\n        Delete delete = new Delete(Bytes.toBytes(rowkey));\n        deletes.add(delete);\n    }\n    table.delete(deletes);\n}</code></pre><p><strong>10.获取多行数据</strong></p>\n<pre><code>public static void getAllrows(String tableName) throws Exception {\n    Table table = connection.getTable(TableName.valueOf(tableName));\n    Scan scan = new Scan();\n    scan.setMaxVersions();\n    ResultScanner resultScanner = table.getScanner(scan);\n    for (Result result : resultScanner) {\n        Cell[] cells = result.rawCells();\n        for (Cell cell : cells) {\n            System.out.print(Bytes.toString(CellUtil.cloneFamily(cell))+&quot; &quot;);\n            System.out.print(Bytes.toString(CellUtil.cloneQualifier(cell))+&quot; &quot;);\n            System.out.print(Bytes.toString(CellUtil.cloneRow(cell))+&quot; &quot;);\n            System.out.println(Bytes.toString(CellUtil.cloneValue(cell)));\n        }\n    }\n}</code></pre><p><strong>11.获取一行数据</strong></p>\n<pre><code>public static void getrow(String tableName,String rowkey) throws Exception {\n    Table table = connection.getTable(TableName.valueOf(tableName));\n    Get get = new Get(Bytes.toBytes(rowkey));\n    Result result = table.get(get);\n    Cell[] cells = result.rawCells();\n    for (Cell cell : cells) {\n        System.out.print(Bytes.toString(CellUtil.cloneFamily(cell))+&quot; &quot;);\n        System.out.print(Bytes.toString(CellUtil.cloneQualifier(cell))+&quot; &quot;);\n        System.out.print(Bytes.toString(CellUtil.cloneRow(cell))+&quot; &quot;);\n        System.out.println(Bytes.toString(CellUtil.cloneValue(cell)));\n    }\n}</code></pre><p><strong>hbase的demo</strong></p>\n<pre><code>package com.chen;\n\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.hbase.*;\nimport org.apache.hadoop.hbase.client.*;\nimport org.apache.hadoop.hbase.util.Bytes;\n\nimport java.io.IOException;\nimport java.util.ArrayList;\nimport java.util.List;\n\npublic class App {\n    static Admin admin = null;\n    static Connection connection = null;\n\n    /**\n     * 静态初始化\n     */\n    static {\n        Configuration configuration = HBaseConfiguration.create();\n        try {\n            connection = ConnectionFactory.createConnection(configuration);\n            admin = connection.getAdmin();\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n\n    /**\n     * 判断表是否存在\n     * @param tableName\n     * @return\n     * @throws Exception\n     */\n    public static boolean isExist(String tableName) throws Exception {\n        return admin.tableExists(TableName.valueOf(tableName));\n    }\n\n    /**\n     * 创建表\n     * @param tableName\n     * @param column\n     * @throws Exception\n     */\n    public static void createTable(String tableName,String ... column) throws Exception {\n        if(isExist(tableName)){\n            System.out.println(tableName+&quot;已经存在&quot;);\n            return;\n        }\n        HTableDescriptor tableDescriptor = new HTableDescriptor(TableName.valueOf(tableName));\n        for (String c : column) {\n            HColumnDescriptor hColumnDescriptor = new HColumnDescriptor(c);\n            tableDescriptor.addFamily(hColumnDescriptor);\n        }\n        admin.createTable(tableDescriptor);\n        System.out.println(tableName+&quot;创建成功&quot;);\n        getAllTable();\n    }\n\n    /**\n     * 删除表\n     * @param tableName\n     * @throws Exception\n     */\n    public static void deleteTable(String tableName) throws Exception {\n        if(isExist(tableName)){\n            admin.disableTable(TableName.valueOf(tableName));\n            admin.deleteTable(TableName.valueOf(tableName));\n        }\n        System.out.println(tableName+&quot;已被删除&quot;);\n        getAllTable();\n    }\n\n    /**\n     * 获取所有表\n     * @throws Exception\n     */\n    public static void getAllTable() throws Exception {\n        TableName[] tableNames = admin.listTableNames();\n        for (TableName tableName : tableNames) {\n            System.out.println(Bytes.toString(tableName.getName()));\n        }\n    }\n\n\n    /**\n     * 添加一行数据\n     * @param tableName\n     * @param rowkey\n     * @param cf\n     * @param column\n     * @param val\n     * @throws Exception\n     */\n    public static void add1Row(String tableName,String rowkey,String cf,String column,String val) throws Exception {\n        Table table = connection.getTable(TableName.valueOf(tableName));\n        Put put = new Put(Bytes.toBytes(rowkey));\n        put.addColumn(Bytes.toBytes(cf),Bytes.toBytes(column),Bytes.toBytes(val));\n        table.put(put);\n    }\n\n\n    /**\n     * 删除一行数据\n     * @param tableName\n     * @param rowkey\n     * @throws Exception\n     */\n    public static void del1Row(String tableName,String rowkey) throws Exception {\n        Table table = connection.getTable(TableName.valueOf(tableName));\n        Delete delete = new Delete(Bytes.toBytes(rowkey));\n        table.delete(delete);\n    }\n\n    /**\n     * 删除多行数据\n     * @param tableName\n     * @param rowkeys\n     * @throws Exception\n     */\n    public static void delMulRow(String tableName,String... rowkeys) throws Exception {\n        Table table = connection.getTable(TableName.valueOf(tableName));\n        List&amp;lt;Delete&amp;gt; deletes = new ArrayList&amp;lt;Delete&amp;gt;();\n        for (String rowkey : rowkeys) {\n            Delete delete = new Delete(Bytes.toBytes(rowkey));\n            deletes.add(delete);\n        }\n        table.delete(deletes);\n    }\n\n    /**\n     * 获取多行数据\n     * @param tableName\n     * @throws Exception\n     */\n    public static void getAllrows(String tableName) throws Exception {\n        Table table = connection.getTable(TableName.valueOf(tableName));\n        Scan scan = new Scan();\n        scan.setMaxVersions();\n        ResultScanner resultScanner = table.getScanner(scan);\n        for (Result result : resultScanner) {\n            Cell[] cells = result.rawCells();\n            for (Cell cell : cells) {\n                System.out.print(Bytes.toString(CellUtil.cloneFamily(cell))+&quot; &quot;);\n                System.out.print(Bytes.toString(CellUtil.cloneQualifier(cell))+&quot; &quot;);\n                System.out.print(Bytes.toString(CellUtil.cloneRow(cell))+&quot; &quot;);\n                System.out.println(Bytes.toString(CellUtil.cloneValue(cell)));\n            }\n        }\n    }\n\n    public static void main(String[] args) throws Exception {\n        /*String table=&quot;t3&quot;;\n        System.out.println(isExist(table));*/\n        //createTable(&quot;test1&quot;,&quot;info&quot;,&quot;extra&quot;);\n        //deleteTable(&quot;test1&quot;);\n        add1Row(&quot;test1&quot;,&quot;r2&quot;,&quot;extra&quot;,&quot;age&quot;,&quot;11&quot;);\n        //del1Row(&quot;test1&quot;,&quot;r1&quot;);\n        getAllrows(&quot;test1&quot;);\n    }\n}\n</code></pre><h1 id=\"flume\"><a href=\"#flume\" class=\"headerlink\" title=\"flume\"></a>flume</h1><h2 id=\"一-flume的搭建\"><a href=\"#一-flume的搭建\" class=\"headerlink\" title=\"一.flume的搭建\"></a>一.flume的搭建</h2><p>1.将在qq939598604的百度网盘中的路径，我的软件/apache-flume-1.8.0-bin.tar.gz下载并上传到/soft/elk目录下<br>2.解压</p>\n<pre><code>cd /soft/elk\ntar –zxvf apache-flume-1.8.0-bin.tar.gz</code></pre><p>3.配置java_home<br>cp flume-env.sh.template flume-env.sh<br>vim flume-env.sh</p>\n<pre><code>export JAVA_HOME=/soft/jdk1.8.0_161</code></pre><p>4.编辑配置文件<br>vim  spool1.conf </p>\n<pre><code>a1.sources = r1\na1.sinks = k1\na1.channels = c1\n\n# Describe/configure the source\na1.sources.r1.type = netcat\na1.sources.r1.bind = localhost\na1.sources.r1.port = 44444\n\n# Describe the sink\na1.sinks.k1.type = logger\n\n# Use a channel which buffers events in memory\na1.channels.c1.type = memory\na1.channels.c1.capacity = 1000\na1.channels.c1.transactionCapacity = 100\n\n# Bind the source and sink to the channel\na1.sources.r1.channels = c1\na1.sinks.k1.channel = c1</code></pre><p>5.启动flume</p>\n<pre><code>/soft/elk/apache-flume-1.8.0-bin/bin/flume-ng agent -c /soft/elk/apache-flume-1.8.0-bin/conf -f /soft/elk/apache-flume-1.8.0-bin/conf/spool1.conf --name a1 -Dflume.root.logger=INFO,console</code></pre><p>6.安装telnet工具</p>\n<pre><code>yum install telnet -y\ntelnet localhost 4444</code></pre><p>7.在telnet终端发送数据到flume中并查看是否有接收到</p>\n<h1 id=\"zookpeer\"><a href=\"#zookpeer\" class=\"headerlink\" title=\"zookpeer\"></a>zookpeer</h1><h2 id=\"一-Zookeeper集群搭建\"><a href=\"#一-Zookeeper集群搭建\" class=\"headerlink\" title=\"一.Zookeeper集群搭建\"></a>一.Zookeeper集群搭建</h2><p>（一）先把Java环境配好，三台机器，配置Zookeeper<br>（二）下载zookeeper-3.4.10.tar.gz，并且上传到/soft/目录下，直接解压zookeeper-3.4.10.tar.gz<br> tar -zxvf zookeeper-3.4.10.tar.gz<br>（三）修改配置文件名称</p>\n<pre><code>mv /soft/zookeeper-3.4.10/conf/zoo_simple.cfg /soft/zookeeper-3.4.10/conf/zoo.cfg</code></pre><p>（四）编辑配置文件</p>\n<pre><code>vim /soft/zookeeper-3.4.10/conf/zoo.cfg</code></pre><p>修改<strong>dataDir=/soft/zookeeper-3.4.10/data</strong><br>同时增加</p>\n<pre><code>server.1=192.168.197.231:2888:3888\nserver.2=192.168.197.232:2888:3888\nserver.3=192.168.197.233:2888:3888</code></pre><p><strong>server.X=A:B:C</strong>  X-代表服务器编号 A-代表ip  B和C-代表端口，这个端口用来系统之间通信</p>\n<p>（五）编辑配置myid文件</p>\n<p>vim /soft/zookeeper-3.4.10/data/myid<br>之后会产生一个新文件，直接在里面写X即可，比如我配置的三个server，当前服务器的ip是多少，myid里面写的X就是server.X=ip:2888:3888 中ip所对应的X</p>\n<pre><code>server.1=192.168.197.231:2888:3888【192.168.197.231服务器上面的myid填写1】\nserver.2=192.168.197.232:2888:3888【192.168.197.232服务器上面的myid填写2】\nserver.3=192.168.197.233:2888:3888【192.168.197.233服务器上面的myid填写3】</code></pre><p>（六）修改环境</p>\n<p>​    vim /etc/profile<br>　　在export PATH语句前添加两行：</p>\n<pre><code>ZOOKEEPER=/soft/zookeeper-3.4.10\nPATH=PATH:ZOOKEEPER/bin</code></pre><p>（六）并执行 source /etc/profile<br>（七）启动zookeeper<br>分别在3台机器启动 zookeeper</p>\n<h1 id=\"kafka\"><a href=\"#kafka\" class=\"headerlink\" title=\"kafka\"></a>kafka</h1><h2 id=\"一-认识\"><a href=\"#一-认识\" class=\"headerlink\" title=\"一.认识\"></a>一.认识</h2><p><strong>首先几个概念：</strong></p>\n<ol>\n<li><strong>kafka作为一个集群运</strong>行在一个或多个服务器上。</li>\n<li>kafka集群存储的消息是以topic为类别记录的。</li>\n<li>每个消息（也叫记录record，我习惯叫消息）是由一个key，一个value和时间戳构成。</li>\n<li>kafka是基于点对点的拉取（pull）模式（看到尚硅谷视频讲到，便记下来）</li>\n</ol>\n<p><strong>kafka有四个核心API：</strong></p>\n<ul>\n<li><p>应用程序使用 <code>Producer API</code> 发布消息到1个或多个topic（主题）。</p>\n</li>\n<li><p>应用程序使用 <code>Consumer API</code> 来订阅一个或多个topic，并处理产生的消息。</p>\n</li>\n<li><p>应用程序使用 <code>Streams API</code> 充当一个流处理器，从1个或多个topic消费输入流，并生产一个输出流到1个或多个输出topic，有效地将输入流转换到输出流。</p>\n</li>\n<li><p><code>Connector API</code>允许构建或运行可重复使用的生产者或消费者，将topic连接到现有的应用程序或数据系统。例如，一个关系数据库的连接器可捕获每一个变化。</p>\n<p><img src=\"C:%5CUsers%5CAdministrator%5CDesktop%5CMd%E7%AC%94%E8%AE%B0%5Cpic%5Cproduct.png\" alt=\"1565660315040\"></p>\n</li>\n</ul>\n<p><strong>基本术语：</strong></p>\n<p><strong>Topic</strong></p>\n<p>Kafka将消息种子(Feed)分门别类，每一类的消息称之为一个主题(Topic).</p>\n<ul>\n<li><p>Topic是Kafka数据写入操作的基本单元，可以指定副本</p>\n</li>\n<li><p>一个Topic包含一个或多个Partition，建Topic时可手动指定Partition个数，个数必须少于服务器个数</p>\n</li>\n<li><p>每条消息属于且仅属于一个Topic</p>\n</li>\n<li><p>Producer发布数据时，必须指定将该消息发布到哪个Topic</p>\n</li>\n<li><p>Consumer订阅消息时，也必须指定订阅哪个Topic的信息</p>\n<p><strong>Partition</strong></p>\n</li>\n<li><p>每个Partition只会在一个Broker上，物理上每个Partition对应的是一个文件夹</p>\n</li>\n<li><p>Kafka默认使用的是hash进行分区，所以会出现不同的分区数据不一样的情况，但是partitioner是可以override的</p>\n</li>\n<li><p>Partition包含多个Segment，每个Segment对应一个文件，Segment可以手动指定大小，当Segment达到阈值时，将不再写数据，每个Segment都是大小相同的</p>\n</li>\n<li><p>Segment由多个不可变的记录组成，记录只会被append到Segment中，不会被单独删除或者修改，每个Segment中的Message数量不一定相等</p>\n<p><strong>Producer</strong></p>\n</li>\n</ul>\n<p>发布消息的对象称之为主题生产者(Kafka topic producer)，写数据只会找leader</p>\n<p><strong>Consumer</strong></p>\n<p>订阅消息并处理发布的消息的对象称之为主题消费者(consumers)</p>\n<p> <strong>Broker</strong></p>\n<p>已发布的消息保存在一组服务器中，称之为Kafka集群。集群中的每一个服务器都是一个代理(Broker). 消费者可以订阅一个或多个主题（topic），并从Broker拉数据，从而消费这些已发布的消息。</p>\n<p> <strong>主题</strong></p>\n<p> Topic是发布的消息的类别或者种子Feed名。对于每一个Topic，Kafka集群维护这一个分区的log，就像下图中的示例： </p>\n<p><img src=\"C:%5CUsers%5CAdministrator%5CDesktop%5CMd%E7%AC%94%E8%AE%B0%5Cpic%5C1565660685648.png\" alt=\"1565660685648\"></p>\n<p> 每一个分区都是一个顺序的、不可变的消息队列， 并且可以持续的添加。分区中的消息都被分了一个序列号，称之为偏移量(offset)，在每个分区中此偏移量都是唯一的。 </p>\n<p>Kafka集群保持所有的消息，直到它们过期， 无论消息是否被消费了。 实际上消费者所持有的仅有的元数据就是这个偏移量，也就是消费者在这个log中的位置。 这个偏移量由消费者控制：正常情况当消费者消费消息的时候，偏移量也线性的的增加。但是实际偏移量由消费者控制，消费者可以将偏移量重置为更老的一个偏移量，重新读取消息。 可以看到这种设计对消费者来说操作自如， 一个消费者的操作不会影响其它消费者对此log的处理。 再说说分区。Kafka中采用分区的设计有几个目的。一是可以处理更多的消息，不受单台服务器的限制。Topic拥有多个分区意味着它可以不受限的处理更多的数据。第二，分区可以作为并行处理的单元，稍后会谈到这一点。</p>\n<p>kafka存储数据有2个地方：broker里面的patition下的log文件，broker的存储策略是文件的大小和存储时间，zookpeer里面的元数据</p>\n<h2 id=\"二-window安装kafka\"><a href=\"#二-window安装kafka\" class=\"headerlink\" title=\"二.window安装kafka\"></a>二.window安装kafka</h2><p><strong>（一）zookeeper在Windows下的安装</strong></p>\n<p>1.把下载的zookeeper的文件解压到指定目录：D:\\zookeeper-3.4.14</p>\n<p>2.复制conf目录下的zoo_sample.cfg文件为zoo.cfg</p>\n<p>3.修改内容如下：</p>\n<pre><code>dataDir=D:\\data\\zookeeper</code></pre><p>4.进入到bin目录，双击启动zkServer.cmd</p>\n<p>5.启动后jps可以看到QuorumPeerMain的进程</p>\n<pre><code>D:\\zookeeper-3.4.14\\bin &gt;jps</code></pre><p>6.启动客户端运行查看一下</p>\n<pre><code>D:\\zookeeper-3.4.14\\bin&gt;zkCli.cmd -server 127.0.0.1:2181</code></pre><p><strong>（二）kafka在Windows下的安装</strong></p>\n<p>1.下载kafka</p>\n<p>下载kafka，必须scala的版本对应kafka_2.11-2.3.0，其中前面的是2.12是scala的 版本号</p>\n<p><a href=\"https://www.apache.org/dyn/closer.cgi?path=/kafka/2.3.0/kafka_2.11-2.3.0.tgz\" target=\"_blank\" rel=\"noopener\">https://www.apache.org/dyn/closer.cgi?path=/kafka/2.3.0/kafka_2.11-2.3.0.tgz</a></p>\n<p>2.解压文件（我的目录是D:\\kafka_2.11-2.3.0  【这里不要在Program Files等文件名之间有空格的目录下，不然一会执行会不识别路径】）</p>\n<p>3.修改D:\\kafka_2.11-2.3.0\\config下server.properties文件</p>\n<pre><code>log.dirs=D:\\kafka_2.11-2.3.0\\kafka-logs\nbroker.id=0\nport=9092\nzookeeper.connect=localhost:2181</code></pre><p>4.进入kafka文件目录D:\\kafka_2.11-2.3.0，执行以下命令，启动kafka通讯的服务器broker</p>\n<pre><code>.\\bin\\windows\\kafka-server-start.bat .\\config\\server.properties</code></pre><p>5.进入kafka文件目录D:\\kafka_2.11-2.3.0\\bin\\windows，创建kafka的消息topics</p>\n<pre><code>kafka-topics.bat --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test</code></pre><p> 6.分别打开两个cmd窗口，进入目录D:\\kafka_2.11-2.3.0\\bin\\windows，创建Producer和Consumer</p>\n<p>（1）Producer</p>\n<p>进入目录D:\\kafka_2.11-2.3.0\\bin\\windows输入如下命令</p>\n<pre><code>kafka-console-producer.bat --broker-list localhost:9092 --topic test</code></pre><p>（2）Consumer</p>\n<p>进入目录D:\\kafka_2.11-2.3.0\\bin\\windows输入如下命令</p>\n<pre><code>kafka-console-consumer.bat --zookeeper localhost:2181 --topic testDemo</code></pre><p>然后就可以在Producer中发信息，在Consumer中收信息了</p>\n<p><strong>（三）kafka集群在Windows下的安装</strong></p>\n<p>1.复制上面的kafka单机版文件夹</p>\n<p>修改文件名为：kafka_2.11-2.3.0–1和 kafka_2.11-2.3.0–2</p>\n<p><img src=\"C:%5CUsers%5CAdministrator%5CDesktop%5CMd%E7%AC%94%E8%AE%B0%5Cpic%5C1565773682533.png\" alt=\"1565773682533\"></p>\n<p>2.修改D:\\kafka_2.11-2.3.0–1\\config下server.properties文件</p>\n<pre><code>log.dirs=D:\\kafka_2.11-2.3.0--1\\kafka-logs\nbroker.id=1\nport=9093\nzookeeper.connect=localhost:2181</code></pre><p>3.修改D:\\kafka_2.11-2.3.0–2\\config下server.properties文件</p>\n<pre><code>log.dirs=D:\\kafka_2.11-2.3.0--2\\kafka-logs\nbroker.id=2\nport=9094\nzookeeper.connect=localhost:2181</code></pre><p>4.分别进入kafka文件目录D:\\kafka_2.11-2.3.0和kafka_2.11-2.3.0–1和 kafka_2.11-2.3.0–2三个文件夹，执行以下命令，启动kafka通讯的服务器broker</p>\n<pre><code>.\\bin\\windows\\kafka-server-start.bat .\\config\\server.properties</code></pre><p>  5.查看kafka集群中所有broker节点</p>\n<p>broker的配置文件中有zookeeper的地址,也有自己的broker ID </p>\n<p>当broker启动后,会在zookeeper中新建一个znode,访问zk并执行ls /brokers/ids 就可以看到zk中存的所有的broker id list，然后确认你增加的broker的ID是否在list里面 </p>\n<pre><code>D:\\zookeeper-3.4.14\\bin&gt;zkCli.cmd -server 127.0.0.1:2181\n[zk: 127.0.0.1:2181(CONNECTED) 2] ls /\n[cluster, controller_epoch, controller, brokers, zookeeper, admin, isr_change_no\ntification, consumers, log_dir_event_notification, latest_producer_id_block, config]\n[zk: 127.0.0.1:2181(CONNECTED) 3] ls /brokers\n[ids, topics, seqid]\n[zk: 127.0.0.1:2181(CONNECTED) 4] ls /brokers/ids\n[0, 1, 2]</code></pre><p>上面可以看到/brokers/ids有[0, 1, 2]，说明是一个集群了</p>\n<p>6.windows下kafka集群的批处理启动脚本</p>\n<pre><code>start d:\\windows_install\\zookeeper-3.4.14\\bin\\zkServer.cmd\nstart d:\\windows_install\\kafka_2.11-2.3.0\\bin\\windows\\kafka-server-start.bat d:\\windows_install\\kafka_2.11-2.3.0\\config\\server.properties\nstart d:\\windows_install\\kafka_2.11-2.3.0--1\\bin\\windows\\kafka-server-start.bat d:\\windows_install\\kafka_2.11-2.3.0--1\\config\\server.properties\nstart d:\\windows_install\\kafka_2.11-2.3.0--2\\bin\\windows\\kafka-server-start.bat d:\\windows_install\\kafka_2.11-2.3.0--2\\config\\server.properties</code></pre><h2 id=\"三-消费者组案例测试\"><a href=\"#三-消费者组案例测试\" class=\"headerlink\" title=\"三.消费者组案例测试\"></a>三.<strong>消费者组案例测试</strong></h2><p><strong>案例一</strong></p>\n<p>生产者：如果topicA只有一个patition，即patition0，启动一个生产者实例</p>\n<p>消费者组中有A和B，其中消费者A先启动，A会绑定topicA中的patition0，然后再启动消费者B，启动的时候会提示，没有patition被绑定，则topicA中的生产数据的时候只有消费者A消费。</p>\n<p><strong>案例二</strong></p>\n<p>在前面的kafka集群3台机器中，连接测试192.168.197.30测试，以下测试是在windows的D:\\windows_install\\kafka_2.11-2.3.0\\bin\\windows&gt;目录下进行</p>\n<p>1.新建一个topic，指定复制因子为3，分区为3</p>\n<pre><code>kafka-topics.bat --create --zookeeper 192.168.197.30:2181 --replication-factor 3 --partitions 3 --topic test\nCreated topic test.</code></pre><p>2.启动一个生产者</p>\n<pre><code>kafka-console-producer.bat --broker-list 192.168.197.30:9092 --topic test</code></pre><p>3.启动消费者A，并指定组id为t</p>\n<pre><code>kafka-console-consumer.bat --bootstrap-server 192.168.197.30:9092 --topic test --group t</code></pre><p>4.启动消费者B，并指定组id为t</p>\n<pre><code>kafka-console-consumer.bat --bootstrap-server 192.168.197.30:9092 --topic test --group t</code></pre><p>5.在生产者端输入消息</p>\n<pre><code>D:\\windows_install\\kafka_2.11-2.3.0\\bin\\windows&gt;kafka-console-producer.bat --broker-list 192.168.197.30:9092 --topic test\n&gt;dafads\n&gt;sdfa\n&gt;fadsads\n&gt;dfads</code></pre><p>6.可以观察到，同个消费者组的消费者，消费消息只能由一个完成，并且只有一次</p>\n<p>消费者A获取到的消息如下：</p>\n<pre><code>D:\\windows_install\\kafka_2.11-2.3.0\\bin\\windows&gt;kafka-console-consumer.bat --botstrap-server 192.168.197.30:9092 --topic test --group t\ndafads\nfadsads</code></pre><p>消费者B获取到的消息如下：</p>\n<pre><code>D:\\windows_install\\kafka_2.11-2.3.0\\bin\\windows&gt;kafka-console-consumer.bat --bootstrap-server 192.168.197.30:9092 --topic test --group t\nsdfa\ndfads</code></pre><p><strong>同个消费者组的消费者，消费消息只能由一个完成，并且只有一次</strong></p>\n<h2 id=\"四-消费者连接集群只需一个broker\"><a href=\"#四-消费者连接集群只需一个broker\" class=\"headerlink\" title=\"四.消费者连接集群只需一个broker\"></a>四.消费者连接集群只需一个broker</h2><p>在前面的kafka集群3台机器中，连接测试192.168.197.30测试，以下测试是在windows的D:\\windows_install\\kafka_2.11-2.3.0\\bin\\windows&gt;目录下进行</p>\n<p>1.新建一个topic，指定复制因子为3，分区为3</p>\n<pre><code>kafka-topics.bat --create --zookeeper 192.168.197.30:2181 --replication-factor 3 --partitions 3 --topic test\nCreated topic test.</code></pre><p>2.启动一个生产者</p>\n<pre><code>kafka-console-producer.bat --broker-list 192.168.197.30:9092 --topic test</code></pre><p>3.启动消费者A，连接的bootstrap-server,参数指定为 <code>--bootstrap-server 192.168.197.30:9092</code>并指定组id为t</p>\n<pre><code>kafka-console-consumer.bat --bootstrap-server 192.168.197.30:9092 --topic test --group t</code></pre><p>4.启动消费者B，连接的bootstrap-server和消费者A不一样,参数指定为 <code>--bootstrap-server 192.168.197.30:9093</code>并指定组id为t</p>\n<pre><code>kafka-console-consumer.bat --bootstrap-server 192.168.197.30:9092 --topic test --group t</code></pre><p>5.在生产者端输入消息</p>\n<pre><code>D:\\windows_install\\kafka_2.11-2.3.0\\bin\\windows&gt;kafka-console-producer.bat --broker-list 192.168.197.30:9092 --topic test\n&gt;ghjhh67\n&gt;ljgty\n&gt;tyetw\n&gt;uioqw</code></pre><p>6.可以观察到，消费者连接集群只需一个broker，即可获取到整个集群的消息</p>\n<p>消费者A获取到的消息如下：</p>\n<pre><code>D:\\windows_install\\kafka_2.11-2.3.0\\bin\\windows&gt;kafka-console-consumer.bat --botstrap-server 192.168.197.30:9092 --topic test --group t\nghjhh67\ntyetw</code></pre><p>消费者B获取到的消息如下：</p>\n<pre><code>D:\\windows_install\\kafka_2.11-2.3.0\\bin\\windows&gt;kafka-console-consumer.bat --bootstrap-server 192.168.197.30:9093 --topic test --group t\nljgty\nuioqw</code></pre><p><strong>消费者连接集群只需一个broker，即可获取到整个集群的消息</strong></p>\n<h2 id=\"五-生产者的java版本代码编写\"><a href=\"#五-生产者的java版本代码编写\" class=\"headerlink\" title=\"五.生产者的java版本代码编写\"></a>五.生产者的java版本代码编写</h2><p><strong>(一)最简单的调用方式</strong></p>\n<p>1.新建一个MyProduce.java，发送消息到test的topic</p>\n<pre><code class=\"java\">public class MyProduce {\n    public static void main(String[] args) {\n        Properties props = new Properties();\n        props.put(&quot;bootstrap.servers&quot;,&quot;192.168.197.30:9092&quot;);\n        props.put(&quot;acks&quot;,&quot;all&quot;);\n        props.put(&quot;retries&quot;,0);\n        props.put(&quot;batch.size&quot;,16384);\n        props.put(&quot;linger.ms&quot;,1);\n        props.put(&quot;buffer.memory&quot;,33554432);\n        props.put(&quot;key.serializer&quot;,&quot;org.apache.kafka.common.serialization.StringSerializer&quot;);\n        props.put(&quot;value.serializer&quot;,&quot;org.apache.kafka.common.serialization.StringSerializer&quot;);\n        Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props);\n        for(int i=0;i&lt;10;i++){\n          producer.send(new ProducerRecord&lt;&gt;(&quot;test&quot;, Integer.toString(i), Integer.toString(i)));\n        }\n        producer.close();\n    }\n}</code></pre>\n<p><strong>(二)有回调的生产者</strong></p>\n<pre><code>package com.gzstrong.TestKafka;\n\nimport org.apache.kafka.clients.producer.*;\n\nimport java.util.Properties;\n\n/**\n * @author 陈锦华\n * @version V1.0\n * @Title:\n * @Description: create by Intellij Idea\n * @date 2019/8/15 0015 上午 9:08\n **/\npublic class MyProduce {\n    public static void main(String[] args) {\n        Properties props = new Properties();\n        props.put(&quot;bootstrap.servers&quot;,&quot;192.168.197.30:9092&quot;);\n        props.put(&quot;acks&quot;,&quot;all&quot;);\n        props.put(&quot;retries&quot;,0);\n        props.put(&quot;batch.size&quot;,16384);\n        props.put(&quot;linger.ms&quot;,1);\n        props.put(&quot;buffer.memory&quot;,33554432);\n        props.put(&quot;key.serializer&quot;,&quot;org.apache.kafka.common.serialization.StringSerializer&quot;);\n        props.put(&quot;value.serializer&quot;,&quot;org.apache.kafka.common.serialization.StringSerializer&quot;);\n        Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props);\n        for(int i=0;i&lt;10;i++){\n            producer.send(new ProducerRecord&lt;&gt;(&quot;test&quot;, Integer.toString(i), Integer.toString(i)), new Callback() {\n                @Override\n                public void onCompletion(RecordMetadata metadata, Exception exception) {\n                    System.out.println(metadata.partition()+&quot;---&quot;+metadata.offset());\n                }\n            });\n\n        }\n        producer.close();\n    }\n}</code></pre><p><strong>(二)指定分区发送，且有回调的生产者</strong></p>\n<p>1.新建ProducePatition.java实现Partitioner接口</p>\n<pre><code>public class ProducePatition implements Partitioner {\n\n    @Override\n    public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {\n        return 0;\n    }\n\n    @Override\n    public void close() {\n\n    }\n\n    @Override\n    public void configure(Map&lt;String, ?&gt; configs) {\n\n    }\n}</code></pre><p>2.在生产者里面设置参数<code>props.put(&quot;partitioner.class&quot;,&quot;com.gzstrong.TestKafka.ProducePatition&quot;);</code></p>\n<pre><code>public class MyProduce {\n    public static void main(String[] args) {\n        Properties props = new Properties();\n        props.put(&quot;bootstrap.servers&quot;,&quot;192.168.197.30:9092&quot;);\n        props.put(&quot;acks&quot;,&quot;all&quot;);\n        props.put(&quot;retries&quot;,0);\n        props.put(&quot;batch.size&quot;,16384);\n        props.put(&quot;linger.ms&quot;,1);\n        props.put(&quot;buffer.memory&quot;,33554432);\n        props.put(&quot;partitioner.class&quot;,&quot;com.gzstrong.TestKafka.ProducePatition&quot;);\n        props.put(&quot;key.serializer&quot;,&quot;org.apache.kafka.common.serialization.StringSerializer&quot;);\n        props.put(&quot;value.serializer&quot;,&quot;org.apache.kafka.common.serialization.StringSerializer&quot;);\n        Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props);\n        for(int i=0;i&lt;10;i++){\n            producer.send(new ProducerRecord&lt;&gt;(&quot;test&quot;, Integer.toString(i), Integer.toString(i)), (metadata, exception) -&gt; System.out.println(metadata.partition()+&quot;---&quot;+metadata.offset()));\n        }\n        producer.close();\n    }\n}</code></pre><h2 id=\"六-消费者java编码\"><a href=\"#六-消费者java编码\" class=\"headerlink\" title=\"六.消费者java编码\"></a>六.消费者java编码</h2><p>（一）高级消费者</p>\n<pre><code>public class MyComSumer {\n    public static void main(String[] args){\n        Properties props = new Properties();\n        props.put(&quot;bootstrap.servers&quot;, &quot;192.168.197.30:9092&quot;);\n        props.put(&quot;group.id&quot;, &quot;test&quot;);\n        props.put(&quot;enable.auto.commit&quot;, &quot;false&quot;);\n        props.put(&quot;auto.commit.interval.ms&quot;, &quot;1000&quot;);\n        props.put(&quot;session.timeout.ms&quot;, &quot;30000&quot;);\n        props.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);\n        props.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);\n        KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(props);\n        consumer.subscribe(Arrays.asList(&quot;test&quot;, &quot;bar&quot;));\n        final int minBatchSize = 200;\n        List&lt;ConsumerRecord&lt;String, String&gt;&gt; buffer = new ArrayList&lt;&gt;();\n        while (true) {\n            ConsumerRecords&lt;String, String&gt; records = consumer.poll(100);\n            for (ConsumerRecord&lt;String, String&gt; record : records) {\n                System.out.println(&quot;offset:&quot;+record.offset()+&quot; partition: &quot;+record.partition()+&quot; record: &quot;+ record);\n            }\n        }\n    }\n}</code></pre><h1 id=\"spark\"><a href=\"#spark\" class=\"headerlink\" title=\"spark\"></a>spark</h1><h2 id=\"一-spark集群搭建\"><a href=\"#一-spark集群搭建\" class=\"headerlink\" title=\"一.spark集群搭建\"></a>一.spark集群搭建</h2><p><strong>（一）.安装基础环境（JAVA和SCALA环境）</strong></p>\n<p><strong>1.安装JDK</strong></p>\n<p>(1)下载jdk1.8.0_161<br>(2)在/etc/profile中添加如下配置<br> vim /etc/profile</p>\n<pre><code>    export JAVA_HOME=/soft/jdk1.8.0_161\n    export JRE_HOME=${JAVA_HOME}/jre\n    export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib\n    export PATH=${JAVA_HOME}/bin:$PATH</code></pre><p>(3)使环境变量生效，source /etc/profile<br>(4)安装验证# java -version </p>\n<p><strong>2.安装SCALA</strong></p>\n<p>(1)到<a href=\"http://www.scala-lang.org/download/2.11.8.html下载scala2.11.8.tar.gz\" target=\"_blank\" rel=\"noopener\">http://www.scala-lang.org/download/2.11.8.html下载scala2.11.8.tar.gz</a><br>将下载的文件上传到/soft目录下</p>\n<pre><code>tar -zxvf /soft/scala-2.11.8.tgz -C /soft/</code></pre><p>(2)在/etc/profile中添加如下配置<br>  vim /etc/profile</p>\n<pre><code>  export SCALA_HOME=/soft/scala-2.11.8\n  export PATH=$SCALA_HOME/bin:$PATH</code></pre><p>(3)使环境变量生效，source /etc/profile<br>(4)安装验证# java -version </p>\n<p><strong>（二）Hadoop2.7.4完全分布式搭建</strong></p>\n<p>*<em>（三）Spark2.1.0完全分布式环境搭建 *</em></p>\n<p>以下操作都在Master节点进行。<br>1.下载二进制包spark-2.1.0-bin-hadoop2.7.tgz<br>2.解压并移动到相应目录，命令如下：</p>\n<pre><code>tar -zxvf spark-2.2.1-bin-hadoop2.7.tgz -C /soft/</code></pre><p>3.修改相应的配置文件。<br>　　在/etc/profile中添加如下配置<br>          vim /etc/profile</p>\n<pre><code>  export SPARK_HOME=/soft/spark-2.2.1-bin-hadoop2.7/\n  export PATH=$PATH:$SPARK_HOME/bin</code></pre><pre><code>使环境变量生效，source /etc/profile</code></pre><p>4.复制spark-env.sh.template成spark-env.sh<br>　  　cp /soft/spark-2.2.1-bin-hadoop2.7/conf/spark-env.sh.template /soft/spark-2.2.1-bin-        hadoop2.7/conf/spark-env.sh<br>5.修改$SPARK_HOME/conf/spark-env.sh，添加如下内容：</p>\n<pre><code>export JAVA_HOME=/soft/jdk1.8.0_161/\nexport SCALA_HOME=/soft/scala-2.11.8\nexport HADOOP_HOME=/soft/hadoop-2.7.4\nexport HADOOP_CONF_DIR=/soft/hadoop-2.7.4/etc/hadoop\nexport SPARK_MASTER_IP=master\nexport SPARK_MASTER_HOST=master\nexport SPARK_WORKER_MEMORY=512m\nexport SPARK_HOME=/soft/spark-2.2.1-bin-hadoop2.7\nexport SPARK_DIST_CLASSPATH=$(/soft/hadoop-2.7.4/bin/hadoop classpath)</code></pre><p>6.复制slaves.template成slaves<br>7.cp /soft/spark-2.2.1-bin-hadoop2.7/conf/slaves.template /soft/spark-2.2.1-bin-hadoop2.7/conf/slaves<br>8.修改$SPARK_HOME/conf/slaves，添加如下内容：</p>\n<pre><code>master\nslave1\nslave2</code></pre><p>9.将配置好的spark文件复制到Slave1和Slave2节点。<br>    scp /opt/spark-2.1.0-bin-hadoop2.7 root@Slave1:/opt<br>          scp /opt/spark-2.1.0-bin-hadoop2.7 root@Slave2:/opt<br>10.修改Slave1和Slave2配置。<br>　　在slave1和slave2上分别修改/etc/profile，增加Spark的配置，过程同Master一样。<br>　　在slave1和slave2修改$SPARK_HOME/conf/spark-env.sh，将export SPARK_LOCAL_IP=114.55.246.88改成slave1和slave2对应节点的IP。<br>11.在master节点启动集群。<br>　　/opt/spark-2.1.0-bin-hadoop2.7/sbin/start-all.sh<br>12.查看集群是否启动成功：<br>　　jps<br>　　master在Hadoop的基础上新增了：<br>　　master<br>　　slave在Hadoop的基础上新增了：<br>　　Worker</p>\n<h2 id=\"二-spark的maven项目构建（基于idea-和maven）\"><a href=\"#二-spark的maven项目构建（基于idea-和maven）\" class=\"headerlink\" title=\"二.spark的maven项目构建（基于idea 和maven）\"></a>二.spark的maven项目构建（基于idea 和maven）</h2><p>首先idea安装scala插件<br><img src=\"https://images.gitee.com/uploads/images/2019/0521/154430_f3a9b447_429848.png\" alt=\"输入图片说明\" title=\"QQ截图20190521154225.png\"></p>\n<p>新建一个maven项目<br>开始创建项目体系结构<br>File –&gt; Project<br><img src=\"https://static.oschina.net/uploads/img/201802/11153035_Ac2b.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"><br><img src=\"https://static.oschina.net/uploads/img/201802/11153132_Ijqk.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"><br><img src=\"https://static.oschina.net/uploads/img/201802/11153403_6Rrj.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"><br><img src=\"https://static.oschina.net/uploads/img/201802/11153427_h2XW.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"></p>\n<p>pom.xml</p>\n<pre><code>&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\n         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd&quot;&gt;\n    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\n    &lt;groupId&gt;com.chen&lt;/groupId&gt;\n    &lt;artifactId&gt;Spark_Test&lt;/artifactId&gt;\n    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;\n    &lt;inceptionYear&gt;2008&lt;/inceptionYear&gt;\n    &lt;properties&gt;\n        &lt;scala.version&gt;2.11.0&lt;/scala.version&gt;\n        &lt;spark.version&gt;2.0.2&lt;/spark.version&gt;\n        &lt;scala&gt;2.11&lt;/scala&gt;\n    &lt;/properties&gt;\n\n    &lt;repositories&gt;\n        &lt;repository&gt;\n            &lt;id&gt;scala-tools.org&lt;/id&gt;\n            &lt;name&gt;Scala-Tools Maven2 Repository&lt;/name&gt;\n            &lt;url&gt;http://scala-tools.org/repo-releases&lt;/url&gt;\n        &lt;/repository&gt;\n    &lt;/repositories&gt;\n\n    &lt;pluginRepositories&gt;\n        &lt;pluginRepository&gt;\n            &lt;id&gt;scala-tools.org&lt;/id&gt;\n            &lt;name&gt;Scala-Tools Maven2 Repository&lt;/name&gt;\n            &lt;url&gt;http://scala-tools.org/repo-releases&lt;/url&gt;\n        &lt;/pluginRepository&gt;\n    &lt;/pluginRepositories&gt;\n\n    &lt;dependencies&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.scala-lang&lt;/groupId&gt;\n            &lt;artifactId&gt;scala-library&lt;/artifactId&gt;\n            &lt;version&gt;${scala.version}&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;junit&lt;/groupId&gt;\n            &lt;artifactId&gt;junit&lt;/artifactId&gt;\n            &lt;version&gt;4.4&lt;/version&gt;\n            &lt;scope&gt;test&lt;/scope&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.specs&lt;/groupId&gt;\n            &lt;artifactId&gt;specs&lt;/artifactId&gt;\n            &lt;version&gt;1.2.5&lt;/version&gt;\n            &lt;scope&gt;test&lt;/scope&gt;\n        &lt;/dependency&gt;\n\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;\n            &lt;artifactId&gt;spark-core_${scala}&lt;/artifactId&gt;\n            &lt;version&gt;${spark.version}&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;\n            &lt;artifactId&gt;spark-streaming_${scala}&lt;/artifactId&gt;\n            &lt;version&gt;${spark.version}&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;\n            &lt;artifactId&gt;spark-sql_${scala}&lt;/artifactId&gt;\n            &lt;version&gt;${spark.version}&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;\n            &lt;artifactId&gt;spark-hive_${scala}&lt;/artifactId&gt;\n            &lt;version&gt;${spark.version}&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;\n            &lt;artifactId&gt;spark-mllib_${scala}&lt;/artifactId&gt;\n            &lt;version&gt;${spark.version}&lt;/version&gt;\n        &lt;/dependency&gt;\n    &lt;/dependencies&gt;\n\n    &lt;build&gt;\n        &lt;sourceDirectory&gt;src/main/scala&lt;/sourceDirectory&gt;\n        &lt;testSourceDirectory&gt;src/test/scala&lt;/testSourceDirectory&gt;\n        &lt;plugins&gt;\n            &lt;plugin&gt;\n                &lt;groupId&gt;org.scala-tools&lt;/groupId&gt;\n                &lt;artifactId&gt;maven-scala-plugin&lt;/artifactId&gt;\n                &lt;executions&gt;\n                    &lt;execution&gt;\n                        &lt;goals&gt;\n                            &lt;goal&gt;compile&lt;/goal&gt;\n                            &lt;goal&gt;testCompile&lt;/goal&gt;\n                        &lt;/goals&gt;\n                    &lt;/execution&gt;\n                &lt;/executions&gt;\n                &lt;configuration&gt;\n                    &lt;scalaVersion&gt;2.11&lt;/scalaVersion&gt;\n                    &lt;args&gt;\n                        &lt;arg&gt;-target:jvm-1.5&lt;/arg&gt;\n                    &lt;/args&gt;\n                &lt;/configuration&gt;\n            &lt;/plugin&gt;\n            &lt;plugin&gt;\n                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n                &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;\n                &lt;version&gt;2.19&lt;/version&gt;\n                &lt;configuration&gt;\n                    &lt;skip&gt;true&lt;/skip&gt;\n                &lt;/configuration&gt;\n            &lt;/plugin&gt;\n\n            &lt;plugin&gt;\n                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;\n                &lt;version&gt;3.6.0&lt;/version&gt;\n                &lt;configuration&gt;\n                    &lt;source&gt;1.8&lt;/source&gt;\n                    &lt;target&gt;1.8&lt;/target&gt;\n                    &lt;excludes&gt;\n                        &lt;exclude&gt;**/*.java&lt;/exclude&gt;\n                    &lt;/excludes&gt;\n                &lt;/configuration&gt;\n            &lt;/plugin&gt;\n            &lt;plugin&gt;\n                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n                &lt;artifactId&gt;maven-eclipse-plugin&lt;/artifactId&gt;\n                &lt;configuration&gt;\n                    &lt;downloadSources&gt;true&lt;/downloadSources&gt;\n                    &lt;buildcommands&gt;\n                        &lt;buildcommand&gt;ch.epfl.lamp.sdt.core.scalabuilder&lt;/buildcommand&gt;\n                    &lt;/buildcommands&gt;\n                    &lt;additionalProjectnatures&gt;\n                        &lt;projectnature&gt;ch.epfl.lamp.sdt.core.scalanature&lt;/projectnature&gt;\n                    &lt;/additionalProjectnatures&gt;\n                    &lt;classpathContainers&gt;\n                        &lt;classpathContainer&gt;org.eclipse.jdt.launching.JRE_CONTAINER&lt;/classpathContainer&gt;\n                        &lt;classpathContainer&gt;ch.epfl.lamp.sdt.launching.SCALA_CONTAINER&lt;/classpathContainer&gt;\n                    &lt;/classpathContainers&gt;\n                &lt;/configuration&gt;\n            &lt;/plugin&gt;\n        &lt;/plugins&gt;\n    &lt;/build&gt;\n    &lt;reporting&gt;\n        &lt;plugins&gt;\n            &lt;plugin&gt;\n                &lt;groupId&gt;org.scala-tools&lt;/groupId&gt;\n                &lt;artifactId&gt;maven-scala-plugin&lt;/artifactId&gt;\n                &lt;configuration&gt;\n                    &lt;scalaVersion&gt;${scala.version}&lt;/scalaVersion&gt;\n                &lt;/configuration&gt;\n            &lt;/plugin&gt;\n        &lt;/plugins&gt;\n    &lt;/reporting&gt;\n&lt;/project&gt;\n</code></pre><p>目录结构如下:<br><img src=\"https://static.oschina.net/uploads/img/201803/29141709_MjWs.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"><br>在src的main目录下新建java和scala文件夹<br><img src=\"https://static.oschina.net/uploads/img/201803/29142045_fhmF.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"><br>同时修改java和scala文件夹为源码文件夹<br><img src=\"https://static.oschina.net/uploads/img/201803/29142301_rELw.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"><br><img src=\"https://static.oschina.net/uploads/img/201803/29142317_bdXa.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"><br>在src的test目录下新建java和scala文件夹<br><img src=\"https://static.oschina.net/uploads/img/201803/29142115_RNRo.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"><br>同时修改java和scala文件夹为测试文件夹<br><img src=\"https://static.oschina.net/uploads/img/201803/29142409_KwUu.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"></p>\n<p>然后设置scal为项目的sdk</p>\n<h2 id=\"三-spark的java7代码编写\"><a href=\"#三-spark的java7代码编写\" class=\"headerlink\" title=\"三.spark的java7代码编写\"></a>三.spark的java7代码编写</h2><p>新建package名称为<br><img src=\"https://static.oschina.net/uploads/img/201803/29142627_StWH.png\" alt=\"输入图片说明\" title=\"在这里输入图片标题\"><br>新建Java7WordCount.java的文件</p>\n<p>Java7WordCount.java</p>\n<pre><code>package com.chen;\n\nimport org.apache.spark.SparkConf;\nimport org.apache.spark.api.java.JavaPairRDD;\nimport org.apache.spark.api.java.JavaRDD;\nimport org.apache.spark.api.java.JavaSparkContext;\nimport org.apache.spark.api.java.function.FlatMapFunction;\nimport org.apache.spark.api.java.function.Function2;\nimport org.apache.spark.api.java.function.PairFunction;\nimport org.apache.spark.api.java.function.VoidFunction;\nimport scala.Tuple2;\n\nimport java.util.Arrays;\nimport java.util.Iterator;\n\n/**\n * @author 陈锦华\n * @version V1.0\n * @Title:\n * @Description: create by Intellij Idea\n * @date 2018/3/29 0029 上午 10:57\n **/\npublic class Java7WordCount {\n\n    /**\n     * 使用Java的方式开发进行本地测试Spark的WordCount程序\n     *\n     */\n        public static void main(String[] args) {\n            /**\n             * * setAppName：设置应用名字，此名字会在Spark web UI显示\n             * setMaster：设置主节点URL，本例使用“local”是指本机单线程，另外还有以下选项：\n             * local[K]：本机K线程\n             * local[*]：本机多线程，线程数与服务器核数相同\n             * spark://HOST:PORT：Spark集群地址和端口，默认端口为7077\n             * mesos://HOST:PORT：Mesos集群地址和端口，默认端口为5050\n             * yarn：YARN集群\n             * 第1步：创建Spark的配置对象SparkConf，设置Spark程序的运行时的配置信息，\n             * 例如说通过setMaster来设置程序要链接的Spark集群的Master的URL,如果设置\n             * 为local，则代表Spark程序在本地运行，特别适合于机器配置条件非常差（例如 只有1G的内存）的初学者 *\n             */\n            SparkConf conf = new SparkConf().setAppName(&quot;Spark WordCount written by Java&quot;).setMaster(&quot;local&quot;);\n            /**\n             * 第2步：创建SparkContext对象\n             * SparkContext是Spark程序所有功能的唯一入口，无论是采用Scala、Java、Python\n             * 、R等都必须有一个SparkContext(不同的语言具体的类名称不同，如果是Java的话则为JavaSparkContext)\n             * SparkContext核心作用：初始化Spark应用程序运行所需要的核心组件，包括DAGScheduler、TaskScheduler、\n             * SchedulerBackend 同时还会负责Spark程序往Master注册程序等\n             * SparkContext是整个Spark应用程序中最为至关重要的一个对象\n             */\n            JavaSparkContext sc = new JavaSparkContext(conf); // 其底层实际上就是Scala的SparkContext\n            /**\n             * 第3步：根据具体的数据来源（HDFS、HBase、Local FS、DB、S3等）通过JavaSparkContext来创建JavaRDD\n             * JavaRDD的创建基本有三种方式：根据外部的数据来源（例如HDFS）、根据Scala集合、由其它的RDD操作\n             * 数据会被RDD划分成为一系列的Partitions，分配到每个Partition的数据属于一个Task的处理范畴\n             * 注意：文件路径不能直接用Windows路径中的反斜扛\\，要改成Linux下的斜扛/\n             */\n            JavaRDD&lt;String&gt; lines = sc.textFile(&quot;C:\\\\offline_FtnInfo.txt&quot;);\n            /**\n             * 第4步：对初始的JavaRDD进行Transformation级别的处理，例如map、filter等高阶函数等的编程，来进行具体的数据计算\n             * 第4.1步：讲每一行的字符串拆分成单个的单词\n             */\n            JavaRDD&lt;String&gt; words = lines.flatMap(new FlatMapFunction&lt;String, String&gt;() {\n                        @Override\n                        public Iterator&lt;String&gt; call(String line) throws Exception {\n                            return Arrays.asList(line.split(&quot; &quot;)).iterator();\n                        }\n                    });\n            /**\n             * 第4步：对初始的JavaRDD进行Transformation级别的处理，例如map、filter等高阶函数等的编程，来进行具体的数据计算\n             * 第4.2步：在单词拆分的基础上对每个单词实例计数为1，也就是word =&gt; (word, 1)\n             */\n            JavaPairRDD&lt;String, Integer&gt; pairs = words.mapToPair(new PairFunction&lt;String, String, Integer&gt;() {\n                        public Tuple2&lt;String, Integer&gt; call(String word) throws Exception {\n                            return new Tuple2&lt;String, Integer&gt;(word, 1);\n                        }\n                    });\n            /**\n             * 第4步：对初始的RDD进行Transformation级别的处理，例如map、filter等高阶函数等的编程，来进行具体的数据计算\n             * 第4.3步：在每个单词实例计数为1基础之上统计每个单词在文件中出现的总次数\n             */\n            JavaPairRDD&lt;String, Integer&gt; wordsCount = pairs.reduceByKey(new Function2&lt;Integer, Integer, Integer&gt;() { // 对相同的Key，进行Value的累计（包括Local和Reducer级别同时Reduce）\n                        public Integer call(Integer v1, Integer v2) throws Exception {\n                            return v1 + v2;\n                        }\n                    });\n            wordsCount.foreach(new VoidFunction&lt;Tuple2&lt;String, Integer&gt;&gt;() {\n                public void call(Tuple2&lt;String, Integer&gt; pairs) throws Exception {\n                    System.out.println(pairs._1 + &quot; : &quot; + pairs._2);\n                }\n            });\n            sc.close();\n        }\n    }</code></pre><h2 id=\"四-spark的java8代码编写\"><a href=\"#四-spark的java8代码编写\" class=\"headerlink\" title=\"四.spark的java8代码编写\"></a>四.spark的java8代码编写</h2><p>新建package名称为com.chen</p>\n<p>新建Java8WordCount.java的文件</p>\n<p>Java8WordCount.java</p>\n<pre><code>package com.chen;\n\nimport org.apache.spark.SparkConf;\nimport org.apache.spark.api.java.JavaPairRDD;\nimport org.apache.spark.api.java.JavaRDD;\nimport org.apache.spark.api.java.JavaSparkContext;\nimport scala.Tuple2;\n\nimport java.util.Arrays;\nimport java.util.List;\n\n/**\n * @author 陈锦华\n * @version V1.0\n * @Title:\n * @Description: create by Intellij Idea\n * @date 2018/3/29 0029 上午 10:57\n **/\npublic class Java8WordCount {\n    /**\n     * 使用Java的方式开发进行本地测试Spark的WordCount程序\n     */\n    public static void main(String[] args) {\n        WordCount2();\n    }\n\n    public static void WordCount1(){\n        /**\n         * 第4步：对初始的JavaRDD进行Transformation级别的处理，例如map、filter等高阶函数等的编程，来进行具体的数据计算\n         * 第4.2步：在单词拆分的基础上对每个单词实例计数为1，也就是word =&gt; (word, 1)\n         * 第4步：对初始的RDD进行Transformation级别的处理，例如map、filter等高阶函数等的编程，来进行具体的数据计算\n         * 第4.3步：在每个单词实例计数为1基础之上统计每个单词在文件中出现的总次数\n         */\n        SparkConf conf = new SparkConf().setAppName(&quot;Spark WordCount written by Java&quot;).setMaster(&quot;local&quot;);\n        JavaSparkContext sc = new JavaSparkContext(conf); // 其底层实际上就是Scala的SparkContext\n        JavaRDD&lt;String&gt; lines = sc.textFile(&quot;C:\\\\offline_FtnInfo.txt&quot;);\n        JavaRDD&lt;String&gt; words = lines.flatMap((line) -&gt;Arrays.asList(line.split(&quot; &quot;)).iterator());\n        JavaPairRDD&lt;String, Integer&gt; pairs = words.mapToPair((word)-&gt;new Tuple2&lt;&gt;(word, 1));\n        JavaPairRDD&lt;String, Integer&gt; wordsCount = pairs.reduceByKey((Integer v1, Integer v2) -&gt;v1 + v2);\n        wordsCount.foreach((Tuple2&lt;String, Integer&gt; pair)-&gt;System.out.println(pair._1 + &quot; : &quot; + pair._2));\n        sc.close();\n    }\n\n    public static void WordCount2(){\n        SparkConf conf = new SparkConf().setAppName(&quot;Spark WordCount written by Java&quot;).setMaster(&quot;local&quot;);\n        JavaSparkContext sc = new JavaSparkContext(conf); // 其底层实际上就是Scala的SparkContext\n        JavaRDD&lt;String&gt; lines = sc.textFile(&quot;C:\\\\offline_FtnInfo.txt&quot;);\n        JavaRDD&lt;String&gt; words = lines.flatMap(line -&gt; Arrays.asList(line.split(&quot; &quot;)).iterator());\n        JavaPairRDD&lt;String, Integer&gt; counts = words.mapToPair(w -&gt; new Tuple2&lt;String, Integer&gt;(w, 1))\n            .reduceByKey((x, y) -&gt; x + y);\n        List&lt;Tuple2&lt;String, Integer&gt;&gt; output = counts.collect();\n            for (Tuple2&lt;?, ?&gt; tuple : output) {\n                System.out.println(tuple._1() + &quot;:== &quot; + tuple._2());\n            }\n        sc.close();\n    }\n}    </code></pre><h2 id=\"五-spark的scalar代码编写\"><a href=\"#五-spark的scalar代码编写\" class=\"headerlink\" title=\"五.spark的scalar代码编写\"></a>五.spark的scalar代码编写</h2><p>1.新建package名称为</p>\n<p>com.chen</p>\n<p>2.新建scalaWordCount.scala的文件</p>\n<p>scalaWordCount.scala</p>\n<pre><code>package com.chen\n\nimport org.apache.spark.{SparkConf, SparkContext}\n\n    object scalaWordCount{\n        def main(args: Array[String]) {\n            //setMaster(&quot;local&quot;) 本机的spark就用local，远端的就写ip\n            //如果是打成jar包运行则需要去掉 setMaster(&quot;local&quot;)因为在参数中会指定。\n            val conf = new SparkConf().setAppName(&quot;local Application&quot;).setMaster(&quot;local&quot;)\n            val sc = new SparkContext(conf)\n            val rdd = sc.textFile(&quot;C:\\\\offline_FtnInfo.txt&quot;)\n            val wordcount = rdd\n                    .flatMap(_.split(&quot; &quot;))\n                    .map((_,1))\n                    .reduceByKey(_ + _)\n                    .map(x =&gt; (x._2,x._1))\n                    .sortByKey(false)\n                    .map(x =&gt; (x._2,x._1)\n                )\n            wordcount.foreach(x=&gt;println(x._1+&quot;的数量是:&quot;+x._2))\n            sc.stop()\n        }\n    }</code></pre><h2 id=\"六-RDD\"><a href=\"#六-RDD\" class=\"headerlink\" title=\"六.RDD\"></a>六.RDD</h2><h3 id=\"（一）rdd的创建方式\"><a href=\"#（一）rdd的创建方式\" class=\"headerlink\" title=\"（一）rdd的创建方式\"></a>（一）rdd的创建方式</h3><p><strong>1.parallelize从集合创建</strong></p>\n<pre><code>var rdd = sc.parallelize(1 to 10)</code></pre><p><strong>2.makeRdd创建</strong></p>\n<pre><code>val seq = List((1, List(&quot;iteblog.com&quot;, &quot;sparkhost1.com&quot;, &quot;sparkhost2.com&quot;)),(2, List(&quot;iteblog.com&quot;, &quot;sparkhost2.com&quot;)))\nval rdd = sc.makeRDD(seq)</code></pre><p><strong>3.从外部存储创建RDD</strong></p>\n<pre><code>var rdd = sc.textFile(&quot;hdfs:///tmp/lxw1234/1.txt&quot;)</code></pre><p><strong>4.从其他HDFS文件格式创建</strong></p>\n<p>hadoopFile</p>\n<p>sequenceFile</p>\n<p>objectFile</p>\n<p>newAPIHadoopFile</p>\n<p>从Hadoop接口API创建</p>\n<p>hadoopRDD</p>\n<p>newAPIHadoopRDD</p>\n<p><strong>5.从HBase创建RDD</strong> </p>\n<pre><code class=\"scala\">import org.apache.hadoop.hbase.{HBaseConfiguration, HTableDescriptor, TableName}\nimport org.apache.hadoop.hbase.{HBaseConfiguration, HTableDescriptor, TableName}\nimport org.apache.hadoop.hbase.mapreduce.TableInputFormat\nimport org.apache.hadoop.hbase.mapreduce.TableInputFormat\nimport org.apache.hadoop.hbase.client.HBaseAdmin\nimport org.apache.hadoop.hbase.client.HBaseAdmin\nval conf = HBaseConfiguration.create()\nconf.set(TableInputFormat.INPUT_TABLE,&quot;lxw1234&quot;)\nvar hbaseRDD = sc.newAPIHadoopRDD(conf,classOf[org.apache.hadoop.hbase.mapreduce.TableInputFormat],classOf[org.apache.hadoop.hbase.io.ImmutableBytesWritable],classOf[org.apache.hadoop.hbase.client.Result])</code></pre>\n<h2 id=\"七-spark-Sql\"><a href=\"#七-spark-Sql\" class=\"headerlink\" title=\"七.spark Sql\"></a>七.spark Sql</h2><h3 id=\"（一）-spark-sql的join\"><a href=\"#（一）-spark-sql的join\" class=\"headerlink\" title=\"（一）.spark sql的join\"></a>（一）.spark sql的join</h3><p>1.spark直接传入List列表用createDataset方法进行创建dataset，然后转DataFrame</p>\n<pre><code>package com.chen\nimport org.apache.spark.sql.{DataFrame, Dataset, SparkSession}\n\nobject TestSpark{\n    def main(args: Array[String]): Unit = {\n        val spark: SparkSession = SparkSession.builder().master(&quot;local[*]&quot;).appName(&quot;sparkTest&quot;).getOrCreate()\n        import spark.implicits._\n        val lines: Dataset[(String)] = spark.createDataset(List(&quot;1,chenjinhua,cn&quot;,&quot;2,Lisi,usa&quot;,&quot;3,jony,usa&quot;))\n        val empDataset: Dataset[(String, String, String)] = lines.map(line =&gt; {\n            val field: Array[String] = line.split(&quot;,&quot;)\n            var id = field(0)\n            var empName = field(1)\n            var code = field(2)\n            (id, empName, code)\n        })\n        val empDataFrame: DataFrame = empDataset.toDF(&quot;id&quot;, &quot;empName&quot;, &quot;code&quot;)\n        empDataFrame.createTempView(&quot;emp&quot;)\n\n        val nations: Dataset[(String)] = spark.createDataset(List(&quot;cn,中国&quot;,&quot;usa,美国&quot;))\n        val nationDataset: Dataset[(String, String)] = nations.map(line =&gt; {\n            val field: Array[String] = line.split(&quot;,&quot;)\n            val code = field(0)\n            val name = field(1)\n            (code, name)\n        })\n        val nationDataFrame: DataFrame = nationDataset.toDF(&quot;code&quot;,&quot;name&quot;)\n        nationDataFrame.createTempView(&quot;nation&quot;)\n        val dframe: DataFrame = spark.sql(&quot;select * from emp left join nation on emp.code=nation.code&quot;)\n        dframe.show()\n        spark.stop()\n    }\n}</code></pre><p>执行之后展示结果如下</p>\n<pre><code>+---+----------+----+----+----+\n| id|   empName|code|code|name|\n+---+----------+----+----+----+\n|  1|chenjinhua|  cn|  cn|  中国|\n|  2|      Lisi| usa| usa|  美国|\n|  3|      jony| usa| usa|  美国|\n+---+----------+----+----+----+</code></pre><h3 id=\"（二）spark-Sql计算nginx的日志\"><a href=\"#（二）spark-Sql计算nginx的日志\" class=\"headerlink\" title=\"（二）spark Sql计算nginx的日志\"></a>（二）spark Sql计算nginx的日志</h3><p>1.access.log</p>\n<pre><code>192.168.197.50 - - [20/Dec/2018:15:46:15 +0800] &quot;GET /api/rep/scRepairBusHouse/datagrid?pageNum=1&amp;pageRow=10&amp;busHouseCode=&amp;orgId= HTTP/1.1&quot; 200 1745 &quot;http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg&quot; &quot;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36&quot;\n192.168.197.50 - - [20/Dec/2018:15:46:15 +0800] &quot;GET /api/sys/coreDepart/showCompsTreeByUser HTTP/1.1&quot; 200 809 &quot;http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg&quot; &quot;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36&quot;\n192.168.197.50 - - [20/Dec/2018:15:46:15 +0800] &quot;GET /api/sys/coreDepart/showCompsTreeByUser HTTP/1.1&quot; 200 809 &quot;http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg&quot; &quot;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36&quot;\n192.168.197.50 - - [20/Dec/2018:15:46:26 +0800] &quot;GET /api/rep/scRepairBusHouse/datagrid?pageNum=1&amp;pageRow=10&amp;busHouseCode=&amp;orgId=1 HTTP/1.1&quot; 200 1745 &quot;http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg&quot; &quot;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36&quot;\n192.168.197.50 - - [20/Dec/2018:15:46:28 +0800] &quot;GET /api/rep/scRepairBusHouse/datagrid?pageNum=1&amp;pageRow=10&amp;busHouseCode=&amp;orgId=6 HTTP/1.1&quot; 200 1340 &quot;http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg&quot; &quot;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36&quot;\n192.168.197.50 - - [20/Dec/2018:15:46:29 +0800] &quot;GET /api/rep/scRepairBusHouse/datagrid?pageNum=1&amp;pageRow=10&amp;busHouseCode=&amp;orgId=7 HTTP/1.1&quot; 200 483 &quot;http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg&quot; &quot;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36&quot;\n192.168.197.50 - - [20/Dec/2018:15:46:30 +0800] &quot;GET /api/rep/scRepairBusHouse/datagrid?pageNum=1&amp;pageRow=10&amp;busHouseCode=&amp;orgId=6 HTTP/1.1&quot; 200 1340 &quot;http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg&quot; &quot;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36&quot;\n192.168.197.50 - - [20/Dec/2018:15:46:30 +0800] &quot;GET /api/rep/scRepairBusHouse/datagrid?pageNum=1&amp;pageRow=10&amp;busHouseCode=&amp;orgId=1 HTTP/1.1&quot; 200 1745 &quot;http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg&quot; &quot;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36&quot;\n192.168.197.145 - - [20/Dec/2018:15:46:30 +0800] &quot;GET /static/js/13.c5de91a3a5351c406417.js HTTP/1.1&quot; 304 0 &quot;http://192.168.197.28:9090/&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299&quot;\n192.168.197.145 - - [20/Dec/2018:15:46:31 +0800] &quot;GET /api/rep/scRepairFixPlace/datagrid?pageNum=1&amp;pageRow=10&amp;positionCode=&amp;orgId= HTTP/1.1&quot; 200 1559 &quot;http://192.168.197.28:9090/&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299&quot;\n192.168.197.145 - - [20/Dec/2018:15:46:31 +0800] &quot;GET /api/sys/coreDepart/showCompsTreeByUser HTTP/1.1&quot; 200 809 &quot;http://192.168.197.28:9090/&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299&quot;\n192.168.197.145 - - [20/Dec/2018:15:46:31 +0800] &quot;GET /api/sys/coreDepart/showCompsTreeByUser HTTP/1.1&quot; 200 809 &quot;http://192.168.197.28:9090/&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299&quot;\n192.168.197.50 - - [20/Dec/2018:15:46:31 +0800] &quot;GET /api/rep/scRepairBusHouse/datagrid?pageNum=1&amp;pageRow=10&amp;busHouseCode=&amp;orgId=1 HTTP/1.1&quot; 200 1745 &quot;http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg&quot; &quot;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36&quot;\n192.168.197.145 - - [20/Dec/2018:15:46:33 +0800] &quot;GET /api/rep/scRepairFixitemInfo/datagrid?pageNum=1&amp;pageRow=10&amp;lineCode=&amp;fixItemTypeId= HTTP/1.1&quot; 200 906 &quot;http://192.168.197.28:9090/&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299&quot;\n192.168.197.145 - - [20/Dec/2018:15:46:33 +0800] &quot;GET /api/rep/scRepairFixitemType/datagrid?fixItemTypeCode= HTTP/1.1&quot; 200 861 &quot;http://192.168.197.28:9090/&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299&quot;\n192.168.197.145 - - [20/Dec/2018:15:46:33 +0800] &quot;GET /api/rep/scRepairFixitemType/selectTreeData HTTP/1.1&quot; 200 861 &quot;http://192.168.197.28:9090/&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299&quot;\n192.168.197.145 - - [20/Dec/2018:15:46:34 +0800] &quot;GET /api/rep/scRepairFaultInfo/datagrid?pageNum=1&amp;pageRow=10&amp;lineCode=&amp;faultTypeId= HTTP/1.1&quot; 200 816 &quot;http://192.168.197.28:9090/&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299&quot;\n192.168.197.145 - - [20/Dec/2018:15:46:34 +0800] &quot;GET /api/rep/scRepairFaultType/selectTreeData HTTP/1.1&quot; 200 992 &quot;http://192.168.197.28:9090/&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299&quot;\n192.168.197.145 - - [20/Dec/2018:15:46:34 +0800] &quot;GET /api/rep/scRepairFaultType/datagrid?faultTypeCode= HTTP/1.1&quot; 200 992 &quot;http://192.168.197.28:9090/&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299&quot;\n192.168.197.50 - - [20/Dec/2018:15:46:37 +0800] &quot;GET /static/js/45.f9d68fececdbd4771c9f.js HTTP/1.1&quot; 200 14268 &quot;http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg&quot; &quot;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36&quot;\n192.168.197.50 - - [20/Dec/2018:15:46:37 +0800] &quot;GET /api/mat/scClRelationClient/datagrid?pageNum=1&amp;pageRow=10&amp;clientName= HTTP/1.1&quot; 200 1815 &quot;http://192.168.197.28:9090/?tdsourcetag=s_pctim_aiomsg&quot; &quot;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36&quot;</code></pre><p>2.计算每个ip访问的次数，并保存到mysql数据库中</p>\n<pre><code>import org.apache.spark.sql.{DataFrame, Dataset, SparkSession}\nobject SparkSqlTest2{\n    def main(args: Array[String]): Unit = {\n        val spark: SparkSession = SparkSession.builder().master(&quot;local[*]&quot;).appName(&quot;sparkTest&quot;).getOrCreate()\n        import spark.implicits._\n        val lines: Dataset[String] = spark.read.textFile(&quot;file:///C:/Users/Administrator/Desktop/access.log&quot;)\n        val data = lines.map(line =&gt; {\n            val fields: Array[String] = line.split(&quot; &quot;)\n            var ip = fields(0)\n            var method = fields(5)\n            var path = fields(6)\n            var HTTPmethod = fields(7)\n            var status = fields(8)\n            var server = fields(10)\n            (ip, method, path, HTTPmethod,status,server)\n        }).toDF(&quot;ip&quot;, &quot;method&quot;, &quot;path&quot;, &quot;HTTPmethod&quot;,&quot;status&quot;, &quot;server&quot;)\n        data.createTempView(&quot;logs&quot;)\n        val frame: DataFrame = spark.sql(&quot;select ip,count(ip) from  logs group by ip&quot;)\n\n        val url=&quot;jdbc:mysql://localhost:3306/anfu&quot;\n        val table=&quot;logs&quot;\n        val prop=new java.util.Properties()\n        prop.put(&quot;driver&quot;,&quot;com.mysql.jdbc.Driver&quot;)\n        prop.put(&quot;user&quot;,&quot;root&quot;)\n        prop.put(&quot;password&quot;,&quot;root&quot;)\n\n        //表自动创建\n        frame.write.jdbc(url,table,prop)\n        spark.stop()\n    }\n}</code></pre><h3 id=\"（三）dataset创建方式\"><a href=\"#（三）dataset创建方式\" class=\"headerlink\" title=\"（三）dataset创建方式\"></a>（三）dataset创建方式</h3><p><strong>1.spark读取text文件</strong></p>\n<pre><code>val lines=spark.read.textFile(&quot;file:///c:/text&quot;)</code></pre><p><strong>2.spark传入list创建</strong></p>\n<pre><code class=\"scala\">val lines = spark.createDataset(List(&quot;1,chenjinhua,cn&quot;,&quot;2,Lisi,usa&quot;,&quot;3,jony,usa&quot;))</code></pre>\n<p><strong>3.spark传入Seq创建</strong></p>\n<pre><code>val dataset = Seq(\n  (1, &quot;zhangyuhang&quot;, java.sql.Date.valueOf(&quot;2018-05-15&quot;)),\n  (2, &quot;zhangqiuyue&quot;, java.sql.Date.valueOf(&quot;2018-05-15&quot;))\n)</code></pre><p><strong>4.spark传入Rdd创建</strong></p>\n<pre><code>val dataset = spark.createDataset(spark.sparkContext.parallelize(1 to 10))</code></pre><h3 id=\"（四）dataFrame创建方式\"><a href=\"#（四）dataFrame创建方式\" class=\"headerlink\" title=\"（四）dataFrame创建方式\"></a>（四）dataFrame创建方式</h3><p><strong>1.使用toDF函数创建DataFrame</strong> </p>\n<pre><code>import spark.implicits._\nval df = Seq(\n  (1, &quot;zhangyuhang&quot;, java.sql.Date.valueOf(&quot;2018-05-15&quot;)),\n  (2, &quot;zhangqiuyue&quot;, java.sql.Date.valueOf(&quot;2018-05-15&quot;))\n).toDF(&quot;id&quot;, &quot;name&quot;, &quot;created_time&quot;)</code></pre><p><strong>2.使用createDataFrame函数创建DataFrame</strong> ，<strong>通过schema + row 来创建</strong> </p>\n<p>可以理解为schema为表的表头，row为表的数据记录 </p>\n<pre><code>import org.apache.spark.sql.types._\n//定义dataframe的结构的schema\nval schema = StructType(List(\n    StructField(&quot;id&quot;, IntegerType, nullable = false),\n    StructField(&quot;name&quot;, StringType, nullable = true),\n    StructField(&quot;create_time&quot;, DateType, nullable = true)\n))\n\n//定义dataframe内容的rdd\nval rdd = sc.parallelize(Seq(\n  Row(1, &quot;zhangyuhang&quot;, java.sql.Date.valueOf(&quot;2018-05-15&quot;)),\n  Row(2, &quot;zhangqiuyue&quot;, java.sql.Date.valueOf(&quot;2018-05-15&quot;))\n))\n//创建dataframe\nval df = spark.createDataFrame(rdd, schema)</code></pre><p>或者</p>\n<pre><code>import org.apache.spark.sql.types._\n//传入属性参数\nval schemaString = &quot; id name create_time&quot;\n//解析参数变成StructField\nval fields = schemaString.split(&quot; &quot;).map(fieldName =&gt; StructField(fieldname, StringType, nullable = true))\n//定义dataframe的结构的schema\nval schema = StructType(fields)\n//定义dataframe内容的rdd\nval lines = sc.textFile(&quot;file:///people.txt&quot;)\nval rdd = lines.spilt(_.split(&quot;,&quot;)).map(field=&gt;ROW(field(0),field(1).trim) )\n//创建dataframe\nval df = spark.createDataFrame(rdd, schema) </code></pre><p><strong>3.通过反射机制创建DataFrame</strong></p>\n<p> 首先要定义一个case class，因为只有case class才能被Spark隐式转化为DataFrame</p>\n<pre><code>import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder\nimport org.apache.spark.sql.Encoder\nimport spark.implicits._\n//创建匹配类\ncase class Person(id:Int,name:String,age:Long)\n//读取文件生成rdd\nval rdd = sc.textFile(&quot;file:///&quot;)\n//通过匹配类把rdd转化成dataframe\nval df = rdd.map(_.split(&quot;,&quot;)).map(attributes =&gt; Person(attributes(0),attributes(1),attributes(2).trim.toInt)).toDF()　</code></pre><h3 id=\"（五）spark-sql设置分区数量\"><a href=\"#（五）spark-sql设置分区数量\" class=\"headerlink\" title=\"（五）spark sql设置分区数量\"></a>（五）spark sql设置分区数量</h3><p>保存文件时可以设置分区为一个，文件数量就会是一个</p>\n<pre><code>spark.sqlContext.setConf(&quot;spark.sql.shuffle.partitions&quot;,&quot;1&quot;)</code></pre><h3 id=\"（六）spark-sql数据读取数据\"><a href=\"#（六）spark-sql数据读取数据\" class=\"headerlink\" title=\"（六）spark sql数据读取数据\"></a>（六）spark sql数据读取数据</h3><p><strong>1.读取parquet文件</strong> </p>\n<pre><code>val df = spark.read.parquet(&quot;hdfs:/path/to/file&quot;)</code></pre><p>*<em>2.读取json文件 *</em></p>\n<pre><code>val df = spark.read.json(&quot;examples/src/main/resources/people.json&quot;)</code></pre><p><strong>3.读取csv</strong></p>\n<pre><code>val df = spark.read.format(&quot;com.databricks.spark.csv&quot;)\n        .option(&quot;header&quot;, &quot;true&quot;) //reading the headers\n        .option(&quot;mode&quot;, &quot;DROPMALFORMED&quot;)\n        .load(&quot;csv/file/path&quot;)</code></pre><p><strong>4.读取Hive表</strong></p>\n<pre><code>spark.table(&quot;test.person&quot;) // 库名.表名 的格式\n     .registerTempTable(&quot;person&quot;)  // 注册成临时表\nspark.sql(\n      &quot;&quot;&quot;\n        | select *\n        | from person\n        | limit 10\n      &quot;&quot;&quot;.stripMargin).show()</code></pre><h3 id=\"（七）spark-sql数据保存\"><a href=\"#（七）spark-sql数据保存\" class=\"headerlink\" title=\"（七）spark sql数据保存\"></a>（七）spark sql数据保存</h3><p><strong>1.通过df.write.format().save(“file:///“)保存</strong> </p>\n<p>write.format()支持输出的格式有parquet、 JSON、csv、JDBC、text等文件格式,save()定义保存的位置</p>\n<p>当我们保存成功后可以在保存位置的目录下看到文件，但是这个文件并不是一个文件而是一个目录。</p>\n<p><strong>（1）parquet格式</strong></p>\n<pre><code>df.write.mode(SaveMode.Append).format(&quot;parquet&quot;).save(&quot;file:///C:/Users/Administrator/Desktop/parquet&quot;)\ndf.write.mode(SaveMode.Append).parquet(&quot;file:///C:/Users/Administrator/Desktop/parquet2&quot;)</code></pre><p><strong>（2）json格式</strong></p>\n<pre><code>df.write.format(&quot;json&quot;).save(&quot;file:///C:/Users/Administrator/Desktop/myjson&quot;)</code></pre><p><strong>（3）csv格式</strong></p>\n<pre><code>df.write.format(&quot;csv&quot;).save(&quot;file:///C:/Users/Administrator/Desktop/mycsv&quot;)</code></pre><p><strong>（4）jdbc格式，保存到mysql数据库</strong></p>\n<pre><code class=\"scala\">val url=&quot;jdbc:mysql://localhost:3306/anfu&quot;\nval table=&quot;logs&quot;\nval prop=new java.util.Properties()\nprop.put(&quot;driver&quot;,&quot;com.mysql.jdbc.Driver&quot;)\nprop.put(&quot;user&quot;,&quot;root&quot;)\nprop.put(&quot;password&quot;,&quot;root&quot;)\n//表自动创建\nframe.write.jdbc(url,table,prop)</code></pre>\n<p><strong>（5）text格式，保存的时候必须是一列，否则报错</strong></p>\n<pre><code>df.write.format(&quot;text&quot;).save(&quot;file:///C:/Users/Administrator/Desktop/mytext&quot;)</code></pre><p><strong>2.通过df.rdd.saveAsTextFile(“file:///“)转化成rdd再保存</strong></p>\n<p><strong>我们对于不同格式的文件读写来说，我们一般使用两套对应方式</strong></p>\n<h2 id=\"八-spark-Stream\"><a href=\"#八-spark-Stream\" class=\"headerlink\" title=\"八.spark Stream\"></a>八.spark Stream</h2><h3 id=\"（一）netcat运用\"><a href=\"#（一）netcat运用\" class=\"headerlink\" title=\"（一）netcat运用\"></a>（一）netcat运用</h3><p><strong>1.netcat在windows下使用</strong></p>\n<p>Windows间传输：</p>\n<p>1、安装NetCat</p>\n<p>2、开启服务端：nc -l -p 9999</p>\n<p>3、开启客户端：nc localhost 9999</p>\n<p>4、客户端和服务端间通信</p>\n<p><strong>2.netcat在linux下使用</strong></p>\n<p><strong>（1）netcat的安装</strong></p>\n<pre><code>yum install nc -y</code></pre><p><strong>（2）netcat使用</strong></p>\n<pre><code>nc -lk 9000</code></pre><h3 id=\"（二）spark-Stream的socketTextStream\"><a href=\"#（二）spark-Stream的socketTextStream\" class=\"headerlink\" title=\"（二）spark Stream的socketTextStream\"></a>（二）spark Stream的socketTextStream</h3><p><strong>（1）代码编写</strong></p>\n<pre><code>import org.apache.spark.SparkContext\nimport org.apache.spark.sql.{DataFrame, Dataset, SparkSession}\nimport org.apache.spark.streaming.dstream.{DStream, ReceiverInputDStream}\nimport org.apache.spark.streaming.{Duration, StreamingContext}\n\nobject SparkStreamTest1{\n    def main(args: Array[String]): Unit = {\n        val spark: SparkSession = SparkSession.builder().master(&quot;local[*]&quot;).appName(&quot;sparkTest&quot;).getOrCreate()\n        val sc= spark.sparkContext\n        val ssc = new StreamingContext(sc,Duration(5000))\n        val line: ReceiverInputDStream[String] = ssc.socketTextStream(&quot;192.168.232.140&quot;,9000)\n        val ds: DStream[(String, Int)] = line.flatMap(_.split(&quot; &quot;)).map((_,1)).reduceByKey(_+_)\n        ds.print()\n        ssc.start()\n        ssc.awaitTermination()\n    }\n}</code></pre><p><strong>（2）在192.168.232.140的netcat下输入数据</strong></p>\n<pre><code>[root@master ~]# nc -lk 9000\ndsfadsfad\nl1l\nkj\nhjhj</code></pre><p><strong>（3）输出结果</strong></p>\n<pre><code>(dsfadsfad,1)\n(hjhj,1)\n(l1l,1)\n(kj,1)</code></pre><h3 id=\"（三）spark-Stream的结果集保存到数据库\"><a href=\"#（三）spark-Stream的结果集保存到数据库\" class=\"headerlink\" title=\"（三）spark Stream的结果集保存到数据库\"></a>（三）spark Stream的结果集保存到数据库</h3><p><strong>（1）获取socketTextStream中的数据进行计算之后保存mysql</strong></p>\n<pre><code>package com.chen\nimport java.sql.{Connection, DriverManager, Statement}\nimport org.apache.log4j.{Level, Logger}\nimport org.apache.spark.sql.SparkSession\nimport org.apache.spark.streaming.dstream.{DStream, ReceiverInputDStream}\nimport org.apache.spark.streaming.{Duration, StreamingContext}\n\nobject SparkStream2MysqlTest1{\n    def main(args: Array[String]): Unit = {\n        Logger.getLogger(&quot;com.chen&quot;).setLevel(Level.OFF)\n        val spark: SparkSession = SparkSession.builder().master(&quot;local[*]&quot;).appName(&quot;sparkTest&quot;).getOrCreate()\n        val sc= spark.sparkContext\n        val ssc = new StreamingContext(sc,Duration(5000))\n        val line: ReceiverInputDStream[String] = ssc.socketTextStream(&quot;192.168.232.140&quot;,9000)\n        val ds: DStream[(String, Int)] = line.flatMap(_.split(&quot; &quot;)).map((_,1)).reduceByKey(_+_)\n\n        ds.foreachRDD(rdd=&gt;rdd.foreachPartition(line=&gt;{\n                Class.forName(&quot;com.mysql.jdbc.Driver&quot;)\n                val connection: Connection = DriverManager.getConnection(&quot;jdbc:mysql://192.168.197.28:3306/sys&quot;,&quot;dev&quot;,&quot;dev@gzstrong&quot;)\n                try{\n                    for (row&lt;-line){\n                        val statement: Statement = connection.createStatement()\n                        val sql=&quot;INSERT INTO `sys`.`test` (`value`, `valueCount`) VALUES (&#39;&quot;+row._1+&quot;&#39;,&#39;&quot;+row._2+&quot;&#39;);&quot;\n                        statement.execute(sql)\n                    }\n                }finally {\n                    connection.close()\n                }\n            })\n        )\n        ssc.start()\n        ssc.awaitTermination()\n    }\n}</code></pre><p><strong>（2）在192.168.232.140的netcat下输入数据</strong></p>\n<pre><code>[root@master ~]# nc -lk 9000\ntest\nsichuang\ngzstrong</code></pre><p><strong>（3）查看数据库中的结果</strong></p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">value</th>\n<th align=\"center\">valuecount</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">test</td>\n<td align=\"center\">1</td>\n</tr>\n<tr>\n<td align=\"center\">sichuang</td>\n<td align=\"center\">1</td>\n</tr>\n<tr>\n<td align=\"center\">gzstrong</td>\n<td align=\"center\">1</td>\n</tr>\n</tbody></table>\n<h3 id=\"（四）spark-Stream与kafka的集成\"><a href=\"#（四）spark-Stream与kafka的集成\" class=\"headerlink\" title=\"（四）spark Stream与kafka的集成\"></a>（四）spark Stream与kafka的集成</h3><h2 id=\"九-Structured-Streaming\"><a href=\"#九-Structured-Streaming\" class=\"headerlink\" title=\"九.Structured Streaming\"></a>九.Structured Streaming</h2><h2 id=\"十-spark案例分析与编程实现\"><a href=\"#十-spark案例分析与编程实现\" class=\"headerlink\" title=\"十.spark案例分析与编程实现\"></a>十.spark案例分析与编程实现</h2><p>案例一</p>\n<p>a. 案例描述</p>\n<p>提起 Word Count(词频数统计)，相信大家都不陌生，就是统计一个或者多个文件中单词出现的次数。本文将此作为一个入门级案例，由浅入深的开启使用 Scala 编写 Spark 大数据处理程序的大门。</p>\n<p>b．案例分析</p>\n<p>对于词频数统计，用 Spark 提供的算子来实现，我们首先需要将文本文件中的每一行转化成一个个的单词, 其次是对每一个出现的单词进行记一次数，最后就是把所有相同单词的计数相加得到最终的结果。</p>\n<p>对于第一步我们自然的想到使用 flatMap 算子把一行文本 split 成多个单词，然后对于第二步我们需要使用 map 算子把单个的单词转化成一个有计数的 Key-Value 对，即 word -&gt; (word,1). 对于最后一步统计相同单词的出现次数，我们需要使用 reduceByKey 算子把相同单词的计数相加得到最终结果。</p>\n<p>c. 编程实现</p>\n<p>清单 1.SparkWordCount 类源码</p>\n<p>SparkWordCount.scala</p>\n<pre><code>import org.apache.spark.SparkConf\nimport org.apache.spark.SparkContext\nimport org.apache.spark.SparkContext._\n\nobject SparkWordCount {\n def FILE_NAME:String = &quot;word_count_results_&quot;;\n def main(args:Array[String]) {\n if (args.length &lt; 1) {\n println(&quot;Usage:SparkWordCount FileName&quot;);\n System.exit(1);\n }\n val conf = new SparkConf().setAppName(&quot;Spark Exercise: Spark Version Word Count Program&quot;);\n val sc = new SparkContext(conf);\n val textFile = sc.textFile(args(0));\n val wordCounts = textFile.flatMap(line =&gt; line.split(&quot; &quot;)).map(\n                                        word =&gt; (word, 1)).reduceByKey((a, b) =&gt; a + b)\n //print the results,for debug use.\n //println(&quot;Word Count program running results:&quot;);\n //wordCounts.collect().foreach(e =&gt; {\n //val (k,v) = e\n //println(k+&quot;=&quot;+v)\n //});\n wordCounts.saveAsTextFile(FILE_NAME+System.currentTimeMillis());\n println(&quot;Word Count program running results are successfully saved.&quot;);\n }\n}</code></pre><p>d. 提交到集群执行</p>\n<p>本实例中, 我们将统计 HDFS 文件系统中/user/fams 目录下所有 txt 文件中词频数。其中 spark-exercise.jar 是 Spark 工程打包后的 jar 包，这个 jar 包执行时会被上传到目标服务器的/home/fams 目录下。运行此实例的具体命令如下：</p>\n<pre><code>./spark-submit \\\n--class com.ibm.spark.exercise.basic.SparkWordCount \\\n--master spark://hadoop036166:7077 \\\n--num-executors 3 \\\n--driver-memory 6g --executor-memory 2g \\\n--executor-cores 2 \\\n/home/fams/sparkexercise.jar \\\nhdfs://hadoop036166:9000/user/fams/*.txt</code></pre><p><strong>案例二</strong></p>\n<p>a. 案例描述</p>\n<p>该案例中，我们将假设我们需要统计一个 1000 万人口的所有人的平均年龄，当然如果您想测试 Spark 对于大数据的处理能力，您可以把人口数放的更大，比如 1 亿人口，当然这个取决于测试所用集群的存储容量。假设这些年龄信息都存储在一个文件里，并且该文件的格式如下，第一列是 ID，第二列是年龄。</p>\n<p>案例二age.txt测试数据格式预览</p>\n<p><img src=\"https://static.oschina.net/uploads/img/201803/29143845_eRx4.jpg\" alt=\"è¾å¥å¾çè¯´æ\"> </p>\n<p>现在我们需要用 Scala 写一个生成 1000 万人口年龄数据的文件，源程序如下：</p>\n<p>清单 3. 年龄信息文件生成类源码</p>\n<pre><code>import java.io.FileWriter\nimport java.io.File\nimport scala.util.Random\n\nobject SampleDataFileGenerator {\n\ndef main(args:Array[String]) {\nval writer = new FileWriter(new File(&quot;C: \\\\sample_age_data.txt&quot;),false)\nval rand = new Random()\nfor ( i &lt;- 1 to 10000000) {\nwriter.write( i + &quot; &quot; + rand.nextInt(100))\nwriter.write(System.getProperty(&quot;line.separator&quot;))\n}\nwriter.flush()\nwriter.close()\n}\n}</code></pre><p>b. 案例分析</p>\n<p>要计算平均年龄，那么首先需要对源文件对应的 RDD 进行处理，也就是将它转化成一个只包含年龄信息的 RDD，其次是计算元素个数即为总人数，然后是把所有年龄数加起来，最后平均年龄=总年龄/人数。</p>\n<p>对于第一步我们需要使用 map 算子把源文件对应的 RDD 映射成一个新的只包含年龄数据的 RDD，很显然需要对在 map 算子的传入函数中使用 split 方法，得到数组后只取第二个元素即为年龄信息；第二步计算数据元素总数需要对于第一步映射的结果 RDD 使用 count 算子；第三步则是使用 reduce 算子对只包含年龄信息的 RDD 的所有元素用加法求和；最后使用除法计算平均年龄即可。</p>\n<p>由于本例输出结果很简单，所以只打印在控制台即可。</p>\n<p>c. 编程实现</p>\n<p>清单 4.AvgAgeCalculator 类源码</p>\n<pre><code>import org.apache.spark.SparkConf\nimport org.apache.spark.SparkContext\nobject AvgAgeCalculator {\n def main(args:Array[String]) {\n if (args.length &lt; 1){\n println(&quot;Usage:AvgAgeCalculator datafile&quot;)\n System.exit(1)\n }\n val conf = new SparkConf().setAppName(&quot;Spark Exercise:Average Age Calculator&quot;)\n val sc = new SparkContext(conf)\n val dataFile = sc.textFile(args(0), 5);\n val count = dataFile.count()\n val ageData = dataFile.map(line =&gt; line.split(&quot; &quot;)(1))\n val totalAge = ageData.map(age =&gt; Integer.parseInt(\n                                String.valueOf(age))).collect().reduce((a,b) =&gt; a+b)\n println(&quot;Total Age:&quot; + totalAge + &quot;;Number of People:&quot; + count )\n val avgAge : Double = totalAge.toDouble / count.toDouble\n println(&quot;Average Age is &quot; + avgAge)\n }\n}</code></pre><p>案例三</p>\n<p>a. 案例描述</p>\n<p>本案例假设我们需要对某个省的人口 (1 亿) 性别还有身高进行统计，需要计算出男女人数，男性中的最高和最低身高，以及女性中的最高和最低身高。本案例中用到的源文件有以下格式, 三列分别是 ID，性别，身高 (cm)。</p>\n<p>案例三测试数据格式预览</p>\n<p>我们将用以下 Scala 程序生成这个文件，源码如下：</p>\n<p>清单 7. 人口信息生成类源码</p>\n<pre><code>import java.io.FileWriter\nimport java.io.File\nimport scala.util.Random\n\nobject PeopleInfoFileGenerator {\n def main(args:Array[String]) {\n val writer = new FileWriter(new File(&quot;C:\\\\LOCAL_DISK_D\\\\sample_people_info.txt&quot;),false)\n val rand = new Random()\n for ( i &lt;- 1 to 100000000) {\n var height = rand.nextInt(220)\n if (height &lt; 50) {\n height = height + 50\n }\n var gender = getRandomGender\n if (height &lt; 100 &amp;&amp; gender == &quot;M&quot;)\n height = height + 100\n if (height &lt; 100 &amp;&amp; gender == &quot;F&quot;)\n height = height + 50\n writer.write( i + &quot; &quot; + getRandomGender + &quot; &quot; + height)\n writer.write(System.getProperty(&quot;line.separator&quot;))\n }\n writer.flush()\n writer.close()\n println(&quot;People Information File generated successfully.&quot;)\n }\n\n def getRandomGender() :String = {\n val rand = new Random()\n val randNum = rand.nextInt(2) + 1\n if (randNum % 2 == 0) {\n &quot;M&quot;\n } else {\n &quot;F&quot;\n }\n }\n}</code></pre><p>b. 案例分析</p>\n<p>对于这个案例，我们要分别统计男女的信息，那么很自然的想到首先需要对于男女信息从源文件的对应的 RDD 中进行分离，这样会产生两个新的 RDD，分别包含男女信息；其次是分别对男女信息对应的 RDD 的数据进行进一步映射，使其只包含身高数据，这样我们又得到两个 RDD，分别对应男性身高和女性身高；最后需要对这两个 RDD 进行排序，进而得到最高和最低的男性或女性身高。</p>\n<p>对于第一步，也就是分离男女信息，我们需要使用 filter 算子，过滤条件就是包含”M” 的行是男性，包含”F”的行是女性；第二步我们需要使用 map 算子把男女各自的身高数据从 RDD 中分离出来；第三步我们需要使用 sortBy 算子对男女身高数据进行排序。</p>\n<p>c. 编程实现</p>\n<p>在实现上，有一个需要注意的点是在 RDD 转化的过程中需要把身高数据转换成整数，否则 sortBy 算子会把它视为字符串，那么排序结果就会受到影响，例如 身高数据如果是：123,110,84,72,100，那么升序排序结果将会是 100,110,123,72,84，显然这是不对的。</p>\n<p>清单 8.PeopleInfoCalculator 类源码</p>\n<pre><code>object PeopleInfoCalculator {\n def main(args:Array[String]) {\n if (args.length &lt; 1){\n println(&quot;Usage:PeopleInfoCalculator datafile&quot;)\n System.exit(1)\n }\n val conf = new SparkConf().setAppName(&quot;Spark Exercise:People Info(Gender &amp; Height) Calculator&quot;)\n val sc = new SparkContext(conf)\n val dataFile = sc.textFile(args(0), 5);\n val maleData = dataFile.filter(line =&gt; line.contains(&quot;M&quot;)).map(\n                              line =&gt; (line.split(&quot; &quot;)(1) + &quot; &quot; + line.split(&quot; &quot;)(2)))\n val femaleData = dataFile.filter(line =&gt; line.contains(&quot;F&quot;)).map(\n                              line =&gt; (line.split(&quot; &quot;)(1) + &quot; &quot; + line.split(&quot; &quot;)(2)))\n //for debug use\n //maleData.collect().foreach { x =&gt; println(x)}\n //femaleData.collect().foreach { x =&gt; println(x)}\n val maleHeightData = maleData.map(line =&gt; line.split(&quot; &quot;)(1).toInt)\n val femaleHeightData = femaleData.map(line =&gt; line.split(&quot; &quot;)(1).toInt)\n //for debug use\n //maleHeightData.collect().foreach { x =&gt; println(x)}\n //femaleHeightData.collect().foreach { x =&gt; println(x)}\n val lowestMale = maleHeightData.sortBy(x =&gt; x,true).first()\n val lowestFemale = femaleHeightData.sortBy(x =&gt; x,true).first()\n //for debug use\n //maleHeightData.collect().sortBy(x =&gt; x).foreach { x =&gt; println(x)}\n //femaleHeightData.collect().sortBy(x =&gt; x).foreach { x =&gt; println(x)}\n val highestMale = maleHeightData.sortBy(x =&gt; x, false).first()\n val highestFemale = femaleHeightData.sortBy(x =&gt; x, false).first()\n println(&quot;Number of Male Peole:&quot; + maleData.count())\n println(&quot;Number of Female Peole:&quot; + femaleData.count())\n println(&quot;Lowest Male:&quot; + lowestMale)\n println(&quot;Lowest Female:&quot; + lowestFemale)\n println(&quot;Highest Male:&quot; + highestMale)\n println(&quot;Highest Female:&quot; + highestFemale)\n }\n}</code></pre><p>案例四</p>\n<p>a. 案例描述</p>\n<p>该案例中我们假设某搜索引擎公司要统计过去一年搜索频率最高的 K 个科技关键词或词组，为了简化问题，我们假设关键词组已经被整理到一个或者多个文本文件中，并且文档具有以下格式。</p>\n<p>图 13. 案例四测试数据格式预览</p>\n<p>我们可以看到一个关键词或者词组可能出现多次，并且大小写格式可能不一致。</p>\n<p>b. 案例分析</p>\n<p>要解决这个问题，首先我们需要对每个关键词出现的次数进行计算，在这个过程中需要识别不同大小写的相同单词或者词组，如”Spark”和“spark” 需要被认定为一个单词。对于出现次数统计的过程和 word count 案例类似；其次我们需要对关键词或者词组按照出现的次数进行降序排序，在排序前需要把 RDD 数据元素从 (k,v) 转化成 (v,k)；最后取排在最前面的 K 个单词或者词组。</p>\n<p>对于第一步，我们需要使用 map 算子对源数据对应的 RDD 数据进行全小写转化并且给词组记一次数，然后调用 reduceByKey 算子计算相同词组的出现次数；第二步我们需要对第一步产生的 RDD 的数据元素用 sortByKey 算子进行降序排序；第三步再对排好序的 RDD 数据使用 take 算子获取前 K 个数据元素。</p>\n<p>c. 编程实现</p>\n<p>清单 10.TopKSearchKeyWords 类源码</p>\n<pre><code>import org.apache.spark.SparkConf\nimport org.apache.spark.SparkContext\n\nobject TopKSearchKeyWords {\n def main(args:Array[String]){\n if (args.length &lt; 2) {\n println(&quot;Usage:TopKSearchKeyWords KeyWordsFile K&quot;);\n System.exit(1)\n }\n val conf = new SparkConf().setAppName(&quot;Spark Exercise:Top K Searching Key Words&quot;)\n val sc = new SparkContext(conf)\n val srcData = sc.textFile(args(0))\n val countedData = srcData.map(line =&gt; (line.toLowerCase(),1)).reduceByKey((a,b) =&gt; a+b)\n //for debug use\n //countedData.foreach(x =&gt; println(x))\n val sortedData = countedData.map{ case (k,v) =&gt; (v,k) }.sortByKey(false)\n val topKData = sortedData.take(args(1).toInt).map{ case (v,k) =&gt; (k,v) }\n topKData.foreach(println)\n }\n}</code></pre><p><strong>案例二的age.txt文件</strong></p>\n<p>1 16</p>\n<p>2 73</p>\n<p>3 74</p>\n<p>4 76 </p>\n<p>5 75</p>\n<p>6 78</p>\n<p>7 66</p>\n<p>8 55</p>\n<p>9 85</p>\n<p>11 25</p>\n<p>12 43</p>\n<p>13 45</p>\n<p>14 61</p>\n<p>15 35</p>\n<p>16 38</p>\n<p>17 69</p>\n<p>18 45</p>\n<p>19 55</p>\n<p>20 45</p>\n<p>21 16</p>\n<p>22 73</p>\n<p>23 74</p>\n<p>24 76 </p>\n<p>25 75</p>\n<p>26 78</p>\n<p>27 66</p>\n<p>28 55</p>\n<p>29 85</p>\n<p>30 85</p>\n<p>31 25</p>\n<p>32 43</p>\n<p>33 45</p>\n<p>34 61</p>\n<p>35 35</p>\n<p>36 38</p>\n<p>37 69</p>\n<p>38 45</p>\n<p>39 55</p>\n<p>40 45</p>\n<p>七.算子reduceByKey和groupByKey，sortByKey和sortBy区别</p>\n<ol>\n<li><p>Spark算子reduceByKey深度解析<br>那么这就基本奠定了reduceByKey的作用域是key-value类型的键值对，并且是只对每个key的value进行处理，如果含有多个key的话，那么就对多个values进行处理。这里的函数是我们自己传入的，也就是说是可人为控制的【其实这是废话，人为控制不了这算子一点用没有】。那么举个例子：</p>\n<p> scala&gt; val x = sc.parallelize(Array((“a”, 1), (“b”, 1), (“a”, 1),</p>\n<pre><code>  | (&quot;a&quot;, 1), (&quot;b&quot;, 1), (&quot;b&quot;, 1),\n  | (&quot;b&quot;, 1), (&quot;b&quot;, 1)), 3)</code></pre></li>\n</ol>\n<p>我们创建了一个Array的字符串，并把其存入spark的集群上，设置了三个分区【这里我们不关注分区，只关注操作】。那么我们调用reduceByKey并且传入函数进行相应操作【本处我们对相同key的value进行相加操作，类似于统计单词出现次数】：</p>\n<pre><code>scala&gt; val y = x.reduceByKey((pre, after) =&gt; (pre + after))</code></pre><p>这里两个参数我们逻辑上让他分别代表同一个key的两个不同values，那么结果想必大家应该猜到了： </p>\n<pre><code>scala&gt; y.collect\nres0: Array[(String, Int)] = Array((a,3), (b,5))</code></pre><ol>\n<li>reduceByKey和groupByKey区别与用法<br>首先，看一看spark官网[1]是怎么解释的：<br>reduceByKey(func, numPartitions=None)<br>reduceByKey用于对每个key对应的多个value进行merge操作，最重要的是它能够在本地先进行merge操作，并且merge操作可以通过函数自定义。</li>\n</ol>\n<p>groupByKey(numPartitions=None)</p>\n<p>也就是，groupByKey也是对每个key进行操作，但只生成一个sequence。需要特别注意“Note”中的话，它告诉我们：如果需要对sequence进行aggregation操作（注意，groupByKey本身不能自定义操作函数），那么，选择reduceByKey/aggregateByKey更好。这是因为groupByKey不能自定义函数，我们需要先用groupByKey生成RDD，然后才能对此RDD通过map进行自定义函数操作。 </p>\n<pre><code>val words = Array(&quot;one&quot;, &quot;two&quot;, &quot;two&quot;, &quot;three&quot;, &quot;three&quot;, &quot;three&quot;)\nval wordPairsRDD = sc.parallelize(words).map(word =&gt; (word, 1))\nval wordCountsWithReduce = wordPairsRDD.reduceByKey(_ + _)\nval wordCountsWithGroup = wordPairsRDD.groupByKey().map(t =&gt; (t._1, t._2.sum))</code></pre><p>上面得到的wordCountsWithReduce和wordCountsWithGroup是完全一样的，但是，它们的内部运算过程是不同的。 </p>\n<p>（1）当采用reduceByKeyt时，Spark可以在每个分区移动数据之前将待输出数据与一个共用的key结合。借助下图可以理解在reduceByKey里究竟发生了什么。 注意在数据对被搬移前同一机器上同样的key是怎样被组合的(reduceByKey中的lamdba函数)。然后lamdba函数在每个区上被再次调用来将所有值reduce成一个最终结果。整个过程如下：</p>\n<p>（2）当采用groupByKey时，由于它不接收函数，spark只能先将所有的键值对(key-value pair)都移动，这样的后果是集群节点之间的开销很大，导致传输延时。整个过程如下：</p>\n<p>因此，在对大数据进行复杂计算时，reduceByKey优于groupByKey。</p>\n<p>另外，如果仅仅是group处理，那么以下函数应该优先于 groupByKey ：</p>\n<p> 　　（1）、combineByKey 组合数据，但是组合之后的数据类型与输入时值的类型不一样。</p>\n<p> 　　（2）、foldByKey合并每一个 key 的所有值，在级联函数和“零值”中使用。</p>\n<ol>\n<li>sortByKey和sortBy区别<br>SortByKey()函数</li>\n</ol>\n<p>sortBy函数是在org.apache.spark.rdd.RDD类中实现的，它的实现如下：</p>\n<pre><code>def sortBy[K](f: (T) =&gt; K,ascending: Boolean = true,\n    numPartitions: Int = this.partitions.size)\n    (implicit ord: Ordering[K], ctag: ClassTag[K]): RDD[T] =\n    this.keyBy[K](f).sortByKey(ascending, numPartitions).values</code></pre><p>　该函数最多可以传三个参数：</p>\n<p>　　第一个参数是一个函数，该函数的也有一个带T泛型的参数，返回类型和RDD中元素的类型是一致的；</p>\n<p>　　第二个参数是ascending，从字面的意思大家应该可以猜到，是的，这参数决定排序后RDD中的元素是升序还是降序，默认是true，也就是升序；</p>\n<p>　　第三个参数是numPartitions，该参数决定排序后的RDD的分区个数，默认排序后的分区个数和排序之前的个数相等，即为this.partitions.size。</p>\n<p>　　从sortBy函数的实现可以看出，第一个参数是必须传入的，而后面的两个参数可以不传入。而且sortBy函数函数的实现依赖于sortByKey函数，关于sortByKey函数后面会进行说明。</p>\n<p>   那么，如何使用sortBy函数呢？</p>\n<pre><code>scala&gt; val data = List(3,1,90,3,5,12)\ndata: List[Int] = List(3, 1, 90, 3, 5, 12)\n\nscala&gt; val rdd = sc.parallelize(data)\nrdd: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[0] at parallelize at &lt;console&gt;:14\n\nscala&gt; rdd.collect\nres0: Array[Int] = Array(3, 1, 90, 3, 5, 12)\n\nscala&gt; rdd.sortBy(x =&gt; x).collect\nres1: Array[Int] = Array(1, 3, 3, 5, 12, 90)\n\nscala&gt; rdd.sortBy(x =&gt; x, false).collect\nres3: Array[Int] = Array(90, 12, 5, 3, 3, 1)\n\nscala&gt; val result = rdd.sortBy(x =&gt; x, false)\nresult: org.apache.spark.rdd.RDD[Int] = MappedRDD[23] at sortBy at &lt;console&gt;:16\n\nscala&gt; result.partitions.size\nres9: Int = 2\n\nscala&gt; val result = rdd.sortBy(x =&gt; x, false, 1)\nresult: org.apache.spark.rdd.RDD[Int] = MappedRDD[26] at sortBy at &lt;console&gt;:16\n\nscala&gt; result.partitions.size\nres10: Int = 1</code></pre><p>上面的实例对rdd中的元素进行升序排序。并对排序后的RDD的分区个数进行了修改，上面的result就是排序后的RDD，默认的分区个数是2，而我们对它进行了修改，所以最后变成了1。</p>\n<pre><code>val data = sc.parallelize(Array((&quot;cc&quot;,12),(&quot;bb&quot;,32),(&quot;cc&quot;,22),(&quot;aa&quot;,18),(&quot;bb&quot;,16),(&quot;dd&quot;,16),(&quot;ee&quot;,54),(&quot;cc&quot;,1),(&quot;ff&quot;,13),(&quot;gg&quot;,68),(&quot;bb&quot;,4)))\nvar sortbykey=data.sortByKey(false).collect\nsortbykey.foreach(x=&gt;(println(x._1+&quot; &quot;+x._2)))</code></pre><p>结果如下</p>\n<p>测到的测试结果如上图所示，显然是根据Key进行了排序。</p>\n<p>SortBy()函数</p>\n<p>sortByKey函数作用于Key-Value形式的RDD，并对Key进行排序。它是在org.apache.spark.rdd.OrderedRDDFunctions中实现的，实现如下</p>\n<pre><code>def sortByKey(ascending: Boolean = true, numPartitions: Int = self.partitions.size)\n    : RDD[(K, V)] =\n{\n  val part = new RangePartitioner(numPartitions, self, ascending)\n  new ShuffledRDD[K, V, V](self, part)\n    .setKeyOrdering(if (ascending) ordering else ordering.reverse)\n}</code></pre><p>从函数的实现可以看出，它主要接受两个函数，含义和sortBy一样，这里就不进行解释了。该函数返回的RDD一定是ShuffledRDD类型的，因为对源RDD进行排序，必须进行Shuffle操作，而Shuffle操作的结果RDD就是ShuffledRDD。其实这个函数的实现很优雅，里面用到了RangePartitioner，它可以使得相应的范围Key数据分到同一个partition中，然后内部用到了mapPartitions对每个partition中的数据进行排序，而每个partition中数据的排序用到了标准的sort机制，避免了大量数据的shuffle。下面对sortByKey的使用进行说明：</p>\n<pre><code>scala&gt; val a = sc.parallelize(List(&quot;wyp&quot;, &quot;iteblog&quot;, &quot;com&quot;, &quot;397090770&quot;, &quot;test&quot;), 2)\na: org.apache.spark.rdd.RDD[String] =ParallelCollectionRDD[30] at parallelize at &lt;console&gt;:12\n\nscala&gt; val b = sc. parallelize (1 to a.count.toInt , 2)\nb: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[31] at parallelize at &lt;console&gt;:14\n\nscala&gt; val c = a.zip(b)\nc: org.apache.spark.rdd.RDD[(String, Int)] = ZippedPartitionsRDD2[32] at zip at &lt;console&gt;:16\n\nscala&gt; c.sortByKey().collect\nres11: Array[(String, Int)] = Array((397090770,4), (com,3), (iteblog,2), (test,5), (wyp,1))\n\n\nval data = sc.parallelize(Array((&quot;cc&quot;,12),(&quot;bb&quot;,32),(&quot;cc&quot;,22),(&quot;aa&quot;,18),(&quot;bb&quot;,16),(&quot;dd&quot;,16),(&quot;ee&quot;,54),(&quot;cc&quot;,1),(&quot;ff&quot;,13),(&quot;gg&quot;,68),(&quot;bb&quot;,4)))\nvar sort=data.reduceByKey(_+_).sortBy(_._2,false).collect()\nsort.foreach(x=&gt;(println(x._1+&quot; &quot;+x._2)))</code></pre><p>结果如下</p>\n<p> 显然，上图显示的结果是根据Value中的数据进行的排序。</p>\n<h1 id=\"海量数据算法\"><a href=\"#海量数据算法\" class=\"headerlink\" title=\"海量数据算法\"></a>海量数据算法</h1><p><strong>数据倾斜的算子</strong></p>\n<p>数据倾斜只会发生在shuffle过程中。这里给大家罗列一些常用的并且可能会触发shuffle操作的算子：distinct、groupByKey、reduceByKey、aggregateByKey、join、cogroup、repartition等。出现数据倾斜时，可能就是你的代码中使用了这些算子中的某一个所导致的。</p>\n<h2 id=\"（一）mapjoin解析\"><a href=\"#（一）mapjoin解析\" class=\"headerlink\" title=\"（一）mapjoin解析\"></a>（一）mapjoin解析</h2><p>利用hive进行join连接操作，相较于MR有两种执行方案，一种为common join，另一种为map join ，map join是相对于common join的一种优化，省去shullfe和reduce的过程，大大的降低的作业运行的时间。 </p>\n<p>select f.a,f.b from A t join B f  on ( f.a=t.a and f.ftime=20110802)  </p>\n<p>该语句中B表有30亿行记录，A表只有100行记录，而且B表中数据倾斜特别严重，有一个key上有15亿行记录，在运行过程中特别的慢，而且在reduece的过程中遇有内存不够而报错。</p>\n<p>为了解决用户的这个问题，考虑使用mapjoin,mapjoin的原理： </p>\n<blockquote>\n<p><strong>MAPJION会把小表全部读入内存中，在map阶段直接拿另外一个表的数据和内存中表数据做匹配，由于在map是进行了join操作，省去了reduce运行的效率也会高很多</strong> </p>\n</blockquote>\n<p>这样就不会由于数据倾斜导致某个reduce上落数据太多而失败。于是原来的sql可以通过使用hint的方式指定join时使用mapjoin。 </p>\n<blockquote>\n<p>select /<em>+ mapjoin(A)</em>/ f.a,f.b from A t join B f  on ( f.a=t.a and f.ftime=20110802)  </p>\n</blockquote>\n<p>再运行发现执行的效率比以前的写法高了好多。 </p>\n<p>mapjoin还有一个很大的好处是能够进行不等连接的join操作，如果将不等条件写在where中，那么mapreduce过程中会进行笛卡尔积，运行效率特别低，如果使用mapjoin操作，在map的过程中就完成了不等值的join操作，效率会高很多。 </p>\n<p>例子： </p>\n<p>select A.a ,A.b from A join B where A.a&gt;B.a </p>\n<p><strong>简单总结一下，mapjoin的使用场景：</strong></p>\n<p>1.关联操作中有一张表非常小</p>\n<p> 2.不等值的链接操作</p>\n<p> <strong>MapJoin原理</strong></p>\n<p><img src=\"C:%5CUsers%5CAdministrator%5CDesktop%5CMd%E7%AC%94%E8%AE%B0%5Cpic%5C1565833762509.png\" alt=\"1565833762509\"></p>\n<p>MapJoin简单说就是在Map阶段将小表读入内存，顺序扫描大表完成Join。</p>\n<p>上图是Hive MapJoin的原理图，出自Facebook工程师Liyin Tang的一篇介绍Join优化的slice，从图中可以看出MapJoin分为两个阶段：</p>\n<ol>\n<li>通过MapReduce Local Task，将小表读入内存，生成HashTableFiles上传至Distributed Cache中，这里会对HashTableFiles进行压缩。</li>\n<li>MapReduce Job在Map阶段，每个Mapper从Distributed Cache读取HashTableFiles到内存中，顺序扫描大表，在Map阶段直接进行Join，将数据传递给下一个MapReduce任务。</li>\n</ol>\n<h2 id=\"（二）美团网的spark调优\"><a href=\"#（二）美团网的spark调优\" class=\"headerlink\" title=\"（二）美团网的spark调优\"></a>（二）美团网的spark调优</h2><p>基础版  <a href=\"https://tech.meituan.com/2016/04/29/spark-tuning-basic.html\" target=\"_blank\" rel=\"noopener\">https://tech.meituan.com/2016/04/29/spark-tuning-basic.html</a></p>\n<p>高级版  <a href=\"https://tech.meituan.com/2016/05/12/spark-tuning-pro.html\" target=\"_blank\" rel=\"noopener\">https://tech.meituan.com/2016/05/12/spark-tuning-pro.html</a></p>\n<h2 id=\"（三）-两阶段聚合（局部聚合-全局聚合）\"><a href=\"#（三）-两阶段聚合（局部聚合-全局聚合）\" class=\"headerlink\" title=\"（三） 两阶段聚合（局部聚合+全局聚合）\"></a>（三） 两阶段聚合（局部聚合+全局聚合）</h2><p><strong>方案适用场景：</strong>对RDD执行reduceByKey等聚合类shuffle算子或者在Spark SQL中使用group by语句进行分组聚合时，比较适用这种方案。</p>\n<p><strong>方案实现思路：</strong>这个方案的核心实现思路就是进行两阶段聚合。第一次是局部聚合，先给每个key都打上一个随机数，比如10以内的随机数，此时原先一样的key就变成不一样的了，比如(hello, 1) (hello, 1) (hello, 1) (hello, 1)，就会变成(1_hello, 1) (1_hello, 1) (2_hello, 1) (2_hello, 1)。接着对打上随机数后的数据，执行reduceByKey等聚合操作，进行局部聚合，那么局部聚合结果，就会变成了(1_hello, 2) (2_hello, 2)。然后将各个key的前缀给去掉，就会变成(hello,2)(hello,2)，再次进行全局聚合操作，就可以得到最终结果了，比如(hello, 4)。</p>\n<p><strong>方案实现原理：</strong>将原本相同的key通过附加随机前缀的方式，变成多个不同的key，就可以让原本被一个task处理的数据分散到多个task上去做局部聚合，进而解决单个task处理数据量过多的问题。接着去除掉随机前缀，再次进行全局聚合，就可以得到最终的结果。具体原理见下图。</p>\n<p><strong>方案优点：</strong>对于聚合类的shuffle操作导致的数据倾斜，效果是非常不错的。通常都可以解决掉数据倾斜，或者至少是大幅度缓解数据倾斜，将Spark作业的性能提升数倍以上。</p>\n<p><strong>方案缺点：</strong>仅仅适用于聚合类的shuffle操作，适用范围相对较窄。如果是join类的shuffle操作，还得用其他的解决方案。</p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"ck061x92o0000qgui7uvel78b","category_id":"ck061x9340004qguiqk4d6f1w","_id":"ck061x93o000eqgui37gka07k"},{"post_id":"ck061x92y0002qgui87xymnjg","category_id":"ck061x9340004qguiqk4d6f1w","_id":"ck061x93q000hqguifudx96uy"},{"post_id":"ck061x93b0006qguitddj6tic","category_id":"ck061x93n000dqguiz62pfdwu","_id":"ck061x93r000kqguic5fa6s58"},{"post_id":"ck061x93g0008qguilc7gicfc","category_id":"ck061x93r000jqguis9a14jxg","_id":"ck061x93t000nqguix9tj6lvl"},{"post_id":"ck061x93i0009qguiy7xacan4","category_id":"ck061x93s000mqguiotd4p4yo","_id":"ck061x93w000rqguij7qqd2im"},{"post_id":"ck061x94u000wqguiycpxkpaj","category_id":"ck061x94w000xqguimrm123rt","_id":"ck061x94y0010qguia576iiw3"},{"post_id":"ck061x9520011qguiu9gjn7hd","category_id":"ck061x93s000mqguiotd4p4yo","_id":"ck061x9560013qguib6mfau7e"}],"PostTag":[{"post_id":"ck061x92o0000qgui7uvel78b","tag_id":"ck061x93a0005qgui4fhwy2zf","_id":"ck061x93n000cqgui6ki0jbkx"},{"post_id":"ck061x92y0002qgui87xymnjg","tag_id":"ck061x93a0005qgui4fhwy2zf","_id":"ck061x93p000gqgui8hsbj2wf"},{"post_id":"ck061x93b0006qguitddj6tic","tag_id":"ck061x93a0005qgui4fhwy2zf","_id":"ck061x93u000pqguiley46sh8"},{"post_id":"ck061x93b0006qguitddj6tic","tag_id":"ck061x93q000iqguisedyjpvc","_id":"ck061x93v000qqguitpw27x59"},{"post_id":"ck061x93b0006qguitddj6tic","tag_id":"ck061x93s000lqgui5ve872bl","_id":"ck061x93y000tqguirj5rrqrb"},{"post_id":"ck061x93g0008qguilc7gicfc","tag_id":"ck061x93t000oqguioj4nphrl","_id":"ck061x93y000uqguikz7s6woo"},{"post_id":"ck061x93i0009qguiy7xacan4","tag_id":"ck061x93w000sqgui2ouvvamg","_id":"ck061x941000vqguiz1iwjxbm"},{"post_id":"ck061x94u000wqguiycpxkpaj","tag_id":"ck061x94w000yqgui1b54xk1u","_id":"ck061x94y000zqgui4y89jj0f"},{"post_id":"ck061x9520011qguiu9gjn7hd","tag_id":"ck061x93w000sqgui2ouvvamg","_id":"ck061x9550012qgui8kkyj10d"}],"Tag":[{"name":"hexo","_id":"ck061x93a0005qgui4fhwy2zf"},{"name":"typora","_id":"ck061x93q000iqguisedyjpvc"},{"name":"picgo","_id":"ck061x93s000lqgui5ve872bl"},{"name":"工具","_id":"ck061x93t000oqguioj4nphrl"},{"name":"汇总","_id":"ck061x93w000sqgui2ouvvamg"},{"name":"activiti","_id":"ck061x94w000yqgui1b54xk1u"}]}}
